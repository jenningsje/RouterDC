{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/chensh/miniconda3/envs/vllm/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from openTSNE import TSNE\n",
    "import torch\n",
    "\n",
    "from train_supervised import RouterDataset, RouterModule\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from transformers import T5EncoderModel, T5Tokenizer, AutoTokenizer, DebertaV2Model\n",
    "\n",
    "dataset_paths = [\"../../datasets/split2_model7/mmlu_test.json\", \"../../datasets/split2_model7/gsm8k-test.json\", \"../../datasets/split2_model7/cmmlu_test.json\",\"../../datasets/split2_model7/arc_challenge_test.json\", \"../../datasets/split2_model7/humaneval_test.json\", \"../../datasets/split2_model7/MATH_prealgebra.json\", \"../../datasets/split2_model7/mbpp.json\", \"../../datasets/split2_model7/ceval.json\"]\n",
    "data_types = [\"probability\", \"multi_attempt\",  \"probability\",  \"probability\" ,\"multi_attempt\", \"multi_attempt\", \"multi_attempt\", \"probability\"]\n",
    "device=\"cuda\"\n",
    "\n",
    "trained_router_path = \"/data/home/chensh/projects/LLM_router/logs/paper_result/supervised/dot_lr_5e-5_step_1000_t_1_seed_5/best_training_model.pth\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/home/chensh/data/huggingface_model/microsoft/mdeberta-v3-base\", truncation_side='left', padding=True)\n",
    "encoder_model = DebertaV2Model.from_pretrained(\"/data/home/chensh/data/huggingface_model/microsoft/mdeberta-v3-base\").to(\"cuda\")\n",
    "\n",
    "router_model = RouterModule(encoder_model, hidden_state_dim=768, node_size=7, similarity_function=\"dot\").to(device)\n",
    "\n",
    "state_dict = torch.load(trained_router_path)\n",
    "router_model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "\n",
    "def count_tensor_elements(tensor):\n",
    "    # 将张量展平为一维数组\n",
    "    flattened_tensor = tensor.view(-1).tolist()\n",
    "\n",
    "    # 使用Counter统计元素出现次数\n",
    "    element_counts = Counter(flattened_tensor)\n",
    "\n",
    "    return element_counts\n",
    "\n",
    "def evaluation(router_model, dataset_paths, dataset_types, tokenizer, batch_size, device): \n",
    "    all_counts = {key:0 for key in range(router_model.node_size)}   \n",
    "    result = {}\n",
    "    with torch.no_grad():\n",
    "        assert len(dataset_paths) == len(dataset_types)\n",
    "        for index, data_path in enumerate(dataset_paths):\n",
    "            print(data_path)\n",
    "            test_dataset = RouterDataset(data_path=data_path)\n",
    "            test_dataset.register_tokenizer(tokenizer)\n",
    "            data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            correct_predict = 0\n",
    "            correct = 0\n",
    "            for batch in data_loader:\n",
    "                inputs, scores, _, _ = batch\n",
    "                inputs = inputs.to(device)\n",
    "                scores = scores.to(device)\n",
    "                x, _ = router_model.forward(**inputs)\n",
    "                softmax_x = nn.Softmax(dim=1)(x)\n",
    "                _, max_index = torch.max(softmax_x, dim=1)\n",
    "                _, target_max_index = torch.max(scores, dim=1)\n",
    "\n",
    "                counts = count_tensor_elements(max_index)\n",
    "                for element, count in counts.items():\n",
    "                    all_counts[element] += count\n",
    "\n",
    "                equals = max_index.eq(target_max_index)\n",
    "                correct += equals.sum().item()\n",
    "\n",
    "                if dataset_types[index] == \"probability\":\n",
    "                    mask = torch.zeros_like(scores)\n",
    "                    mask = mask.scatter_(1, max_index.unsqueeze(1), 1)\n",
    "                    scores[scores > 0] = 1\n",
    "                    correct_predict += (scores * mask).sum().item()\n",
    "                elif dataset_types[index] == \"multi_attempt\":\n",
    "                    mask = torch.zeros_like(scores)\n",
    "                    mask = mask.scatter_(1, max_index.unsqueeze(1), 1)\n",
    "                    correct_predict += (scores * mask).sum().item()\n",
    "\n",
    "            acc_predict = correct_predict/len(test_dataset)\n",
    "            acc = correct/len(test_dataset)\n",
    "            print(f\"acc_{data_path}:\", acc_predict)\n",
    "            print(\"acc\", acc)\n",
    "            result[data_path] = [acc, acc_predict]\n",
    "    return result, all_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../../datasets/split2_model7/mmlu_test.json\n",
      "acc_../../datasets/split2_model7/mmlu_test.json: 0.6047946831236648\n",
      "acc 0.22193211488250653\n",
      "../../datasets/split2_model7/gsm8k-test.json\n",
      "acc_../../datasets/split2_model7/gsm8k-test.json: 0.6668688403195373\n",
      "acc 0.27824109173616374\n",
      "../../datasets/split2_model7/cmmlu_test.json\n",
      "acc_../../datasets/split2_model7/cmmlu_test.json: 0.45266187050359713\n",
      "acc 0.2489208633093525\n",
      "../../datasets/split2_model7/arc_challenge_test.json\n",
      "acc_../../datasets/split2_model7/arc_challenge_test.json: 0.53125\n",
      "acc 0.20738636363636365\n",
      "../../datasets/split2_model7/humaneval_test.json\n",
      "acc_../../datasets/split2_model7/humaneval_test.json: 0.44285711950185347\n",
      "acc 0.2857142857142857\n",
      "../../datasets/split2_model7/MATH_prealgebra.json\n",
      "acc_../../datasets/split2_model7/MATH_prealgebra.json: 0.34443168771526983\n",
      "acc 0.09873708381171067\n",
      "../../datasets/split2_model7/mbpp.json\n",
      "acc_../../datasets/split2_model7/mbpp.json: 0.4110000057220459\n",
      "acc 0.254\n",
      "../../datasets/split2_model7/ceval.json\n",
      "acc_../../datasets/split2_model7/ceval.json: 0.44947994056463597\n",
      "acc 0.23699851411589895\n"
     ]
    }
   ],
   "source": [
    "all_acount_list = []\n",
    "for i in range(len(dataset_paths)):\n",
    "   result, acount = evaluation(router_model, [dataset_paths[i]], [data_types[i]], tokenizer, 32, device)\n",
    "   all_acount_list.append(acount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.16 0.02 0.13 0.25 0.2  0.06 0.44 0.06]\n",
      " [0.02 0.39 0.   0.02 0.   0.18 0.01 0.  ]\n",
      " [0.32 0.01 0.45 0.38 0.06 0.09 0.06 0.54]\n",
      " [0.03 0.02 0.08 0.04 0.02 0.02 0.   0.07]\n",
      " [0.12 0.04 0.05 0.14 0.37 0.16 0.   0.14]\n",
      " [0.14 0.04 0.08 0.09 0.02 0.09 0.03 0.07]\n",
      " [0.21 0.49 0.2  0.09 0.33 0.39 0.46 0.11]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "distribution_matrix = np.array( [list(dict_item.values()) for dict_item in all_acount_list])\n",
    "distribution_matrix = distribution_matrix / np.sum(distribution_matrix, axis=1, keepdims=True)\n",
    "distribution_matrix = np.around(distribution_matrix, 2) \n",
    "distribution_matrix = distribution_matrix.T\n",
    "distribution_matrix[[2,3]] = distribution_matrix[[3,2]]\n",
    "print(distribution_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16, 0.02, 0.13, 0.25, 0.2 , 0.06, 0.44, 0.06],\n",
       "       [0.02, 0.39, 0.  , 0.02, 0.  , 0.18, 0.01, 0.  ],\n",
       "       [0.32, 0.01, 0.45, 0.38, 0.06, 0.09, 0.06, 0.54],\n",
       "       [0.03, 0.02, 0.08, 0.04, 0.02, 0.02, 0.  , 0.07],\n",
       "       [0.12, 0.04, 0.05, 0.14, 0.37, 0.16, 0.  , 0.14],\n",
       "       [0.14, 0.04, 0.08, 0.09, 0.02, 0.09, 0.03, 0.07],\n",
       "       [0.21, 0.49, 0.2 , 0.09, 0.33, 0.39, 0.46, 0.11]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1250.01, 605.7099999999999, 3061.8000000000006, 445.83, 799.48, 953.24, 2273.89]\n",
      "[0.13312197 0.06450613 0.32607168 0.04747944 0.085142   0.10151694\n",
      " 0.24216184]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "386.7232619909813"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "data_len_list = []\n",
    "for file_path in dataset_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data_list = json.load(f)\n",
    "        data_len_list.append(len(data_list))\n",
    "\n",
    "all_sample_distribution = [0, 0, 0, 0, 0, 0, 0]\n",
    "for j, per_model_distribution in enumerate(distribution_matrix):\n",
    "    for i in range(5):\n",
    "        all_sample_distribution[j] += per_model_distribution[i] * data_len_list[i]\n",
    "\n",
    "print(all_sample_distribution)\n",
    "all_sample_distribution = np.array(all_sample_distribution)\n",
    "all_sample_distribution = all_sample_distribution / np.sum(all_sample_distribution) \n",
    "print(all_sample_distribution)\n",
    "\n",
    "np.sum( all_sample_distribution * np.array([416.4469283, 433.7455524, 404.0106289, 426.7654369, 414.8200222, 379.9586915, 319.6867065]))\n",
    "\n",
    "\n",
    "# np.sum( all_sample_distribution * np.array([258.8383127, 247.6017654, 257.8926255, 263.7625816, 192.1132418, 236.866828, 188.8286372]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/chensh/miniconda3/envs/vllm/lib/python3.9/site-packages/transformers/convert_slow_tokenizer.py:550: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"../..\")\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "from openTSNE import TSNE\n",
    "import torch\n",
    "\n",
    "from train_lora_retriever import RouterDataset, RouterModule\n",
    "from torch.utils.data import Dataset, DataLoader, ConcatDataset\n",
    "from transformers import T5EncoderModel, T5Tokenizer, AutoTokenizer, DebertaV2Model\n",
    "\n",
    "dataset_paths = [\"../../datasets/split2_model7/mmlu_test.json\", \"../../datasets/split2_model7/gsm8k-test.json\", \"../../datasets/split2_model7/cmmlu_test.json\",\"../../datasets/split2_model7/arc_challenge_test.json\", \"../../datasets/split2_model7/humaneval_test.json\", \"../../datasets/split2_model7/MATH_prealgebra.json\", \"../../datasets/split2_model7/mbpp.json\", \"../../datasets/split2_model7/ceval.json\"]\n",
    "data_types = [\"probability\", \"multi_attempt\",  \"probability\",  \"probability\" ,\"multi_attempt\", \"multi_attempt\", \"multi_attempt\", \"probability\"]\n",
    "device=\"cuda\"\n",
    "\n",
    "trained_router_path = \"/data/home/chensh/projects/LLM_router/logs/lora_retriever/lr_5e-5_step_1000_t_1_seed_0/best_training_model.pth\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"/data/home/chensh/data/huggingface_model/microsoft/mdeberta-v3-base\", truncation_side='left', padding=True)\n",
    "encoder_model = DebertaV2Model.from_pretrained(\"/data/home/chensh/data/huggingface_model/microsoft/mdeberta-v3-base\").to(\"cuda\")\n",
    "\n",
    "router_model = RouterModule(encoder_model, hidden_state_dim=768, node_size=7, similarity_function=\"cos\").to(device)\n",
    "\n",
    "state_dict = torch.load(trained_router_path)\n",
    "router_model.load_state_dict(state_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from collections import Counter\n",
    "\n",
    "def count_tensor_elements(tensor):\n",
    "    # 将张量展平为一维数组\n",
    "    flattened_tensor = tensor.view(-1).tolist()\n",
    "\n",
    "    # 使用Counter统计元素出现次数\n",
    "    element_counts = Counter(flattened_tensor)\n",
    "\n",
    "    return element_counts\n",
    "\n",
    "def evaluation(router_model, dataset_paths, dataset_types, tokenizer, batch_size, device, ref_data_path, cluster_model_map):   \n",
    "    # get the embedding of each cluster\n",
    "    all_counts = {key:0 for key in range(router_model.node_size)}   \n",
    "    result = {}\n",
    "    with torch.no_grad():\n",
    "        # get the embeddings for each cluster\n",
    "        cluster_embeddings = []\n",
    "        for index, data_path in enumerate(ref_data_path):\n",
    "            test_dataset = RouterDataset(data_path=data_path)\n",
    "            test_dataset.register_tokenizer(tokenizer)\n",
    "            data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            temp_embeddings = []\n",
    "            for i, batch in enumerate(data_loader):\n",
    "                if i > 5:\n",
    "                    break\n",
    "                inputs, scores, _, _ = batch\n",
    "                inputs = inputs.to(device)\n",
    "                scores = scores.to(device)\n",
    "                _, hidden_state = router_model.forward(**inputs)\n",
    "                temp_embeddings.append(hidden_state)\n",
    "            temp_embeddings = torch.concat(temp_embeddings, dim=0)\n",
    "            cluster_embedding = torch.mean(temp_embeddings, dim=0)\n",
    "            cluster_embeddings.append(cluster_embedding)\n",
    "        cluster_embeddings = torch.stack(cluster_embeddings)\n",
    "\n",
    "        assert len(dataset_paths) == len(dataset_types)\n",
    "        for index, data_path in enumerate(dataset_paths):\n",
    "            test_dataset = RouterDataset(data_path=data_path)\n",
    "            test_dataset.register_tokenizer(tokenizer)\n",
    "            data_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "            correct_predict = 0\n",
    "            correct = 0\n",
    "            for batch in data_loader:\n",
    "                inputs, scores, _, _ = batch\n",
    "                inputs = inputs.to(device)\n",
    "                scores = scores.to(device)\n",
    "                _, hidden_state = router_model.forward(**inputs)\n",
    "                x = router_model.compute_similarity(hidden_state, cluster_embeddings)\n",
    "                softmax_x = nn.Softmax(dim=1)(x)\n",
    "                _, max_index = torch.max(softmax_x, dim=1)\n",
    "                \n",
    "                cluster_model_map = torch.tensor(cluster_model_map).type_as(max_index)\n",
    "                maped_max_index = torch.gather(cluster_model_map, dim=0, index=max_index)\n",
    "                \n",
    "                counts = count_tensor_elements(maped_max_index)\n",
    "                for element, count in counts.items():\n",
    "                    all_counts[element] += count\n",
    "\n",
    "                _, target_max_index = torch.max(scores, dim=1)\n",
    "                equals = maped_max_index.eq(target_max_index)\n",
    "                correct += equals.sum().item()\n",
    "\n",
    "                if dataset_types[index] == \"probability\":\n",
    "                    mask = torch.zeros_like(scores)\n",
    "                    mask = mask.scatter_(1, maped_max_index.unsqueeze(1), 1)\n",
    "                    scores[scores > 0] = 1\n",
    "                    correct_predict += (scores * mask).sum().item()\n",
    "                elif dataset_types[index] == \"multi_attempt\":\n",
    "                    mask = torch.zeros_like(scores)\n",
    "                    mask = mask.scatter_(1, maped_max_index.unsqueeze(1), 1)\n",
    "                    correct_predict += (scores * mask).sum().item()\n",
    "\n",
    "            acc_predict = correct_predict/len(test_dataset)\n",
    "            acc = correct/len(test_dataset)\n",
    "            print(f\"acc_{data_path}:\", acc_predict)\n",
    "            print(\"acc\", acc)\n",
    "            result[data_path] = [acc, acc_predict]\n",
    "    return result, all_counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_259578/3926884117.py:54: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  cluster_model_map = torch.tensor(cluster_model_map).type_as(max_index)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc_../../datasets/split2_model7/mmlu_test.json: 0.6347021125089011\n",
      "acc 0.04984571564206029\n",
      "acc_../../datasets/split2_model7/gsm8k-test.json: 0.6862016656888625\n",
      "acc 0.1425322213798332\n",
      "acc_../../datasets/split2_model7/cmmlu_test.json: 0.5176978417266187\n",
      "acc 0.07942446043165467\n",
      "acc_../../datasets/split2_model7/arc_challenge_test.json: 0.5767045454545454\n",
      "acc 0.2840909090909091\n",
      "acc_../../datasets/split2_model7/humaneval_test.json: 0.4489795918367347\n",
      "acc 0.22448979591836735\n",
      "acc_../../datasets/split2_model7/MATH_prealgebra.json: 0.35017221584385766\n",
      "acc 0.04477611940298507\n",
      "acc_../../datasets/split2_model7/mbpp.json: 0.4300000019073486\n",
      "acc 0.088\n",
      "acc_../../datasets/split2_model7/ceval.json: 0.5200594353640416\n",
      "acc 0.07800891530460624\n"
     ]
    }
   ],
   "source": [
    "all_acount_list = []\n",
    "for i in range(len(dataset_paths)):\n",
    "   result, acount = evaluation(router_model, [dataset_paths[i]], [data_types[i]], tokenizer, 32, device, cluster_model_map = [3, 6, 5, 5, 4], ref_data_path=[\"../../datasets/lora_retriever/cluster_0.json\",\"../../datasets/lora_retriever/cluster_1.json\", \"../../datasets/lora_retriever/cluster_2.json\", \"../../datasets/lora_retriever/cluster_3.json\",\"../../datasets/lora_retriever/cluster_4.json\",])\n",
    "   all_acount_list.append(acount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.   0.   0.   0.98 0.   0.01 0.   0.  ]\n",
      " [0.   0.   0.   0.   0.   0.   0.   0.  ]\n",
      " [0.28 0.05 0.   0.02 0.88 0.13 0.03 0.  ]\n",
      " [0.72 0.   1.   0.   0.12 0.29 0.97 1.  ]\n",
      " [0.   0.95 0.   0.   0.   0.58 0.   0.  ]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "distribution_matrix2 = np.array( [list(dict_item.values()) for dict_item in all_acount_list])\n",
    "distribution_matrix2 = distribution_matrix2 / np.sum(distribution_matrix2, axis=1, keepdims=True)\n",
    "distribution_matrix2 = np.around(distribution_matrix2, 2) \n",
    "distribution_matrix2 = distribution_matrix2.T\n",
    "distribution_matrix2[[2,3]] = distribution_matrix2[[3,2]]\n",
    "print(distribution_matrix2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 8.71, 0.0, 128.23000000000002, 2083.59, 505.17999999999995]\n",
      "[0.         0.         0.0031955  0.         0.04704462 0.76442101\n",
      " 0.18533887]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "225.9252564863228"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "import json\n",
    "\n",
    "data_len_list = []\n",
    "for file_path in dataset_paths:\n",
    "    with open(file_path, 'r') as f:\n",
    "        data_list = json.load(f)\n",
    "        data_len_list.append(len(data_list))\n",
    "\n",
    "all_sample_distribution = [0, 0, 0, 0, 0, 0, 0]\n",
    "for j, per_model_distribution in enumerate(distribution_matrix2):\n",
    "    for i in range(5, 8):\n",
    "        all_sample_distribution[j] += per_model_distribution[i] * data_len_list[i]\n",
    "\n",
    "print(all_sample_distribution)\n",
    "all_sample_distribution = np.array(all_sample_distribution)\n",
    "all_sample_distribution = all_sample_distribution / np.sum(all_sample_distribution) \n",
    "print(all_sample_distribution)\n",
    "\n",
    "# np.sum( all_sample_distribution * np.array([416.4469283, 433.7455524, 404.0106289, 426.7654369, 414.8200222, 379.9586915, 319.6867065]))\n",
    "\n",
    "np.sum( all_sample_distribution * np.array([258.8383127, 247.6017654, 257.8926255, 263.7625816, 192.1132418, 236.866828, 188.8286372]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
