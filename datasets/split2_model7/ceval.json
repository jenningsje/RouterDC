[{"question": "\u4f7f\u7528\u4f4d\u586b\u5145\u65b9\u6cd5\uff0c\u4ee501111110\u4e3a\u4f4d\u9996flag\uff0c\u6570\u636e\u4e3a011011111111111111110010\uff0c\u6c42\u95ee\u4f20\u9001\u65f6\u8981\u6dfb\u52a0\u51e0\u4e2a0____\nA. 1\nB. 2\nC. 3\nD. 4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.31408067417579427, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.33065623127838456, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.333183235354062, "meta-llama/Meta-Llama-3-8B": 0.30601362565976303, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.39258743618895164}}, {"question": "\u5728802.3\u6807\u51c6\u4e2d\uff0c\u53d1\u9001\u5e27\u4e4b\u524d\u9700\u8981____\nA. \u7b49\u5f85\u51b2\u7a81\nB. \u7b49\u5f85\u4ee4\u724c\nC. \u76d1\u542c\u4ecb\u8d28\nD. \u63a5\u53d7\u4e00\u4e2a\u5e27\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6343344073698344, "meta-math/MetaMath-Mistral-7B": 0.6988825122514638, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9973435942024261, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6070076475339087, "meta-llama/Meta-Llama-3-8B": 0.9554828782603846, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8603483743589195}}, {"question": "TCP\u7aef\u5bf9\u7aef\u901a\u4fe1\u4f5c\u7528\u4e8e____\nA. \u4e3b\u673a\u4e4b\u95f4\nB. \u7f51\u7edc\u4e4b\u95f4\nC. \u8fdb\u7a0b\u4e4b\u95f4\nD. \u4e3b\u673a\u5230\u7f51\u7edc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9219775748023132, "meta-math/MetaMath-Mistral-7B": 0.9940929992423175, "itpossible/Chinese-Mistral-7B-v0.1": 0.40101791712441026, "HuggingFaceH4/zephyr-7b-beta": 0.9994525463161874, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9616845928854485, "meta-llama/Meta-Llama-3-8B": 0.9394690063325226, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9377878073494383}}, {"question": "\u5bf9\u4e8e\u4f20\u8f93\u5c42\u6765\u8bf4\u9519\u8bef\u7684\u662f____\nA. TCP\u662f\u5168\u53cc\u5de5\u534f\u8bae\nB. TCP\u662f\u5b57\u8282\u6d41\u534f\u8bae\nC. TCP\u548cUDP\u534f\u8bae\u4e0d\u80fd\u4f7f\u7528\u540c\u4e00\u4e2a\u7aef\u53e3\nD. TSAD\u662fIP\u548c\u7aef\u53e3\u7684\u7ec4\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6443063634800414, "meta-math/MetaMath-Mistral-7B": 0.7911057872239488, "itpossible/Chinese-Mistral-7B-v0.1": 0.5198773582716864, "HuggingFaceH4/zephyr-7b-beta": 0.9995197338342788, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8832720596851603, "meta-llama/Meta-Llama-3-8B": 0.7151900926679302, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6412632247335176}}, {"question": "\u5df2\u77e5\u5f53\u524dTCP\u8fde\u63a5\u7684RTT\u503c\u4e3a35ms\uff0c\u8fde\u7eed\u6536\u52303\u4e2a\u786e\u8ba4\u62a5\u6587\u6bb5\uff0c\u5b83\u4eec\u6bd4\u76f8\u5e94\u7684\u6570\u636e\u62a5\u6587\u6bb5\u7684\u53d1\u9001\u65f6\u95f4\u6ede\u540e\u4e8627ms\u300130ms\u4e0e21ms\u3002\u5047\u8bbe\u03b1=0.2\uff0c\u5219\u7b2c\u4e09\u4e2a\u786e\u8ba4\u62a5\u6587\u6bb5\u5230\u8fbe\u540e\u65b0\u7684RTT\u4f30\u8ba1\u503c\u4e3a____\u3002\nA. 33.4ms\nB. 32.7ms\nC. 21ms\nD. 30.4ms\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8eUDP\u534f\u8bae\uff0c\u5982\u679c\u60f3\u5b9e\u73b0\u53ef\u9760\u4f20\u8f93\uff0c\u5e94\u5728\u54ea\u4e00\u5c42\u5b9e\u73b0____\nA. \u6570\u636e\u94fe\u8def\u5c42\nB. \u7f51\u7edc\u5c42\nC. \u4f20\u8f93\u5c42\nD. \u5e94\u7528\u5c42\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5619461367241481, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6216271621403, "meta-llama/Meta-Llama-3-8B": 0.5107356955961669, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6570\u636e\u94fe\u8def\u5c42\u91c7\u7528\u4e86\u540e\u9000N\u5e27\u7684(GBN)\u534f\u8bae\uff0c\u5982\u679c\u53d1\u9001\u7a97\u53e3\u7684\u5927\u5c0f\u662f32\uff0c\u90a3\u4e48\u81f3\u5c11\u9700\u8981____\u4f4d\u7684\u5e8f\u5217\u53f7\u624d\u80fd\u4fdd\u8bc1\u534f\u8bae\u4e0d\u51fa\u9519\u3002\nA. 4\nB. 5\nC. 6\nD. 7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3318363651291731, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.38989529574667126, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.35686329776860143, "meta-llama/Meta-Llama-3-8B": 0.29633329997703484, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "TCP\u201c\u4e09\u6b21\u63e1\u624b\u201d\u8fc7\u7a0b\u4e2d\uff0c\u7b2c\u4e8c\u6b21\u201c\u63e1\u624b\u201d\u65f6\uff0c\u53d1\u9001\u7684\u62a5\u6587\u6bb5\u4e2d____\u6807\u5fd7\u4f4d\u88ab\u7f6e\u4e3a1\u3002\nA. SYN\nB. ACK\nC. ACK\u548cRST\nD. SYN\u548cACK\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7640675151302312, "meta-math/MetaMath-Mistral-7B": 0.8265283636763091, "itpossible/Chinese-Mistral-7B-v0.1": 0.6743619461927896, "HuggingFaceH4/zephyr-7b-beta": 0.9976296414792357, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9091289935358218, "meta-llama/Meta-Llama-3-8B": 0.8000276092882203, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5461997469278145}}, {"question": "\u4e00\u4e2aTCP\u8fde\u63a5\u7684\u6570\u636e\u4f20\u8f93\u9636\u6bb5\uff0c\u5982\u679c\u53d1\u9001\u7aef\u7684\u53d1\u9001\u7a97\u53e3\u503c\u75312000\u53d8\u4e3a3000\uff0c\u610f\u5473\u7740\u53d1\u9001\u7aef\u53ef\u4ee5____\u3002\nA. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90013000\u4e2aTCP\u62a5\u6587\u6bb5\nB. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90011000B\nC. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90013000B\nD. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90012000\u4e2aTCP\u62a5\u6587\u6bb5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5275319573282355, "meta-math/MetaMath-Mistral-7B": 0.8947400906214701, "itpossible/Chinese-Mistral-7B-v0.1": 0.525722406449243, "HuggingFaceH4/zephyr-7b-beta": 0.7453089664130458, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8448861299111856, "meta-llama/Meta-Llama-3-8B": 0.5620893804325239, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u4f20\u8f93\u5c42\u7684\u9762\u5411\u8fde\u63a5\u670d\u52a1\u7684\u7279\u6027\u662f____\u3002\nA. \u65e2\u4e0d\u4fdd\u8bc1\u53ef\u9760\uff0c\u4e5f\u4e0d\u4fdd\u8bc1\u6309\u5e8f\u4ea4\u4ed8\nB. \u4e0d\u4fdd\u8bc1\u53ef\u9760\uff0c\u4f46\u4fdd\u8bc1\u6309\u5e8f\u4ea4\u4ed8\nC. \u4fdd\u8bc1\u53ef\u9760\uff0c\u4f46\u4e0d\u4fdd\u8bc1\u6309\u5e8f\u4ea4\u4ed8\nD. \u65e2\u4fdd\u8bc1\u53ef\u9760\uff0c\u4e5f\u4fdd\u8bc1\u6309\u5e8f\u4ea4\u4ed8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7859792107650851, "meta-math/MetaMath-Mistral-7B": 0.792815706431993, "itpossible/Chinese-Mistral-7B-v0.1": 0.7881070443267376, "HuggingFaceH4/zephyr-7b-beta": 0.9999193339144774, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8695741640030493, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u91c7\u7528\u94fe\u8def\u72b6\u6001\u7b97\u6cd5\nA. RIP\nB. OSPF\nC. BGP-4\nD. EGP\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9288615288128657, "meta-math/MetaMath-Mistral-7B": 0.9968306452871523, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9995480751589997, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9690890110965346, "meta-llama/Meta-Llama-3-8B": 0.9675851326285089, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8436446953847554}}, {"question": "\u4e00\u4e2aTCP\u8fde\u63a5\u7684\u6570\u636e\u4f20\u8f93\u9636\u6bb5\uff0c\u5982\u679c\u53d1\u9001\u7aef\u7684\u53d1\u9001\u7a97\u53e3\u503c\u75312000\u53d8\u4e3a3000\uff0c\u610f\u5473\u7740\u53d1\u9001\u7aef\u53ef\u4ee5____\u3002\nA. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90013000\u4e2aTCP\u62a5\u6587\u6bb5\nB. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90011000\u5b57\u8282\nC. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90013000\u5b57\u8282\nD. \u5728\u6536\u5230\u4e00\u4e2a\u786e\u8ba4\u4e4b\u524d\u53ef\u4ee5\u53d1\u90012000\u4e2aTCP\u62a5\u6587\u6bb5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5947184773767836, "meta-math/MetaMath-Mistral-7B": 0.9469035799263701, "itpossible/Chinese-Mistral-7B-v0.1": 0.431033945941338, "HuggingFaceH4/zephyr-7b-beta": 0.9697670423575951, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7542432428372222, "meta-llama/Meta-Llama-3-8B": 0.5486567472042243, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u4ea4\u6362\u6280\u672f\u53d9\u8ff0\u9519\u8bef\u7684\u662f____\nA. \u7535\u8def\u4ea4\u6362\u5728\u53d1\u9001\u4e0e\u63a5\u6536\u65b9\u7684\u7269\u7406\u94fe\u8def\u4e0a\u9884\u7559\u5e26\u5bbd\nB. \u6570\u636e\u62a5\u4ea4\u6362\u53ef\u80fd\u51fa\u73b0\u5206\u7ec4\u4e71\u5e8f\nC. \u6570\u636e\u62a5\u4ea4\u6362\u53ef\u80fd\u51fa\u73b0\u5206\u7ec4\u4e71\u5e8f\nD. \u62a5\u6587\u4ea4\u6362\u8981\u6c42\u6709\u8f83\u5927\u7f13\u5b58\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3460058095032025, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u73b0\u5728\u5927\u91cf\u7684\u8ba1\u7b97\u673a\u662f\u901a\u8fc7\u8bf8\u5982\u4ee5\u592a\u7f51\u8fd9\u6837\u7684\u5c40\u57df\u7f51\u8fde\u5165\u5e7f\u57df\u7f51\u7684\uff0c\u800c\u5c40\u57df\u7f51\u4e0e\u5e7f\u57df\u7f51\u7684\u4e92\u8054\u662f\u901a\u8fc7____\u5b9e\u73b0\u7684\u3002\nA. \u8def\u7531\u5668\nB. \u8d44\u6e90\u5b50\u7f51\nC. \u6865\u63a5\u5668\nD. \u4e2d\u7ee7\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7723793707334169, "meta-math/MetaMath-Mistral-7B": 0.9728317712275111, "itpossible/Chinese-Mistral-7B-v0.1": 0.8560370662124517, "HuggingFaceH4/zephyr-7b-beta": 0.9998168509087041, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.978980128209357, "meta-llama/Meta-Llama-3-8B": 0.9563995354195406, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7445418767760639}}, {"question": "\u5c40\u57df\u7f51\u7684\u534f\u8bae\u7ed3\u6784\u5305\u62ec____\u3002\n\u2160\uff0e\u7f51\u7edc\u5c42\u2161\uff0e\u6570\u636e\u94fe\u8def\u5c42\n\u2162\uff0e\u7269\u7406\u5c42\u2163\uff0e\u4ecb\u8d28\u8bbf\u95ee\u63a7\u5236\u5c42\nA. \u2160\u3001\u2161\u3001\u2162\nB. \u2160\u3001\u2161\u3001\u2163\nC. \u2160\u3001\u2162\u3001\u2163\nD. \u2161\u3001\u2162\u3001\u2163\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.321937374146456, "meta-math/MetaMath-Mistral-7B": 0.3589842246166939, "itpossible/Chinese-Mistral-7B-v0.1": 0.27416108226793107, "HuggingFaceH4/zephyr-7b-beta": 0.8758436177234843, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "HTTP1.0\u4e2d\uff0c\u4f20\u8f93\u4e00\u4e2a\u6587\u672c\u548c\u4e09\u4e2a\u56fe\u7247\u9700\u8981\u5efa\u7acb____\u4e2aTCP\u8fde\u63a5\nA. 2\nB. 3\nC. 4\nD. 5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3332764561785216, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3588823130168717, "meta-llama/Meta-Llama-3-8B": 0.3926712425938697, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "UDP\u62a5\u5934\u90e8\u957f\u5ea6\u4e3a____\u3002\nA. 8B\nB. 20B\nC. 60B\nD. \u4e0d\u5b9a\u957f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4820741646379375, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8753893041371493}}, {"question": "\u4e3b\u673a\u7532\u4e0e\u4e3b\u673a\u4e59\u4e4b\u95f4\u5df2\u5efa\u7acb\u4e00\u4e2aTCP\u8fde\u63a5\uff0c\u4e3b\u673a\u7532\u5411\u4e3b\u673a\u4e59\u53d1\u9001\u4e863\u4e2a\u8fde\u7eed\u7684TCP\u6bb5\uff0c\u5206\u522b\u5305\u542b300\u5b57\u8282\u3001400\u5b57\u8282\u548c500\u5b57\u8282\u7684\u6709\u6548\u8f7d\u8377\uff0c\u7b2c3\u4e2a\u6bb5\u7684\u5e8f\u53f7\u4e3a9000\u82e5\u4e3b\u673a\u4e59\u4ec5\u6b63\u786e\u63a5\u6536\u5230\u7b2c1\u548c\u7b2c3\u4e2a\u6bb5\uff0c\u5219\u4e3b\u673a\u4e59\u53d1\u9001\u7ed9\u4e3b\u673a\u7532\u7684\u786e\u8ba4\u5e8f\u53f7\u662f____\u3002\nA. 300\nB. 500\nC. 1200\nD. 1400\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.28850952576306876, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5\u91c7\u7528\u540e\u9000N\u5e27ARQ\u534f\u8bae\u8fdb\u884c\u6d41\u91cf\u63a7\u5236\uff0c\u5e27\u7f16\u53f7\u5b57\u6bb5\u4e3a7\u4f4d\uff0c\u5219\u53d1\u9001\u7a97\u53e3\u7684\u6700\u5927\u957f\u5ea6\u4e3a____\u3002\nA. 7\nB. 8\nC. 127\nD. 128\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4748496605322499, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728Unix\u7684\u4e24\u4e2a\u6587\u4ef6\u7cfb\u7edf\u4e4b\u95f4\u5efa\u7acb\u6587\u4ef6\u6216\u76ee\u5f55\u7684\u94fe\u63a5\u547d\u4ee4\u662f____\u3002\nA. ln\nB. ln \u2013s\nC. ls \u2013n\nD. ls \u2013i\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5614928682329539, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.49317946138669894, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8172523758808906, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9739419020460325}}, {"question": "\u4e0b\u9762\u51e0\u6761\u4e2d\uff0c____\u662f\u52a8\u6001\u91cd\u5b9a\u4f4d\u7684\u7279\u70b9\u3002\nA. \u9700\u8981\u4e00\u4e2a\u590d\u6742\u7684\u91cd\u5b9a\u4f4d\u88c5\u5165\u7a0b\u5e8f\nB. \u5b58\u50a8\u7ba1\u7406\u7b97\u6cd5\u6bd4\u8f83\u7b80\u5355\nC. \u4e0d\u9700\u5730\u5740\u53d8\u6362\u786c\u4ef6\u673a\u6784\u7684\u652f\u6301\nD. \u5728\u6267\u884c\u65f6\u5c06\u903b\u8f91\u5730\u5740\u53d8\u6362\u6210\u5185\u5b58\u5730\u5740\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.980879063114677, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7881654408634237, "meta-llama/Meta-Llama-3-8B": 0.6989690052351742, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6996400798223964}}, {"question": "Unix\u6253\u5f00\u6587\u4ef6\u673a\u6784\u4e2d\u7684\u8fdb\u7a0b\u6253\u5f00\u6587\u4ef6\u8868\u662f\u8fdb\u7a0b\u6269\u5145\u63a7\u5236\u5757user\u7ed3\u6784\u4e2d\u7684____\u3002\nA. u_pdir\nB. u_ofile\nC. u_dirp\nD. u_pofile\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8013542306556078, "meta-math/MetaMath-Mistral-7B": 0.9117245082331469, "itpossible/Chinese-Mistral-7B-v0.1": 0.7693334606083637, "HuggingFaceH4/zephyr-7b-beta": 0.9926294110727094, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7961575532332746, "meta-llama/Meta-Llama-3-8B": 0.9413205184806451, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8997158222014301}}, {"question": "\u5728\u865a\u62df\u9875\u5f0f\u5b58\u50a8\u7ba1\u7406\u65b9\u6848\u4e2d\uff0c____\u5b8c\u6210\u5c06\u9875\u9762\u8c03\u5165\u5185\u5b58\u7684\u5de5\u4f5c\u3002\nA. \u6587\u4ef6\u8bfb\u5199\nB. \u9875\u9762\u6dd8\u6c70\u8fc7\u7a0b\nC. \u9875\u9762\u5de5\u4f5c\u96c6\u5904\u7406\nD. \u7f3a\u9875\u4e2d\u65ad\u5904\u7406\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8450835688634899, "meta-math/MetaMath-Mistral-7B": 0.9378195017196984, "itpossible/Chinese-Mistral-7B-v0.1": 0.783351353389075, "HuggingFaceH4/zephyr-7b-beta": 0.9981422093432455, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9153407456228484, "meta-llama/Meta-Llama-3-8B": 0.7963047746428018, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7839560003740854}}, {"question": "\u65e9\u671f\u91c7\u7528\u4ea4\u6362\u6280\u672f\u7684\u76ee\u7684\u662f____\u3002\nA. \u80fd\u8fd0\u884c\u66f4\u591a\u7684\u7a0b\u5e8f\nB. \u80fd\u8fd0\u884c\u66f4\u5927\u7684\u7a0b\u5e8f\nC. \u5b9e\u73b0\u5206\u65f6\u7cfb\u7edf\nD. \u5b9e\u73b0\u865a\u62df\u5b58\u50a8\u6280\u672f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u9762\u5bf9\u4e8e\u6bb5\u5f0f\u548c\u9875\u5f0f\u5b58\u50a8\u7ba1\u7406\u7279\u70b9\u7684\u63cf\u8ff0\u4e2d\uff0c____\u662f\u6b63\u786e\u7684\u3002\nA. \u9875\u5f0f\u91c7\u7528\u9759\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\uff0c\u6bb5\u5f0f\u91c7\u7528\u9759\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\nB. \u9875\u5f0f\u91c7\u7528\u9759\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\uff0c\u6bb5\u5f0f\u91c7\u7528\u52a8\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\nC. \u9875\u5f0f\u91c7\u7528\u52a8\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\uff0c\u6bb5\u5f0f\u91c7\u7528\u9759\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\nD. \u9875\u5f0f\u91c7\u7528\u52a8\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\uff0c\u6bb5\u5f0f\u91c7\u7528\u52a8\u6001\u91cd\u5b9a\u4f4d\u65b9\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.46441634685475053, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u9762\u51e0\u70b9\u63aa\u65bd\u4e2d\uff0c____\u4e0d\u5c5e\u4e8eUnix\u7684\u52a8\u6001\u4f18\u5148\u6743\u6cd5\u3002\nA. \u8fdb\u7a0b\u5728\u6838\u5fc3\u6001\u4e0b\u8fd0\u884c\uff0c\u4e0d\u8fdb\u884c\u5f3a\u8feb\u8c03\u5ea6\nB. \u8d4b\u4e88\u56e0\u7b49\u5f85\u4e0d\u540c\u8d44\u6e90\u6216\u4e8b\u4ef6\u7684\u7761\u7720\u8fdb\u7a0b\u4e0d\u540c\u7684\u4f18\u5148\u6570\nC. \u8d85\u7ea7\u7528\u6237\u8fdb\u7a0b\u53ef\u4ee5\u8981\u6c42\u7cfb\u7edf\u8d4b\u4e88\u8f83\u9ad8\u7684\u4f18\u5148\u6743\nD. \u7531\u65f6\u95f4\u7247\u8f6e\u8f6c\u6cd5\u89c4\u5b9a\u5404\u4e2a\u5c31\u7eea\u8fdb\u7a0b\u987a\u6b21\u8f6e\u6d41\u4f7f\u7528\u5904\u7406\u673a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5829108311548532, "meta-math/MetaMath-Mistral-7B": 0.7576584224396833, "itpossible/Chinese-Mistral-7B-v0.1": 0.4569079644807096, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8082301926138417, "meta-llama/Meta-Llama-3-8B": 0.6923076799694312, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5935373058283403}}, {"question": "\u5728Unix\u4e2d\uff0cpasswd\u547d\u4ee4\u4f4d\u4e8e____\u76ee\u5f55\u4e2d\u7684\u3002\nA. /usr/bin\nB. /lib\nC. /etc\nD. /dev\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4690896469978423, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "Linux\u5b58\u50a8\u7ba1\u7406\u7684\u7279\u70b9\u662f\u91c7\u7528\u5728\u5927\u5c0f\u4e0d\u540c\u7684\u5206\u533a\u91cc\u5b9e\u73b0____\u7684\u5b58\u50a8\u7ba1\u7406\u6280\u672f\u3002\nA. \u53ef\u53d8\u5206\u533a\nB. \u5206\u9875\nC. \u5206\u6bb5\nD. \u6bb5\u9875\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "Windows_2000\u91c7\u7528\u7684\u7cfb\u7edf\u6a21\u578b\u4e0d\u5305\u62ec____\u3002\nA. \u5ba2\u6237\u673a/\u670d\u52a1\u5668\u6a21\u578b\nB. \u5bf9\u8c61\u6a21\u578b\nC. \u5bf9\u79f0\u591a\u5904\u7406\u6a21\u578b\nD. \u5206\u5e03\u5f0f\u5904\u7406\u6a21\u578b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728Unix\u4e2d\uff0c\u5411\u6d88\u606f\u961f\u5217\u53d1\u9001\u4e00\u4e2a\u6d88\u606f\u7684\u7cfb\u7edf\u8c03\u7528\u662f____\u3002\nA. msgsnd\nB. shmat\nC. semop\nD. send\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.869308665533285, "meta-math/MetaMath-Mistral-7B": 0.9506989335557221, "itpossible/Chinese-Mistral-7B-v0.1": 0.7460983103588428, "HuggingFaceH4/zephyr-7b-beta": 0.9465742105163995, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8700947801248193, "meta-llama/Meta-Llama-3-8B": 0.9755806970611361, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9552845199466888}}, {"question": "\u8bbe\u8ba1\u6279\u5904\u7406\u591a\u9053\u7cfb\u7edf\u65f6\uff0c\u9996\u5148\u8981\u8003\u8651\u7684\u662f____\u3002\nA. \u7075\u6d3b\u6027\u548c\u53ef\u9002\u5e94\u6027\nB. \u7cfb\u7edf\u6548\u7387\u548c\u541e\u5410\u91cf\nC. \u4ea4\u4e92\u6027\u548c\u54cd\u5e94\u65f6\u95f4\nD. \u5b9e\u65f6\u6027\u548c\u53ef\u9760\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5181205748470197, "meta-math/MetaMath-Mistral-7B": 0.727118378926206, "itpossible/Chinese-Mistral-7B-v0.1": 0.4366194747879353, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7560395759603222, "meta-llama/Meta-Llama-3-8B": 0.8925598158368487, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7942494290768969}}, {"question": "\u6587\u4ef6\u4fdd\u5bc6\u7684\u76ee\u7684\u662f\u6307\u9632\u6b62\u6587\u4ef6\u88ab____\u3002\nA. \u7be1\u6539\nB. \u7834\u574f\nC. \u7a83\u53d6\nD. \u5220\u9664\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.94173694967705, "meta-math/MetaMath-Mistral-7B": 0.9623619729909869, "itpossible/Chinese-Mistral-7B-v0.1": 0.7914497003262345, "HuggingFaceH4/zephyr-7b-beta": 0.9968669325686589, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8618907387701292, "meta-llama/Meta-Llama-3-8B": 0.6824601466612732, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u9762\u54ea\u4e00\u4e2a\u547d\u4ee4\u53ef\u4ee5\u56de\u5230\u7528\u6237\u4e3b\u76ee\u5f55____\u3002\nA. cd ..\nB. cd HOME\nC. cd .\nD. cd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6841797194245515, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e3a\u4e86\u6587\u4ef6\u7684\u4fdd\u5bc6\uff0c\u53ef\u4ee5\u7528____\u7684\u65b9\u6cd5\u4f7f\u6587\u4ef6\u7684\u5185\u5bb9\u5bf9\u5176\u4ed6\u4e3b\u4f53\u65e0\u610f\u4e49\u3002\nA. \u5b58\u53d6\u63a7\u5236\u8868\nB. \u9690\u853d\u6587\u4ef6\u76ee\u5f55\nC. \u8bbe\u7f6e\u53e3\u4ee4\nD. \u4f7f\u7528\u5bc6\u7801\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.37380585302853203, "itpossible/Chinese-Mistral-7B-v0.1": 0.6481867137347421, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u64cd\u4f5c\u7cfb\u7edf\u4e2d\u5e94\u7528\u6700\u591a\u7684\u6570\u636e\u7ed3\u6784\u662f____\u3002\nA. \u5806\u6808\nB. \u961f\u5217\nC. \u6811\nD. \u56fe\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8226303158673703, "meta-math/MetaMath-Mistral-7B": 0.6746339445930335, "itpossible/Chinese-Mistral-7B-v0.1": 0.6119753641649013, "HuggingFaceH4/zephyr-7b-beta": 0.8259418840825751, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7481021790527547, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7222154600604779}}, {"question": "\u4e2d\u65ad\u548cDMA\u5728\u64cd\u4f5c\u8fc7\u7a0b\u4e2d____\u5d4c\u5957\u3002\nA. \u90fd\u4e0d\u53ef\u4ee5\nB. \u4e2d\u65ad\u53ef\u4ee5\u3001\u4f46DMA\u4e0d\u53ef\u4ee5\nC. \u90fd\u53ef\u4ee5\nD. \u4e2d\u65ad\u4e0d\u53ef\u4ee5\u3001\u4f46DMA\u53ef\u4ee5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u8bf7\u6c42\u5206\u9875\u7cfb\u7edf\u4e2d\uff0c\u9875\u9762\u7f6e\u6362\u7b97\u6cd5\u5e38\u7528\u7684\u662f____\u3002\nA. \u6700\u4f18\u6dd8\u6c70\u7b97\u6cd5\nB. \u9996\u6b21\u9002\u5e94\u7b97\u6cd5\nC. \u6700\u8fd1\u6700\u5c11\u4f7f\u7528\u6dd8\u6c70\u7b97\u6cd5\nD. \u6700\u4f73\u9002\u5e94\u7b97\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8077301906003375, "meta-math/MetaMath-Mistral-7B": 0.8552007273524583, "itpossible/Chinese-Mistral-7B-v0.1": 0.5691376107202293, "HuggingFaceH4/zephyr-7b-beta": 0.8751461672930587, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6589201368704156, "meta-llama/Meta-Llama-3-8B": 0.7959347675186389, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9197461095237711}}, {"question": "Unix\u7684\u8f6f\u4e2d\u65ad\u673a\u5236\u662f____\u3002\nA. \u8bbe\u5907\u4e2d\u65ad\nB. \u4fe1\u53f7\u91cf\nC. \u7cfb\u7edf\u8c03\u7528\nD. \u4fe1\u53f7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6412198111024017, "meta-math/MetaMath-Mistral-7B": 0.9475316892219352, "itpossible/Chinese-Mistral-7B-v0.1": 0.526238641392213, "HuggingFaceH4/zephyr-7b-beta": 0.8713227720748641, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6094598573665103, "meta-llama/Meta-Llama-3-8B": 0.9363476783909143, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6233810590991699}}, {"question": "\u6307\u4ee4\u4e2d\u5730\u5740\u7801\u7684\u957f\u5ea6\u4e0d\u4ec5\u4e0e\u4e3b\u5b58\u5bb9\u91cf\u6709\u5173\uff0c\u800c\u4e14\u8fd8\u4e0e____\u6709\u5173\u3002\nA. \u4e3b\u5b58\u5b57\u957f\nB. \u6700\u5c0f\u5bfb\u5740\u5355\u4f4d\nC. \u6307\u4ee4\u683c\u5f0f\nD. \u5730\u5740\u7801\u683c\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5199028554703752, "itpossible/Chinese-Mistral-7B-v0.1": 0.3520821795518118, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.523688315216541, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f00\u4e2d\u65ad\u548c\u5173\u4e2d\u65ad\u4e24\u79cd\u64cd\u4f5c\u90fd\u7528\u4e8e\u5bf9____\u8fdb\u884c\u8bbe\u7f6e\u3002\nA. \u4e2d\u65ad\u5141\u8bb8\u89e6\u53d1\u5668\nB. \u4e2d\u65ad\u5c4f\u853d\u5bc4\u5b58\u5668\nC. \u4e2d\u65ad\u8bf7\u6c42\u5bc4\u5b58\u5668\nD. \u4e2d\u65ad\u5411\u91cf\u5bc4\u5b58\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8ba1\u7b97\u673a\u7cfb\u7edf\u7684\u5c42\u6b21\u7ed3\u6784\u53ef\u4ee5\u5206\u4e3a6\u5c42\uff0c\u5176\u5c42\u6b21\u4e4b\u95f4\u7684\u4f9d\u5b58\u5173\u7cfb\u662f____\u3002\nA. \u4e0a\u4e0b\u5c42\u4e4b\u95f4\u76f8\u4e92\u65e0\u5173\nB. \u4e0a\u5c42\u5b9e\u73b0\u5bf9\u4e0b\u5c42\u7684\u529f\u80fd\u6269\u5c55\uff0c\u800c\u4e0b\u5c42\u662f\u5b9e\u73b0\u4e0a\u5c42\u7684\u57fa\u7840\nC. \u4e0a\u5c42\u5b9e\u73b0\u5bf9\u4e0b\u5c42\u7684\u6269\u5c55\u4f5c\u7528\uff0c\u800c\u4e0b\u5c42\u5bf9\u4e0a\u5c42\u6709\u9650\u5236\u4f5c\u7528\nD. \u4e0a\u5c42\u548c\u4e0b\u5c42\u7684\u5173\u7cfb\u662f\u76f8\u4e92\u4f9d\u5b58\u3001\u4e0d\u53ef\u5206\u5272\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8793433900764372, "meta-math/MetaMath-Mistral-7B": 0.9590702048623795, "itpossible/Chinese-Mistral-7B-v0.1": 0.5382465318343895, "HuggingFaceH4/zephyr-7b-beta": 0.9944739151413047, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8933717990949492, "meta-llama/Meta-Llama-3-8B": 0.6525594125744691, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.942841172739387}}, {"question": "\u5728\u4e3b\u673a\u4e0e\u5916\u8bbe\u7684\u4fe1\u606f\u4f20\u9001\u4e2d\uff0c____\u4e0d\u662f\u4e00\u79cd\u7a0b\u5e8f\u63a7\u5236\u65b9\u5f0f\u3002\nA. \u76f4\u63a5\u7a0b\u5e8f\u63a7\u5236\nB. \u7a0b\u5e8f\u4e2d\u65ad\nC. \u76f4\u63a5\u5b58\u50a8\u5668\u5b58\u50a8(DMA)\nD. \u901a\u9053\u63a7\u5236\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8eLRU\u7b97\u6cd5\uff0c\u4ee5\u4e0b\u8bba\u8ff0\u6b63\u786e\u7684\u662f____\u3002\nA. LRU\u7b97\u6cd5\u66ff\u6362\u6389\u90a3\u4e9b\u5728Cache\u4e2d\u9a7b\u7559\u65f6\u95f4\u6700\u957f\u4e14\u672a\u88ab\u5f15\u7528\u7684\u5757\nB. LRU\u7b97\u6cd5\u66ff\u6362\u6389\u90a3\u4e9b\u5728Cache\u4e2d\u9a7b\u7559\u65f6\u95f4\u6700\u77ed\u4e14\u672a\u88ab\u5f15\u7528\u7684\u5757\nC. LRU\u7b97\u6cd5\u66ff\u6362\u6389\u90a3\u4e9b\u5728Cache\u4e2d\u9a7b\u7559\u65f6\u95f4\u6700\u957f\u4e14\u4ecd\u5728\u5f15\u7528\u7684\u5757\nD. LRU\u7b97\u6cd5\u66ff\u6362\u6389\u90a3\u4e9b\u5728Cache\u4e2d\u9a7b\u7559\u65f6\u95f4\u6700\u77ed\u4e14\u4ecd\u5728\u5f15\u7528\u7684\u5757\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4886397803426785, "meta-math/MetaMath-Mistral-7B": 0.9734800577580877, "itpossible/Chinese-Mistral-7B-v0.1": 0.611975372604457, "HuggingFaceH4/zephyr-7b-beta": 0.9436773756386253, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9274919268832923, "meta-llama/Meta-Llama-3-8B": 0.44064789105379315, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9577270338405484}}, {"question": "\u5df2\u77e5\u4e00\u53f0\u65f6\u949f\u9891\u7387\u4e3a2GHz\u7684\u8ba1\u7b97\u673a\u7684CPI\u4e3a1.2\u3002\u67d0\u7a0b\u5e8fP\u5728\u8be5\u8ba1\u7b97\u673a\u4e0a\u7684\u6307\u4ee4\u6761\u6570\u4e3a$4\u00d710^9$\u3002\u82e5\u5728\u8be5\u8ba1\u7b97\u673a\u4e0a\uff0c\u7a0b\u5e8fP\u4ece\u5f00\u59cb\u542f\u52a8\u5230\u6267\u884c\u7ed3\u675f\u6240\u7ecf\u5386\u7684\u65f6\u95f4\u662f4s\uff0c\u5219\u8fd0\u884cP\u6240\u7528CPU\u65f6\u95f4\u5360\u6574\u4e2aCPU\u65f6\u95f4\u7684\u767e\u5206\u6bd4\u5927\u7ea6\u662f____\u3002\nA. 40%\nB. 60%\nC. 80%\nD. 100%\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6274250846926516, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.25756620677129083, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u603b\u7ebf\u5bbd\u5ea6\u4e0e\u4e0b\u5217____\u6709\u5173\u3002\nA. \u63a7\u5236\u7ebf\u6839\u6570\nB. \u6570\u636e\u7ebf\u6839\u6570\nC. \u5730\u5740\u7ebf\u6839\u6570\nD. \u4ee5\u4e0a\u90fd\u4e0d\u5bf9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8562546213530383, "meta-math/MetaMath-Mistral-7B": 0.9884213836079461, "itpossible/Chinese-Mistral-7B-v0.1": 0.7464090616011512, "HuggingFaceH4/zephyr-7b-beta": 0.9981385645094561, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9817477011790734, "meta-llama/Meta-Llama-3-8B": 0.5417450079637177, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4270450203246949}}, {"question": "\u8ba1\u7b97\u673a\u7684\u6307\u4ee4\u7cfb\u7edf\u662f\u8ba1\u7b97\u673a____\u7684\u63a5\u53e3\u3002\nA. \u6570\u636e\u548c\u6307\u4ee4\nB. \u547d\u4ee4\u548c\u663e\u793a\nC. \u8f93\u5165\u7cfb\u7edf\u548c\u8f93\u51fa\u7cfb\u7edf\nD. \u8f6f\u4ef6\u548c\u786c\u4ef6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9966371344628586, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4205232166353252, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6538270607607478}}, {"question": "\u6309\u901a\u9053\u7684\u5de5\u4f5c\u65b9\u5f0f\u5206\uff0c\u901a\u9053\u6709____\u3002\nA. \u9009\u62e9\u901a\u9053\nB. \u5b57\u8282\u591a\u8def\u901a\u9053\nC. \u6570\u7ec4\u591a\u8def\u901a\u9053\nD. \u4ee5\u4e0a\u7b54\u6848\u5747\u6b63\u786e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8546055094702107, "meta-math/MetaMath-Mistral-7B": 0.9690410036663915, "itpossible/Chinese-Mistral-7B-v0.1": 0.5667617090836065, "HuggingFaceH4/zephyr-7b-beta": 0.7277947282074523, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9373576501743018, "meta-llama/Meta-Llama-3-8B": 0.6274250951215825, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.602015649107445}}, {"question": "\u7528\u6d77\u660e\u7801\u5bf9\u957f\u5ea6\u4e3a8\u4f4d\u7684\u6570\u636e\u8fdb\u884c\u68c0/\u7ea0\u9519\u65f6\uff0c\u82e5\u80fd\u7ea0\u6b63\u4e00\u4f4d\u9519\uff0c\u5219\u6821\u9a8c\u4f4d\u6570\u81f3\u5c11\u4e3a____\u3002\nA. 2\nB. 3\nC. 4\nD. 5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35686329776860143, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5266794467435242, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.35272477412331865}}, {"question": "\u5fae\u578b\u8ba1\u7b97\u673a\u7684\u53d1\u5c55\u4ee5____\u6280\u672f\u4e3a\u6807\u5fd7\u3002\nA. \u64cd\u4f5c\u7cfb\u7edf\nB. \u5fae\u5904\u7406\u5668\nC. \u78c1\u76d8\nD. \u8f6f\u4ef6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9355503486372445, "meta-math/MetaMath-Mistral-7B": 0.9960148448674995, "itpossible/Chinese-Mistral-7B-v0.1": 0.9028657500944322, "HuggingFaceH4/zephyr-7b-beta": 0.9997755360422859, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9895291321543253, "meta-llama/Meta-Llama-3-8B": 0.9605072052260055, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9987627712356775}}, {"question": "\u4e00\u4e2a16\u4f4d\u65e0\u7b26\u53f7\u4e8c\u8fdb\u5236\u6570\u7684\u8868\u793a\u8303\u56f4\u662f____\u3002\nA. 0\uff5e65536\nB. 0\uff5e65535\nC. -32768\uff5e32767\nD. -32768\uff5e32768\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6534071487085331, "meta-math/MetaMath-Mistral-7B": 0.9629876977367097, "itpossible/Chinese-Mistral-7B-v0.1": 0.36150852560561064, "HuggingFaceH4/zephyr-7b-beta": 0.9979298549355134, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8272616655290763, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5b50\u7a0b\u5e8f\u8c03\u7528\u6307\u4ee4\u6267\u884c\u65f6\uff0c\u8981\u628a\u5f53\u524d\u7a0b\u5e8f\u8ba1\u6570\u5668(PC)\u7684\u5185\u5bb9\u5b58\u5230____\u3002\nA. \u901a\u7528\u5bc4\u5b58\u5668\nB. \u5806\u6808\nC. \u6307\u4ee4\u5bc4\u5b58\u5668\nD. \u6570\u636e\u7f13\u51b2\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9400537282875603, "meta-math/MetaMath-Mistral-7B": 0.9970419003341534, "itpossible/Chinese-Mistral-7B-v0.1": 0.8602799774015288, "HuggingFaceH4/zephyr-7b-beta": 0.9999234090979178, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9983389953440873, "meta-llama/Meta-Llama-3-8B": 0.9310531544374967, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8418047568915742}}, {"question": "\u67d0\u8ba1\u7b97\u673a\u5b57\u957f32\u4f4d\uff0c\u5176\u5b58\u50a8\u5bb9\u91cf\u662f1MB\u3002\u82e5\u6309\u5b57\u7f16\u5740\uff0c\u5b83\u7684\u5bfb\u5740\u8303\u56f4\u662f____\u3002\nA. 0\uff5e1M\nB. 0\uff5e512K\nC. 0\uff5e256K\nD. 0\uff5e256KB\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.29863342676099575, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5355\u5730\u5740\u53cc\u76ee\u8fd0\u7b97\u7c7b\u6307\u4ee4\u4e2d\uff0c\u9664\u5730\u5740\u7801\u6307\u660e\u7684\u4e00\u4e2a\u64cd\u4f5c\u6570\u4ee5\u5916\uff0c\u53e6\u4e00\u4e2a\u64cd\u4f5c\u6570\u901a\u5e38\u91c7\u7528____\u3002\nA. \u5806\u6808\u5bfb\u5740\u65b9\u5f0f\nB. \u7acb\u5373\u5bfb\u5740\u65b9\u5f0f\nC. \u95f4\u63a5\u5bfb\u5740\u65b9\u5f0f\nD. \u9690\u542b\u6307\u5b9a\u65b9\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.42188961116078033, "meta-math/MetaMath-Mistral-7B": 0.4639755659934469, "itpossible/Chinese-Mistral-7B-v0.1": 0.5494763684777636, "HuggingFaceH4/zephyr-7b-beta": 0.9836446074498091, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47369843406030043, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u65ad\u53d1\u751f\u65f6\uff0c\u7a0b\u5e8f\u8ba1\u6570\u5668\u5185\u5bb9\u7684\u4fdd\u62a4\u548c\u66f4\u65b0\u662f\u7531____\u5b8c\u6210\u7684\u3002\nA. \u786c\u4ef6\u81ea\u52a8\nB. \u8fdb\u6808\u6307\u4ee4\u548c\u8f6c\u79fb\u6307\u4ee4\nC. \u8bbf\u5b58\u6307\u4ee4\nD. \u4e2d\u65ad\u670d\u52a1\u7a0b\u5e8f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8084548939400739, "meta-math/MetaMath-Mistral-7B": 0.9871365949505552, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6508575114714957, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8409450724306613, "meta-llama/Meta-Llama-3-8B": 0.7457521609233128, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8567245758775702}}, {"question": "\u6267\u884cfor\u5faa\u73af\u65f6\uff0c\u9700\u8981\u4f20\u9001\u5faa\u73af\u6b21\u6570\u503c\u7ed9\u67d0\u4e13\u7528\u5bc4\u5b58\u5668\uff0c\u4e00\u822c\u4f7f\u7528\u7684\u5bfb\u5740\u65b9\u5f0f\u662f____\u3002\nA. \u7acb\u5373\u5bfb\u5740\nB. \u76f4\u63a5\u5bfb\u5740\nC. \u57fa\u5740\u5bfb\u5740\nD. \u76f8\u5bf9\u5bfb\u5740\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28966338381871215, "meta-math/MetaMath-Mistral-7B": 0.35289251391850557, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5417450025983709, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5940327246278464}}, {"question": "\u5bf9\u771f\u503c0\u8868\u793a\u5f62\u5f0f\u552f\u4e00\u7684\u673a\u5668\u6570\u662f____\u3002\nA. \u539f\u7801\nB. \u8865\u7801\u548c\u79fb\u7801\nC. \u53cd\u7801\nD. \u4ee5\u4e0a\u90fd\u4e0d\u5bf9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2920177551543942, "meta-math/MetaMath-Mistral-7B": 0.4732546881749753, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41601988974296555, "meta-llama/Meta-Llama-3-8B": 0.43241138747909885, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6430245689037364}}, {"question": "\u4e0b\u5217\u5173\u4e8eCache\u7684\u8bf4\u6cd5\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u91c7\u7528\u76f4\u63a5\u6620\u50cf\u65f6\uff0cCache\u65e0\u9700\u8003\u8651\u66ff\u6362\u95ee\u9898\nB. \u5982\u679c\u9009\u7528\u6700\u4f18\u66ff\u6362\u7b97\u6cd5\uff0c\u5219Cache\u7684\u547d\u4e2d\u7387\u53ef\u4ee5\u8fbe\u5230100%\nC. Cache\u672c\u8eab\u7684\u901f\u5ea6\u8d8a\u5feb\uff0c\u5219Cache\u5b58\u50a8\u5668\u7684\u7b49\u6548\u8bbf\u95ee\u901f\u5ea6\u5c31\u8d8a\u5feb\nD. Cache\u7684\u5bb9\u91cf\u4e0e\u4e3b\u5b58\u7684\u5bb9\u91cf\u5dee\u522b\u8d8a\u5927\u8d8a\u597d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5422312327897031, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u901a\u7528\u5bc4\u5b58\u5668\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u53ef\u5b58\u653e\u6307\u4ee4\u7684\u5bc4\u5b58\u5668\nB. \u53ef\u5b58\u653e\u7a0b\u5e8f\u72b6\u6001\u5b57\u7684\u5bc4\u5b58\u5668\nC. \u672c\u8eab\u5177\u6709\u8ba1\u6570\u903b\u8f91\u4e0e\u79fb\u4f4d\u903b\u8f91\u7684\u5bc4\u5b58\u5668\nD. \u53ef\u5b58\u653e\u8fd0\u7b97\u7ed3\u679c\u7684\u5bc4\u5b58\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8027123175223185, "meta-math/MetaMath-Mistral-7B": 0.9746604210965784, "itpossible/Chinese-Mistral-7B-v0.1": 0.3559524557971753, "HuggingFaceH4/zephyr-7b-beta": 0.9982918003144222, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8184806948173672, "meta-llama/Meta-Llama-3-8B": 0.619831118659059, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8570689984926337}}, {"question": "\u5fae\u7a0b\u5e8f\u5b58\u653e\u7684\u4f4d\u7f6e\u662f____\u3002\nA. CPU\nB. \u9ad8\u901f\u7f13\u51b2\u5b58\u50a8\u5668\nC. \u4e3b\u5b58\u50a8\u5668\nD. \u78c1\u76d8\u5b58\u50a8\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u91c7\u7528\u5206\u5757\u67e5\u627e\u65f6\uff0c\u6570\u636e\u7684\u7ec4\u7ec7\u65b9\u5f0f\u4e3a____\nA. \u6570\u636e\u5206\u6210\u82e5\u5e72\u5757\uff0c \u6bcf\u5757\u5185\u6570\u636e\u6709\u5e8f\nB. \u6570\u636e\u5206\u6210\u82e5\u5e72\u5757\uff0c \u6bcf\u5757\u5185\u6570\u636e\u4e0d\u5fc5\u6709\u5e8f\uff0c \u4f46\u5757\u95f4\u5fc5\u987b\u6709\u5e8f\uff0c \u6bcf\u5757\u5185\u6700\u5927\uff08 \u6216\u6700\u5c0f\uff09 \u7684\u6570\u636e\u7ec4\u6210\u7d22\u5f15\u5757\nC. \u6570\u636e\u5206\u6210\u82e5\u5e72\u5757\uff0c \u6bcf\u5757\u5185\u6570\u636e\u6709\u5e8f\uff0c \u4f46\u5757\u95f4\u5fc5\u987b\u6709\u5e8f\uff0c \u6bcf\u5757\u5185\u6700\u5927\uff08 \u6216\u6700\u5c0f\uff09 \u7684\u6570\u636e\u7ec4\u6210\u7d22\u5f15\u5757\nD. \u6570\u636e\u5206\u6210\u82e5\u5e72\u5757\uff0c \u6bcf\u5757\uff08 \u9664\u6700\u540e\u4e00\u5757\u5916\uff09 \u4e2d\u6570\u636e\u4e2a\u6570\u9700\u76f8\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6041952201079991, "itpossible/Chinese-Mistral-7B-v0.1": 0.39396560778112244, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5b9e\u73b0\u4e00\u4e2a\u94f6\u884c\u7cfb\u7edf\uff0c\u5305\u62ec\u5b58\u94b1\u3001\u53d6\u94b1\u3001\u8f6c\u8d26\u7b49\u591a\u9879\u4e1a\u52a1\uff0c\u6700\u6070\u5f53\u7684\u8d44\u6e90\u7ec4\u5408\u65b9\u5f0f\u662f____\nA. \u7ee7\u627f\nB. \u91cd\u8f7d\nC. \u7ec4\u5408\nD. \u5b9e\u4f8b\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5524432139242215, "meta-math/MetaMath-Mistral-7B": 0.8572343814113582, "itpossible/Chinese-Mistral-7B-v0.1": 0.43619758431097255, "HuggingFaceH4/zephyr-7b-beta": 0.9952085776372421, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.611926969642453, "meta-llama/Meta-Llama-3-8B": 0.5501667453606544, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9051141642042163}}, {"question": "#include<iostream.h>\nclass date\n{\nprivate:\nint day,month,year;\npublic:\ndate(){}\ndate(int x,int y,int z){day=x;month=y,year=z;}\nvoid set(){day=1;month=10;year=2002;}\nvoid display(){cout<<day<<\"/\"<<month<<\"/\"<<year<<\"\";}\n};\nvoid main()\n{\ndate day1;\ndate day2(10,10,2002);\nday1.set();\nday1.display();\nday2.display();\n}\n\u4e0a\u9762C++\u7a0b\u5e8f\u8fd0\u884c\u7684\u7ed3\u679c\u662f____\u3002\nA. 10/10/2002 1/10/2002\nB. 1/10/2002 10/10/2002\nC. 10/10/2002 10/10/2002\nD. 1/10/2002 1/10/2002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3632122790984034, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5047\u5b9aA\u662f\u4e00\u4e2a\u7c7b\u7684\u540d\u5b57\uff0c\u4e0b\u9762\u56db\u4e2a\u8bed\u53e5\u603b\u5171\u4f1a\u5f15\u53d1\u7c7bA\u6784\u9020\u51fd\u6570\u7684\u8c03\u7528\u591a\u5c11\u6b21____\n\u2460A *p=newA;\n\u2461A p2[10];\n\u2462A p3;\n\u2463A *p4[10];\nA. 11\nB. 12\nC. 21\nD. 22\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30150657848650314, "meta-math/MetaMath-Mistral-7B": 0.34445452180439035, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.307023896814742, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u4ee5\u4e0b\u7a0b\u5e8f\u4ee3\u7801\n#include<iostream>\nusing namespace std;\nclass integer{\npublic:\ninteger(int value=0):value(value){}\ninteger operator+(integer itg){\nreturn value+=itg.value;\n}\nfriend ostream&operator<<(ostream&os,integer&it){\nreturn os<<it.value;\n}\nprivate:\nint value;\n};\nint main()\n{\ninteger i;\ninteger ii;\nii=2+i;\ncout<<\"i=\"<<i<<\",\";\ncout<<\"ii=\"<<ii<<endl;\nreturn 0;\n}\n\u7f16\u8bd1\u60c5\u51b5\u6216\u8fd0\u884c\u65f6\u8f93\u51fa\u662f____\nA. i=0 ,ii=2\nB. i=2 ,ii=2\nC. i=0 ,ii=0\nD. \u7f16\u8bd1\u9519\u8bef\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4179598248770773, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4ee5\u4e0b\u5404\u79cd\u67e5\u627e\u65b9\u6cd5\u4e2d\uff0c\u5e73\u5747\u67e5\u627e\u65f6\u95f4\u4e0e\u7ed3\u70b9\u4e2a\u6570\u65e0\u5173\u7684\u67e5\u627e\u65b9\u6cd5\u662f____\nA. \u987a\u5e8f\u67e5\u627e\nB. \u6298\u534a\u67e5\u627e\nC. \u54c8\u5e0c\u67e5\u627e\nD. \u5206\u5757\u67e5\u627e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7910196186392214, "meta-math/MetaMath-Mistral-7B": 0.9191740370078887, "itpossible/Chinese-Mistral-7B-v0.1": 0.4460019416117121, "HuggingFaceH4/zephyr-7b-beta": 0.9975901782803115, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9306919724630834, "meta-llama/Meta-Llama-3-8B": 0.8058420074051443, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.977681437388087}}, {"question": "\u8bfb\u4e0b\u9762C++\u7a0b\u5e8f\uff1a\n#include<iostream.h>\nclass vehicle{\nprotected:\nint wheels;\npublic:\nvehicle(int in_wheels=4){wheels=in_wheels;}\nint get_wheels(){return wheels;}\n};\nvoid main()\n{\nvehicle unicyclel;\nvehicle unicycle2(3);\ncout<<\"Theunickele1has\"<<unicyclel.get_wheels()<<\"wheel.\\n\";\ncout<<\"Theunickele2has\"<<unicycle2.get_wheels()<<\"wheel.\\n\";\n}\n\u7f16\u8bd1\u540e\u8f93\u51fa\u7ed3\u679c\u4e3a____\u3002\nA. The unicycle1 has 0 wheel.\nThe unicycle2 has 3 wheel.\nB. The unicycle1 has 4 wheel.\nThe unicycle2 has 4 wheel.\nC. The unicycle1 has 4 wheel.\nThe unicycle2 has 3 wheel.\nD. The unicycle1 has 0 wheel.\nThe unicycle2 has 4 wheel.\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4766145238621021, "meta-math/MetaMath-Mistral-7B": 0.7609986106928275, "itpossible/Chinese-Mistral-7B-v0.1": 0.37325339864157286, "HuggingFaceH4/zephyr-7b-beta": 0.9985731929740354, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6877144176600337, "meta-llama/Meta-Llama-3-8B": 0.41245789202394834, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8058450386216114}}, {"question": "\u4ee5\u4e0b\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u5728const\u6210\u5458\u51fd\u6570\u4e2d\u4e0d\u53ef\u4ee5\u4f7f\u7528this\u6307\u9488\uff1b\nB. \u5728static\u6210\u5458\u51fd\u6570\u4e2d\u4e0d\u53ef\u4ee5\u4f7f\u7528this \u6307\u9488\uff1b\nC. \u62bd\u8c61\u7c7b\u7684\u6210\u5458\u51fd\u6570\u90fd\u662f\u7eaf\u865a\u51fd\u6570\uff1b\nD. \u62bd\u8c61\u7c7b\u7684\u6d3e\u751f\u7c7b\u5fc5\u987b\u5b9e\u73b0\u62bd\u8c61\u7c7b\u4e2d\u7684\u7eaf\u865a\u51fd\u6570\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u4e2an\u4e2a\u9876\u70b9\u7684\u8fde\u901a\u65e0\u5411\u56fe\uff0c\u5176\u8fb9\u7684\u4e2a\u6570\u81f3\u5c11\u4e3a____\nA. n-1\nB. n\nC. n+1\nD. nlogn\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6426946556679348, "meta-math/MetaMath-Mistral-7B": 0.9900754147258853, "itpossible/Chinese-Mistral-7B-v0.1": 0.4141793731416027, "HuggingFaceH4/zephyr-7b-beta": 0.9999812340851201, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9125954723241639, "meta-llama/Meta-Llama-3-8B": 0.811875911242053, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8724965947489494}}, {"question": "\u5728C++\u7a0b\u5e8f\u4e2d\u51fa\u73b0____\u60c5\u51b5\u65f6\uff0c\u5c06\u5f15\u53d1\u4e00\u4e2a\u5f02\u5e38\u3002\nA. \u5728 main \u51fd\u6570\u7684\u7ed3\u5c3e\u5c11\u4e86\u4e00\u4e2a\u5927\u62ec\u53f7\nB. for \u5faa\u73af\u8bed\u6cd5\u9519\u8bef\nC. \u88ab\u96f6\u9664\u6216\u6570\u7ec4\u6ea2\u51fa\nD. \u6570\u7ec4\u6ca1\u6709\u88ab\u8d4b\u6ee1\u503c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5253720230358462, "meta-math/MetaMath-Mistral-7B": 0.6363805550438886, "itpossible/Chinese-Mistral-7B-v0.1": 0.40202865642572594, "HuggingFaceH4/zephyr-7b-beta": 0.9965650811269272, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9124473327198741, "meta-llama/Meta-Llama-3-8B": 0.8985464448646783, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.992198324664368}}, {"question": "\u7ebf\u6027\u8868\u82e5\u91c7\u7528\u94fe\u5f0f\u5b58\u50a8\u7ed3\u6784\u65f6\uff0c\u8981\u6c42\u5185\u5b58\u4e2d\u53ef\u7528\u5b58\u50a8\u5355\u5143\u7684\u5730\u5740____\u3002\nA. \u5fc5\u987b\u662f\u8fde\u7eed\u7684\nB. \u90e8\u5206\u5730\u5740\u5fc5\u987b\u662f\u8fde\u7eed\u7684\nC. \u4e00\u5b9a\u662f\u4e0d\u8fde\u7eed\u7684\nD. \u8fde\u7eed\u4e0d\u8fde\u7eed\u90fd\u53ef\u4ee5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u7c7b\u4e2d\u8bf4\u660e\u7684\u53cb\u5143\u51fd\u6570\u65f6____\nA. \u5fc5\u987b\u58f0\u660e\u5728\u79c1\u6709\u6210\u5458\u90e8\u5206\nB. \u5fc5\u987b\u58f0\u660e\u5728\u5171\u6709\u6210\u5458\u90e8\u5206\nC. \u5fc5\u987b\u58f0\u660e\u5728\u7c7b\u5f00\u59cb\u5904\nD. \u53ef\u4ee5\u58f0\u660e\u5728\u7c7b\u4e2d\u4efb\u4f55\u5730\u65b9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40907350926901087, "meta-math/MetaMath-Mistral-7B": 0.408884077261466, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9998027369266606, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6409876750614175, "meta-llama/Meta-Llama-3-8B": 0.4389239746943771, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u670914\u4e2a\u5143\u7d20\u7684\u6709\u5e8f\u8868A[1..14]\u4f5c\u4e8c\u5206\u67e5\u627e\uff0c\u67e5\u627e\u5143\u7d20A[6]\u65f6\u7684\u88ab\u6bd4\u8f83\u5143\u7d20\u4f9d\u6b21\u4e3a____\nA. A[l], A[2], A[3], A[4]\nB. A[l], A[14], A[7], A[4]\nC. A[7], A[5], A[3], A[6]\nD. A[7], A[3], A[5], A[6]\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.35686329776860143, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6982\u5ff5____\u4f53\u73b0\u4e86\u9762\u5411\u5bf9\u8c61\u7684\u591a\u6001\u6027\u3002\nA. \u865a\u57fa\u7c7b\nB. \u865a\u51fd\u6570\nC. \u5bf9\u8c61\u5bb9\u5668\nD. \u5c01\u88c5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9373232450733925, "meta-math/MetaMath-Mistral-7B": 0.9961863081848825, "itpossible/Chinese-Mistral-7B-v0.1": 0.9487072628448804, "HuggingFaceH4/zephyr-7b-beta": 0.9999898912141594, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9963078028235552, "meta-llama/Meta-Llama-3-8B": 0.9541740477106926, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9997541640859181}}, {"question": "\u82e5\u6709\u5b9a\u4e49char s[]={'1','2','3','0','0','4','5'};\u5219cout<<s\u7684\u7ed3\u679c\u4e3a____\nA. 1230045\nB. 12300\nC. 1230\nD. 123\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728C++\u4e2d\uff0c\u6570\u636e\u5c01\u88c5\u8981\u89e3\u51b3\u7684\u95ee\u9898\u662f____\u3002\nA. \u6570\u636e\u89c4\u8303\u5316\u6392\u5217\nB. \u6570\u636e\u9ad8\u901f\u8f6c\u6362\nC. \u907f\u514d\u6570\u636e\u4e22\u5931\nD. \u4fdd\u8bc1\u6570\u636e\u5b8c\u6574\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8918945307188784, "meta-math/MetaMath-Mistral-7B": 0.7696348876918242, "itpossible/Chinese-Mistral-7B-v0.1": 0.7874966002295821, "HuggingFaceH4/zephyr-7b-beta": 0.9999427687228855, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9782955249379346, "meta-llama/Meta-Llama-3-8B": 0.5244783153805874, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9573333193108284}}, {"question": "\u5728\u987a\u5e8f\u8868\uff08\u957f\u5ea6\u4e3a127\uff09\u4e2d\u63d2\u5165\u4e00\u4e2a\u5143\u7d20\u5e73\u5747\u8981\u79fb\u52a8____\u4e2a\u5143\u7d20\u3002\nA. 8\nB. 63.5\nC. 63\nD. 7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35002889983337143, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5501670512010732, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7380394619837448}}, {"question": "\u5173\u4e8e\u5de6\u503c\u5f15\u7528\uff0c\u4e0b\u5217\u7528\u6cd5\u6216\u53d9\u8ff0\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u5f15\u7528\u53ef\u4ee5\u5148\u5b9a\u4e49\uff0c\u518d\u8d4b\u503c\uff1b\nB. \u5f15\u7528\u53ef\u4ee5\u4f5c\u4e3a\u51fd\u6570\u53c2\u6570\uff1b\nC. \u51fd\u6570\u53ef\u4ee5\u8fd4\u56de\u5f15\u7528\uff1b\nD. \u5f15\u7528\u662f\u53e6\u4e00\u4e2a\u6709\u540d\u5b57\u53d8\u91cf\u7684\u522b\u540d\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5718630807642693, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8790854120853788, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.619376333667041}}, {"question": "\u73b0\u4eca\u7684\u8f6f\u4ef6\u6216\u662f\u64cd\u4f5c\u7cfb\u7edf\u5f80\u5f80\u90fd\u670932\u4f4d\u548c64\u4f4d\u7684\u4e0d\u540c\u7684\u7248\u672c\uff0c\u4e3b\u8981\u7684\u533a\u522b\u5c31\u662f32\u4f4d\u7684\u5e94\u7528\u7a0b\u5e8f\u4e2d\uff0c\u4f7f\u752832\u4e2a\u4e8c\u8fdb\u5236\u4f4d\uff08\u53734\u5b57\u8282\uff09\u6765\u8868\u793a\u5185\u5b58\u5730\u5740\uff0c64\u4f4d\u8f6f\u4ef6\u5219\u662f\u752864\u4e2a\u4e8c\u8fdb\u5236\u4f4d\u8868\u793a\u5185\u5b58\u5730\u5740\u3002\u4e8e\u662f\uff0c\u5f53\u6211\u4eec\u5728\u5c06\u4e00\u4e2a\u7a0b\u5e8f\u7f16\u8bd1\u4e3a64\u4f4d\u7684\u7a0b\u5e8f\u65f6\uff0c\u6709\u4e0b\u5217\u8bed\u53e5\ncout<<sizeof(int)<<\"\"<<sizeof(int*)<<\"\";\ncout<<sizeof(double)<<\"\"<<sizeof(double*)<<endl;\n\u5176\u8f93\u51fa\u4f1a\u662f____;\nA. 4 4 8 8\nB. 4 4 8 4\nC. 4 8 8 8\nD. 4 8 4 8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36385828438381157, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2821833983601388, "HuggingFaceH4/zephyr-7b-beta": 0.9336676201080552, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5323223140344981, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7030404655815304}}, {"question": "\u4e0b\u8ff0\u54ea\u4e00\u6761\u662f\u987a\u5e8f\u5b58\u50a8\u7ed3\u6784\u7684\u4f18\u70b9\uff1f____\nA. \u5b58\u50a8\u5bc6\u5ea6\u5927\nB. \u63d2\u5165\u8fd0\u7b97\u65b9\u4fbf\nC. \u5220\u9664\u8fd0\u7b97\u65b9\u4fbf\nD. \u53ef\u65b9\u4fbf\u5730\u7528\u4e8e\u5404\u79cd\u903b\u8f91\u7ed3\u6784\u7684\u5b58\u50a8\u8868\u793a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8592429636958524, "meta-math/MetaMath-Mistral-7B": 0.9968164576145543, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9999164270704373, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9280663661280882, "meta-llama/Meta-Llama-3-8B": 0.6923076736210073, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6923695061536463}}, {"question": "\u5c06\u4e00\u68f5\u6709100\u4e2a\u7ed3\u70b9\u7684\u5b8c\u5168\u4e8c\u53c9\u6811\u4ece\u6839\u8fd9\u4e00\u5c42\u5f00\u59cb\uff0c\u6bcf\u4e00\u5c42\u4e0a\u4ece\u5de6\u5230\u53f3\u4f9d\u6b21\u5bf9\u7ed3\u70b9\u8fdb\u884c\u7f16\u53f7\uff0c\u6839\u7ed3\u70b9\u7684\u7f16\u53f7\u4e3a1\uff0c\u5219\u7f16\u53f7\u4e3a49\u7684\u7ed3\u70b9\u7684\u5de6\u5b69\u5b50\u7f16\u53f7\u4e3a____\u3002\nA. 98\nB. 99\nC. 50\nD. 48\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5604219982506249, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7312099482069006}}, {"question": "\u4e0b\u9762\u54ea\u79cd\u6570\u636e\u7ed3\u6784\u6700\u9002\u5408\u7528\u4e8e\u521b\u5efa\u4e00\u4e2a\u4f18\u5148\u7ea7\u961f\u5217\uff1f____\nA. \u6808\nB. \u53cc\u5411\u94fe\u8868\nC. \u5355\u5411\u94fe\u8868\nD. \u5806\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.952197064750861, "meta-math/MetaMath-Mistral-7B": 0.9991669505238853, "itpossible/Chinese-Mistral-7B-v0.1": 0.9165360072594184, "HuggingFaceH4/zephyr-7b-beta": 0.9999915346403202, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9951221598266627, "meta-llama/Meta-Llama-3-8B": 0.9476575747070514, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9973402786125017}}, {"question": "\u5173\u4e8e\u591a\u6001\u6027\uff0c\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. C++\u8bed\u8a00\u7684\u591a\u6001\u6027\u5206\u4e3a\u7f16\u8bd1\u65f6\u7684\u591a\u6001\u6027\u548c\u8fd0\u884c\u65f6\u7684\u591a\u6001\u6027\uff1b\nB. \u8fd0\u884c\u65f6\u7684\u591a\u6001\u6027\u53ef\u901a\u8fc7\u865a\u51fd\u6570\u548c\u51fd\u6570\u91cd\u8f7d\u5b9e\u73b0\uff1b\nC. \u7f16\u8bd1\u65f6\u7684\u591a\u6001\u6027\u53ef\u901a\u8fc7\u6a21\u677f\u5b9e\u73b0\uff1b\nD. \u5b9e\u73b0\u8fd0\u884c\u65f6\u591a\u6001\u6027\u7684\u673a\u5236\u79f0\u4e3a\u52a8\u6001\u591a\u6001\u6027\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u6784\u9020\u51fd\u6570\uff0c\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u6784\u9020\u51fd\u6570\u5fc5\u987b\u6307\u5b9a\u7c7b\u578b\u8bf4\u660e\uff1b\nB. \u6784\u9020\u51fd\u6570\u7684\u51fd\u6570\u540d\u4e0e\u7c7b\u540d\u76f8\u540c\uff1b\nC. \u6784\u9020\u51fd\u6570\u53ef\u4ee5\u8bbe\u7f6e\u7f3a\u7701\u53c2\u6570\uff1b\nD. \u6784\u9020\u51fd\u6570\u53ef\u4ee5\u91cd\u8f7d\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3035988665653362, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6437934385978119, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.82556973833277}}, {"question": "\u5bf9\u4e8e\u6808\u64cd\u4f5c\u6570\u636e\u7684\u539f\u5219\u662f____\u3002\nA. \u5148\u8fdb\u5148\u51fa\nB. \u540e\u8fdb\u5148\u51fa\nC. \u540e\u8fdb\u540e\u51fa\nD. \u4e0d\u5206\u987a\u5e8f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5422334531622439, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u6808S\u548c\u961fQ\u7684\u521d\u59cb\u72b6\u6001\u5747\u4e3a\u7a7a\uff0c\u5143\u7d20abcdef\u4f9d\u6b21\u901a\u8fc7\u6808S\uff0c\u4e00\u4e2a\u5143\u7d20\u51fa\u6808\u540e\u5373\u8fdb\u961fQ\uff0c\u82e56\u4e2a\u5143\u7d20\u51fa\u6808\u7684\u5e8f\u5217\u662fcefdba\uff0c\u5219\u6808S\u7684\u5bb9\u91cf\u81f3\u5c11\u5e94\u8be5\u662f____\nA. 6\nB. 4\nC. 3\nD. 2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3454901351726419, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3403147063768956, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u9762\u5173\u4e8e\u6a21\u7248\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u7c7b\u6a21\u7248\u63d0\u4f9b\u4e86\u4e00\u79cd\u5bf9\u7c7b\u4e2d\u7c7b\u578b\u8fdb\u884c\u53c2\u6570\u5316\u7684\u65b9\u6cd5; \u5728\u5b9e\u4f8b\u5316\u6a21\u7248\u7c7b\u65f6\uff0c\u5b9e\u9645\u7684\u6570\u636e\u7c7b\u578b\u4f1a\u4ee3\u66ff\u4e0e\u7c7b\u6210\u5458\u6216\u65b9\u6cd5\u76f8\u5173\u8054\u7684\u7c7b\u578b\u53c2\u6570\nB. \u7c7b\u6a21\u7248\u4e2d\u5fc5\u987b\u5305\u542b\u7c7b\u6210\u5458\u4e0e\u7c7b\u65b9\u6cd5\nC. \u4e0d\u53ef\u4ee5\u7528\u81ea\u5b9a\u4e49\u7684\u6570\u636e\u7c7b\u578b\u5b9e\u4f8b\u5316\u4e00\u4e2a\u6a21\u7248\u7c7b\nD. \u7c7b\u6a21\u7248\u4e2d\u7c7b\u65b9\u6cd5\u7684\u53c2\u6570\u5fc5\u987b\u7528\u5360\u4f4d\u7b26\u66ff\u4ee3\uff0c\u800c\u4e0d\u80fd\u4f7f\u7528\u5b9e\u9645\u6570\u636e\u7c7b\u578b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7994316346361365, "meta-math/MetaMath-Mistral-7B": 0.9487936307037289, "itpossible/Chinese-Mistral-7B-v0.1": 0.5484304896840178, "HuggingFaceH4/zephyr-7b-beta": 0.9999041091260699, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.96176751734654, "meta-llama/Meta-Llama-3-8B": 0.7885726504884474, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9903261535610994}}, {"question": "\u73b0\u6709\u4e00\u68f5\u65e0\u91cd\u590d\u5173\u952e\u5b57\u7684AVL\u6811\uff0c\u5bf9\u5176\u8fdb\u884c\u4e2d\u5e8f\u904d\u5386\u53ef\u5f97\u5230\u4e00\u4e2a\u964d\u5e8f\u5e8f\u5217\u3002\u4e0b\u5217\u5173\u4e8e\u8be5AVL\u6811\u7684\u53d9\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f\uff1a____\nA. \u6839\u7ed3\u70b9\u7684\u5ea6\u4e00\u5b9a\u4e3a 2\nB. \u6811\u4e2d\u6700\u5c0f\u5143\u7d20\u4e00\u5b9a\u662f\u53f6\u7ed3\u70b9\nC. \u6700\u540e\u63d2\u5165\u7684\u5143\u7d20\u4e00\u5b9a\u662f\u53f6\u7ed3\u70b9\nD. \u6811\u4e2d\u6700\u5927\u5143\u7d20\u4e00\u5b9a\u662f\u65e0\u5de6\u5b50\u6811\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3013812289234467, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.889385295420177, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4124578775795746, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8ba1\u7b97\u7b97\u6cd5\u7684\u65f6\u95f4\u590d\u6742\u5ea6\u662f\u5c5e\u4e8e\u4e00\u79cd____\u7684\u65b9\u6cd5\u3002\nA. \u4e8b\u524d\u7edf\u8ba1\nB. \u4e8b\u524d\u5206\u6790\u4f30\u7b97\nC. \u4e8b\u540e\u7edf\u8ba1\nD. \u4e8b\u540e\u5206\u6790\u4f30\u7b97\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4308879653813403, "meta-math/MetaMath-Mistral-7B": 0.7500304042566394, "itpossible/Chinese-Mistral-7B-v0.1": 0.4716472028482283, "HuggingFaceH4/zephyr-7b-beta": 0.9938034713924481, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6079137175595952, "meta-llama/Meta-Llama-3-8B": 0.6177599338144183, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5047\u5b9aAB\u4e3a\u4e00\u4e2a\u7c7b\uff0cr2\u662fAB\u7c7b\u7684\u5bf9\u8c61\uff0c\u6267\u884c\u201cAB r1=3;\u201d\u65f6\u5c06\u81ea\u52a8\u8c03\u7528\u8be5\u7c7b\u7684____\nA. \u5e26\u4e00\u4e2a\u6574\u578b\u53c2\u6570\u7684\u6784\u9020\u51fd\u6570\nB. \u65e0\u53c2\u6784\u9020\u51fd\u6570\nC. \u8d4b\u503c\u8fd0\u7b97\u7b26\u91cd\u8f7d\u51fd\u6570\nD. \u62f7\u8d1d\u6784\u9020\u51fd\u6570\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6392\u5e8f\u7b97\u6cd5\u4e2d\uff0c\u5143\u7d20\u7684\u79fb\u52a8\u6b21\u6570\u4e0e\u5173\u952e\u5b57\u7684\u521d\u59cb\u6392\u5217\u6b21\u5e8f\u65e0\u5173\u7684\u662f____\nA. \u76f4\u63a5\u63d2\u5165\u6392\u5e8f\nB. \u5192\u6ce1\u6392\u5e8f\nC. \u57fa\u6570\u6392\u5e8f\nD. \u5feb\u901f\u6392\u5e8f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3611581904220661, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8786431929615934, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6512744953624392, "meta-llama/Meta-Llama-3-8B": 0.6890595876213337, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.67876269387151}}, {"question": "\u7ebf\u6027\u94fe\u8868\u4e0d\u5177\u6709\u7684\u7279\u70b9\u662f____\u3002\nA. \u968f\u673a\u8bbf\u95ee\nB. \u4e0d\u5fc5\u4e8b\u5148\u4f30\u8ba1\u6240\u9700\u5b58\u50a8\u7a7a\u95f4\u5927\u5c0f\nC. \u63d2\u5165\u4e0e\u5220\u9664\u65f6\u4e0d\u5fc5\u79fb\u52a8\u5143\u7d20\nD. \u6240\u9700\u7a7a\u95f4\u4e0e\u7ebf\u6027\u8868\u957f\u5ea6\u6210\u6b63\u6bd4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28343502843642576, "meta-math/MetaMath-Mistral-7B": 0.5666417441354337, "itpossible/Chinese-Mistral-7B-v0.1": 0.40322669517609055, "HuggingFaceH4/zephyr-7b-beta": 0.9994329230622992, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.553076263398462, "meta-llama/Meta-Llama-3-8B": 0.3632122790984034, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4478421568990153}}, {"question": "\u8bbe\u6709\u4e00\u4e2a\u9012\u5f52\u7b97\u6cd5\u5982\u4e0b\uff1a\nint fact(int n){\nif(n<=0)return 1;\nelse return n*fact(n-1);\n}\n\u4e0b\u9762\u6b63\u786e\u7684\u53d9\u8ff0\u662f____\nA. \u8ba1\u7b97fact(n)\u9700\u8981\u6267\u884cn\u6b21\u9012\u5f52\nB. fact(7)=5040\nC. \u6b64\u9012\u5f52\u7b97\u6cd5\u6700\u591a\u53ea\u80fd\u8ba1\u7b97\u5230fact(8)\nD. \u4ee5\u4e0a\u7ed3\u8bba\u90fd\u4e0d\u5bf9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4380958753810311, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728C++\u4e2d\uff0c\u4e00\u4e2a\u51fd\u6570\u4e3avoid f(int=1,char='a'),\u53e6\u4e00\u4e2a\u51fd\u6570\u4e3avoid f(int),\u5219\u5b83\u4eec____\u3002\nA. \u4e0d\u80fd\u5728\u540c\u4e00\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\nB. \u53ef\u4ee5\u5728\u540c\u4e00\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\u5e76\u53ef\u91cd\u8f7d\nC. \u53ef\u4ee5\u5728\u540c\u4e00\u7a0b\u5e8f\u4e2d\u5b9a\u4e49\uff0c\u4f46\u4e0d\u53ef\u91cd\u8f7d\nD. \u4ee5\u4e0a\u8bf4\u6cd5\u90fd\u4e0d\u6b63\u786e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7160819033674196, "meta-math/MetaMath-Mistral-7B": 0.9921868615561101, "itpossible/Chinese-Mistral-7B-v0.1": 0.7924214703795, "HuggingFaceH4/zephyr-7b-beta": 0.9998110324426227, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.927168735713033, "meta-llama/Meta-Llama-3-8B": 0.5150773335103445, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u4e00\u4e2a\u6709\u5411\u56fe\u7684\u90bb\u63a5\u77e9\u9635\u8868\u793a\uff0c\u8981\u5220\u9664\u6240\u6709\u4ece\u7b2ci\u4e2a\u7ed3\u70b9\u53d1\u51fa\u7684\u8fb9\uff0c\u5e94____\u3002\nA. \u5c06\u90bb\u63a5\u77e9\u9635\u7684\u7b2ci\u884c\u5220\u9664\nB. \u5c06\u90bb\u63a5\u77e9\u9635\u7684\u7b2ci\u884c\u5143\u7d20\u5168\u90e8\u7f6e\u4e3a0\nC. \u5c06\u90bb\u63a5\u77e9\u9635\u7684\u7b2ci\u5217\u5220\u9664\nD. \u5c06\u90bb\u63a5\u77e9\u9635\u7684\u7b2ci\u5217\u5143\u7d20\u5168\u90e8\u7f6e\u4e3a0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.323661650661437, "meta-math/MetaMath-Mistral-7B": 0.37185500165591856, "itpossible/Chinese-Mistral-7B-v0.1": 0.5436656961367015, "HuggingFaceH4/zephyr-7b-beta": 0.957526758815351, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44966497550277706, "meta-llama/Meta-Llama-3-8B": 0.4243954712122014, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.812660961021655}}, {"question": "\u2014\u7ec4\u5173\u952e\u5b57\u5e8f\u5217A(12,14,3,16,8,7,10,17,5,11,9,6,13,15,4),\u4e3a\u6392\u6210\u9012\u589e\u5e8f\u5229\u7528\u5806\u6392\u5e8f\u7684\u65b9\u6cd5\u5efa\u7acb\u7684\u521d\u59cb\u7684\u5806\u4e3a____\nA. \uff08 3\uff0c 4\uff0c 5, 8\uff0c 9\uff0c 7, 6, 17\uff0c 16\uff0c 14\uff0c 11\uff0c 12\uff0c 13\uff0c 15\uff0c 10 )\nB. ( 3\uff0c 5, 4, 8, 9\uff0c 7, 6\uff0c 17\uff0c 16\uff0c 14, 11\uff0c 12, 13\uff0c 15\uff0c 10 )\nC. ( 17, 16, 15, 14, 11, 13, 10, 12, 5, 8, 9, 6, 7\uff0c 3\uff0c 4 )\nD. ( 17, 16, 14, 15, 11, 13, 10, 12, 5, 8, 9, 6, 7, 3, 4 )\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3060136256597631, "HuggingFaceH4/zephyr-7b-beta": 0.9734975581207816, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5\u4e00\u4e2a\u7ebf\u6027\u8868\u4e2d\u6700\u5e38\u7528\u7684\u64cd\u4f5c\u662f\u53d6\u7b2c1\u4e2a\u5143\u7d20\u548c\u6211\u7b2c1\u4e2a\u5143\u7d20\u7684\u524d\u8d8b\u5143\u7d20\uff0c\u5219\u91c7\u7528____\u5b58\u50a8\u65b9\u5f0f\u6700\u8282\u7701\u65f6\u95f4\u3002\nA. \u987a\u5e8f\u8868\nB. \u5355\u94fe\u8868\nC. \u53cc\u94fe\u8868\nD. \u5355\u5faa\u73af\u94fe\u8868\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.42276111885526063, "HuggingFaceH4/zephyr-7b-beta": 0.4241087131299134, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.34668920612958265, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u03b1\u7c92\u5b50\u5728\u52a0\u901f\u5668\u4e2d\u88ab\u52a0\u901f\uff0c\u5f53\u5176\u8d28\u91cf\u4e3a\u9759\u6b62\u8d28\u91cf\u7684 3 \u500d\u65f6\uff0c\u5176\u52a8\u80fd\u4e3a\u9759\u6b62\u80fd\u91cf\u7684____\nA. 2\u500d\nB. 3\u500d\nC. 4\u500d\nD. 5\u500d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u4e09\u4e2a\u76f4\u5f84\u76f8\u540c\u7684\u91d1\u5c5e\u5c0f\u7403\uff0c\u5c0f\u74031\u548c2\u5e26\u7b49\u91cf\u540c\u53f7\u7535\u8377\uff0c\u4e24\u8005\u7684\u8ddd\u79bb\u8fdc\u5927\u4e8e\u5c0f\u7403\u76f4\u5f84\uff0c\u76f8\u4e92\u4f5c\u7528\u529b\u4e3aF\u3002\u5c0f\u74033\u4e0d\u5e26\u7535\uff0c\u88c5\u6709\u7edd\u7f18\u624b\u67c4\uff0e\u7528\u5c0f\u74033\u5148\u548c\u5c0f\u74031\u78b0\u4e00\u4e0b\uff0c\u63a5\u7740\u53c8\u548c\u5c0f\u74032\u78b0\u4e00\u4e0b\uff0c\u7136\u540e\u79fb\u53bb\u3002\u5219\u6b64\u65f6\u5c0f\u74031\u548c2\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u529b\u4e3a____\nA. F/4\nB. 3F/8\nC. F/2\nD. 3F/4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3035988665653362, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u53cc\u7f1d\u5e72\u6d89\u5b9e\u9a8c\u4e2d\uff0c\u4e24\u6761\u7f1d\u7684\u5bbd\u5ea6\u539f\u6765\u662f\u76f8\u7b49\u7684\u3002\u82e5\u5176\u4e2d\u4e00\u7f1d\u7684\u5bbd\u5ea6\u7565\u53d8\u7a84(\u7f1d\u4e2d\u5fc3\u4f4d\u7f6e\u4e0d\u53d8)\uff0c\u5219____\nA. \u5e72\u6d89\u6761\u7eb9\u7684\u95f4\u8ddd\u53d8\u5bbd\nB. \u5e72\u6d89\u6761\u7eb9\u7684\u95f4\u8ddd\u53d8\u7a84\nC. \u5e72\u6d89\u6761\u7eb9\u7684\u95f4\u8ddd\u4e0d\u53d8\uff0c\u4f46\u539f\u6781\u5c0f\u5904\u7684\u5f3a\u5ea6\u4e0d\u518d\u4e3a\u96f6\nD. \u4e0d\u518d\u53d1\u751f\u5e72\u6d89\u73b0\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u7528\u9891\u7387\u4e3a\u03bd_1\u548c\u03bd_2\u7684\u4e24\u79cd\u5355\u8272\u5149\uff0c\u5148\u540e\u7167\u5c04\u540c\u4e00\u79cd\u91d1\u5c5e\u5747\u80fd\u4ea7\u751f\u5149\u7535\u6548\u5e94\u3002\u5df2\u77e5\u91d1\u5c5e\u7684\u7ea2\u9650\u9891\u7387\u4e3a\u03bd_0\uff0c\u6d4b\u5f97\u4e24\u6b21\u7167\u5c04\u65f6\u7684\u904f\u6b62\u7535\u538b|U_{a2}|=2|U_{a1}|\uff0c\u5219\u8fd9\u4e24\u79cd\u5355\u8272\u5149\u7684\u9891\u7387\u6709\u5982\u4e0b\u5173\u7cfb\uff1a____\nA. \u03bd_2=\u03bd_1-\u03bd_0\nB. \u03bd_2=\u03bd_1+\u03bd_0\nC. \u03bd_2=2\u03bd_1-\u03bd_0\nD. \u03bd_2=\u03bd_1-2\u03bd_0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5924236179031722, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e24\u74f6\u4e0d\u540c\u79cd\u7c7b\u7684\u7406\u60f3\u6c14\u4f53\uff0c\u5b83\u4eec\u7684\u6e29\u5ea6\u548c\u538b\u5f3a\u90fd\u76f8\u540c\uff0c\u4f46\u4f53\u79ef\u4e0d\u540c\uff0c\u5219\u5355\u4f4d\u4f53\u79ef\u5185\u7684\u6c14\u4f53\u5206\u5b50\u6570$n$\uff0c\u5355\u4f4d\u4f53\u79ef\u5185\u7684\u6c14\u4f53\u5206\u5b50\u7684\u603b\u5e73\u52a8\u52a8\u80fd($E_K/V$)\uff0c\u5355\u4f4d\u4f53\u79ef\u5185\u7684\u6c14\u4f53\u8d28\u91cf$\\rho$\uff0c\u5206\u522b\u6709\u5982\u4e0b\u5173\u7cfb\uff1a____\nA. $n$\u4e0d\u540c\uff0c($E_K/V$)\u4e0d\u540c\uff0c$\\rho$\u4e0d\u540c\nB. $n$\u4e0d\u540c\uff0c($E_K/V$)\u4e0d\u540c\uff0c$\\rho$\u76f8\u540c\nC. $n$\u76f8\u540c\uff0c($E_K/V$)\u76f8\u540c\uff0c$\\rho$\u4e0d\u540c\nD. $n$\u76f8\u540c\uff0c($E_K/V$)\u76f8\u540c\uff0c$\\rho$\u76f8\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u58f0\u6ce2\u901a\u8fc7\u7406\u60f3\u6c14\u4f53\u7684\u901f\u7387\u6b63\u6bd4\u4e8e\u6c14\u4f53\u5206\u5b50\u7684\u70ed\u8fd0\u52a8\u5e73\u5747\u901f\u7387\uff0c\u5219\u58f0\u6ce2\u901a\u8fc7\u5177\u6709\u76f8\u540c\u6e29\u5ea6\u7684\u6c27\u6c14\u548c\u6c22\u6c14\u7684\u901f\u7387\u4e4b\u6bd4$V_{O_2}/V_{H_2}$\u4e3a____\nA. 1\nB. 1/2\nC. 1/3\nD. 1/4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e24\u5757\u5e73\u73bb\u7483\u6784\u6210\u7a7a\u6c14\u5288\u5f62\u819c\uff0c\u5de6\u8fb9\u4e3a\u68f1\u8fb9\uff0c\u7528\u5355\u8272\u5e73\u884c\u5149\u5782\u76f4\u5165\u5c04\u3002\u82e5\u4e0a\u9762\u7684\u5e73\u73bb\u7483\u4ee5\u68f1\u8fb9\u4e3a\u8f74\uff0c\u6cbf\u9006\u65f6\u9488\u65b9\u5411\u4f5c\u5fae\u5c0f\u8f6c\u52a8\uff0c\u5219\u5e72\u6d89\u6761\u7eb9\u7684____\nA. \u95f4\u9694\u53d8\u5c0f\uff0c\u5e76\u5411\u68f1\u8fb9\u65b9\u5411\u5e73\u79fb\nB. \u95f4\u9694\u53d8\u5927\uff0c\u5e76\u5411\u8fdc\u79bb\u68f1\u8fb9\u65b9\u5411\u5e73\u79fb\nC. \u95f4\u9694\u4e0d\u53d8\uff0c\u5411\u68f1\u8fb9\u65b9\u5411\u5e73\u79fb\nD. \u95f4\u9694\u53d8\u5c0f\uff0c\u5e76\u5411\u8fdc\u79bb\u68f1\u8fb9\u65b9\u5411\u5e73\u79fb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32800055807227485, "meta-math/MetaMath-Mistral-7B": 0.5251619768578105, "itpossible/Chinese-Mistral-7B-v0.1": 0.3182896805125179, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4503887184158779, "meta-llama/Meta-Llama-3-8B": 0.3331832353540621, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6293996157507041}}, {"question": "\u5728\u53cc\u7f1d\u5e72\u6d89\u5b9e\u9a8c\u4e2d\uff0c\u4e24\u7f1d\u95f4\u8ddd\u4e3ad\uff0c\u53cc\u7f1d\u4e0e\u5c4f\u5e55\u7684\u8ddd\u79bb\u4e3aD(D>>d)\uff0c\u5355\u8272\u5149\u6ce2\u957f\u4e3a\u03bb\uff0c\u5c4f\u5e55\u4e0a\u76f8\u90bb\u660e\u6761\u7eb9\u4e4b\u95f4\u7684\u8ddd\u79bb\u4e3a____\nA. \u03bbD/d\nB. \u03bbd/D\nC. \u03bbD/(2d)\nD. \u03bbd/(2D)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2866128117777278, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.44934428842773}}, {"question": "\u5173\u4e8e\u7535\u573a\u5f3a\u5ea6\u5b9a\u4e49\u5f0fE=F/q0\uff0c\u4e0b\u5217\u8bf4\u6cd5\u4e2d\u54ea\u4e2a\u662f\u6b63\u786e\u7684\uff1f____\nA. \u573a\u5f3aE\u7684\u5927\u5c0f\u4e0e\u8bd5\u63a2\u7535\u8377q0\u7684\u5927\u5c0f\u6210\u53cd\u6bd4\nB. \u5bf9\u573a\u4e2d\u67d0\u70b9\uff0c\u8bd5\u63a2\u7535\u8377\u53d7\u529bF\u4e0eq0\u7684\u6bd4\u503c\u4e0d\u56e0q0\u800c\u53d8\nC. \u8bd5\u63a2\u7535\u8377\u53d7\u529bF\u7684\u65b9\u5411\u5c31\u662f\u573a\u5f3aE\u7684\u65b9\u5411\nD. \u82e5\u573a\u4e2d\u67d0\u70b9\u4e0d\u653e\u8bd5\u63a2\u7535\u8377q0\uff0c\u5219F=0\uff0c\u4ece\u800cE=0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.32783897398951767, "HuggingFaceH4/zephyr-7b-beta": 0.6271191282018009, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u6709\u4e00\u4e2a\u5e26\u6b63\u7535\u7684\u5bfc\u4f53\u7403\u58f3\uff0c\u5f53\u7403\u58f3\u5185\u5145\u6ee1\u7535\u4ecb\u8d28\u3001\u7403\u58f3\u5916\u662f\u771f\u7a7a\u65f6\uff0c\u7403\u58f3\u5916\u4e00\u70b9\u7684\u573a\u5f3a\u5927\u5c0f\u548c\u7535\u52bf\u7528E1\uff0cU1\u8868\u793a\uff1b\u800c\u7403\u58f3\u5185\u3001\u5916\u5747\u4e3a\u771f\u7a7a\u65f6\uff0c\u58f3\u5916\u4e00\u70b9\u7684\u573a\u5f3a\u5927\u5c0f\u548c\u7535\u52bf\u7528E2\uff0cU2\u8868\u793a\uff0c\u5219\u4e24\u79cd\u60c5\u51b5\u4e0b\u58f3\u5916\u540c\u4e00\u70b9\u5904\u7684\u573a\u5f3a\u5927\u5c0f\u548c\u7535\u52bf\u5927\u5c0f\u7684\u5173\u7cfb\u4e3a____\nA. E1 = E2\uff0cU1 = U2\nB. E1 = E2\uff0cU1 > U2\nC. E1 > E2\uff0cU1 > U2\nD. E1 < E2\uff0cU1 < U2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.27240321009873075, "meta-math/MetaMath-Mistral-7B": 0.5149178195362778, "itpossible/Chinese-Mistral-7B-v0.1": 0.31828968051251794, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6039639416912119, "meta-llama/Meta-Llama-3-8B": 0.25756620677129083, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5982\u679c\u5728\u7a7a\u6c14\u5e73\u884c\u677f\u7535\u5bb9\u5668\u7684\u4e24\u6781\u677f\u95f4\u5e73\u884c\u5730\u63d2\u5165\u4e00\u5757\u4e0e\u6781\u677f\u9762\u79ef\u76f8\u540c\u7684\u91d1\u5c5e\u677f\uff0c\u5219\u7531\u4e8e\u91d1\u5c5e\u677f\u7684\u63d2\u5165\u53ca\u5176\u76f8\u5bf9\u6781\u677f\u6240\u653e\u4f4d\u7f6e\u7684\u4e0d\u540c\uff0c\u5bf9\u7535\u5bb9\u5668\u7535\u5bb9\u7684\u5f71\u54cd\u4e3a\uff1a____\nA. \u4f7f\u7535\u5bb9\u51cf\u5c0f\uff0c\u4f46\u4e0e\u91d1\u5c5e\u677f\u76f8\u5bf9\u6781\u677f\u7684\u4f4d\u7f6e\u65e0\u5173\nB. \u4f7f\u7535\u5bb9\u51cf\u5c0f\uff0c\u4e14\u4e0e\u91d1\u5c5e\u677f\u76f8\u5bf9\u6781\u677f\u7684\u4f4d\u7f6e\u6709\u5173\nC. \u4f7f\u7535\u5bb9\u589e\u5927\uff0c\u4f46\u4e0e\u91d1\u5c5e\u677f\u76f8\u5bf9\u6781\u677f\u7684\u4f4d\u7f6e\u65e0\u5173\nD. \u4f7f\u7535\u5bb9\u589e\u5927\uff0c\u4e14\u4e0e\u91d1\u5c5e\u677f\u76f8\u5bf9\u6781\u677f\u7684\u4f4d\u7f6e\u6709\u5173\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u6ce2\u957f\u4e3a\u03bb\u7684\u9a7b\u6ce2\u4e2d\u4e24\u4e2a\u76f8\u90bb\u6ce2\u8282\u4e4b\u95f4\u7684\u8ddd\u79bb\u4e3a\uff1a____\nA. \u03bb\nB. 3\u03bb/4\nC. \u03bb/2\nD. \u03bb/4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38938704019880777, "meta-math/MetaMath-Mistral-7B": 0.5820227011360619, "itpossible/Chinese-Mistral-7B-v0.1": 0.31712010892822357, "HuggingFaceH4/zephyr-7b-beta": 0.44272192335243965, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4846426077145077, "meta-llama/Meta-Llama-3-8B": 0.36078609119776345, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4466121292582237}}, {"question": "\u7528\u5f3a\u5ea6\u4e3aI\uff0c\u6ce2\u957f\u4e3a\u03bb\u7684X\u5c04\u7ebf(\u4f26\u7434\u5c04\u7ebf)\u5206\u522b\u7167\u5c04\u9502(Z=3)\u548c\u94c1(Z=26)\uff0e\u82e5\u5728\u540c\u4e00\u6563\u5c04\u89d2\u4e0b\u6d4b\u5f97\u5eb7\u666e\u987f\u6563\u5c04\u7684X\u5c04\u7ebf\u6ce2\u957f\u5206\u522b\u4e3a\u03bb_{Li}\u548c\u03bb_{Fe}(\u03bb_{Li}\uff0c\u03bb_{Fe}>\u03bb)\uff0c\u5b83\u4eec\u5bf9\u5e94\u7684\u5f3a\u5ea6\u5206\u522b\u4e3aI_{Li}\u548cI_{Fe}\uff0c\u5219____\nA. \u03bb_{Li}>\u03bb_{Fe}, I_{Li}<I_{Fe}\nB. \u03bb_{Li}=\u03bb_{Fe}, I_{Li}=I_{Fe}\nC. \u03bb_{Li}=\u03bb_{Fe}, I_{Li}>I_{Fe}\nD. \u03bb_{Li}<\u03bb_{Fe}, I_{Li}>I_{Fe}\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.310313193127302, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3293968358831398}}, {"question": "\u4e24\u4e2a\u76f8\u8ddd\u4e0d\u592a\u8fdc\u7684\u5e73\u9762\u5706\u7ebf\u5708\uff0c\u600e\u6837\u53ef\u4f7f\u5176\u4e92\u611f\u7cfb\u6570\u8fd1\u4f3c\u4e3a\u96f6\uff1f____\uff08\u8bbe\u5176\u4e2d\u4e00\u7ebf\u5708\u7684\u8f74\u7ebf\u6070\u901a\u8fc7\u53e6\u4e00\u7ebf\u5708\u7684\u5706\u5fc3\uff09\nA. \u4e24\u7ebf\u5708\u7684\u8f74\u7ebf\u4e92\u76f8\u5e73\u884c\u653e\u7f6e\nB. \u4e24\u7ebf\u5708\u5e76\u8054\nC. \u4e24\u7ebf\u5708\u7684\u8f74\u7ebf\u4e92\u76f8\u5782\u76f4\u653e\u7f6e\nD. \u4e24\u7ebf\u5708\u4e32\u8054\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5025449998467665, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6567231676467752, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4696891965901002, "meta-llama/Meta-Llama-3-8B": 0.4310339313236754, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7318152583726605}}, {"question": "\u4e00\u7279\u6b8a\u7684\u8f7b\u5f39\u7c27\uff0c\u5f39\u6027\u529bF=-kx3\uff0ck\u4e3a\u4e00\u5e38\u91cf\u7cfb\u6570\uff0cx\u4e3a\u4f38\u957f(\u6216\u538b\u7f29)\u91cf\u3002\u73b0\u5c06\u5f39\u7c27\u6c34\u5e73\u653e\u7f6e\u4e8e\u5149\u6ed1\u7684\u6c34\u5e73\u9762\u4e0a\uff0c\u4e00\u7aef\u56fa\u5b9a\uff0c\u4e00\u7aef\u4e0e\u8d28\u91cf\u4e3am\u7684\u6ed1\u5757\u76f8\u8fde\u800c\u5904\u4e8e\u81ea\u7136\u957f\u5ea6\u72b6\u6001\u3002\u4eca\u6cbf\u5f39\u7c27\u957f\u5ea6\u65b9\u5411\u7ed9\u6ed1\u5757\u4e00\u4e2a\u51b2\u91cf\uff0c\u4f7f\u5176\u83b7\u5f97\u4e00\u901f\u5ea6v\uff0c\u538b\u7f29\u5f39\u7c27\uff0c\u5219\u5f39\u7c27\u88ab\u538b\u7f29\u7684\u6700\u5927\u957f\u5ea6\u4e3a____\nA. \\sqrt{m/k}v\nB. \\sqrt{k/m}v\nC. (4mv/k)^(1/4)\nD. (2mv^2/k)^(1/4)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4006796757977685, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.37354501646787847, "HuggingFaceH4/zephyr-7b-beta": 0.8985846837253846, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.33482349867891054, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u4e2a\u5706\u9525\u6446\u7684\u6446\u7ebf\u957f\u4e3al\uff0c\u6446\u7ebf\u4e0e\u7ad6\u76f4\u65b9\u5411\u7684\u5939\u89d2\u6052\u4e3a\u03b8\uff0c\u5982\u56fe\u6240\u793a\u3002\u5219\u6446\u9524\u8f6c\u52a8\u7684\u5468\u671f\u4e3a____\nA. $\\sqrt{l/g}$\nB. $\\sqrt{l\\cos \u03b8/g}$\nC. $2\u03c0\\sqrt{l/g}$\nD. $2\u03c0\\sqrt{l\\cos\u03b8/g}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4156323572915429, "meta-math/MetaMath-Mistral-7B": 0.4633111808340899, "itpossible/Chinese-Mistral-7B-v0.1": 0.3331832353540621, "HuggingFaceH4/zephyr-7b-beta": 0.9788575101320345, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.39267124259386976, "meta-llama/Meta-Llama-3-8B": 0.3881207341645942, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u628a\u4e00\u5e73\u51f8\u900f\u955c\u653e\u5728\u5e73\u73bb\u7483\u4e0a\uff0c\u6784\u6210\u725b\u987f\u73af\u88c5\u7f6e\uff0e\u5f53\u5e73\u51f8\u900f\u955c\u6162\u6162\u5730\u5411\u4e0a\u5e73\u79fb\u65f6\uff0c\u7531\u53cd\u5c04\u5149\u5f62\u6210\u7684\u725b\u987f\u73af____\nA. \u5411\u4e2d\u5fc3\u6536\u7f29\uff0c\u6761\u7eb9\u95f4\u9694\u53d8\u5c0f\nB. \u5411\u4e2d\u5fc3\u6536\u7f29\uff0c\u73af\u5fc3\u5448\u660e\u6697\u4ea4\u66ff\u53d8\u5316\nC. \u5411\u5916\u6269\u5f20\uff0c\u73af\u5fc3\u5448\u660e\u6697\u4ea4\u66ff\u53d8\u5316\nD. \u5411\u5916\u6269\u5f20\uff0c\u6761\u7eb9\u95f4\u9694\u53d8\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2821833983601388, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8e\u6cbf\u66f2\u7ebf\u8fd0\u52a8\u7684\u7269\u4f53\uff0c\u4ee5\u4e0b\u51e0\u79cd\u8bf4\u6cd5\u4e2d\u54ea\u4e00\u79cd\u662f\u6b63\u786e\u7684____\nA. \u5207\u5411\u52a0\u901f\u5ea6\u5fc5\u4e0d\u4e3a\u96f6\nB. \u6cd5\u5411\u52a0\u901f\u5ea6\u5fc5\u4e0d\u4e3a\u96f6\uff08\u62d0\u70b9\u5904\u9664\u5916\uff09\nC. \u7531\u4e8e\u901f\u5ea6\u6cbf\u5207\u7ebf\u65b9\u5411\uff0c\u6cd5\u5411\u5206\u901f\u5ea6\u5fc5\u4e3a\u96f6\uff0c\u56e0\u6b64\u6cd5\u5411\u52a0\u901f\u5ea6\u5fc5\u4e3a\u96f6\nD. \u82e5\u7269\u4f53\u4f5c\u5300\u901f\u7387\u8fd0\u52a8\uff0c\u5176\u603b\u52a0\u901f\u5ea6\u5fc5\u4e3a\u96f6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5269642010108049, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4086606111719461}}, {"question": "\u6709\u4e09\u4e2a\u76f4\u5f84\u76f8\u540c\u7684\u91d1\u5c5e\u5c0f\u7403\uff0e\u5c0f\u74031\u548c\u5c0f\u74032\u5e26\u7b49\u91cf\u5f02\u53f7\u7535\u8377\uff0c\u4e24\u8005\u7684\u8ddd\u79bb\u8fdc\u5927\u4e8e\u5c0f\u7403\u76f4\u5f84\uff0c\u76f8\u4e92\u4f5c\u7528\u529b\u4e3aF\uff0e\u5c0f\u74033\u4e0d\u5e26\u7535\u5e76\u88c5\u6709\u7edd\u7f18\u624b\u67c4\uff0e\u7528\u5c0f\u74033\u5148\u548c\u5c0f\u74031\u78b0\u4e00\u4e0b\uff0c\u63a5\u7740\u53c8\u548c\u5c0f\u74032\u78b0\u4e00\u4e0b\uff0c\u7136\u540e\u79fb\u53bb\uff0e\u5219\u6b64\u65f6\u5c0f\u74031\u548c2\u4e4b\u95f4\u7684\u76f8\u4e92\u4f5c\u7528\u529b\u4e3a____\nA. 0\nB. F/4\nC. F/3\nD. F/2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "$HO_2$\u7684\u6cb8\u70b9\u6bd4$H_2S$\u7684\u9ad8,\u53ef\u4ee5\u4ece____\u89d2\u5ea6\u6765\u8fdb\u884c\u89e3\u91ca\u3002\nA. \u5171\u4ef7\u952e\u7262\u56fa\nB. \u53d8\u5f62\u6027\nC. \u6c22\u952e\nD. \u5206\u5b50\u95f4\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2866128117777278, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5796433131624419}}, {"question": "$Mg(OH)_2$\u9971\u548c\u6eb6\u6db2\u4e2d\u7684$[OH^-]=10^{-4}mol/dm^3$,\u82e5\u5f80\u8be5\u6eb6\u6db2\u4e2d\u52a0\u5165NaOH\u6eb6\u6db2,\u4f7f\u6eb6\u6db2\u4e2d$[OH^-]$\u7684\u6d53\u5ea6\u53d8\u4e3a\u539f\u6765\u768410\u500d,\u5219$Mg(OH)_2$\u7684\u6eb6\u89e3\u5ea6\u5728\u7406\u8bba\u4e0a\u5c06____\nA. \u53d8\u4e3a\u539f\u6765\u7684$10^{-3}$\u500d\nB. \u53d8\u4e3a\u539f\u6765\u7684$10^{-2}$\u500d\nC. \u53d8\u4e3a\u539f\u6765\u7684$10$\u500d\nD. \u4e0d\u53d1\u751f\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29539205153207015, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f30\u8ba1\u4e0b\u5217\u5206\u5b50\u6216\u79bb\u5b50\u4e2d\uff0c\u952e\u89d2\u6700\u5c0f\u7684\u662f____\nA. $NH_3$\nB. $NO_3^{-}$\nC. $NF_3$\nD. $NCl_3$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3160427140241836, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.28661281177772774, "HuggingFaceH4/zephyr-7b-beta": 0.5126263708225359, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3306562312783846, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5$K_b^{\\theta}(NH_3\u00b7H_2O)=1.8\u00d710^{-5}$\uff0c\u7528$NH_3\u00b7H_2O$\u548c$NH_4Cl$\u914d\u5236pH=9.00\u7684\u7f13\u51b2\u6eb6\u6db2\u65f6\uff0cc($NH_3\u00b7H_2O$)/c($NH_4Cl$)=____\nA. 5.6\nB. 0.56\nC. 1.8\nD. 3.6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.34031470637689565, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3993599173585029}}, {"question": "\u6839\u636e\u9178\u78b1\u8d28\u5b50\u7406\u8bba\u3001HCI\u3001HAc\u548c$NH_4^+$\u9178\u6027\u7531\u5f31\u5230\u5f3a\u7684\u987a\u5e8f\u4e3a____\nA. $NH_4^+<HAc<HCl$\nB. $HAc<HCl<NH_4^+$\nC. $NH_4^+<HCl<HAc$\nD. $HAc<NH_4^+<HCl$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8752890013107305}}, {"question": "\u4e8c\u6c27\u5316\u6c2e\u901a\u5165NaOH\u6eb6\u6db2\uff0c\u5f97\u5230\u7684\u4e3b\u8981\u4ea7\u7269\u662f____\nA. $NaNO_2$\nB. $NaNO_2$\u548c$O_2$\nC. $NaNO_3$\u548cNO\nD. $NaNO_3$\u548c$NaNO_2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3976501684312547, "meta-math/MetaMath-Mistral-7B": 0.4087009733881603, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9759347525534978, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36871012025740935, "meta-llama/Meta-Llama-3-8B": 0.37106890620496596, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5$[ML_4]^{2+}$\u7684$K_f=a$\uff0c$[MY_4]^{2-}$\u7684$K_f=b$\uff0c\u5219\u53cd\u5e94$[ML_4]^{2+}+4Y^-=[MY_4]^{2-}+4L$\u7684\u5e73\u8861\u5e38\u6570K\u4e3a____\nA. ab\nB. a+b\nC. a/b\nD. b/a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u6eb6\u6db2\u7684pH=0.04,\u5219\u5176\u4e2d$H^+$\u7684\u6d53\u5ea6\u4e3a____\nA. $0.912mol/dm^3$\nB. $0.91mol/dm^3$\nC. $0.9mol/dm^3$\nD. $1.1mol/dm^3$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.28850952576306876, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728573K\u65f6\uff0c\u53cd\u5e94$N_2(g)+3H_2(g)\\rightleftharpoons2NH_3(g)$\u7684$\u0394_rG_m^{\\theta}=21.93kJ\u00b7mol^{-1}$\uff0c\u5219\u53cd\u5e94\u7684\u7ecf\u9a8c\u5e73\u8861\u5e38\u6570$K_c/(mol\u00b7dm^{-3})^2$\u4e3a____\nA. $4.5\u00d710^{-6}$\nB. $1.0\u00d710^{-2}$\nC. $1.9\u00d710^{-1}$\nD. 22.12\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2821833983601388, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u5bf9\u542b\u6c27\u9178\u4e2d\uff0c\u90fd\u662f\u4e00\u5143\u9178\u7684\u662f____\nA. $H_3BO_3$\uff0c$H_3PO_3$\nB. $H_3PO_3$\uff0c$H_2CO_3$\nC. $H_2CO_3$\uff0c$H_3PO_2$\nD. $H_3BO_3$\uff0c$H_3PO_2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u76f8\u540c\u8d28\u91cf\u7684$KHC_2O_4\u00b7H_2C_2O_2\u00b72H_2O$\u6807\u5b9a$0.1000mol/dm^3NaOH$\u548c$0.1000mol/dm^3c_{1/5KMnO_4}$\u7684\u9178\u6027\u6eb6\u6db2,\u53cd\u5e94\u5b8c\u5168\u65f6,\u6d88\u8017\u7684\u4f53\u79ef\u4e3a$V_{NaOH}$\u548c$V_{KMnO_4}$,\u5219\u4e24\u8005\u7684\u5173\u7cfb\u662f____\nA. $V_{NaOH}=V_{KMnO_4}$\nB. $V_{NaOH}=3/4V_{KMnO_4}$\nC. $V_{NaOH}=2V_{KMnO_4}$\nD. $V_{NaOH}=2/3V_{KMnO_4}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.2731272040287072, "meta-llama/Meta-Llama-3-8B": 0.27727478132119343, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3919625743870292}}, {"question": "\u5e38\u6e29\u4e0b\u4ee5\u6db2\u6001\u5f62\u5f0f\u5b58\u5728\u7684\u662f____\nA. $CrO_3$\nB. $MnO_2$\nC. $Mn_2O_7$\nD. $WO_3$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33080677653042406, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\nA. \u5355\u8d28\u7684\u7113\u4e3a\u96f6\nB. \u53cd\u5e94\u7684\u70ed\u6548\u5e94\u5c31\u662f\u8be5\u53cd\u5e94\u7684\u6469\u5c14\u7113\u53d8\nC. \u5355\u8d28\u7684\u6469\u5c14\u751f\u6210\u7113\u4e3a\u96f6\nD. \u7531\u6700\u7a33\u5b9a\u5355\u8d28\u751f\u62101mol\u5316\u5408\u7269\u65f6\uff0c\u8be5\u5316\u5408\u7269\u7684\u6807\u51c6\u6469\u5c14\u751f\u6210\u542b$\\Delta_\\mathfrak{f}H_\\mathfrak{m}^\\mathfrak{e}$\u7b49\u4e8e\u8be5\u751f\u6210\u53cd\u5e94\u7684$\\Delta_\\mathfrak{r}H_\\mathfrak{m}^\\mathfrak{e}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30677095106660357, "meta-math/MetaMath-Mistral-7B": 0.3499320087587727, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9422029865302803, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6139794468876232, "meta-llama/Meta-Llama-3-8B": 0.5175540000984752, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5052963652571734}}, {"question": "\u6bd4\u8f83\u539f\u5b50\u6838\u59162s\u548c2p\u539f\u5b50\u8f68\u9053\u7684\u80fd\u91cf\uff0c____\nA. \u6240\u6709\u539f\u5b50\u4e24\u8005\u90fd\u76f8\u7b49\nB. \u6240\u6709\u539f\u5b50\u4e24\u8005\u90fd\u4e0d\u7b49\nC. H\u7684\u4e24\u8005\u76f8\u7b49\nD. Ne\u7684\u4e24\u8005\u76f8\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u4e24\u79cd\u96be\u6eb6\u7535\u89e3\u8d28,\u5176\u4e2d$K^{\\theta}_{sp}$\u5c0f\u7684\u6eb6\u89e3\u5ea6\u4e00\u5b9a\u5c0f\nB. \u4e24\u79cd\u96be\u6eb6\u7535\u89e3\u8d28,\u5176\u4e2d$K^{\\theta}_{sp}$\u5c0f\u7684\u6eb6\u89e3\u5ea6\u4e00\u5b9a\u5c0f\nC. \u76d0\u6548\u5e94\u3001\u9178\u6548\u5e94\ufe51\u914d\u4f4d\u6548\u5e94\u90fd\u4f1a\u589e\u52a0\u96be\u6eb6\u7535\u89e3\u8d28\u7684\u6eb6\u89e3\u5ea6\nD. \u540c\u79bb\u5b50\u6548\u5e94\u4f7f\u96be\u6eb6\u7535\u89e3\u8d28\u7684\u6eb6\u89e3\u5ea6\u53d8\u5c0f,\u4e5f\u4f7f$K^{\\theta}_{sp}$\u53d8\u5c0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3689108554330874, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u539f\u5b50\u5e8f\u53f7\u4e3a24\u7684\u5143\u7d20\u7684\u57fa\u6001\u539f\u5b50\uff0c\u5176\u6838\u5916\u7535\u5b50\u6392\u5e03\u4e3a____\nA. [Ar]3d6\nB. [Ar]3d54s1\nC. [Ar]3d44s2\nD. [Ar]4s24p4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2848664895071882, "meta-math/MetaMath-Mistral-7B": 0.3287145937103622, "itpossible/Chinese-Mistral-7B-v0.1": 0.29539205153207015, "HuggingFaceH4/zephyr-7b-beta": 0.48081810040642126, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636eVSEPR\u7406\u8bba\uff0c\u4e8c\u786b\u5316\u78b3\u5206\u5b50\u5e94\u8be5\u662f____\nA. \u76f4\u7ebf\u578b\nB. \u949d\u89d2\u4e09\u89d2\u5f62\nC. \u7b49\u8fb9\u4e09\u89d2\u5f62\nD. \u5176\u4ed6\u4e09\u4e2a\u90fd\u4e0d\u5bf9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u7269\u8d28\u4e2d\u4e0d\u662f\u4e00\u5143\u9178\u7684\u662f____\nA. $H_3BO_3$\nB. $HNO_2$\nC. $H_3PO_3$\nD. $H[Ag(CN)_2]$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5364\u7d20\u5355\u8d28\u4e2d\uff0c\u5728NaOH\u6eb6\u6db2\u4e2d\u4e0d\u53d1\u751f\u6b67\u5316\u53cd\u5e94\u7684\u662f____\nA. $F_2$\nB. $Cl_2$\nC. $Br_2$\nD. $I_2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3130040453954638, "meta-math/MetaMath-Mistral-7B": 0.6773229333693064, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5593095358207979, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6813928055347347, "meta-llama/Meta-Llama-3-8B": 0.5658897519223933, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6233641634775456}}, {"question": "\u5bf9\u4e8e\u4e00\u4e2a\u5316\u5b66\u53cd\u5e94\u6765\u8bf4\uff0c\u4e0b\u5217\u8bf4\u6cd5\u4e2d\u6b63\u786e\u7684\u662f____\nA. \u6807\u51c6\u53cd\u5e94\u5409\u5e03\u65af\u81ea\u7531\u80fd\u53d8\u5316\u503c\u8d8a\u8d1f\uff0c\u53cd\u5e94\u901f\u7387\u8d8a\u5feb\nB. \u6807\u51c6\u53cd\u5e94\u7113\u53d8\u8d8a\u8d1f\uff0c\u53cd\u5e94\u901f\u7387\u8d8a\u5feb\nC. \u6d3b\u5316\u80fd\u8d8a\u5927\uff0c\u53cd\u5e94\u901f\u7387\u8d8a\u5feb\nD. \u6d3b\u5316\u80fd\u8d8a\u5c0f\uff0c\u53cd\u5e94\u901f\u7387\u8d8a\u5feb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7b49\u4f53\u79ef\u6df7\u5408pH=1.0\u4e0epH=3.0\u7684\u4e24\u79cd\u4e00\u5143\u5f3a\u9178\u6eb6\u6db2\uff0c\u6df7\u5408\u6eb6\u6db2pH\u4e3a____\nA. 0.3\nB. 1.3\nC. 1.5\nD. 2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2821833983601388, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7528NaOH\u6ef4\u5b9a$H_3BO_3$\u65f6\uff0c\u52a0\u5165\u591a\u5143\u9187\u7684\u4f5c\u7528\u662f____\nA. \u6c89\u6dc0\u5242\nB. \u87af\u5408\u5242\nC. \u6c27\u5316\u5242\nD. \u8fd8\u539f\u5242\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2977681115275404, "meta-math/MetaMath-Mistral-7B": 0.4697500042372767, "itpossible/Chinese-Mistral-7B-v0.1": 0.45092007275187534, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44391743844858456, "meta-llama/Meta-Llama-3-8B": 0.5062980309815868, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6688886780729097}}, {"question": "HCl\uff0cHBr\uff0cHI\u4e09\u79cd\u7269\u8d28\u7684\u6cb8\u70b9\u4f9d\u6b21\u5347\u9ad8\u7684\u4e3b\u8981\u539f\u56e0\u662f____\nA. \u8303\u5fb7\u534e\u529b\u51cf\u5c0f\nB. \u53d6\u5411\u529b\u589e\u5927\nC. \u8bf1\u5bfc\u529b\u589e\u5927\nD. \u8272\u6563\u529b\u589e\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u90fd\u662f\u5e7f\u5ea6\u6027\u8d28\u3002\nA. $C_v$\uff0cQ\uff0cV\uff0cS\nB. w\uff0cU\uff0cV\uff0cH\nC. P\uff0cU\uff0cV\uff0cG\nD. $\\mu_i$\uff0cU\uff0cH\uff0cS\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5201448968316538, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5150775524864499}}, {"question": "\u6c42\u6781\u9650\uff1a$\\lim_{x\\rightarrow0}\\frac{\\int_{x^2}^x{\\frac{\\sin\\left(xt\\right)}{t}}\\mathrm{d}t}{x^2}=$____\nA. $\\frac{5}{6}$\nB. 1\nC. $\\frac{7}{6}$\nD. $\\frac{4}{3}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3588823130168717, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3233250233605477, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe$n$\u4e3a\u6b63\u6574\u6570\uff0c\u6c42\u6781\u9650\uff1a$\\lim_{x\\rightarrow+\\infty}\\left[\\frac{x^n}{\\left(x-1\\right)\\left(x-2\\right)\\cdots\\left(x-n\\right)}\\right]^x=$____\nA. $e^{\\frac{(n-1)(n+1)}{2}}$\nB. $e^{\\frac{(n-1)n}{2}}$\nC. $e^{\\frac{n(n+1)}{2}}$\nD. $e^{\\frac{n^{2}}{2}}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37325341258520334, "meta-math/MetaMath-Mistral-7B": 0.7352035642097813, "itpossible/Chinese-Mistral-7B-v0.1": 0.33424000363035195, "HuggingFaceH4/zephyr-7b-beta": 0.8400346287381397, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49642125225922296, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5724807497644413}}, {"question": "\u8bbe\u5e73\u9762\u533a\u57df$D$\u7531\u76f4\u7ebf$y=\\frac{1}{2}x-\\frac{1}{2\\sqrt{5}}$\u3001$y=2x-\\frac{2}{\\sqrt{5}}$\u548c$y=x$\u56f4\u6210\uff0c\u51fd\u6570$z=3xy+3$\u5728$D$\u4e0a\u7684\u6700\u5927\u503c\u548c\u6700\u5c0f\u503c\u5206\u522b\u662fM\u548cm\uff0c\u5219____\nA. $M=6,m=3$\nB. $M=\\dfrac{27}{5},m=3$\nC. $M=\\dfrac{18}{5},m=3$\nD. $M={\\frac{27}{5}},m={\\frac{117}{40}}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5606199991155172, "meta-math/MetaMath-Mistral-7B": 0.5522717112975469, "itpossible/Chinese-Mistral-7B-v0.1": 0.39083047486116995, "HuggingFaceH4/zephyr-7b-beta": 0.9687508300486842, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4435043247787303, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u51fd\u6570$f\\left(x\\right)$\u8fde\u7eed\uff0c\u4e14$f\\left(x\\right)>0$\uff0c\u6c42\u79ef\u5206\uff1a$int_0^1{\\ln f\\left(x+t\\right)}\\mathrm{d}t=$____\nA. $\\int_0^x{\\ln \\frac{f\\left( t+2 \\right)}{f\\left( t \\right)}}\\mathrm{d}t+\\int_0^1{\\ln f\\left( t \\right)}\\mathrm{d}t$\nB. $\\int_0^1{\\ln \\frac{f\\left( t+2 \\right)}{f\\left( t \\right)}}\\mathrm{d}t+\\int_0^1{\\ln f\\left( t \\right)}\\mathrm{d}t$\nC. $\\int_0^2x{\\ln \\frac{f\\left( t+1 \\right)}{f\\left( t \\right)}}\\mathrm{d}t+\\int_0^1{\\ln f\\left( t \\right)}\\mathrm{d}t$\nD. $\\int_0^x{\\ln \\frac{f\\left( t+2 \\right)}{f\\left( t \\right)}}\\mathrm{d}t+\\int_0^1{\\ln f\\left( t \\right)}\\mathrm{d}t$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3527809287490976, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7346007034649353}}, {"question": "\u8bbe\u6709\u754c\u533a\u57df$\\Omega$\u7531\u5e73\u9762$2x+y+2z=2$\u4e0e\u4e09\u4e2a\u5750\u6807\u5e73\u9762\u56f4\u6210\uff0c$\\Sigma$\u4e3a\u6574\u4e2a\u8868\u9762\u7684\u5916\u4fa7\uff1b\\\\\u8ba1\u7b97\u66f2\u9762\u79ef\u5206\uff1a$I=\\iint_{\\Sigma}{\\left(x^2+1\\right)\\mathrm{d}y\\mathrm{d}z-2y\\mathrm{d}z\\mathrm{d}x+3z\\mathrm{d}x\\mathrm{d}y}=$____\nA. $\\frac{1}{2}$\nB. 1\nC. $\\frac{3}{2}$\nD. $\\frac{5}{2}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5$\\int_0^{+\\infty}{\\frac{\\sin x}{x}\\mathrm{d}x=\\frac{\\pi}{2}}$\uff0c\u5219$\\int_0^{+\\infty}{\\int_0^{+\\infty}{\\frac{\\sin x\\sin\\left(x+y\\right)}{x\\left(x+y\\right)}}}\\mathrm{d}x\\mathrm{d}y$=____\nA. $\\frac{\\pi ^2}{12}$\nB. $\\frac{\\pi ^2}{8}$\nC. $\\frac{\\pi ^2}{4}$\nD. $\\frac{\\pi ^2}{2}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u66f2\u7ebf$C=\\left\\{(x,y,z):x={\\sqrt{3}}\\cos(t),y={\\sqrt{3}}\\sin(t),z={\\frac{2}{3}}t^{\\frac{3}{2}},0\\leq t\\leq5\\right\\}$\uff0c\u5219\u66f2\u7ebf\u79ef\u5206$\\int_C(x^2+y^2)\\mathrm{d}s=$____\nA. $\\frac{3}{4}\\left(16\\sqrt{2}-3\\sqrt{3}\\right)$\nB. $2\\bigl(16\\sqrt{2}-3\\sqrt{3}\\bigr)$\nC. $\\frac{9}{4}\\left(16\\sqrt{2}-3\\sqrt{3}\\right)$\nD. $\\frac{3}{2}\\left(16\\sqrt{2}-3\\sqrt{3}\\right)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2821833983601388, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8ba1\u7b97\u4e8c\u91cd\u79ef\u5206:$\\iint_D{x\\mathrm{d}x\\mathrm{d}y}=$.\u5176\u4e2d$D$\u4e3a\u7531\u76f4\u7ebf$y=-x+2,x$\u8f74\u4ee5\u53ca\u66f2\u7ebf$y=\\sqrt{2x-x^2}$\u6240\u56f4\u6210\u7684\u5e73\u9762\u533a\u57df.____\nA. $\\frac{\\pi}{4}+\\frac{1}{3}$\nB. $\\frac{\\pi}{2}+\\frac{1}{3}$\nC. $\\frac{\\pi}{2}+\\frac{1}{4}$\nD. $\\frac{\\pi}{2}+\\frac{2}{3}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.308176776288574, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4703896037014585, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36321227331295963, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c42\u6781\u9650\uff1a$L=\\lim_{n\\rightarrow\\infty}\\sqrt{n}\\left(1-\\sum_{k=1}^n{\\frac{1}{n+\\sqrt{k}}}\\right)$=____\nA. $\\frac{1}{3}$\nB. $\\frac{2}{3}$\nC. 1\nD. $\\frac{4}{3}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2885095257630687, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "$x=1$\u662f\u51fd\u6570$f\\left(x\\right)=\\frac{bx^2+x+1}{ax+1}$\u7684\u53ef\u53bb\u95f4\u65ad\u70b9\uff0c\u6c42$a,b$\u7684\u503c\uff1f____\nA. $a=-1,b=-2$\nB. $a=-2,b=-1$\nC. $a=-2,b=-2$\nD. $a=-1,b=0$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c42$\\sum_{n=1}^{\\infty}{\\frac{\\left(-1\\right)^{n+1}-2^n}{n}x^n}$\u7684\u548c\u51fd\u6570.____\nA. $\\ln\\left(1-2x-x^2\\right),x\\in\\left[-\\dfrac{1}{2},\\dfrac{1}{2}\\right)$\nB. $\\ln\\left(1-x-x^2\\right),x\\in\\left(-\\dfrac{1}{2},\\dfrac{1}{2}\\right)$\nC. $\\ln\\left(1-2x-2x^2\\right),x\\in\\left[-\\dfrac{1}{2},\\dfrac{1}{2}\\right)$\nD. $\\ln\\left(1-x-2x^2\\right),x\\in\\left[-\\dfrac{1}{2},\\dfrac{1}{2}\\right)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9345123937093833, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3689108554330874, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c42\u6781\u9650\uff1a$\\lim_{x\\rightarrow0}\\frac{\\sqrt{1+x\\cos x}-\\sqrt{1+\\sin x}}{x^3}=$____\nA. $-\\dfrac{1}{3}$\nB. $-\\dfrac{1}{4}$\nC. $-\\dfrac{1}{5}$\nD. $-\\dfrac{1}{6}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30601362565976303, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3638582843838116, "HuggingFaceH4/zephyr-7b-beta": 0.4797225687108928, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c42\u6781\u9650\uff1a$\\lim_{n\\rightarrow\\infty}\\sum_{k=1}^n{\\frac{k}{\\left(k+1\\right)!}}=$____\nA. 1\nB. 0\nC. -1\nD. 2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2821833983601388, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2731272040287072, "HuggingFaceH4/zephyr-7b-beta": 0.7863284219481844, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.325455072595945, "meta-llama/Meta-Llama-3-8B": 0.4800666587474368, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.553177132624872}}, {"question": "\u5df2\u77e5\u66f2\u7ebfC\u662f\u5706$(x-1)^{2}+(y-6)^{2}=25$\u4e0a\u4ece\u70b9$A(1,1)$\u6cbf\u9006\u65f6\u9488\u65b9\u5411\u5230$B(4,2)$\u7684\u4e00\u6bb5\u5f27\uff0c\u5219$\\oint_{C}(3\\ln(1+y)+5x^{2})\\mathrm{d}x+\\Bigl({\\frac{3x}{1+y}}-2y\\Bigr)\\mathrm{d}y=$____\nA. $108+3\\ln\\Bigl(\\frac{27}{2}\\Bigr)$\nB. $3\\ln\\left(\\dfrac{81}{2}\\right)-102$\nC. $102+3\\ln\\Bigl(\\frac{81}{2}\\Bigr)$\nD. $3\\ln\\left(\\dfrac{27}{2}\\right)-97$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3160424181481997, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36385828438381157, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe$D$\u662f\u5168\u5e73\u9762\uff0c$f\\left(x\\right)=\\begin{cases}\r\nx\\text{\uff0c}-1\\leq x\\leq2\\\\\r\n0\\text{\uff0c}\\text{\u5176\u4ed6}\\\\\r\n\\end{cases}$\uff1b\u8ba1\u7b97$\\iint_D{f\\left(x\\right)f\\left(x^2-y\\right)}\\mathrm{d}\\sigma=$____\nA. $\\frac{9}{4}$\nB. $\\frac{5}{2}$\nC. $\\frac{11}{4}$\nD. 3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3230435121167668, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4077116124521774}}, {"question": "\u8ba1\u7b97\u5e7f\u4e49\u79ef\u5206\uff1a$\\int_0^{+\\infty}{\\frac{\\mathrm{d}x}{\\left(1+x^2\\right)\\left(1+x^4\\right)}}$____\nA. $\\frac{\\pi}{8}$\nB. $\\frac{\\pi}{4}$\nC. $\\frac{\\pi}{2}$\nD. $\\frac{\\pi}{3}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u6570\u5217$\\left\\{a_n\\right\\}$\uff0c\u5176\u4e2d$a_n=\\cos n\\alpha$\uff0c\u5176\u524d$n$$\u9879\u548c\u4e3a$S_n$.\u6c42\uff1a$S_n=$____\nA. $\\frac{\\cos \\frac{n}{2}\\alpha \\cdot \\sin \\frac{n\\alpha}{2}}{\\sin \\frac{\\alpha}{2}}$\nB. $\\frac{\\cos \\frac{n+1}{2}\\alpha \\cdot \\sin \\frac{n\\alpha}{2}}{\\sin \\frac{\\alpha}{2}}$\nC. $\\frac{\\cos \\frac{n+1}{2}\\alpha \\cdot \\sin \\frac{n\\alpha}{2}}{\\sin \\frac{\\alpha}{3}}$\nD. $\\frac{\\cos \\frac{n-1}{2}\\alpha \\cdot \\sin \\frac{n\\alpha}{2}}{\\sin \\frac{\\alpha}{2}}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5610162282696188}}, {"question": "\u8ba1\u7b97\u5b9a\u79ef\u5206\uff1a$\\int_{-1}^1{\\frac{\\mathrm{d}x}{\\left(1+\\mathrm{e}^x\\right)\\left(1+x^2\\right)}}$____\nA. $\\frac{\\pi}{8}$\nB. $\\frac{\\pi}{4}$\nC. $\\frac{\\pi}{2}$\nD. $\\pi$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c42\u6781\u9650\uff1a$\\lim_{x\\rightarrow0}\\frac{\\tan2x^2-x^2}{\\sin x^2+3x^2}=$____\nA. $\\frac{1}{2}$\nB. $\\frac{1}{4}$\nC. $\\frac{1}{8}$\nD. $\\frac{3}{5}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u968f\u673a\u53d8\u91cf$X$\u548c$Y$\u76f8\u4e92\u72ec\u7acb\uff0c\u4e14X$\\sim N(0\uff0c1)\uff0cY\\sim N(0$\uff0c2)\uff0c\u5219$D\\left(X^2Y^2\\right)=$____\nA. 10\nB. 20\nC. 32\nD. 45\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35812340772526235, "meta-math/MetaMath-Mistral-7B": 0.38822592917159904, "itpossible/Chinese-Mistral-7B-v0.1": 0.3128363857141096, "HuggingFaceH4/zephyr-7b-beta": 0.6800331350961328, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.43921757655972987, "meta-llama/Meta-Llama-3-8B": 0.30601362565976303, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5293487087692085}}, {"question": "\u8bbe\u968f\u673a\u53d8\u91cf$(X,Y)$\u7684\u6982\u7387\u5bc6\u5ea6\u4e3a$f(x,y)=\\left\\{\\begin{array}{cc}6y,&0<x<1,0<y<x\uff0c\\\\0,&\\text{\u5176\u4ed6.}\\end{array}\\right.$,$$\\text{\u5219}P\\left(X>\\frac{1}{2}\\mid Y=\\frac{1}{3}\\right)=$$____\nA. $\\frac{3}{4}$\nB. $\\frac{2}{3}$\nC. $\\frac{1}{4}$\nD. $\\frac{1}{3}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3035988665653362, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3786604796126523}}, {"question": "\u603b\u4f53\u7684\u7b80\u5355\u6837\u672c,$\\bar{X}$\u4e3a\u6837\u672c\u5747\u503c,\u5219$D(\\bar{X})=$____\nA. $\\frac{3}{80}$\nB. $\\frac{9}{16}$\nC. $\\frac{3}{1600}$\nD. $\\frac{3}{160}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3267511338789866, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2801288226217134, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40870095898383446, "meta-llama/Meta-Llama-3-8B": 0.2731272040287072, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u603b\u4f53$X$\u670d\u4ece\u62c9\u666e\u62c9\u65af\u5206\u5e03$f(x,\\lambda)=\\frac{1}{4\\lambda}e^{-\\frac{|x|}{2\\lambda}},-\\infty<x<\\infty$,\u5176\u4e2d$\\lambda>0$\u3002\u5219$E(|X|)=$____\nA. $\\frac{1}{2 \\lambda}$\nB. $\\frac{1}{\\lambda}$\nC. $2 \\lambda$\nD. $\\lambda$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe$X_1,X_2,\\cdots X_{12}$\u662f\u6765\u81ea\u6b63\u6001\u603b\u4f53$X\\sim N\\left(0,\\sigma^2\\right)$\u7684\u7b80\u5355\u6837\u672c,\u968f\u673a\u53d8\u91cf$Y=\\frac{\\sum_{i=1}^6X_i^2}{\\sum_{j=1}^6X_{j+6}^2}$\u670d\u4ece\u7684\u5206\u5e03\u4e3a:____\nA. $\\chi^2(6)$\nB. $\\chi^2(1)$\nC. $F(5,5)$\nD. $F(6,6)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0.9339937826537117, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8e\u4efb\u610f\u4e24\u4e2a\u968f\u673a\u53d8\u91cfX\u548c$Y$\uff0c\u82e5$E(XY)=EX\\cdot EY$\uff0c\u5219____\nA. $D(X Y)=D(X) \\cdot D(Y)$\nB. $D(X+Y)=D(X)+D(Y)$\nC. X\u548cY\u72ec\u7acb\nD. X\u548cY\u4e0d\u76f8\u5173\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe$(X_1,X_2,...,X_n)$\u662f\u53d6\u81ea\u603b\u4f53X\u7684\u4e00\u4e2a\u6837\u672c\uff0cX\u7684\u6982\u7387\u5bc6\u5ea6\u5982\u4e0b\uff1a$f(x)=\\begin{cases}\\frac12e^{-\\frac{(x-\\mu)}{2}},x\\geq\\mu,\\\\0,\u5176\u4ed6\\end{cases}$,$\\mu$\u4e3a\u672a\u77e5\u53c2\u6570\u3002\u5219$\\mu$\u7684\u6700\u5927\u4f3c\u7136\u4f30\u8ba1\u91cf\u662f.____\nA. $\\hat{\\mu}=\\max _{1 \\leq i \\leq n} X_i$\nB. $\\hat{\\mu}=\\frac13 \\max _{1 \\leq i \\leq n} X_i$\nC. $\\hat{\\mu}=\\min _{1 \\leq i \\leq n} X_i$\nD. $\\hat{\\mu}=\\frac12 \\min _{1 \\leq i \\leq n} X_i$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4e8b\u4ef6$A$\u548c$B$\u540c\u65f6\u53d1\u751f\u65f6$C$\u4e5f\u53d1\u751f\uff0c\u5219\u4e0b\u5217\u5f0f\u5b50\u4e2d\u6210\u7acb\u7684\u662f____\nA. $P(C)=P(A \\cap B)$\nB. $P(C) \\leq P(A)+P(B)-1$\nC. $P(C)=P(A \\cup B)$\nD. $P(C) \\geq P(A)+P(B)-1$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4332739965056716}}, {"question": "$$\n\\text{\u8bbe}0<P(A)<1\uff0c0<P(B)<1\\text{\uff0c}\n$$\n$P(A\\mid B)+P(\\bar{A}\\mid\\bar{B})=1$\uff0c\u5219____\nA. \u4e8b\u4ef6A\u548cB\u4e92\u4e0d\u76f8\u5bb9\nB. \u4e8b\u4ef6A\u548cB\u4e92\u76f8\u5bf9\u7acb\nC. \u4e8b\u4ef6A\u548cB\u4e92\u4e0d\u72ec\u7acb\nD. \u4e8b\u4ef6A\u548cB\u76f8\u4e92\u72ec\u7acb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3499323714911699, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5888685801055771, "HuggingFaceH4/zephyr-7b-beta": 0.751021755526603, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbeX\u548cY\u5206\u522b\u8868\u793a\u6254n\u6b21\u786c\u5e01\u51fa\u73b0\u6b63\u9762\u548c\u53cd\u9762\u7684\u6b21\u6570\uff0c\u5219$X\uff0cY$\u7684\u76f8\u5173\u7cfb\u6570\u4e3a____\nA. -1\nB. 0\nC. \\frac{1}{2}\nD. 1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u4e8c\u7ef4\u968f\u673a\u53d8\u91cf$(X,Y)$\u5728\u533a\u57df$D=\\left\\{(x,y):x^2+y^2<1\\right\\}$\u5185\u5747\u5300\u5206\u5e03,\u5219$X$\u4e0e$Y$\u4e3a____\nA. \u72ec\u7acb\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\nB. \u72ec\u7acb\u4e0d\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\nC. \u4e0d\u72ec\u7acb\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\nD. \u4e0d\u72ec\u7acb\u4e5f\u4e0d\u540c\u5206\u5e03\u7684\u968f\u673a\u53d8\u91cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3528619536675027, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8675997583575263}}, {"question": "\u8bbe$X\\sim N(1\uff0c4)\uff0cY\\sim N(3\uff0c16)\uff0cP\\{Y=aX+b\\}=1$\uff0c\u4e14$\\rho_{XY}=-1$\uff0c\u5219____\nA. a=2, b=5\nB. a=-2, b=-5\nC. a=-2, b=5\nD. a=2, b=-5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32545507259594497, "meta-math/MetaMath-Mistral-7B": 0.4209626922472216, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7410410453537751, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3248694388439253, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.40067961385279605}}, {"question": "\u8bbe\u603b\u4f53$X$\u7684\u5206\u5e03\u5217\u5982\u4e0b:\n\n\\begin{tabular}{|c|c|c|c|}\n\\hline$\\boldsymbol{X}$&0&1&2\\\\\n\\hline$\\boldsymbol{p}$&$2/5$&$1/5$&$2/5$\\\\\n\\hline\n\\end{tabular}\n\n$\\left(X_{1},X_{2},\\cdots X_{n}\\right)$\u662f\u6765\u81ea\u4e8e\u8be5\u603b\u4f53\u7684\u6837\u672c,$X_{(n)}=\\max\\left(X_{1},X_{2},\\cdots X_{n}\\right)$,\n\n(i)$P\\left(\\mathbf{X}_{(n)}=0\\right)=\\left(\\frac{2}{5}\\right)^{n}$,\n(ii)$P\\left(X_{(n)}=1\\right)=\\frac{2}{5}\\left(c_{0}^{1}\\left(\\frac{1}{5}\\right)^{n-1}\\right.$,\n(iii)$P\\left(\\mathbf{X}_{(n)}=2\\right)=1-\\left(\\frac{2}{5}\\right)^{n}$,\n\n\u4e0a\u8ff0(i)\u3001(ii)\u3001(iii)\u4e2d\u6b63\u786e\u4e2a\u6570\u4e3a____\nA. 2\nB. 1\nC. 0\nD. 3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.30702389681474196, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36029124167861426, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u968f\u673a\u53d8\u91cf(X,Y)\u7684\u6982\u7387\u5bc6\u5ea6\u4e3a$f(x,y)=\\begin{cases}2,0<x<y,0<y<1\\\\0,\u5176\u4ed6\\end{cases}$.\u52190<y<1\u65f6\uff0cf_{X|Y}(x|y)=____\nA. $\\begin{cases}\\frac{1}{x}, & 0<y<x, \\\\ 0, & \\text { \u5176\u4ed6 }\\end{cases}$\nB. $\\{\\begin{array}{cl}\\frac{1}{2 x}, & |y|<x, \\\\0, & \\text { \u5176\u4ed6}\\end{array}$\nC. $\\begin{cases}\\frac{1}{y}, & 0<x<y, \\\\ 0, & \\text { \u5176\u4ed6. }\\end{cases}$\nD. $\\begin{cases}\\frac{1}{2y}, & |x|<y, \\\\ 0, & \\text { \u5176\u4ed6. }\\end{cases}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3885978497153787, "meta-math/MetaMath-Mistral-7B": 0.48393659541283823, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9541838231385991, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6373550295883156, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3784463411225503}}, {"question": "\u8bbe\u603b\u4f53$X$\u7684\u5206\u5e03\u5f8b\u4e3a\n\n\\begin{tabular}{|l|l|l|l|}\n\\hline$X$&-1&0&2\\\\\n\\hline$P$&$\\frac{1}{3}\\theta$&$1-\\frac{2}{3}\\theta$&$\\frac{1}{3}\\theta$\\\\\n\\hline\n\\end{tabular}\n\n$\\left(X_{1},X_{2},\\cdots,X_{n}\\right)$\u4e3a\u6765\u81ea\u603b\u4f53\u7684\u6837\u672c,\u8bbe\u6709\u4ee5\u4e0b\u56db\u4e2a\u7edf\u8ba1\u91cf\n\n(i)$\\frac{3}{n}\\sum_{i=1}^{n}X_{i}$,(ii)$\\left.X_{1}+\\frac{2}{n-1}\\right)_{i=2}^{n}X_{i}$,(iii)$\\frac{3}{5n}\\sum_{i=1}^{n}X_{i}^{2}$,(iv)$\\frac{1}{3n}\\sum_{i=1}^{n}X_{i}^{2}$\n\n\u5728\u4e0a\u8ff0\u56db\u4e2a\u7edf\u8ba1\u91cf\u4e2d,\u662f\u53c2\u6570$\\theta$\u7684\u4e00\u81f4\u4f30\u8ba1\u91cf\u7684\u4e2a\u6570\u662f____\nA. 0\nB. 2\nC. 1\nD. 3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5251619729311727}}, {"question": "\u8bbe$X_1,...,X_4,X_5$\u76f8\u4e92\u72ec\u7acb\u3001\u4e14\u90fd\u670d\u4eceN(0,4).\u8bbe$\\alpha\\in(0,1)$,$k>0$,$P(X_1^2+X_2^2+X_3^2+X_4^2\\le kX_5^2)=\\alpha$\u5219k=____\nA. $\\frac{1}{4}F_{\\alpha}(4,1)$\nB. $\\frac{1}{4}F_{1-\\alpha}(4,1)$\nC. $4F_{\\alpha}(4,1)$\nD. $4F_{1-\\alpha}(4,1)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9872232280361328, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe$X_1,X_1,\\cdots X_8$\u4e3a\u6765\u81ea\u603b\u4f53$X\\sim N\\left(\\mu_1,1\\right)$\u7684\u7b80\u5355\u6837\u672c,$\\bar{X},S_1^2$\u5206\u5225\u662f\u5176\u5bf9\u5e94\u7684\u6837\u672c\u5747\u503c\u4e0e\u6837\u672c\u65b9\u5dee\u3002$Y_1,Y_1,\\cdots,Y_7$\u4e3a\u6765\u81ea\u603b$Y\\sim N\\left(\\mu_2,1\\right)$\u7684\u7b80\u5355\u6837\u672c,$\\bar{Y},S_2^2$\u5206\u522b\u662f\u5176\u5bf9\u5e94\u7684\u6837\u672c\u5747\u503c\u4e0e\u6837\u672c\u65b9\u5dee\u3002\u4e0b\u5217\u9009\u9879\u6b63\u786e\u7684\u662f\uff1a____\nA. $\\sum_{i=1}^8\\left(X_i-\\mu_1\\right)^2+\\sum_{i=1}^7\\left(Y_i-\\mu_2\\right)^2 \\sim \\chi^2(15)$\nB. $E\\left(\\sum_{i=1}^8\\left(X_i-\\mu_1\\right)^2+\\sum_{i=1}^7\\left(Y_i-\\mu_2\\right)^2\\right)=15$\nC. $\\mathrm{D}(\\bar{X}+\\bar{Y})=\\frac{1}{8}+\\frac{1}{7}$\nD. $\\bar{X}-\\bar{Y} \\sim \\mathrm{N}\\left(\\mu_1-\\mu_2, \\frac{1}{8}+\\frac{1}{7}\\right)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5\u968f\u673a\u53d8\u91cfX\u7684\u5206\u5e03\u51fd\u6570\u4e3a$F(x)=pF_1(x)+qF_2(x)$\uff0c\u5176\u4e2d$F_1(x)$\uff0c$F_2(x)$\u4e3a\u4e24\u4e2a\u5206\u5e03\u51fd\u6570\uff0c\u5e38\u6570p\uff0cq\u6ee1\u8db3:$p>0$\uff0c$q>0$\uff0c$p+q=1$\uff0c\u90a3\u4e48X\u7684\u5206\u5e03\u53eb\u4f5c$F_1(x)\uff0cF_2(x)$\u7684\u6df7\u5408\u5206\u5e03.\u8bbe$\\mu_1\uff0c\\mu_2$\u5206\u522b\u4e3a$F_1(x)\uff0cF_2(x)$\u7684\u671f\u671b\uff0c$\\sigma_1^2,\\sigma_2^2$\u5206\u522b\u4e3a$F_1(\\mathrm{x})$\uff0c$F_2(\\mathrm{x})$\u7684\u65b9\u5dee\uff0c\u5219$DX=$____\nA. $p \\sigma_1^2+q \\sigma_2^2$\nB. $p^2 \\sigma_1^2+q^2 \\sigma_2^2$\nC. $p \\sigma_1^2+q \\sigma_2^2+p q\\left(\\mu_1-\\mu_2\\right)^2$\nD. $p \\sigma_1^2+q \\sigma_2^2+p q\\left(\\sigma_1-\\sigma_2\\right)^2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6244562129257408, "meta-math/MetaMath-Mistral-7B": 0.7302773744355553, "itpossible/Chinese-Mistral-7B-v0.1": 0.4316066378451956, "HuggingFaceH4/zephyr-7b-beta": 0.7436759256692252, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5835212949910878, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7522893625601751}}, {"question": "\u4e0b\u5217\u96c6\u5408\u4e2d\u4e0e$\\mathbf{\\{}1,2\\}$\u4e0d\u76f8\u7b49\u7684\u662f:____\nA. $\\{1,2\\}\\cup\\phi$\nB. $\\{1,2\\}$\nC. $\\{1,2,2\\}$\nD. $\\{x|\\ x\\in{\\mathcal{R}}\\land x^{2}-3x+2=0\\}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ee4P\uff1a\u5929\u6c14\u5f88\u51b7\uff0cQ\uff1a\u8001\u738b\u6765\u4e86\uff0c\u5219\u547d\u9898\u201c\u867d\u7136\u5929\u6c14\u5f88\u51b7\uff0c\u4f46\u662f\u8001\u738b\u8fd8\u662f\u6765\u4e86\u201d\u53ef\u7b26\u53f7\u5316\u4e3a____\nA. P\u2227Q\nB. P\u2192Q\nC. P\u2227\ufe41Q\nD. P\u2192\ufe41Q\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5844107666272004, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8e\u96c6\u5408A\u4e0a\u7684\u4e8c\u5143\u5173\u7cfbR\uff0c\u82e5$B\\subseteq A$\uff0c$C\\subseteq A$\uff0c$R\\uparrow\\ B$\u4ee3\u8868\u5173\u7cfbR\u5728\u96c6\u5408B\u4e0a\u53d7\u9650\uff0c\u5219\u4e0b\u5217\u662f\u6b63\u786e\u7684____\nA. $R[B\\cap C]=R[B]\\cap R[C]$\nB. $R[B]-R[C]=R[B-C]$\nC. $B\\subseteq A\\Leftrightarrow R[B]\\subseteq R[A]$\nD. $R\\uparrow(B\\cup C)=R\\uparrow B\\cup R\\uparrow C$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u82e5\u7b80\u5355\u56fe\u6bcf\u4e2a\u8282\u70b9\u7684\u5ea6\u5927\u4e8e\u7b49\u4e8e$\\frac{n}{2}$,\u5219$G$\u6709$H$\u56de\u8def\nB. \u7b80\u5355\u56fe$G$\u5b58\u5728$H$\u56de\u8def\u7684\u5145\u8981\u6761\u4ef6\u662f\u5176\u95ed\u5408\u56fe\u5b58\u5728$H$\u56de\u8def\nC. \u7b80\u5355\u56fe$G$\u7684\u4efb\u610f\u7ed3\u70b9$v_i$\uff0c$v_j$\u4e4b\u95f4\u6052\u6709$d(v_{j})+d(v_{j})\\geq n{-}1$\uff0c \u5219$G$\u5b58\u5728$H$\u56de\u8def\nD. \u7b80\u5355\u56fe\u7684\u95ed\u5408\u56fe\u552f\u4e00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37717214950587247, "meta-math/MetaMath-Mistral-7B": 0.3160424181481997, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34993200875877273, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7321163461221056}}, {"question": "\u7ed9\u5b9an\u4e2a\u7ed3\u70b9\u7684\u4e00\u4e2a\u56fe\uff0c\u5b83\u662f\u4e00\u4e2a\u6811\u7684\u4e0b\u5217\u8bf4\u6cd5\u4e2d\uff0c____\u662f\u4e0d\u5bf9\u7684\u3002\nA. \u65e0\u56de\u8def\u7684\u8fde\u901a\u56fe\nB. \u65e0\u56de\u8def\u4f46\u82e5\u589e\u52a0\u4e00\u6761\u65b0\u8fb9\u5c31\u6709\u56de\u8def\nC. \u8fde\u901a\u4e14m=n-1\uff0c \u5176\u4e2dm\u662f\u8fb9\u6570\uff0cn\u662f\u7ed3\u70b9\u6570\nD. \u6240\u6709\u7ed3\u70b9\u7684\u5ea6\u6570>2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5348240276409856, "meta-math/MetaMath-Mistral-7B": 0.6477822941599447, "itpossible/Chinese-Mistral-7B-v0.1": 0.5036304370270329, "HuggingFaceH4/zephyr-7b-beta": 0.9965693747101979, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9236772362323487, "meta-llama/Meta-Llama-3-8B": 0.701192016899855, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7157007170874349}}, {"question": "\u516d\u9636\u7fa4\u7684\u4efb\u4f55\u975e\u5e73\u51e1\u5b50\u7fa4\u4e00\u5b9a\u4e0d\u662f____\nA. 2\u9636\nB. 5\u9636\nC. 3\u9636\nD. 6\u9636\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.366176398652905, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5292563570923206, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u9762\u8bf4\u6cd5____\u662f\u9519\u8bef\u7684\nA. \u4e0d\u5b58\u5728\u65e2\u81ea\u53cd\u53c8\u53cd\u81ea\u53cd\u7684\u5173\u7cfb\nB. \u5b58\u5728\u5373\u5bf9\u79f0\u53c8\u53cd\u5bf9\u79f0\u7684\u5173\u7cfb\nC. \u5b58\u5728\u5373\u4e0d\u5bf9\u79f0\u53c8\u4e0d\u53cd\u5bf9\u79f0\u7684\u5173\u7cfb\nD. \u7531\u4e00\u4e2a\u6709\u5e8f\u5bf9\u6784\u6210\u7684\u4e8c\u5143\u5173\u7cfb\u4e00\u5b9a\u662f\u4e00\u4e2a\u4f20\u9012\u5173\u7cfb\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbe\u56feG\u662f\u67096\u4e2a\u9876\u70b9\u7684\u8fde\u901a\u56fe\uff0c\u603b\u5ea6\u6570\u4e3a20\uff0c\u5219\u4eceG\u4e2d\u5220\u53bb____\u8fb9\u540e\u4f7f\u4e4b\u53d8\u6210\u6811\u3002\nA. 10\nB. 5\nC. 3\nD. 2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.35866706094071804, "itpossible/Chinese-Mistral-7B-v0.1": 0.28850952576306876, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbeG\u4e3a\u5e73\u9762\u56fe\uff0c\u5219\u4e0b\u9762\u53ef\u80fd\u4e0d\u6b63\u786e\u7684\u9009\u9879\u662f_____\nA. G = (G*)*\nB. G*= ((G*)*)*\nC. (G*)* = (G*)*)*)*\nD. ((G*)*)*= ((((G*)*)*)*)*\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.2926661932032274, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u4e00\u68f5\u6811T\u4e2d\u6709\u5ea6\u4e3a5\uff0c4\uff0c3\uff0c2\u7684\u9876\u70b9\u5404\u4e00\u4e2a\uff0c\u5176\u4f59\u4e3a\u6811\u53f6\u9876\u70b9\uff0cT\u7684\u6811\u53f6\u9876\u70b9\u6570\u4e3a\u54ea\u9879\uff1f____\nA. 8\nB. 7\nC. 6\nD. 5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.303006867405966, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.47340447283744186}}, {"question": "\u542b5\u4e2a\u9876\u70b9\u30013\u6761\u8fb9\u7684\u4e0d\u540c\u6784\u7684\u7b80\u5355\u56fe\u6709\u51e0\u4e2a?____\nA. 2\nB. 3\nC. 4\nD. 5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3327407661033064, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8385096003914987, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3423962339378881, "meta-llama/Meta-Llama-3-8B": 0.3088936322941584, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3483843623669063}}, {"question": "\u4e0b\u9762\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u90bb\u63a5\u77e9\u9635\u80fd\u8868\u793a\u81ea\u73af\uff0c\u4e5f\u80fd\u8868\u793a\u91cd\u8fb9\nB. \u6709\u5411\u56fe\u90bb\u63a5\u77e9\u9635\u7684\u7b2c$i$\u884c\u975e\u96f6\u5143\u7684\u6570\u76ee\u6070\u597d\u662f$\\nu_{i}$\u7684\u6b63\u5ea6\u3002\u7b2c$j$\u5217\u975e\u96f6\u5143\u7684\u6570\u76ee\u662f$\\nu_{j}$\u7684\u8d1f\u5ea6\nC. \u5173\u8054\u77e9\u9635\u80fd\u8868\u793a\u91cd\u8fb9\uff0c\u4e0d\u80fd\u8868\u793a\u81ea\u73af\nD. \u6709\u5411\u56fe\u5173\u8054\u77e9\u9635\u7b2c$i$\u884c\u4e2d1 \u7684\u6570\u76ee\u662f$\\nu_{i}$\u7684\u6b63\u5ea6\uff0c-1 \u7684\u6570\u76ee\u662f$\\nu_{i}$\u7684\u8d1f\u5ea6\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3121829301806, "meta-math/MetaMath-Mistral-7B": 0.5928099345011725, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5f0f\u4e0d\u4e00\u5b9a\u6210\u7acb\u7684\u662f____\nA. $(\\forall x)(P(x)\\wedge Q(x))=(\\forall x)P(x)\\wedge(\\forall x)Q(x)$\nB. $(\\exists x)(P(x)\\lor Q(x))=(\\exists x)P(x)\\lor(\\exists x)Q(x)$\nC. $(\\forall x)(\\forall y)(P(x)\\lor{Q(x)}(y))=(\\forall x)P(x)\\lor(\\forall x)Q(x)$\nD. $(\\exists x)(P(x)\\wedge Q(x))=(\\exists x)P(x)\\wedge(\\exists x)Q(x)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5623650928318508, "itpossible/Chinese-Mistral-7B-v0.1": 0.34031470637689565, "HuggingFaceH4/zephyr-7b-beta": 0.8798886635847831, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.37354501646787847, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbeA={2\uff0c3\uff0c4\uff0c6\uff0c9\uff0c12\uff0c18}\uff0cA\u4e2d\u7684\u6574\u9664\u5173\u7cfbR\u662f\u504f\u5e8f\u5173\u7cfb\uff0c\u90a3\u4e48\u5728\u504f\u5e8f\u96c6<A\uff0cR>\u4e2d\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. A\u7684\u6700\u5927\u5143\u7d20\u662f18\uff1b\nB. A \u7684\u6700\u5c0f\u5143\u7d20\u662f2\uff1b\nC. B= {3\uff0c9}\u7684\u4e0a\u754c\u53ea\u6709 18\uff1b\nD. B= {4\uff0c9} \u6ca1\u6709\u4e0a\u4e0b\u754c\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2909633459929373, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bbeG\u4e3a\u5e73\u9762\u56fe\uff0c\u5219\u4e0b\u9762\u53ef\u80fd\u4e0d\u8fde\u901a\u7684\u56fe\u662f____\nA. G\u7684\u95ed\u5408\u56fe\nB. G*\nC. (G*)*\nD. (((G)*)*)*\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.48454907012798465, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5104934369984531, "meta-llama/Meta-Llama-3-8B": 0.2772747813211935, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u4e2a\u65e0\u5411\u56fe\u6709\u4e94\u4e2a\u7ed3\u70b9\uff0c\u5176\u4e2d4\u4e2a\u7684\u5ea6\u6570\u662f1,2,3,4,\u5219\u7b2c5\u4e2a\u7ed3\u70b9\u7684\u5ea6\u6570\u4e0d\u53ef\u80fd\u662f____\nA. 0\nB. 2\nC. 4\nD. 5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33872465861069406, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u516c\u5171\u7535\u7f51\u7535\u538b\u5904\u4e8e\u6b63\u5e38\u8303\u56f4\u5185\u65f6\uff0c\u901a\u8fc7220kV\u7535\u538b\u7b49\u7ea7\u63a5\u5165\u7535\u7f51\u7684\u5149\u4f0f\u53d1\u7535\u7ad9\u5e94\u80fd\u591f\u63a7\u5236\u5149\u4f0f\u53d1\u7535\u7ad9\u5e76\u7f51\u70b9\u7535\u538b\u5728\u6807\u79f0\u7535\u538b\u7684____\u8303\u56f4\u5185\u3002\nA. 95%\uff5e105%\nB. 97%\uff5e107%\nC. 100%\uff5e105%\nD. 100%\uff5e110%\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8409442468816545, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5c06\u4e09\u76f8\u611f\u5e94\u7535\u52a8\u673a\u7684\u8f6c\u5b50\u7535\u963b\u589e\u5927\u4e00\u500d\uff0c\u5219\u7535\u673a\u7684\u542f\u52a8\u8f6c\u77e9____\nA. \u589e\u5927\nB. \u51cf\u5c0f\nC. \u4e0d\u53d8\nD. \u65e0\u6cd5\u5224\u65ad\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4805121962018543, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6680308473893413}}, {"question": "\u5f53\u5149\u4f0f\u53d1\u7535\u7cfb\u7edf\u8bbe\u8ba1\u4e3a\u4e0d\u53ef\u9006\u5e76\u7f51\u65b9\u5f0f\u65f6\uff0c\u5e94\u914d\u7f6e____\u3002\nA. \u5355\u76f8\u5173\u53e3\u8868\nB. \u9006\u5411\u529f\u7387\u4fdd\u62a4\u8bbe\u5907\nC. \u5355\u76f8\u4fdd\u62a4\u8bbe\u5907\nD. \u9891\u7387\u3001\u7535\u538b\u63a7\u5236\u88c5\u7f6e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4702008436521869, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.9036827893154902, "HuggingFaceH4/zephyr-7b-beta": 0.7874409860434549, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.648355484686756, "meta-llama/Meta-Llama-3-8B": 0.37887214559235705, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u536b\u661f\u63a5\u6536\u5929\u7ebf\u5e94\u6b63\u9762\u671d____\uff0c\u5728\u63a5\u6536\u65b9\u5411\u4e0a\u4e0d\u5e94\u6709\u5efa\u7b51\u7269\u7b49\u906e\u6321\u7269\u3002\nA. \u4e1c\nB. \u897f\nC. \u5357\nD. \u5317\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3148300531811561, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "100kW\u5149\u4f0f\u7535\u7ad9\u6b63\u5e38\u8fd0\u884c\u60c5\u51b5\u4e0b\uff0c\u6709\u529f\u529f\u7387\u53d8\u5316\u901f\u7387\u5e94\u4e0d\u8d85\u8fc7____\u3002\nA. 5MW/min\nB. 10MW/min\nC. 15MW/min\nD. 20MW/min\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36559911096815423, "meta-math/MetaMath-Mistral-7B": 0.501225262957705, "itpossible/Chinese-Mistral-7B-v0.1": 0.333183235354062, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.35125369870111733, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7863471800584009}}, {"question": "\u5728\u7cfb\u7edf\u7684\u521d\u59cb\u8fd0\u884c\u6761\u4ef6\u3001\u6545\u969c\u6301\u7eed\u65f6\u95f4\u5747\u5b8c\u5168\u76f8\u540c\u7684\u60c5\u51b5\u4e0b\uff0c\u5bfc\u81f4\u7cfb\u7edf\u7684\u6682\u6001\u7a33\u5b9a\u6027\u6700\u5dee\u7684\u662f____\nA. \u5355\u76f8\u63a5\u5730\u77ed\u8def\nB. \u4e24\u76f8\u77ed\u8def\nC. \u4e09\u76f8\u77ed\u8def\nD. \u65ad\u76f8\u6545\u969c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.2866128117777278, "itpossible/Chinese-Mistral-7B-v0.1": 0.35509572434873293, "HuggingFaceH4/zephyr-7b-beta": 0.7646626047873579, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4065059027901228, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6cb9\u65ad\u8def\u5668\u5185\u7684\u53d8\u538b\u5668\u6cb9\u7684\u4f5c\u7528\u662f____\nA. \u7edd\u7f18\u548c\u9632\u9508\nB. \u7edd\u7f18\u548c\u6563\u70ed\nC. \u7edd\u7f18\u548c\u706d\u5f27\nD. \u7edd\u7f18\u548c\u5e72\u71e5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5522770492510483, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9907228649657848, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5873401565253322, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.558309754102091}}, {"question": "\u67d0\u7535\u7f51110kV\u516c\u5171\u8fde\u63a5\u70b9\u5904\u7684\u6700\u5c0f\u77ed\u8def\u5bb9\u91cf\u4e3a500MVA\uff0c\u8be5\u8fde\u63a5\u70b9\u7684\u5168\u90e8\u7528\u6237\u5411\u8be5\u70b9\u6ce8\u5165\u76843\u6b21\u8c10\u6ce2\u7535\u6d41\u5206\u91cf(\u65b9\u5747\u6839\u503c)\u4e0d\u5e94\u8d85\u8fc7____\u3002\nA. 6.4A\nB. 10A\nC. 15A\nD. 20A\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.48051241470931716, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3954699049739945, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u706b\u707e\u81ea\u52a8\u62a5\u8b66\u7cfb\u7edf\u4e3b\u7535\u6e90\u7684\u4fdd\u62a4\u5f00\u5173\u4e0d\u5e94\u91c7\u7528____\u3002\nA. \u5851\u58f3\u65ad\u8def\u5668\nB. \u7194\u65ad\u5668\nC. \u5269\u4f59\u7535\u6d41\u4fdd\u62a4\u5f00\u5173\nD. \u5fae\u578b\u65ad\u8def\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2998701595284818, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.595121838251005, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.47905136066556653}}, {"question": "\u7528\u6237\u51b2\u51fb\u8d1f\u8377\u5f15\u8d77\u7684\u7cfb\u7edf\u9891\u7387\u53d8\u52a8\u4e00\u822c\u4e0d\u5f97\u8d85\u8fc7____\u3002\nA. \u00b10.5Hz\nB. \u00b10.4Hz\nC. \u00b10.3Hz\nD. \u00b10.2Hz\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u7535\u529b\u7cfb\u7edf\u627f\u53d7\u5927\u6270\u52a8\u80fd\u529b\u7684\u5b89\u5168\u7a33\u5b9a\u6807\u51c6\uff0c\u53d1\u751f____\u6545\u969c\u65f6\u5141\u8bb8\u91c7\u53d6\u5207\u673a\u548c\u5207\u8d1f\u8377\u7b49\u7a33\u5b9a\u63a7\u5236\u63aa\u65bd\u3002\nA. \u4efb\u4e00\u53d1\u7535\u673a\u8df3\u95f8\u6216\u5931\u78c1\nB. \u76f4\u6d41\u8f93\u7535\u7ebf\u8def\u5355\u6781\nC. \u53d7\u7aef\u7cfb\u7edf\u4efb\u4e00\u53d8\u538b\u5668\u6545\u969c\u9000\u51fa\u8fd0\u884c\nD. \u4efb\u4e00\u6bb5\u6bcd\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u6027\u70b9\u4e0d\u76f4\u63a5\u63a5\u5730\u7cfb\u7edf\u7684\u8f93\u7535\u7ebf\u8def\u7684\u5e72\u6270\u8ba1\u7b97\u5e94\u7b26\u5408\u4ee5\u4e0b____\u9879\u89c4\u5b9a\u3002\nA. \u8003\u8651\u591a\u6761\u8f93\u7535\u7ebf\u8def\u7684\u5408\u6210\u5e72\u6270\u5f71\u54cd\nB. \u5bf9\u97f3\u9891\u53cc\u7ebf\u7535\u8bdd\u7684\u5e72\u6270\u5f71\u54cd\u5e94\u6309\u8f93\u7535\u7ebf\u8def\u6b63\u5e38\u8fd0\u884c\u72b6\u6001\u8ba1\u7b97\uff0c\u540c\u65f6\u5e94\u8003\u8651\u8f93\u7535\u7ebf\u8def\u57fa\u6ce2\u548c\u8c10\u6ce2\u7535\u538b\u7684\u611f\u5e94\u5f71\u54cd\nC. \u5bf9\u97f3\u9891\u53cc\u7ebf\u7535\u8bdd\u7684\u5e72\u6270\u5f71\u54cd\u5e94\u6309\u8f93\u7535\u7ebf\u8def\u5355\u76f8\u63a5\u5730\u77ed\u8def\u6545\u969c\u72b6\u6001\u8ba1\u7b97\uff0c\u540c\u65f6\u5e94\u8003\u8651\u8f93\u7535\u7ebf\u8def\u57fa\u6ce2\u548c\u8c10\u6ce2\u7535\u538b\u7684\u611f\u5e94\u5f71\u54cd\nD. \u5bf9\u7ebf-\u5730\u7535\u62a5\u56de\u8def\u7684\u5e72\u6270\u5f71\u54cd\u5e94\u6309\u8f93\u7535\u7ebf\u8def\u5355\u76f8\u63a5\u5730\u77ed\u8def\u6545\u969c\u72b6\u6001\u8ba1\u7b97\uff0c\u540c\u65f6\u5e94\u8003\u8651\u8f93\u7535\u7ebf\u8def\u57fa\u6ce2\u7535\u6d41\u3001\u7535\u538b\u7684\u611f\u5e94\u5f71\u54cd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6277097498657135, "meta-math/MetaMath-Mistral-7B": 0.7946164631212438, "itpossible/Chinese-Mistral-7B-v0.1": 0.401488463839659, "HuggingFaceH4/zephyr-7b-beta": 0.8634334305973814, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5159702041358171, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u8f93\u7535\u7ebf\u8def\u5bf9\u7535\u4fe1\u7ebf\u8def\u611f\u5e94\u4ea7\u751f\u7684\u566a\u58f0\u8ba1\u7535\u52a8\u52bf\u6216\u5e72\u6270\u7535\u6d41\u8d85\u8fc7\u5141\u8bb8\u503c\u65f6\uff0c\u5e94\u6839\u636e\u5177\u4f53\u60c5\u51b5\u8fdb\u884c\u5168\u9762\u6280\u672f\u7ecf\u6d4e\u6bd4\u8f83\uff0c\u5408\u7406\u9009\u7528\u9632\u62a4\u63aa\u65bd\uff0c\u4ee5\u6ee1\u8db3\u5141\u8bb8\u503c\u7684\u8981\u6c42\uff0c\u4e0b\u5217____\u9879\u4e0d\u662f\u7535\u4fe1\u7ebf\u8def\u65b9\u9762\u53ef\u9009\u7528\u7684\u63aa\u65bd\u3002\nA. \u52a0\u88c5\u653e\u7535\u5668\nB. \u660e\u7ebf\u6539\u7535\u7f06\nC. \u6539\u8fc1\u7535\u4fe1\u7ebf\u8def\u8def\u5f84\nD. \u6709\u7ebf\u901a\u4fe1\u6539\u65e0\u7ebf\u901a\u4fe1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7535\u538b\u4e92\u611f\u5668\u4f4e\u538b\u4fa7\u4e24\u76f8\u7535\u538b\u964d\u4e3a\u96f6\u3001\u4e00\u76f8\u6b63\u5e38\u3001\u4e00\u4e2a\u7ebf\u7535\u538b\u4e3a\u96f6\uff0c\u5219\u8bf4\u660e____\nA. \u4f4e\u538b\u4fa7\u4e24\u76f8\u7194\u65ad\u5668\u7194\u65ad\nB. \u4f4e\u538b\u4fa7\u4e00\u76f8\u7194\u4e1d\u65ad\nC. \u9ad8\u538b\u4fa7\u4e00\u76f8\u7194\u4e1d\u65ad\nD. \u9ad8\u538b\u4fa7\u4e24\u76f8\u7194\u4e1d\u65ad\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.32332502336054775, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5337436524773919}}, {"question": "\u65e0\u529f\u529f\u7387\u4e0d\u8db3\u7684\u7535\u529b\u7cfb\u7edf\u4e2d\uff0c\u9996\u5148\u5e94\u91c7\u7528\u7684\u63aa\u65bd\u662f____\nA. \u6539\u53d8\u53d8\u538b\u5668\u7684\u53d8\u6bd4\nB. \u91c7\u7528\u65e0\u529f\u8865\u507f\u88c5\u7f6e\u8865\u507f\u65e0\u529f\u7684\u7f3a\u989d\nC. \u589e\u52a0\u53d1\u7535\u673a\u7684\u6709\u529f\u51fa\u529b\nD. \u8c03\u8282\u53d1\u7535\u673a\u7684\u52b1\u78c1\u7535\u6d41\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7558211835159425, "meta-math/MetaMath-Mistral-7B": 0.982059602905807, "itpossible/Chinese-Mistral-7B-v0.1": 0.9384611445573382, "HuggingFaceH4/zephyr-7b-beta": 0.9989912409894199, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9779464173888192, "meta-llama/Meta-Llama-3-8B": 0.6109588524261916, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8767757705797085}}, {"question": "\u9001\u7535\u7ebf\u8def\u5728\u8de8\u8d8a\u6807\u51c6\u8f68\u8ddd\u94c1\u8def\u3001\u9ad8\u901f\u516c\u8def\u53ca\u4e00\u7ea7\u516c\u8def\u65f6\uff0c\u5bf9\u88ab\u8de8\u8d8a\u7269\u8ddd\u79bb\u8ba1\u7b97\uff0c\u4e0b\u5217\u8bf4\u6cd5____\u662f\u6b63\u786e\u7684\u3002\nA. \u65e0\u8bba\u6863\u8ddd\u5927\u5c0f\uff0c\u6700\u5927\u5f27\u5782\u5e94\u6309\u5bfc\u7ebf\u6e29\u5ea670\u2103\u8ba1\u7b97\nB. \u65e0\u8bba\u6863\u8ddd\u5927\u5c0f\uff0c\u6700\u5927\u5f27\u5782\u5e94\u6309\u5bfc\u7ebf\u6e29\u5ea640\u2103\u8ba1\u7b97\nC. \u8de8\u8d8a\u6863\u8ddd\u5c0f\u4e8e300m\uff0c\u6700\u5927\u5f27\u5782\u5e94\u6309\u5bfc\u7ebf\u6e29\u5ea640\u2103\u8ba1\u7b97\nD. \u8de8\u8d8a\u6863\u8ddd\u8d85\u8fc7300m\uff0c\u6700\u5927\u5f27\u5782\u5e94\u6309\u5bfc\u7ebf\u6e29\u5ea670\u2103\u8ba1\u7b97\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.41967678545264997, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8423542577448081, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e09\u76f8\u5bf9\u79f0\u4e2d\u6027\u70b9\u4e0d\u76f4\u63a5\u63a5\u5730\u7684\u7535\u529b\u7ebf\u4e00\u76f8\u77ed\u8def\u63a5\u5730\u6545\u969c\uff0c\u4ee5\u53ca\u4ea4\u6d41\u7535\u6c14\u94c1\u9053\u63a5\u89e6\u7f51\u548c\u5176\u4ed6\u4e0d\u5bf9\u79f0\u7535\u529b\u7ebf\u6b63\u5e38\u8fd0\u884c\u72b6\u6001\u4e0b\uff0c\u4eba\u4f53\u78b0\u89e6\u90bb\u8fd1\u901a\u4fe1\u5bfc\u7ebf\u65f6\uff0c\u7531\u5bb9\u6027\u8026\u5408\u5f15\u8d77\u7684\u6d41\u7ecf\u4eba\u4f53\u7684\u7535\u6d41\u5141\u8bb8\u503c\u4e3a____\u3002\nA. 10mA\nB. 12mA\nC. 18mA\nD. 15mA\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e3a\u8282\u7701\u6295\u8d44\u3001\u51cf\u5c11\u5de5\u7a0b\u91cf\uff0c\u9664\u7528\u6237\u6709\u7279\u6b8a\u8981\u6c42\u5916\uff0c\u4e00\u822c\u5de5\u7a0b\u5b9c\u91c7\u7528____\u5de1\u67e5\u65b9\u5f0f\u3002\nA. \u5728\u7ebf\u5f0f\nB. \u79bb\u7ebf\u5f0f\nC. \u5728\u7ebf\u4e0e\u79bb\u7ebf\u7ed3\u5408\nD. \u4ee5\u4e0a\u5747\u53ef\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4887236794731971, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3660090199399449, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u901a\u8fc710\uff5e35kV\u7535\u538b\u7b49\u7ea7\u5e76\u7f51\u7684\u5149\u4f0f\u53d1\u7535\u7ad9\u529f\u7387\u56e0\u6570\u5e94\u80fd\u5728____\u8303\u56f4\u5185\u8fde\u7eed\u53ef\u8c03\uff0c\u6709\u7279\u6b8a\u8981\u6c42\u65f6\uff0c\u53ef\u505a\u9002\u5f53\u8c03\u6574\u4ee5\u7a33\u5b9a\u7535\u538b\u6c34\u5e73\u3002\nA. \u8d85\u524d0.95\uff5e\u6ede\u540e0.95\nB. \u8d85\u524d0.98\uff5e\u6ede\u540e0.98\nC. \u8d85\u524d0.95\uff5e\u6ede\u540e0.9\nD. \u8d85\u524d0.9\uff5e\u6ede\u540e0.9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4653251126673113, "HuggingFaceH4/zephyr-7b-beta": 0.3401211452465684, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.490595776980742, "meta-llama/Meta-Llama-3-8B": 0.3632122790984034, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5149\u4f0f\u53d1\u7535\u7ad9\u8c03\u5ea6\u7ba1\u8f96\u8bbe\u5907\u4f9b\u7535\u7535\u6e90\u5e94\u91c7\u7528\u4e0d\u95f4\u65ad\u7535\u6e90\u88c5\u7f6e(UPS)\u6216\u7ad9\u5185\u76f4\u6d41\u7535\u6e90\u7cfb\u7edf\u4f9b\u7535\uff0c\u5728\u4ea4\u6d41\u4f9b\u7535\u7535\u6e90\u6d88\u5931\u540e\uff0c\u4e0d\u95f4\u65ad\u7535\u6e90\u88c5\u7f6e\u5e26\u8d1f\u8377\u8fd0\u884c\u65f6\u95f4\u5e94\u5927\u4e8e____\u3002\nA. 30min\nB. 40min\nC. 60min\nD. 120min\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5149\u4f0f\u7535\u7ad9\u65e0\u529f\u7535\u538b\u63a7\u5236\u7cfb\u7edf\u54cd\u5e94\u65f6\u95f4\u5e94\u4e3a____\u3002\nA. \u22645s\nB. \u226410s\nC. \u226420s\nD. \u226430s\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u4e8b\u6545\u5907\u7528\u5bb9\u91cf\u7684\u786e\u5b9a\u65b9\u6cd5\uff0c\u4e0b\u9762____\u662f\u6b63\u786e\u7684\u3002\nA. \u62c5\u4efb\u7cfb\u7edf\u4e8b\u6545\u5907\u7528\u7684\u6c34\u7535\u5382\uff0c\u5e94\u6709\u4e13\u7528\u7684\u5907\u7528\u5e93\u5bb9\u4f5c\u4fdd\u8bc1\nB. \u6c34\u7535\u5382\u7684\u7a7a\u95f2\u5bb9\u91cf\u53ef\u4e3a\u7cfb\u7edf\u7684\u4e8b\u6545\u5907\u7528\nC. \u6c34\u7535\u5382\u62c5\u4efb\u4e8b\u6545\u5907\u7528\uff0c\u5728\u4e8b\u6545\u6d88\u9664\u540e\u768410\u5929\uff0c\u5e94\u4fdd\u8bc1\u6062\u590d\u6c34\u7535\u5382\u6240\u6d88\u843d\u7684\u5907\u7528\u5e93\u5bb9\nD. \u7cfb\u7edf\u7684\u4e8b\u6545\u5907\u7528\u5bb9\u91cf\u53ef\u901a\u8fc7\u4f20\u7edf\u7684\u767e\u5206\u7387\u6cd5\u786e\u5b9a\u6216\u7535\u529b\u4e0d\u8db3\u6982\u7387\u6cd5(LOLP)\u786e\u5b9a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6701110881870853, "meta-math/MetaMath-Mistral-7B": 0.9782505526402068, "itpossible/Chinese-Mistral-7B-v0.1": 0.4137189634084383, "HuggingFaceH4/zephyr-7b-beta": 0.9986468711370833, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9127246413049943, "meta-llama/Meta-Llama-3-8B": 0.5243222918601541, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8226072570602727}}, {"question": "\u4e09\u7ea7\u8d1f\u8377\u5bf9\u4f9b\u7535\u7684\u8981\u6c42\u662f____\u3002\nA. \u65e0\u7279\u6b8a\u8981\u6c42\nB. \u7531\u4e24\u8def\u4f4e\u538b\u7535\u6e90\u4f9b\u7535\nC. \u7531\u4e24\u8def\u9ad8\u538b\u7535\u6e90\u4f9b\u7535\nD. \u7531\u4e00\u56de6kV\u53ca\u4ee5\u4e0a\u4e13\u7528\u67b6\u7a7a\u7ebf\u4f9b\u7535\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u91c7\u7528\u9700\u8981\u7cfb\u6570\u6cd5\u8ba1\u7b97\u8865\u507f\u7535\u5bb9\u5668\u7684\u5bb9\u91cf\u65f6\uff0c\u5982\u679c\u8865\u507f\u524d\u7684\u529f\u7387\u56e0\u6570\u4e3a0.8\uff0c\u8865\u507f\u540e\u7684\u529f\u7387\u56e0\u6570\u4e3a0.9\uff0c\u603b\u7684\u6709\u529f\u8ba1\u7b97\u8d1f\u8377\u4e3a750kW\uff0c\u5219\u7535\u5bb9\u5668\u8865\u507f\u5bb9\u91cf\u7684\u8ba1\u7b97\u503c\u7ea6\u4e3a____\u3002\nA. 100kvar\nB. 150kvar\nC. 200kvar\nD. 300kvar\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.48896455894179536, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3583275739447147}}, {"question": "\u5f53\u91c7\u7528____\u7c7b\u706f\u5177\u65f6\uff0c\u706f\u5177\u7684\u5916\u9732\u53ef\u5bfc\u7535\u90e8\u5206\u5e94\u53ef\u9760\u63a5\u5730\u3002\nA. \u2160\nB. \u2161\nC. \u2162\nD. \u2163\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.35203281844824685, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40525307155005386, "meta-llama/Meta-Llama-3-8B": 0.28012882262171335, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.32623178146117626}}, {"question": "\u8ba1\u7b97\u8f93\u7535\u7ebf\u8def\u5bf9\u90bb\u8fd1\u7535\u4fe1\u7ebf\u8def\u611f\u5e94\u4ea7\u751f\u7684\u78c1\u5371\u9669\u5f71\u54cd\uff0c\u5e94\u8003\u8651____\u5e74\u7535\u529b\u7cfb\u7edf\u53d1\u5c55\u7684\u89c4\u5212\u5bb9\u91cf\u3002\nA. 3\uff5e5\nB. 6\uff5e8\nC. 4\uff5e7\nD. 5\uff5e10\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.344785902992216, "HuggingFaceH4/zephyr-7b-beta": 0.8761083369755452, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u5c5e\u4e8e\u5de5\u4e1a\u4f01\u4e1a\u8d1f\u8377\u8ba1\u7b97\u5e38\u7528\u65b9\u6cd5\u7684\u662f____\u3002\nA. \u5229\u7528\u7cfb\u6570\u6cd5\nB. \u9010\u70b9\u8ba1\u7b97\u6cd5\nC. \u9700\u7528\u7cfb\u6570\u6cd5\nD. \u5355\u4f4d\u9762\u79ef\u74e6\u7279\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5825616571411841, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6579351287180931, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4527237462445692, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5149\u4f0f\u53d1\u7535\u7ad9\u529f\u7387\u9884\u6d4b\u7cfb\u7edf\u6240\u6709\u6570\u636e\u81f3\u5c11\u4fdd\u5b58____\u3002\nA. 5\u5e74\nB. 8\u5e74\nC. 10\u5e74\nD. 12\u5e74\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4025265366722338, "meta-math/MetaMath-Mistral-7B": 0.4435041094836205, "itpossible/Chinese-Mistral-7B-v0.1": 0.3403147063768956, "HuggingFaceH4/zephyr-7b-beta": 0.7619210436779386, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3349017728881002, "meta-llama/Meta-Llama-3-8B": 0.2986334267609957, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3900852433273489}}, {"question": "\u5ba2\u623f\u8bbe\u7f6e\u706b\u707e\u5e94\u6025\u5e7f\u64ad\u4e13\u7528\u626c\u58f0\u5668\u65f6\uff0c\u5176\u529f\u7387\u4e0d\u5b9c\u5c0f\u4e8e____\u3002\nA. 0.5W\nB. 0.8W\nC. 1W\nD. 1.2W\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4566951730715616, "meta-math/MetaMath-Mistral-7B": 0.6179018575976974, "itpossible/Chinese-Mistral-7B-v0.1": 0.47776354226150874, "HuggingFaceH4/zephyr-7b-beta": 0.9027075448229681, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5872666339441762, "meta-llama/Meta-Llama-3-8B": 0.4000694279782004, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6120843575431714}}, {"question": "\u6c11\u7528\u5efa\u7b51\u5185\u626c\u58f0\u5668\u8bbe\u7f6e\u5728\u8d70\u9053\u548c\u5927\u5385\u7b49\u516c\u5171\u573a\u6240\uff0c\u626c\u58f0\u5668\u6570\u91cf\u5e94\u80fd\u4fdd\u8bc1\u4ece\u4e00\u4e2a\u9632\u706b\u5206\u533a\u5185\u7684\u4efb\u4f55\u90e8\u4f4d\u5230\u6700\u8fd1\u4e00\u4e2a\u626c\u58f0\u5668\u7684\u8ddd\u79bb\u4e0d\u5927\u4e8e____\u3002\nA. 50m\nB. 40m\nC. 35m\nD. 25m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6920564793015188, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u53d8\u7535\u7ad9\u6709\u4e00\u7ec4\u53cc\u661f\u5f62\u63a5\u7ebf\u768435kV\u7535\u5bb9\u5668\u7ec4\uff0c\u6bcf\u661f\u7684\u6bcf\u76f8\u67092\u4e2a\u4e32\u8054\u6bb5\uff0c\u6bcf\u6bb5\u75315\u53f01000kvar\u7535\u5bb9\u5668\u5e76\u8054\u7ec4\u6210\uff0c\u6b64\u7535\u5bb9\u5668\u7ec4\u7684\u603b\u5bb9\u91cf\u4e3a____\u3002\nA. 15000kvar\nB. 20000kvar\nC. 30000kvar\nD. 60000kvar\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9586197773015301, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u88c5\u673a\u5bb9\u91cf____\u53ca\u4ee5\u4e0a\u7684\u5149\u4f0f\u53d1\u7535\u7ad9\u5e94\u914d\u7f6e\u5149\u4f0f\u53d1\u7535\u529f\u7387\u9884\u6d4b\u7cfb\u7edf\u3002\nA. 10MW\nB. 20MW\nC. 50MW\nD. 100MW\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.300783317901063, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6f6e\u6d41\u8ba1\u7b97\u5e38\u7528\u7684\u65b9\u6cd5\u662f____\nA. \u89e3\u6790\u6cd5\nB. \u8fed\u4ee3\u6cd5\u548c\u725b\u987f\u6cd5\nC. \u79ef\u5206\u6cd5\nD. \u5dee\u5206\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4069544536284589, "meta-math/MetaMath-Mistral-7B": 0.6942883212937533, "itpossible/Chinese-Mistral-7B-v0.1": 0.7003099822472141, "HuggingFaceH4/zephyr-7b-beta": 0.7015403881120152, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5104934221038551, "meta-llama/Meta-Llama-3-8B": 0.48617933164170885, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7a7a\u8c03\u673a\u623f\u3001\u51b7\u51bb\u673a\u623f\u3001\u53d8\u7535\u7ad9\u7b49\u76d1\u63a7\u70b9\u96c6\u4e2d\u7684\u673a\u623f\uff0c\u5b9c\u8bbe\u697c\u5b87\u81ea\u63a7\u7cfb\u7edf\u7ebf\u69fd\uff0c\u4e3a\u6297\u5e72\u6270\uff0c\u6b64\u7ebf\u69fd\u5e94\u91c7\u7528\u53cc\u683c\u91d1\u5c5e\u7ebf\u69fd\uff0c\u4fe1\u53f7\u7ebf\u548c____\u63a7\u5236\u7ebf\u5206\u5f00\u6577\u8bbe\u3002\nA. 110V\nB. 220V\nC. 380V\nD. 460V\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35224507430019897, "meta-math/MetaMath-Mistral-7B": 0.56563117345123, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0750kV\u67b6\u7a7a\u8f93\u7535\u7ebf\u8def\u91c7\u7528\u94a2\u82af\u94dd\u5305\u94a2\u7ede\u7ebf\uff0c\u6863\u8ddd\u4e3a1100m\uff0c\u8de8\u8d8a\u901a\u822a\u6cb3\u6d41\uff0c\u9a8c\u7b97\u5bfc\u7ebf\u5141\u8bb8\u8f7d\u6d41\u91cf\u65f6\uff0c\u5141\u8bb8\u6e29\u5ea6\u5b9c\u53d6____\u3002\nA. 70\u2103\nB. 80\u2103\nC. 90\u2103\nD. 100\u2103\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u666e\u901a\u53d8\u538b\u5668\u7ec4\u8ddd\u79bb\u98ce\u529b\u53d1\u7535\u673a\u7ec4\u7684\u8ddd\u79bb\u6ee1\u8db3DL/T 5383\u20142007\u300a\u98ce\u529b\u53d1\u7535\u573a\u8bbe\u8ba1\u6280\u672f\u89c4\u8303\u300b5.1.5\u4e2d\u7684\u89c4\u5b9a\u3002\u7bb1\u5f0f\u53d8\u538b\u5668\u7ec4\u8ddd\u79bb\u98ce\u529b\u53d1\u7535\u673a\u7ec4____10m\u3002\nA. \u4e0d\u5e94\u5927\u4e8e\nB. \u4e0d\u5e94\u5c0f\u4e8e\nC. \u5e94\u5927\u4e8e\nD. \u5e94\u5c0f\u4e8e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3295826656903648, "meta-math/MetaMath-Mistral-7B": 0.6307955329344102, "itpossible/Chinese-Mistral-7B-v0.1": 0.3534716292209113, "HuggingFaceH4/zephyr-7b-beta": 0.6545382757471417, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8e\u6613\u71c3\u7269\u8d28\u6bd4\u7a7a\u6c14\u91cd\u7684\u7206\u70b8\u6027\u6c14\u4f53\u73af\u5883\uff0c\u5e03\u7f6e\u57281\u533a\u30012\u533a\u9644\u8fd1\u7684\u53d8\u914d\u7535\u6240\u548c\u63a7\u5236\u5ba4\u7684\u5ba4\u5185\u5730\u9762\uff0c\u5e94\u9ad8\u51fa\u5ba4\u5916\u5730\u9762____\u3002\nA. 0.5m\nB. 0.6m\nC. 0.7m\nD. 0.8m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3356821304491814, "meta-math/MetaMath-Mistral-7B": 0.5158824305403928, "itpossible/Chinese-Mistral-7B-v0.1": 0.31031319312730204, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3500288944602904, "meta-llama/Meta-Llama-3-8B": 0.3060136256597631, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6d4b\u91cf\u67d0\u4e00\u91cf\u503c\uff0c\u5176\u7ed3\u679c\u4e3a\uff1a10.5\uff0c10.7\uff0c10.3\uff0c\u6c42\u5176B\u7c7b\u6807\u51c6\u4e0d\u786e\u5b9a\u5ea6\u4e3a____\u3002(\u5176\u4e2dn=2\u65f6\uff0c\u6781\u5dee\u7cfb\u6570C=1.13\uff1bn=3\u65f6\uff0c\u6781\u5dee\u7cfb\u6570C=1.69\uff1bn=4\u65f6\uff0c\u6781\u5dee\u7cfb\u6570C=2.060)\nA. 0.35\nB. 0.12\nC. 0.19\nD. 0.24\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u7535\u5b66\u8ba1\u91cf\u4e2d\uff0c\u4e3a\u4e86\u6d88\u9664\u70ed\u7535\u52bf\u5e26\u6765\u7684\u7cfb\u7edf\u8bef\u5dee\uff0c\u5e38\u5e38\u6539\u53d8\u6d4b\u91cf\u4eea\u5668\u7684\u7535\u6d41\u65b9\u5411\uff0c\u53d6\u4e24\u6b21\u8bfb\u6570\u548c\u7684\u4e8c\u5206\u4e4b\u4e00\u4e3a\u6d4b\u91cf\u8bfb\u6570\u7ed3\u679c\uff0c\u8fd9\u6837\u7684\u6d4b\u91cf\u65b9\u6cd5\u79f0\u4e3a____\u3002\nA. \u8865\u507f\u6d4b\u91cf\u6cd5\nB. \u57fa\u672c\u6d4b\u91cf\u6cd5\nC. \u95f4\u63a5\u6d4b\u91cf\u6cd5\nD. \u7b26\u5408\u6d4b\u91cf\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44719401270104575, "meta-math/MetaMath-Mistral-7B": 0.9270685262747015, "itpossible/Chinese-Mistral-7B-v0.1": 0.5531771529516624, "HuggingFaceH4/zephyr-7b-beta": 0.9994633699892502, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5631081523865228, "meta-llama/Meta-Llama-3-8B": 0.645375867488842, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9948901180778572}}, {"question": "\u56fd\u5bb6\u8ba1\u91cf\u68c0\u5b9a\u89c4\u7a0b\u662f\u7531____\u7ec4\u7ec7\u7f16\u5199\u5e76\u6279\u51c6\u9881\u5e03\uff0c\u5728\u5168\u56fd\u8303\u56f4\u5185\u65bd\u884c\uff0c\u4f5c\u4e3a\u786e\u5b9a\u8ba1\u91cf\u5668\u5177\u6cd5\u5b9a\u5730\u4f4d\u7684\u6280\u672f\u6587\u4ef6\u3002\nA. \u5168\u56fd\u4e13\u4e1a\u8ba1\u91cf\u6280\u672f\u59d4\u5458\u4f1a\nB. \u5168\u56fd\u8ba1\u91cf\u6d4b\u8bd5\u5b66\u4f1a\nC. \u56fd\u5bb6\u8ba1\u91cf\u9662\nD. \u56fd\u52a1\u9662\u8ba1\u91cf\u884c\u653f\u90e8\u95e8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6048941453711425, "HuggingFaceH4/zephyr-7b-beta": 0.9144459327376104, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "SI\u57fa\u672c\u5355\u4f4d\u5171\u6709\u4e03\u4e2a\u5e76\u6709\u76f8\u5e94\u7684\u5355\u4f4d\u7b26\u53f7\uff0c\u4ee5\u4e0b\u54ea\u4e2a\u7b26\u53f7\u662f\u6b63\u786e\u7684\u3002____\nA. \u8d28\u91cf--m\nB. \u7269\u8d28\u7684\u91cf--mm\nC. \u70ed\u529b\u5b66\u6e29\u5ea6--\u2103\nD. \u7535\u6d41--A\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7885009953439368, "itpossible/Chinese-Mistral-7B-v0.1": 0.30702389681474196, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4638207295605946, "meta-llama/Meta-Llama-3-8B": 0.5349679934739762, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9013343143191586}}, {"question": "\u8ba1\u91cf\u7684\u6700\u7ec8\u76ee\u7684\u662f____\u3002\nA. \u5b9e\u73b0\u5355\u4f4d\u7edf\u4e00\nB. \u4e3a\u56fd\u6c11\u7ecf\u6d4e\u548c\u79d1\u5b66\u6280\u672f\u53d1\u5c55\u670d\u52a1\nC. \u7ef4\u62a4\u4eba\u6c11\u5229\u76ca\nD. \u786e\u4fdd\u91cf\u503c\u51c6\u786e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6775924309519793, "HuggingFaceH4/zephyr-7b-beta": 0.9875751695680784, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6358412466904539, "meta-llama/Meta-Llama-3-8B": 0.8184174283983455, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6867663723919765}}, {"question": "\u6d4b\u91cf\u4f20\u611f\u5668\u662f\u6307____\u3002\nA. \u4e00\u79cd\u6307\u793a\u5f0f\u8ba1\u91cf\u5668\u5177\nB. \u8f93\u5165\u548c\u8f93\u51fa\u4e3a\u540c\u79cd\u91cf\u7684\u4eea\u5668\nC. \u63d0\u4f9b\u4e0e\u8f93\u5165\u91cf\u6709\u786e\u5b9a\u5173\u7cfb\u7684\u8f93\u51fa\u91cf\u7684\u5668\u4ef6\nD. \u901a\u8fc7\u8f6c\u6362\u5f97\u5230\u7684\u6307\u793a\u503c\u6216\u7b49\u6548\u4fe1\u606f\u7684\u4eea\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7567676555786679, "meta-math/MetaMath-Mistral-7B": 0.9082068176289131, "itpossible/Chinese-Mistral-7B-v0.1": 0.6126755132633973, "HuggingFaceH4/zephyr-7b-beta": 0.754630417785966, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9090630234856629, "meta-llama/Meta-Llama-3-8B": 0.7148068759357424, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9752284481584098}}, {"question": "\u67d0\u8ba1\u91cf\u6280\u672f\u673a\u6784\u62df\u5efa\u7acb\u4ee5\u4e00\u7b49\u94c2\u7535\u963b\u6e29\u5ea6\u8ba1\u4e3a\u8ba1\u91cf\u6807\u51c6\u5668\u7684\u8ba1\u91cf\u6807\u51c6\uff0c\u7528\u4e8e\u68c0\u5b9a\u4e8c\u7b49\u94c2\u7535\u963b\u6e29\u5ea6\u8ba1\uff0c\u5219\u8be5\u8ba1\u91cf\u6807\u51c6\u5e94\u547d\u540d\u4e3a____\u3002\nA. \u4e00\u7b49\u94c2\u7535\u963b\u6e29\u5ea6\u8ba1\u68c0\u5b9a\u88c5\u7f6e\nB. \u4e00\u7b49\u94c2\u7535\u963b\u6e29\u5ea6\u8ba1\u6807\u51c6\u88c5\u7f6e\nC. \u4e8c\u7b49\u94c2\u7535\u963b\u6e29\u5ea6\u8ba1\u6807\u51c6\u88c5\u7f6e\nD. \u4e8c\u7b49\u94c2\u7535\u963b\u6e29\u5ea6\u8ba1\u6807\u51c6\u5668\u7ec4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38253224097524136, "meta-math/MetaMath-Mistral-7B": 0.6387009477274177, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9520066716538653, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7990405320417002, "meta-llama/Meta-Llama-3-8B": 0.5469986186804172, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8108400725926821}}, {"question": "\u4f9d\u636eJJF1002-2010\u300a\u56fd\u5bb6\u8ba1\u91cf\u68c0\u5b9a\u89c4\u7a0b\u7f16\u5199\u89c4\u5219\u300b\uff0c\u4e0b\u5217\u5173\u4e8e\u8ba1\u91cf\u68c0\u5b9a\u89c4\u7a0b\u7f16\u5199\u539f\u5219\u7684\u8bf4\u6cd5\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u8ba1\u91cf\u68c0\u5b9a\u89c4\u7a0b\u7684\u7f16\u5199\u5e94\u7b26\u5408\u56fd\u5bb6\u6709\u5173\u6cd5\u5f8b\u3001\u6cd5\u89c4\u7684\u89c4\u5b9a\nB. \u8ba1\u91cf\u68c0\u5b9a\u89c4\u7a0b\u7684\u7f16\u5199\u5e94\u7b26\u5408\u8303\u56f4\u5fc5\u987b\u660e\u786e\uff0c\u5728\u5176\u754c\u5b9a\u7684\u8303\u56f4\u5185\uff0c\u6309\u9700\u8981\u529b\u6c42\u5b8c\u6574\nC. \u5728\u8003\u8651\u64cd\u4f5c\u7684\u53ef\u884c\u6027\u53ca\u5b9e\u65bd\u7684\u7ecf\u6d4e\u6027\u7684\u524d\u63d0\u4e0b\uff0c\u5c3d\u91cf\u91c7\u7528\u6700\u65b0\u6280\u672f\nD. \u6839\u636e\u56fd\u60c5\uff0c\u79ef\u6781\u91c7\u7528\u56fd\u9645\u6cd5\u5236\u8ba1\u91cf\u7ec4\u7ec7\uff08OIML\uff09\u53d1\u5e03\u7684\u56fd\u9645\u5efa\u8bae\uff0c\u56fd\u9645\u6587\u4ef6\u53ca\u6709\u5173\u7684\u56fd\u9645\u7ec4\u7ec7\uff08\u5982ISO\uff0cIEC\u7b49\uff09\u53d1\u5e03\u7684\u56fd\u9645\u6807\u51c6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4424026454867804, "meta-math/MetaMath-Mistral-7B": 0.730832678223281, "itpossible/Chinese-Mistral-7B-v0.1": 0.3940554704033166, "HuggingFaceH4/zephyr-7b-beta": 0.9758601731432175, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5221508245037898, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u6cd5\u5b9a\u8ba1\u91cf\u5355\u4f4d\u5305\u62ecSI\u8f85\u52a9\u5355\u4f4d\u5728\u5185\u7684\u5177\u6709\u4e13\u95e8\u540d\u79f0\u7684SI\u5bfc\u51fa\u5355\u4f4d\u5171\u6709____\u4e2a\u3002\nA. 7\nB. 16\nC. 20\nD. 21\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.46793706120590767, "itpossible/Chinese-Mistral-7B-v0.1": 0.3790504762382752, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e00\u4e2a\u88ab\u6d4b\u91cf\u8fdb\u884c\u91cd\u590d\u89c2\u6d4b\uff0c\u5728\u6240\u5f97\u7684\u4e00\u7cfb\u5217\u6d4b\u91cf\u503c\u4e2d\uff0c\u51fa\u73b0\u4e86\u4e0e\u5176\u4ed6\u503c\u504f\u79bb\u8f83\u8fdc\u7684\u4e2a\u522b\u503c\u65f6\uff0c\u5e94____\u3002\nA. \u5c06\u8fd9\u4e9b\u503c\u5254\u9664\nB. \u4fdd\u7559\u6240\u6709\u7684\u6570\u636e\uff0c\u4ee5\u4fbf\u4fdd\u8bc1\u6d4b\u91cf\u7ed3\u679c\u7684\u5b8c\u6574\u6027\nC. \u5224\u522b\u5176\u662f\u5426\u662f\u5f02\u5e38\u503c\uff0c\u786e\u4e3a\u5f02\u5e38\u503c\u7684\u4e88\u4ee5\u5254\u9664\nD. \u5e9f\u5f03\u8fd9\u7ec4\u6d4b\u91cf\u503c\uff0c\u91cd\u65b0\u6d4b\u91cf\uff0c\u83b7\u5f97\u4e00\u7ec4\u65b0\u7684\u6d4b\u91cf\u503c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.918513815557327, "meta-math/MetaMath-Mistral-7B": 0.9930071725221526, "itpossible/Chinese-Mistral-7B-v0.1": 0.8988549169038214, "HuggingFaceH4/zephyr-7b-beta": 0.9975404359967065, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9648907787418176, "meta-llama/Meta-Llama-3-8B": 0.8953118455226438, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8565628441682324}}, {"question": "\u501f\u52a9\u4e8e\u4e00\u5207\u53ef\u5229\u7528\u7684\u6709\u5173\u4fe1\u606f\u8fdb\u884c\u79d1\u5b66\u5224\u65ad\uff0c\u5f97\u5230\u4f30\u8ba1\u7684\u6807\u51c6\u504f\u5dee\u4e3a____\u6807\u51c6\u4e0d\u786e\u5b9a\u5ea6\u3002\nA. A\u7c7b\nB. B\u7c7b\nC. \u5408\u6210\nD. \u6269\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u578b\u5f0f\u8bc4\u4ef7\u7ed3\u675f\u540e\uff0c\u7ecf\u5ba1\u67e5\u5408\u683c\u7684\uff0c\u7531____\u5411\u7533\u8bf7\u5355\u4f4d\u9881\u53d1\u578b\u5f0f\u6279\u51c6\u8bc1\u4e66\u3002\nA. \u8ba1\u91cf\u6280\u672f\u673a\u6784\nB. \u53d7\u7406\u7533\u8bf7\u7684\u653f\u5e9c\u8ba1\u91cf\u884c\u653f\u90e8\u95e8\nC. \u4e0a\u7ea7\u653f\u5e9c\u8ba1\u91cf\u4e3b\u7ba1\u90e8\u95e8\nD. \u56fd\u5bb6\u8d28\u68c0\u603b\u5c40\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5893012107186921, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5552791692202023, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4657060983879261}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u8ba1\u91cf\u6807\u51c6\u8003\u6838\u7684\u8bf4\u6cd5\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u65b0\u5efa\u8ba1\u91cf\u6807\u51c6\u7684\u8003\u6838\u5e94\u9996\u5148\u8fdb\u884c\u4e66\u9762\u5ba1\u67e5\uff0c\u57fa\u672c\u7b26\u5408\u8981\u6c42\u540e\u518d\u8fdb\u884c\u73b0\u573a\u8003\u6838\nB. \u8ba1\u91cf\u6807\u51c6\u8003\u6838\u575a\u6301\u9010\u9879\u9010\u6761\u8003\u6838\u539f\u5219\uff0c\u4f46\u5217\u5165\u8ba1\u91cf\u6807\u51c6\u7b80\u5316\u8003\u6838\u76ee\u5f55\u7684\u53ef\u6309\u89c4\u5b9a\u7b80\u5316\nC. \u8003\u8bc4\u5458\u987b\u7ecf\u56fd\u5bb6\u6216\u7701\u7ea7\u8d28\u91cf\u6280\u672f\u76d1\u7763\u90e8\u95e8\u8003\u6838\u5408\u683c\nD. \u8ba1\u91cf\u6807\u51c6\u8003\u6838\u5b9e\u65bd\u7ec4\u957f\u8d1f\u8d23\u5236\uff0c\u6bcf\u9879\u8ba1\u91cf\u6807\u51c6\u4e00\u822c\u75311\u81f32\u540d\u8003\u8bc4\u5458\u6267\u884c\u8003\u6838\u4efb\u52a1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f3a\u5236\u68c0\u5b9a\u4e0e\u975e\u5f3a\u5236\u68c0\u5b9a\u5747\u5c5e\u4e8e____\u3002\nA. \u884c\u653f\u89c4\u5b9a\nB. \u6cd5\u5236\u68c0\u5b9a\nC. \u6cd5\u5f8b\u89c4\u5b9a\nD. \u5408\u540c\u89c4\u5b9a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3331189250436602, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.46788744394017995, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u793e\u4f1a\u516c\u7528\u8ba1\u91cf\u6807\u51c6\u5668\u5177\u7531____\u7ea7\u4ee5\u4e0a\u5730\u65b9\u4eba\u6c11\u653f\u5e9c\u8ba1\u91cf\u884c\u653f\u90e8\u95e8\u6839\u636e\u672c\u5730\u533a\u7684\u9700\u8981\u7edf\u4e00\u7ec4\u7ec7\u5efa\u7acb\u3002\nA. \u7701\nB. \u5e02\nC. \u53bf\nD. \u76f8\u5173\u90e8\u95e8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u901a\u5e38\u628a\u88ab\u6d4b\u91cf\u503c\u4e3a\u96f6\u65f6\u6d4b\u91cf\u4eea\u5668\u7684\u793a\u503c\u76f8\u5bf9\u4e8e\u6807\u5c3a\u96f6\u523b\u7ebf\u4e4b\u5dee\u503c\u79f0\u4e3a____\u3002\nA. \u96f6\u4f4d\u8bef\u5dee\nB. \u56fa\u6709\u8bef\u5dee\nC. \u96f6\u503c\u8bef\u5dee(\u5373\u96f6\u503c\u7684\u57fa\u503c\u8bef\u5dee)\nD. \u6d4b\u91cf\u4eea\u5668\u7684\u504f\u79fb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5649902638585106, "meta-math/MetaMath-Mistral-7B": 0.7244276593483835, "itpossible/Chinese-Mistral-7B-v0.1": 0.665644521532915, "HuggingFaceH4/zephyr-7b-beta": 0.5862416071216532, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5452671370730434, "meta-llama/Meta-Llama-3-8B": 0.47729382854869234, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.52876076776313}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u300a\u8ba1\u91cf\u6807\u51c6\u6280\u672f\u62a5\u544a\u300b\u5185\u5bb9\u7684\u8868\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u8ba1\u91cf\u6807\u51c6\u7684\u6d4b\u91cf\u8303\u56f4\u5e94\u4e0e\u8ba1\u91cf\u6807\u51c6\u5668\u6240\u63d0\u4f9b\u7684\u6d4b\u91cf\u8303\u56f4\u76f8\u540c\nB. \u8ba1\u91cf\u6807\u51c6\u7684\u4e0d\u786e\u5b9a\u5ea6\u5206\u6bb5\u7ed9\u51fa\u65f6\uff0c\u5e94\u7ed9\u51fa\u5404\u6bb5\u7684\u6700\u5c0f\u4e0d\u786e\u5b9a\u5ea6\nC. \u68c0\u5b9a\u6216\u6821\u51c6\u7ed3\u679c\u7684\u6d4b\u91cf\u4e0d\u786e\u5b9a\u5ea6\u8bc4\u5b9a\u7ed3\u679c\u5e94\u5c0f\u4e8e\u8ba1\u91cf\u6807\u51c6\u7684\u6269\u5c55\u4e0d\u786e\u5b9a\u5ea6\nD. \u68c0\u5b9a\u6216\u6821\u51c6\u7ed3\u679c\u9a8c\u8bc1\u65f6\u5982\u679c\u4e0d\u53ef\u80fd\u91c7\u7528\u4f20\u9012\u6bd4\u8f83\u6cd5\uff0c\u53ef\u91c7\u7528\u591a\u4e2a\u5b9e\u9a8c\u5ba4\u4e4b\u95f4\u6bd4\u5bf9\u7684\u65b9\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4387718460501942, "meta-llama/Meta-Llama-3-8B": 0.3723092414146507, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u6ce8\u518c\u8bc1\u300b\u6bcf\u4e00\u6ce8\u518c\u6709\u6548\u671f\u4e3a____\u5e74\u3002\u5728\u6709\u6548\u671f\u9650\u5185\u662f\u6ce8\u518c\u8ba1\u91cf\u5e08\u7684____\u51ed\u8bc1\uff0c\u7531\u6ce8\u518c\u8ba1\u91cf\u5e08\u672c\u4eba\u4fdd\u7ba1\u548c\u4f7f\u7528\u3002\nA. 5\uff0c\u8d44\u8d28\nB. 3\uff0c\u8d44\u8d28\nC. 5\uff0c\u6267\u4e1a\nD. 3\uff0c\u6267\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6800174617893273}}, {"question": "\u4ee5\u4e0b\u5728\u8bc1\u4e66\u4e0a\u7ed9\u51fa\u7684k=2\u7684\u6269\u5c55\u4e0d\u786e\u5b9a\u5ea6\u4e2d____\u7684\u8868\u793a\u65b9\u5f0f\u662f\u6b63\u786e\u7684\u3002\nA. U=0.00800mg\nB. Ur=8\u00d710-3\nC. U=523.8\u03bcm\nD. 0.0000008m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.39202249910751874, "meta-math/MetaMath-Mistral-7B": 0.5612834895589386, "itpossible/Chinese-Mistral-7B-v0.1": 0.39325343687947123, "HuggingFaceH4/zephyr-7b-beta": 0.9205690888127996, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7477548760066136}}, {"question": "\u4f7f\u6d4b\u91cf\u4eea\u5668\u7684\u89c4\u5b9a\u8ba1\u91cf\u7279\u6027\u4e0d\u53d7\u635f\u4e5f\u4e0d\u964d\u4f4e\uff0c\u5176\u540e\u4ecd\u53ef\u5728\u989d\u5b9a\u64cd\u4f5c\u6761\u4ef6\u4e0b\u8fd0\u884c\u800c\u80fd\u627f\u53d7\u7684\u6781\u7aef\u6761\u4ef6\u79f0____\nA. \u53c2\u8003\u6761\u4ef6\nB. \u989d\u5b9a\u64cd\u4f5c\u6761\u4ef6\nC. \u6b63\u5e38\u4f7f\u7528\u6761\u4ef6\nD. \u6781\u9650\u6761\u4ef6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7201170809111095, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.619181955471747, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7507947107385664}}, {"question": "____\u662f\u5bf9\u6d4b\u91cf\u6240\u5305\u62ec\u7684\u786c\u4ef6\u548c\u8f6f\u4ef6\u7684\u7edf\u79f0\u3002\nA. \u6d4b\u91cf\u8bbe\u5907\nB. \u6d4b\u91cf\u4eea\u5668\nC. \u6d4b\u91cf\u57fa\u51c6\nD. \u6d4b\u91cf\u6807\u51c6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5234552363747663, "meta-math/MetaMath-Mistral-7B": 0.44653091836709136, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9791436361876614, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4853399784198446, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bc1\u4e66\u3001\u62a5\u544a\u7684\u526f\u672c____\nA. \u5e94\u6309\u89c4\u5b9a\u7684\u4fdd\u5b58\u671f\u4fdd\u5b58\nB. \u6839\u636e\u9700\u8981\u53ef\u4ee5\u4fdd\u5b58\u4e5f\u53ef\u4ee5\u4e0d\u4fdd\u5b58\nC. \u53ea\u80fd\u662f\u539f\u4ef6\u7684\u590d\u5370\u4ef6\u624d\u80fd\u4fdd\u8bc1\u4e0e\u539f\u4ef6\u5b8c\u5168\u4e00\u81f4\nD. \u5e94\u6c38\u4e45\u4fdd\u5b58\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6519443791577377, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5279784291504039, "HuggingFaceH4/zephyr-7b-beta": 0.7972551161044213, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7687438070255852, "meta-llama/Meta-Llama-3-8B": 0.838331995447268, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8924839579802347}}, {"question": "\u957f\u65b9\u5f62\u9762\u79ef\u662f\u901a\u8fc7\u6d4b\u91cf\u5176\u957f\u5ea6\u548c\u5bbd\u5ea6\u7528\u5176\u4e58\u79ef\u6765\u786e\u5b9a\u7684\uff0c\u540c\u4f53\u5bc6\u5ea6\u662f\u6839\u636e\u6d4b\u91cf\u7269\u4f53\u7684\u8d28\u91cf\u548c\u4f53\u79ef\u7684\u7ed3\u679c\uff0c\u6309\u5bc6\u5ea6\u5b9a\u4e49\u516c\u5f0f\u8ba1\u7b97\u7684\u3002\u8fd9\u79cd\u6d4b\u91cf\u65b9\u6cd5\u901a\u5e38\u79f0\u4e3a____\u3002\nA. \u5b9a\u4e49\u6d4b\u91cf\u6cd5\nB. \u66ff\u4ee3\u6d4b\u91cf\u6cd5\nC. \u95f4\u63a5\u6d4b\u91cf\u6cd5\nD. \u7b26\u5408\u6d4b\u91cf\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8228629829823692, "meta-math/MetaMath-Mistral-7B": 0.923990393282142, "itpossible/Chinese-Mistral-7B-v0.1": 0.5015219298462886, "HuggingFaceH4/zephyr-7b-beta": 0.9997638594654168, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8399627346275566, "meta-llama/Meta-Llama-3-8B": 0.4930919731159906, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9884901013112797}}, {"question": "\u7a33\u5b9a\u6027\u662f\u6307\u6d4b\u91cf\u4eea\u5668\u4fdd\u6301\u5176\u8ba1\u91cf\u7279\u6027\u968f\u65f6\u95f4____\u7684\u80fd\u529b\u3002\nA. \u54cd\u5e94\u53d8\u5316\nB. \u6162\u53d8\u5316\nC. \u7a33\u5b9a\nD. \u6052\u5b9a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5295780897276104, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3858720996141509, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u5168\u96c6\u4e3a\u5b9e\u6570\u96c6$\\mathbb{R}$\uff0c\u96c6\u5408$A=\\{x|x^{2}-2x<0\\},B=\\left\\{x|l og_{2}x>0\\right\\}$\uff0c\u5219$\\left(\\complement_R A \\right) \\cap B$\u7684\u503c\u4e3a____\nA. $\\left(-\\infty,0\\right]\\cup(1,+\\infty)$\nB. $\\left(0,1\\right]$\nC. $\\left[2,+\\infty\\right)$\nD. $\\emptyset$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u629b\u7269\u7ebf$x^2=2y$\u7684\u7126\u70b9\u5750\u6807\u662f____\nA. $(\\frac{1}{4},0)$\nB. $(0,\\frac{1}{2})$\nC. $(0,\\frac{1}{4})$\nD. $(\\frac{1}{2},0)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.264634220591857, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "$\\forall x\\neq0$,$\\left(x+\\frac{1}{x}\\right)^{10}$\u53ef\u5199\u6210\u5173\u4e8e$\\left(x^2+\\frac{1}{x^2}\\right)$\u7684\u591a\u9879\u5f0f\uff0c\u5219\u8be5\u591a\u9879\u5f0f\u5404\u9879\u7cfb\u6570\u4e4b\u548c\u4e3a____\nA. 240\nB. 241\nC. 242\nD. 243\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fc7\u53cc\u66f2\u7ebf${\\frac{x^{2}}{a^{2}}}-{\\frac{y^{2}}{b^{2}}}=1(a>0,b>0)$\u7684\u4e00\u4e2a\u7126\u70b9F\u5f15\u5b83\u7684\u6e10\u8fd1\u7ebf\u7684\u5782\u7ebf\uff0c\u5782\u8db3\u4e3aM\uff0c\u5ef6\u957fFM\u4ea4y\u8f74\u4e8eE\uff0c\u82e5|FM|=2|ME|\uff0c\u5219\u8be5\u53cc\u66f2\u7ebf\u7684\u79bb\u5fc3\u7387\u4e3a____\nA. 3\nB. 2\nC. $\\sqrt3$\nD. $\\sqrt2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3013812289234467, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.371068906204966, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3689108554330873}}, {"question": "\u8981\u5f97\u5230\u51fd\u6570$f(x)=\\sin(2x+{\\frac{\\pi}{3}})$\u7684\u5bfc\u51fd\u6570$f^{\\prime}(x)$\u7684\u56fe\u8c61\uff0c\u53ea\u9700\u5c06$f(x)$\u7684\u56fe\u50cf____\nA. \u5411\u5de6\u5e73\u79fb$\\frac{\\pi}{2}$\u4e2a\u5355\u4f4d\uff0c\u518d\u628a\u5404\u70b9\u7684\u7eb5\u5750\u6807\u4f38\u957f\u5230\u539f\u6765\u76842\u500d\uff08\u6a2a\u5750\u6807\u4e0d\u53d8\uff09\nB. \u5411\u5de6\u5e73\u79fb$\\frac{\\pi}{2}$\u4e2a\u5355\u4f4d\uff0c\u518d\u628a\u5404\u70b9\u7684\u7eb5\u5750\u6807\u7f29\u77ed\u5230\u539f\u6765\u7684$\\frac{1}{2}$\u500d\uff08\u6a2a\u5750\u6807\u4e0d\u53d8\uff09\nC. \u5411\u53f3\u5e73\u79fb$\\frac{\\pi}{4}$\u4e2a\u5355\u4f4d\uff0c\u518d\u628a\u5404\u70b9\u7684\u7eb5\u5750\u6807\u4f38\u957f\u5230\u539f\u6765\u7684$\\frac{1}{2}$\u500d\uff08\u6a2a\u5750\u6807\u4e0d\u53d8\uff09\nD. \u5411\u53f3\u5e73\u79fb$\\frac{\\pi}{4}$\u4e2a\u5355\u4f4d\uff0c\u518d\u628a\u5404\u70b9\u7684\u7eb5\u5750\u6807\u4f38\u957f\u5230\u539f\u6765\u76842\u500d\uff08\u6a2a\u5750\u6807\u4e0d\u53d8\uff09\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3060136256597631, "HuggingFaceH4/zephyr-7b-beta": 0.6441395489546198, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u8fb9\u957f\u4e3a3\uff0c4\uff0c5\u7684\u4e09\u89d2\u5f62\u5185\u90e8\u4efb\u53d6\u4e00\u70b9P,\u5219\u70b9P\u5230\u4e09\u4e2a\u9876\u70b9\u8ddd\u79bb\u90fd\u5927\u4e8e1\u7684\u6982\u7387\u4e3a____\nA. $\\frac{6-\\pi}{6}$\nB. $\\frac{12-\\pi}{12}$\nC. $\\frac{\\pi}{6}$\nD. $\\frac{\\pi}{12}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29068935354339714, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u692d\u5706$x^{2}+m y^{2}=1$\u7684\u7126\u70b9\u5728x\u8f74\u4e0a\uff0c\u957f\u8f74\u957f\u662f\u77ed\u8f74\u957f\u7684\u4e24\u500d\uff0c\u5219m\u7684\u503c\u4e3a____\nA. $\\dfrac{1}{4}$\nB. $\\dfrac{1}{2}$\nC. 2\nD. 4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5$\\sin(\\frac{\\pi}{4}-x)=\\frac{3}{5}$\uff0c\u5219$\\sin2x$\u7684\u503c\u4e3a____\nA. $\\frac{19}{25}$\nB. $\\frac{16}{25}$\nC. $\\frac{14}{25}$\nD. $\\frac{7}{25}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2906893535433972, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u51fd\u6570$f(x)=a \\ln x-2x$,\u82e5\u4e0d\u7b49\u5f0f$f(x+1)>a x-2e^{x}$\u5728$x \\in \\left(0 +\\infty\\right)$\u4e0a\u6052\u6210\u7acb\uff0c\u5219\u5b9e\u6570a\u7684\u53d6\u503c\u8303\u56f4\u662f____\nA. $a{\\leq}2$\nB. $a\\geq2$\nC. $a{\\leq}0$\nD. $0\\leq a\\leq2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "17\u4e16\u7eaa\uff0c\u5728\u7814\u7a76\u5929\u6587\u5b66\u7684\u8fc7\u7a0b\u4e2d\uff0c\u4e3a\u4e86\u7b80\u5316\u5927\u6570\u8fd0\u7b97\uff0c\u82cf\u683c\u5170\u6570\u5b66\u5bb6\u7eb3\u76ae\u5c14\u53d1\u660e\u4e86\u5bf9\u6570\uff0c\u5bf9\u6570\u7684\u601d\u60f3\u65b9\u6cd5\u5373\u628a\u4e58\u65b9\u548c\u4e58\u6cd5\u8fd0\u7b97\u5206\u522b\u8f6c\u5316\u4e3a\u4e58\u6cd5\u548c\u52a0\u6cd5\uff0c\u6570\u5b66\u5bb6\u62c9\u666e\u62c9\u65af\u79f0\u8d5e\u4e3a\u201c\u5bf9\u6570\u7684\u53d1\u660e\u5728\u5b9e\u6548\u4e0a\u7b49\u4e8e\u628a\u5929\u6587\u5b66\u5bb6\u7684\u5bff\u547d\u5ef6\u957f\u4e86\u8bb8\u591a\u500d\u201d.\u5df2\u77e5$\\lg2\\approx0.3010$\uff0c$\\lg3\\approx0.4771$\uff0c\u8bbe$N=4^5\\times27$\uff0c\u5219N\u6240\u5728\u7684\u533a\u95f4\u4e3a____\nA. $\\left(10^{15},10^{16}\\right)$\nB. $\\left(10^{16},10^{17}\\right)$\nC. $\\left(10^{17},10^{18}\\right)$\nD. $\\left(10^{18},10^{19}\\right)$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2948380239243211, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4830961923036099, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3924103904757602}}, {"question": "\u4e3a\u505a\u597d\u793e\u533a\u65b0\u51a0\u75ab\u60c5\u9632\u63a7\u5de5\u4f5c\uff0c\u9700\u5c06\u4e94\u540d\u5fd7\u613f\u8005\u5206\u914d\u5230\u4e09\u4e2a\u793e\u533a\u53bb\u5f00\u5c55\u5de5\u4f5c\uff0c\u6bcf\u540d\u5fd7\u613f\u8005\u53ea\u5206\u914d\u5230\u4e00\u4e2a\u793e\u533a\uff0c\u6bcf\u4e2a\u793e\u533a\u81f3\u5c11\u5206\u914d\u4e00\u540d\u5fd7\u613f\u8005\uff0c\u5fd7\u613f\u8005\u7532\u548c\u4e59\u5fc5\u987b\u53bb\u540c\u4e00\u4e2a\u793e\u533a\uff0c\u5219\u4e0d\u540c\u7684\u5206\u914d\u65b9\u6cd5\u5171\u6709____\nA. 12\u79cd\nB. 18\u79cd\nC. 24\u79cd\nD. 36\u79cd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6570\u5b66\u5bf9\u4e8e\u4e00\u4e2a\u56fd\u5bb6\u7684\u53d1\u5c55\u81f3\u5173\u91cd\u8981\uff0c\u53d1\u8fbe\u56fd\u5bb6\u5e38\u5e38\u628a\u4fdd\u6301\u6570\u5b66\u9886\u5148\u5730\u4f4d\u4f5c\u4e3a\u4ed6\u4eec\u7684\u6218\u7565\u9700\u6c42\uff0e\u73b0\u67d0\u5927\u5b66\u4e3a\u63d0\u9ad8\u6570\u5b66\u7cfb\u5b66\u751f\u7684\u6570\u5b66\u7d20\u517b\uff0c\u7279\u5f00\u8bbe\u4e86\u201c\u53e4\u4eca\u6570\u5b66\u601d\u60f3\u201d\u201c\u4e16\u754c\u6570\u5b66\u901a\u53f2\u201d\u201c\u51e0\u4f55\u539f\u672c\u201d\u201c\u4ec0\u4e48\u662f\u6570\u5b66\u201d\u56db\u95e8\u9009\u4fee\u8bfe\u7a0b\uff0c\u8981\u6c42\u6570\u5b66\u7cfb\u6bcf\u4f4d\u540c\u5b66\u6bcf\u5b66\u5e74\u81f3\u591a\u90093\u95e8\uff0c\u5927\u4e00\u5230\u5927\u4e093\u5b66\u5e74\u5fc5\u987b\u5c06\u56db\u95e8\u9009\u4fee\u8bfe\u7a0b\u9009\u5b8c\uff0c\u5219\u6bcf\u4f4d\u540c\u5b66\u7684\u4e0d\u540c\u9009\u4fee\u65b9\u5f0f\u6709____\nA. 60\u79cd\nB. 78\u79cd\nC. 84\u79cd\nD. 144\u79cd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2772747813211935, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5\u5e73\u9762$\\alpha$\u7684\u6cd5\u5411\u91cf\u4e3a$\\vec{n}_{1}=(3,2,1)$\uff0c\u5e73\u9762$\\beta$\u7684\u6cd5\u5411\u91cf\u4e3a$\\vec{n}_{2}=(2,0,-1)$\u5219\u5e73\u9762$\\alpha$\u4e0e\u5e73\u9762$\\beta$\u5939\u89d2\u7684\u4f59\u5f26\u503c\u4e3a____\nA. $\\frac{\\sqrt{70}}{14}$\nB. $\\frac{\\sqrt{70}}{10}$\nC. $-\\frac{\\sqrt{70}}{14}$\nD. $-\\frac{\\sqrt{70}}{10}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.39677601199564055, "meta-math/MetaMath-Mistral-7B": 0.6039639624650316, "itpossible/Chinese-Mistral-7B-v0.1": 0.30702389681474196, "HuggingFaceH4/zephyr-7b-beta": 0.9803934653888373, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.582022701136062, "meta-llama/Meta-Llama-3-8B": 0.2953920515320701, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6042524993002857}}, {"question": "\u5df2\u77e5$\u5e73\u9762\\alpha // \u5e73\u9762\\beta$\uff0c$m\\subset\\alpha$\uff0c$n\\subset\\beta$\uff0c\u5219\u4e0b\u5217\u7ed3\u8bba\u4e00\u5b9a\u6b63\u786e\u662f____\nA. m,n\u662f\u5e73\u884c\u76f4\u7ebf\nB. m,n\u662f\u5f02\u9762\u76f4\u7ebf\nC. m,n\u662f\u5171\u9762\u76f4\u7ebf\nD. m,n\u662f\u4e0d\u76f8\u4ea4\u76f4\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5\u629b\u7269\u7ebf$y^2=2px$\u7684\u7126\u70b9\u4e0e\u692d\u5706$\\frac{x^2}{6}+\\frac{y^2}{2}=1$\u7684\u53f3\u7126\u70b9\u91cd\u5408\uff0c\u5219p\u7684\u503c\u4e3a____\nA. -2\nB. 2\nC. -4\nD. 4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5448858508303147, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4e00\u7535\u5b50\u96c6\u6210\u5757\u6709\u4e09\u4e2a\u5143\u4ef6a\uff0cb\uff0cc\u5e76\u8054\u6784\u6210\uff0c\u4e09\u4e2a\u5143\u4ef6\u662f\u5426\u6709\u6545\u969c\u76f8\u4e92\u72ec\u7acb\uff0e\u5df2\u77e5\u81f3\u5c111\u4e2a\u5143\u4ef6\u6b63\u5e38\u5de5\u4f5c\uff0c\u8be5\u96c6\u6210\u5757\u5c31\u80fd\u6b63\u5e38\u8fd0\u884c\uff0e\u82e5\u6bcf\u4e2a\u5143\u4ef6\u80fd\u6b63\u5e38\u5de5\u4f5c\u7684\u6982\u7387\u5747\u4e3a$\\frac{4}{5}$\u5219\u5728\u8be5\u96c6\u6210\u5757\u80fd\u591f\u6b63\u5e38\u5de5\u4f5c\u7684\u60c5\u51b5\u4e0b\uff0c\u6709\u4e14\u4ec5\u6709\u4e00\u4e2a\u5143\u4ef6\u51fa\u73b0\u6545\u969c\u7684\u6982\u7387\u4e3a____\nA. $\\frac{12}{31}$\nB. $\\frac{48}{125}$\nC. $\\frac{16}{25}$\nD. $\\frac{16}{125}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u6761\u4ef6$p:\\left|x+1\\right|>2$\uff0c\u6761\u4ef6$q:x>a$,\u4e14$\\neg p$\u662f$\\neg q$\u7684\u5145\u5206\u4e0d\u5fc5\u8981\u6761\u4ef6\uff0c\u5219\u5b9e\u6570a\u7684\u53d6\u503c\u8303\u56f4\u662f____\nA. $a\\geq1$\nB. $a\\leq1$\nC. $a\\geq-1$\nD. $a\\leq -3$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.325455072595945, "meta-llama/Meta-Llama-3-8B": 0.287988029147044, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u51fd\u6570$f(x)$\u662f\u5b9a\u4e49\u5728$\\mathbb{R}$\u4e0a\u7684\u5076\u51fd\u6570\uff0c\u4e14\u5728$\\left(0,+\\infty\\right)$\u4e0a\u5355\u8c03\u9012\u589e\uff0c\u5219____\nA. $f(-3)<f(-\\log_{3}13)<f(2^{0.6})$\nB. $f(-3)<f(2^{0.6})<f(-\\log_{3}13)$\nC. $f(2^{0.6})< f(-\\log_{3}13) <f(-3)$\nD. $f(2^{0.6})<f(-3)< f(-\\log_{3}13) $\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2849652956172042, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u7269\u7406\u5b66\u7684\u91cd\u5927\u53d1\u73b0\u4e2d\u79d1\u5b66\u5bb6\u4eec\u521b\u9020\u51fa\u4e86\u8bb8\u591a\u7269\u7406\u5b66\u7814\u7a76\u65b9\u6cd5\uff0c\u5982\u7406\u60f3\u5b9e\u9a8c\u6cd5\u3001\u63a7\u5236\u53d8\u91cf\u6cd5 \u3001\u6781\u9650\u601d\u60f3\u6cd5\u3001\u5fae\u5143\u6cd5\u548c\u5efa\u7acb\u7269\u7406\u6a21\u578b\u6cd5\u7b49\u3002\u4ee5\u4e0b\u5173\u4e8e\u6240\u7528\u7269\u7406\u5b66\u7814\u7a76\u65b9\u6cd5\u7684\u53d9\u8ff0\u6b63\u786e\u7684\u662f____\nA. \u5728\u7269\u4f53\u672c\u8eab\u7684\u5927\u5c0f\u548c\u5f62\u72b6\u5bf9\u7814\u7a76\u7684\u95ee\u9898\u5f71\u54cd\u975e\u5e38\u5c0f\u65f6\uff0c\u7269\u4f53\u53ef\u7b80\u5316\u4e3a\u4e00\u4e2a\u5177\u6709\u8d28\u91cf\u7684\u70b9\uff0c\u8fd9\u79cd\u65b9\u6cd5\u53eb\u6781\u9650\u601d\u60f3\u6cd5\nB. \u6839\u636e\u529f\u7387\u7684\u5b9a\u4e49\u5f0f\uff0c\u5f53\u65f6\u95f4\u95f4\u9694\u975e\u5e38\u5c0f\u65f6\uff0c\u5c31\u53ef\u4ee5\u7528\u8fd9\u4e00\u95f4\u9694\u5185\u7684\u5e73\u5747\u529f\u7387\u8868\u793a\u95f4\u9694\u5185\u67d0\u4e00\u65f6\u523b\u7684\u77ac\u65f6\u529f\u7387\uff0c\u8fd9\u5e94\u7528\u4e86\u63a7\u5236\u53d8\u91cf\u6cd5\nC. \u5982\u679c\u4e00\u4e2a\u529b\u7684\u4f5c\u7528\u6548\u679c\u4e0e\u53e6\u5916\u4e24\u4e2a\u529b\u7684\u4f5c\u7528\u6548\u679c\u76f8\u540c\uff0c\u8fd9\u4e2a\u529b\u5c31\u662f\u90a3\u4e24\u4e2a\u529b\u7684\u5408\u529b\u3002\u8fd9\u91cc\u91c7\u7528\u4e86\u7406\u60f3\u5b9e\u9a8c\u6cd5\nD. \u5728\u63a8\u5bfc\u5f39\u7c27\u5f39\u529b\u505a\u529f\u7684\u8868\u8fbe\u5f0f\u65f6\uff0c\u628a\u6574\u4e2a\u505a\u529f\u8fc7\u7a0b\u5212\u5206\u6210\u5f88\u591a\u5c0f\u6bb5\uff0c\u6bcf\u4e00\u5c0f\u6bb5\u8fd1\u4f3c\u770b\u4f5c\u6052\u529b\u505a\u529f\uff0c\u7136\u540e\u628a\u5404\u5c0f\u6bb5\u5f39\u529b\u6240\u505a\u7684\u529f\u76f8\u52a0\uff0c\u8fd9\u91cc\u91c7\u7528\u4e86\u5fae\u5143\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3936874995067734, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.35096048266444385, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u539f\u5b50\u7684\u6838\u5f0f\u7ed3\u6784\u5b66\u8bf4,\u662f\u5362\u745f\u798f\u6839\u636e\u4ee5\u4e0b\u54ea\u4e2a\u5b9e\u9a8c\u6216\u73b0\u8c61\u63d0\u51fa\u6765\u7684____\nA. \u5149\u7535\u6548\u5e94\u5b9e\u9a8c\nB. \u6c22\u539f\u5b50\u5149\u8c31\u5b9e\u9a8c\nC. $\\alpha$\u7c92\u5b50\u6563\u5c04\u5b9e\u9a8c\nD. \u5929\u7136\u653e\u5c04\u73b0\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.375661615905471, "meta-math/MetaMath-Mistral-7B": 0.39855635395481104, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.719430478575407, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.873868015137993, "meta-llama/Meta-Llama-3-8B": 0.8885826429591838, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9223083349516825}}, {"question": "\u5c0f\u8239\u5728\u9759\u6c34\u4e2d\u7684\u901f\u5ea6\u662f4m/s\uff0c\u4e00\u6761\u6cb3\u5bbd120m\uff0c\u6cb3\u6c34\u6d41\u901f\u4e3a5m/s\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u5c0f\u8239\u5728\u6cb3\u4e2d\u8fd0\u52a8\u7684\u6700\u5927\u901f\u5ea6\u662f9m/s\nB. \u5c0f\u8239\u6e21\u6cb3\u7684\u6700\u77ed\u65f6\u95f4\u662f24s\nC. \u5c0f\u8239\u80fd\u5230\u8fbe\u6cb3\u7684\u6b63\u5bf9\u5cb8\nD. \u5c0f\u8239\u6e21\u6cb3\u7684\u6700\u5c0f\u4f4d\u79fb\u662f200m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u795e\u821f\u516d\u53f7\u201d\u98de\u8239\u4ece\u53d1\u5c04\u81f3\u8fd4\u56de\u7684\u5404\u9636\u6bb5\u4e2d\uff0c\u673a\u68b0\u80fd\u5b88\u6052\u7684\u662f____\nA. \u52a0\u901f\u5347\u7a7a\u9636\u6bb5\nB. \u5728\u5706\u8f68\u9053\u7ed5\u5730\u7403\u8fd0\u884c\u9636\u6bb5\nC. \u8fdb\u5165\u5927\u6c14\u5c42\u51cf\u901f\u9636\u6bb5\nD. \u964d\u843d\u4f1e\u5f20\u5f00\u540e\u4e0b\u964d\u9636\u6bb5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44556439938712444, "meta-math/MetaMath-Mistral-7B": 0.8654224787348587, "itpossible/Chinese-Mistral-7B-v0.1": 0.39083047486116995, "HuggingFaceH4/zephyr-7b-beta": 0.9429521088343392, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4980398096880152, "meta-llama/Meta-Llama-3-8B": 0.473990831393238, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.48051241470931716}}, {"question": "\u7ad9\u5728\u5730\u9762\u4e0a\uff0c\u5148\u5c06\u4e24\u817f\u5f2f\u66f2\uff0c\u518d\u7528\u529b\u8e6c\u5730\uff0c\u5c31\u80fd\u8df3\u79bb\u5730\u9762\uff0c\u4eba\u80fd\u8df3\u8d77\u79bb\u5f00\u5730\u9762\u7684\u539f\u56e0\u662f:____\nA. \u4eba\u9664\u4e86\u53d7\u5230\u5730\u9762\u7684\u5f39\u529b\u5916\uff0c\u8fd8\u53d7\u5230\u4e00\u4e2a\u5411\u4e0a\u7684\u529b\nB. \u5730\u9762\u5bf9\u4eba\u7684\u652f\u6301\u529b\u5927\u4e8e\u4eba\u53d7\u5230\u7684\u91cd\u529b\nC. \u5730\u9762\u5bf9\u4eba\u7684\u652f\u6301\u529b\u5927\u4e8e\u4eba\u5bf9\u5730\u9762\u7684\u538b\u529b\nD. \u4eba\u5bf9\u5730\u9762\u7684\u538b\u529b\u548c\u5730\u9762\u5bf9\u4eba\u7684\u652f\u6301\u529b\u662f\u4e00\u5bf9\u5e73\u8861\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4f60\u4ece\u5546\u5e97\u4e70\u56de\u4e00\u53ea\u6807\u6709\u201c220V\uff0c100W\u201d\u5b57\u6837\u7684\u767d\u70bd\u706f\u540e\uff0c\u76f4\u63a5\u7528\u591a\u7528\u7535\u8868\u6d4b\u91cf\u767d\u70bd\u706f\u7684\u7535\u963b\u503c\uff0c\u5173\u4e8e\u6d4b\u91cf\u7ed3\u679c\uff0c\u4ee5\u4e0b\u8bf4\u6cd5\u6b63\u786e\u7684\u9009\u9879\u662f____\nA. \u6d4b\u91cf\u503c\u7b49\u4e8e$484\\Omega$\nB. \u6d4b\u91cf\u503c\u5c0f\u4e8e$484\\Omega$\nC. \u6d4b\u91cf\u503c\u5927\u4e8e$484\\Omega$\nD. \u65e0\u6cd5\u5224\u65ad\u6d4b\u91cf\u503c\u4e0e$484\\Omega$\u4e4b\u95f4\u7684\u5927\u5c0f\u5173\u7cfb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u53ea\u7535\u7089\u7684\u7535\u963b\u4e1d\u548c\u4e00\u53f0\u7535\u52a8\u673a\u7ebf\u5708\u7535\u963b\u76f8\u540c\uff0c\u5c06\u5b83\u4eec\u5e76\u8054\u63a5\u5165\u7535\u8def\uff0c\u5f53\u7535\u52a8\u673a\u6b63\u5e38\u5de5\u4f5c\u65f6\uff0c\u901a\u8fc7\u7535\u52a8\u673a\u7684\u7535\u6d41\u4e0e\u901a\u8fc7\u7535\u7089\u7684\u7535\u6d41\u7684\u5173\u7cfb\u4e3a____\nA. \u7535\u52a8\u673a\u7684\u7535\u6d41\u5927\u4e8e\u7535\u7089\u7684\u7535\u6d41\nB. \u7535\u52a8\u673a\u7684\u7535\u6d41\u7b49\u4e8e\u7535\u7089\u7684\u7535\u6d41\nC. \u7535\u52a8\u673a\u7684\u7535\u6d41\u5c0f\u4e8e\u7535\u7089\u7684\u7535\u6d41\nD. \u65e0\u6cd5\u5224\u65ad\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4124578775795746, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8677740876911062}}, {"question": "\u4e0b\u5217\u6709\u5173\u7269\u7406\u5b66\u53f2\u7684\u5185\u5bb9\uff0c\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u5f00\u666e\u52d2\u9610\u8ff0\u4e86\u884c\u661f\u7684\u8fd0\u52a8\u5b9a\u5f8b\uff0c\u5e76\u63d0\u51fa\u4e86\u4e07\u6709\u5f15\u529b\u5b9a\u5f8b\nB. \u725b\u987f\u63d0\u51fa\u4e86\u4e07\u6709\u5f15\u529b\u5b9a\u5f8b\uff0c\u5e76\u901a\u8fc7\u5b9e\u9a8c\u7cbe\u786e\u6d4b\u91cf\u4e86\u5f15\u529b\u5e38\u91cfG\u7684\u6570\u503c\nC. \u6cd5\u62c9\u7b2c\u63d0\u51fa\u4e00\u79cd\u89c2\u70b9\uff0c\u8ba4\u4e3a\u5728\u7535\u8377\u7684\u5468\u56f4\u5b58\u5728\u7531\u5b83\u4ea7\u751f\u7684\u7535\u573a\nD. \u5e93\u4ed1\u901a\u8fc7\u5b9e\u9a8c\u6d4b\u5b9a\u4e86\u5143\u7535\u8377$e$\u7684\u6570\u503c\u7ea6\u4e3a$1.6\\times10^{-19}\\text{C}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31712010892822357, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.46683855109474853}}, {"question": "\u7269\u4f53\u5728\u5408\u5916\u529bF\u4f5c\u7528\u4e0b\uff0c\u4ea7\u751f\u52a0\u901f\u5ea6a\uff0c\u4e0b\u9762\u8bf4\u6cd5\u4e2d\u6b63\u786e\u7684\u662f____\nA. \u5728\u5300\u51cf\u901f\u76f4\u7ebf\u8fd0\u52a8\u4e2d\uff0ca\u4e0eF\u53cd\u5411\nB. \u53ea\u6709\u5728\u5300\u52a0\u901f\u76f4\u7ebf\u8fd0\u52a8\u4e2d\uff0ca\u624d\u4e0eF\u540c\u5411\nC. \u4e0d\u8bba\u5728\u4ec0\u4e48\u8fd0\u52a8\u4e2d\uff0ca\u4e0eF\u7684\u65b9\u5411\u603b\u662f\u4e00\u81f4\u7684\nD. \u4ee5\u4e0a\u8bf4\u6cd5\u90fd\u4e0d\u5bf9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37354501646787847, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9065364630444135, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4479780449407606, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u540c\u5b66\u8eab\u9ad81.8m\uff0c\u5728\u8fd0\u52a8\u4f1a\u4e0a\u4ed6\u53c2\u52a0\u8df3\u9ad8\u6bd4\u8d5b\u4e2d\uff0c\u8d77\u8df3\u540e\u8eab\u4f53\u6a2a\u7740\u8d8a\u8fc7\u4e861.8m\u9ad8\u5ea6\u7684\u6a2a\u6746\uff0c\u636e\u6b64\u6211\u4eec\u53ef\u4f30\u7b97\u51fa\u4ed6\u8d77\u8df3\u65f6\u7ad6\u76f4\u5411\u4e0a\u7684\u901f\u5ea6\u5927\u7ea6\u4e3a\uff08\u53d6g=$10m/s^2$\uff09____\nA. 2m/s\nB. 4m/s\nC. 6m/s\nD. 8m/s\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.37480846975763354, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4216209499672546}}, {"question": "\u4e00\u4e2a\u8d28\u91cf\u4e3a2kg\u7684\u7269\u4f53\u540c\u65f6\u53d7\u5230\u4e24\u4e2a\u529b\u7684\u4f5c\u7528\uff0c\u8fd9\u4e24\u4e2a\u529b\u7684\u5927\u5c0f\u5206\u522b\u4e3a2N\u548c6N\uff0c\u5f53\u4e24\u4e2a\u529b\u7684\u65b9\u5411\u53d1\u751f\u53d8\u5316\u65f6\uff0c\u7269\u4f53\u7684\u52a0\u901f\u5ea6\u5927\u5c0f\u4e0d\u53ef\u80fd\u4e3a____\nA. $1m/s^{2}$\nB. $2m/s^{2}$\nC. $3m/s^{2}$\nD. $4m/s^{2}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8408982571193077, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4eba\u7c7b\u5728\u63a2\u7d22\u81ea\u7136\u89c4\u5f8b\u7684\u8fdb\u7a0b\u4e2d\u603b\u7ed3\u4e86\u8bb8\u591a\u79d1\u5b66\u65b9\u6cd5\uff0c\u5982\u5206\u6790\u5f52\u7eb3\u6cd5\u3001\u6f14\u7ece\u6cd5\u3001\u7b49\u6548\u66ff\u4ee3\u6cd5\u3001\u63a7\u5236\u53d8\u91cf\u6cd5\u3001\u7406\u60f3\u5b9e\u9a8c\u6cd5\u7b49\uff0e\u5728\u4e0b\u5217\u7814\u7a76\u4e2d\uff0c\u8fd0\u7528\u7406\u60f3\u5b9e\u9a8c\u6cd5\u8fdb\u884c\u7814\u7a76\u7684\u662f____\nA. \u7231\u56e0\u65af\u5766\u63d0\u51fa\u5149\u5b50\u5047\u8bf4\nB. \u9ea6\u514b\u65af\u97e6\u63d0\u51fa\u7535\u78c1\u573a\u7406\u8bba\nC. \u5362\u745f\u798f\u63d0\u51fa\u539f\u5b50\u7684\u6838\u5f0f\u7ed3\u6784\u6a21\u578b\nD. \u4f3d\u5229\u7565\u5f97\u51fa\u529b\u4e0d\u662f\u7ef4\u6301\u7269\u4f53\u8fd0\u52a8\u539f\u56e0\u7684\u7ed3\u8bba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3147016600931864, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.408803903699319}}, {"question": "\u8d28\u91cf\u4e3am\u7684\u6ed1\u5757\u6cbf\u9ad8\u4e3ah\uff0c\u957f\u4e3al\u7684\u7c97\u7cd9\u659c\u9762\u5300\u901f\u4e0b\u6ed1\uff0c\u5728\u6ed1\u5757\u4ece\u659c\u9762\u9876\u7aef\u6ed1\u81f3\u4f4e\u7aef\u7684\u8fc7\u7a0b\u4e2d____\nA. \u91cd\u529b\u5bf9\u6ed1\u5757\u6240\u505a\u7684\u529f\u4e3a$mgh$\nB. \u6ed1\u5757\u514b\u670d\u6469\u64e6\u6240\u505a\u7684\u529f\u4e3a$mgl$\nC. \u6ed1\u5757\u7684\u673a\u68b0\u80fd\u4fdd\u6301\u4e0d\u53d8\nD. \u6ed1\u5757\u7684\u91cd\u529b\u52bf\u80fd\u589e\u52a0\u4e86$mgh$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5317\u4eac\u65f6\u95f42022\u5e743\u67085\u65e514\u65f601\u5206\uff0c\u6211\u56fd\u5728\u897f\u660c\u536b\u661f\u53d1\u5c04\u4e2d\u5fc3\u4f7f\u7528\u957f\u5f81\u4e8c\u53f7\u4e19\u8fd0\u8f7d\u706b\u7bad\uff0c\u91c7\u7528\u201c\u4e00\u7bad\u591a\u661f\u201d\u6280\u672f\uff0c\u6210\u529f\u5c06\u94f6\u6cb3\u822a\u592902\u6279\u536b\u661f\uff086\u9897\uff09\u53ca\u5176\u642d\u8f7d\u76841\u9897\u5546\u4e1a\u9065\u611f\u536b\u661f\u53d1\u5c04\u5347\u7a7a\u3002\u9065\u611f\u536b\u661f\u8fdb\u5165\u8ddd\u5730\u8868\u7ea6500km\u7684\u8fd1\u5730\u8f68\u9053\u505a\u5300\u901f\u5706\u5468\u8fd0\u52a8\u3002\u5df2\u77e5\u5f15\u529b\u5e38\u91cf\u4e3aG\uff0c\u5730\u7403\u534a\u5f84\u4e3aR\uff0c\u5730\u7403\u8868\u9762\u91cd\u529b\u52a0\u901f\u5ea6\u4e3ag\u3002\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u8be5\u9065\u611f\u536b\u661f\u7684\u8f68\u9053\u5c5e\u4e8e\u5730\u7403\u540c\u6b65\u8f68\u9053\nB. \u6839\u636e\u9898\u76ee\u5df2\u77e5\u6761\u4ef6\uff0c\u53ef\u4ee5\u4f30\u7b97\u8be5\u9065\u611f\u536b\u661f\u7684\u7ebf\u901f\u5ea6\u5927\u5c0f\nC. \u6839\u636e\u5df2\u77e5\u6761\u4ef6\u53ef\u4ee5\u8ba1\u7b97\u8be5\u9065\u611f\u536b\u661f\u6240\u53d7\u4e07\u6709\u5f15\u529b\u5927\u5c0f\nD. \u8be5\u9065\u611f\u536b\u661f\u5728\u8f68\u9053\u4e0a\u7684\u89d2\u901f\u5ea6\u6bd4\u6708\u7403\u7ed5\u5730\u7403\u7684\u89d2\u901f\u5ea6\u5c0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.31408067417579427, "meta-math/MetaMath-Mistral-7B": 0.44033071620591985, "itpossible/Chinese-Mistral-7B-v0.1": 0.34993229125498293, "HuggingFaceH4/zephyr-7b-beta": 0.6931443045680633, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5566746716720041, "meta-llama/Meta-Llama-3-8B": 0.42684411173654924, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5592404855729488}}, {"question": "\u4e24\u5217\u632f\u52a8\u65b9\u5411\u76f8\u540c\u3001\u632f\u5e45\u5206\u522b\u4e3aA1\u548cA2\u7684\u76f8\u5e72\u7b80\u8c10\u6a2a\u6ce2\u76f8\u9047\u3002\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u6ce2\u5cf0\u4e0e\u6ce2\u8c37\u76f8\u9047\u5904\u8d28\u70b9\u7684\u632f\u5e45\u4e3a$|A_1-A_2|$\nB. \u6ce2\u5cf0\u4e0e\u6ce2\u5cf0\u76f8\u9047\u5904\u8d28\u70b9\u79bb\u5f00\u5e73\u8861\u4f4d\u7f6e\u7684\u4f4d\u79fb\u59cb\u7ec8\u4e3a$A_{1}+A_{2}$\nC. \u6ce2\u5cf0\u4e0e\u6ce2\u8c37\u76f8\u9047\u5904\u8d28\u70b9\u7684\u4f4d\u79fb\u603b\u662f\u5c0f\u4e8e\u6ce2\u5cf0\u4e0e\u6ce2\u5cf0\u76f8\u9047\u5904\u8d28\u70b9\u7684\u4f4d\u79fb\nD. \u6ce2\u5cf0\u4e0e\u6ce2\u5cf0\u76f8\u9047\u5904\u8d28\u70b9\u7684\u632f\u5e45\u4e00\u5b9a\u5c0f\u4e8e\u6ce2\u5cf0\u4e0e\u6ce2\u8c37\u76f8\u9047\u5904\u8d28\u70b9\u7684\u632f\u5e45\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2658638974902097, "meta-math/MetaMath-Mistral-7B": 0.38822592917159904, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5364816102320026}}, {"question": "\u4e09\u79cd\u4e0d\u540c\u6837\u7684\u5165\u5c04\u5149A\u3001B\u3001C \u5206\u522b\u5c04\u5728\u4e09\u79cd\u4e0d\u540c\u6837\u7684\u91d1\u5c5ea\uff0cb\uff0cc \u8868\u9762\uff0c\u5747\u53ef\u4f7f\u91d1\u5c5e\u4e2d\u9038\u51fa\u5149\u5b50\uff0c\u4e09\u79cd\u5165\u5c04\u5149\u7684\u6ce2\u957f$\\lambda_A > \\lambda_B > \\lambda_C$\uff0c\u5219____\nA. \u7528\u5165\u5c04\u5149A\u7167\u5c04\u91d1\u5c5eb\u6216c\uff0c\u91d1\u5c5eb\uff0cc\u5747\u53ef\u4ee5\u53d1\u751f\u5149\u7535\u6548\u5e94\u73b0\u8c61\nB. \u7528\u5165\u5c04\u5149A\u4e0eB\u540c\u65f6\u7167\u5c04\u91d1\u5c5ec\uff0c\u91d1\u5c5ec\u53ef\u53d1\u751f\u5149\u7535\u6548\u5e94\u73b0\u8c61\nC. \u7528\u5165\u5c04\u5149C\u7167\u5c04\u91d1\u5c5ea\u6216b\uff0c\u91d1\u5c5ea\uff0cb\u5747\u53ef\u4ee5\u53d1\u751f\u5149\u7535\u6548\u5e94\u73b0\u8c61\nD. \u7528\u5165\u5c04\u5149B\u6216C\u7167\u5c04\u91d1\u5c5ea\uff0c\u4e0d\u53ef\u4f7f\u91d1\u5c5ea\u53d1\u751f\u5149\u7535\u6548\u5e94\u73b0\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28779648136618213, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u63d0\u51fa\u201c\u7535\u573a\u7ebf\u201d\u7684\u79d1\u5b66\u5bb6\u662f____\nA. \u5e93\u4ed1\nB. \u6cd5\u62c9\u7b2c\nC. \u9ea6\u514b\u65af\u97e6\nD. \u7231\u56e0\u65af\u5766\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40212718287110993, "meta-math/MetaMath-Mistral-7B": 0.6965348532120734, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36029123724508655, "meta-llama/Meta-Llama-3-8B": 0.3614418320658242, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u5fc5\u7136\u8d28\u91cf\u7684\u6c14\u4f53\uff0c\u4ee5\u4e0b\u6709\u5173\u6c14\u4f53\u7684\u538b\u5f3a\u3001\u4f53\u79ef\u3001\u6e29\u5ea6\u4e4b\u95f4\u5173\u7cfb\u7684\u8bf4\u6cd5\u6b63\u786e\u7684\u9009\u9879\u662f____\nA. \u82e5\u662f\u4fdd\u6301\u6c14\u4f53\u7684\u4f53\u79ef\u4e0d\u53d8\uff0c\u6e29\u5ea6\u9ad8\u5347\uff0c\u538b\u5f3a\u51cf\u5c0f\nB. \u82e5\u662f\u4fdd\u6301\u6c14\u4f53\u7684\u4f53\u79ef\u4e0d\u53d8\uff0c\u6e29\u5ea6\u964d\u4f4e\uff0c\u538b\u5f3a\u589e\u5927\nC. \u82e5\u662f\u4fdd\u6301\u6c14\u4f53\u7684\u6e29\u5ea6\u4e0d\u53d8\uff0c\u4f53\u79ef\u8d8a\u5c0f\uff0c\u538b\u5f3a\u8d8a\u5c0f\nD. \u82e5\u662f\u4fdd\u6301\u6c14\u4f53\u7684\u6e29\u5ea6\u4e0d\u53d8\uff0c\u4f53\u79ef\u8d8a\u5c0f\uff0c\u538b\u5f3a\u8d8a\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33839672915571045, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6054594413049469}}, {"question": "\u5728\u901a\u5e38\u60c5\u51b5\u4e0b\u56fa\u4f53\u5206\u5b50\u95f4\u7684\u5e73\u5747\u8ddd\u79bb\u4e3ar0\uff0c\u5206\u5b50\u95f4\u5f15\u529b\u548c\u65a5\u529b\u6070\u597d\u5927\u5c0f\u76f8\u7b49\uff0c\u7531\u6b64\u53ef\u4ee5\u5224\u5b9a\uff0c\u5728\u901a\u5e38\u60c5\u51b5\u4e0b____\nA. \u56fa\u4f53\u6536\u7f29\u65f6\uff0c\u5206\u5b50\u95f4\u8ddd\u589e\u5927\uff0c\u5206\u5b50\u529b\u8868\u73b0\u4e3a\u5f15\u529b\nB. \u56fa\u4f53\u81a8\u80c0\u65f6\uff0c\u5206\u5b50\u95f4\u8ddd\u589e\u5927\uff0c\u5206\u5b50\u529b\u8868\u73b0\u4e3a\u65a5\u529b\nC. \u56fa\u4f53\u6536\u7f29\u65f6\uff0c\u5206\u5b50\u95f4\u8ddd\u51cf\u5c0f\uff0c\u5206\u5b50\u529b\u8868\u73b0\u4e3a\u5f15\u529b\nD. \u56fa\u4f53\u6536\u7f29\u65f6\uff0c\u5206\u5b50\u95f4\u8ddd\u51cf\u5c0f\uff0c\u5206\u5b50\u529b\u8868\u73b0\u4e3a\u65a5\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7283980653251247, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5138631372008886}}, {"question": "\u5bf9\u4e8e\u6dc0\u7c89\u548c\u7ea4\u7ef4\u7d20\u4e24\u79cd\u7269\u8d28\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u4e24\u8005\u90fd\u80fd\u6c34\u89e3\uff0c\u4e14\u6c34\u89e3\u7684\u6700\u7ec8\u4ea7\u7269\u76f8\u540c\nB. \u4e24\u8005\u542bC\u3001H\u3001O\u4e09\u79cd\u5143\u7d20\u7684\u8d28\u91cf\u5206\u6570\u76f8\u540c\uff0c\u4e14\u4e92\u4e3a\u540c\u5206\u5f02\u6784\u4f53\nC. \u5b83\u4eec\u90fd\u5c5e\u4e8e\u7cd6\u7c7b\uff0c\u4e14\u90fd\u662f\u6eb6\u4e8e\u6c34\u7684\u9ad8\u5206\u5b50\u5316\u5408\u7269\nD. \u90fd\u53ef \u7528$\\left ( C_6H_6O_5\\right )_n$\u8868\u793a\uff0c\u4f46\u6dc0\u7c89\u80fd\u53d1\u751f\u94f6\u955c\u53cd\u5e94\uff0c\u800c\u7ea4\u7ef4\u7d20\u4e0d\u80fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9081419742934138}}, {"question": "a mol $Na_2O_2$\u548c b mol $NaHCO_3$\u56fa\u4f53\u6df7\u5408\u540e\uff0c\u5728\u5bc6\u95ed\u5bb9\u5668\u4e2d\u52a0\u70ed\u5230250\u2103\uff0c\u4f7f\u5176\u5145\u5206\u53cd\u5e94\uff0c\u5f53\u6392\u51fa\u6c14\u4f53\u4e3a\u4e24\u79cd\u6c14\u4f53\u65f6\uff0ca\ufe30b\u4e0d\u53ef\u80fd\u4e3a\uff1a____\nA. $3\ufe304$\nB. $3\ufe302$\nC. $2\ufe303$\nD. $4\ufe305$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2731272040287072, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5061803580507155}}, {"question": "X\u3001Y\u3001Z\u3001W\u3001R\u662f5\u79cd\u77ed\u5468\u671f\u5143\u7d20\uff0c\u5176\u539f\u5b50\u5e8f\u6570\u4f9d\u6b21\u589e\u5927\u3002X\u662f\u5468\u671f\u8868\u4e2d\u539f\u5b50\u534a\u5f84\u6700\u5c0f\u7684\u5143\u7d20\uff0cY\u539f\u5b50\u6700\u5916\u5c42\u7535\u5b50\u6570\u662f\u6b21\u5916\u5c42\u7535\u5b50\u6570\u76843\u500d\uff0cZ\u3001W\u3001R\u5904\u4e8e\u540c\u4e00\u5468\u671f\uff0cR\u4e0eY\u5904\u4e8e\u540c\u4e00\u4e3b\u65cf\uff0cZ\u3001W\u539f\u5b50\u7684\u6838\u5916\u7535\u5b50\u6570\u4e4b\u548c\u4e0eY\u3001R\u539f\u5b50\u7684\u6838\u5916\u7535\u5b50\u6570\u4e4b\u548c\u76f8\u7b49\u3002\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u5143\u7d20Y\u3001Z\u3001W\u5177\u6709\u76f8\u540c\u7535\u5b50\u5c42\u7ed3\u6784\u7684\u79bb\u5b50\uff0c\u5176\u534a\u5f84\u4f9d\u6b21\u589e\u5927\nB. \u5143\u7d20X\u4e0d\u80fd\u4e0e\u5143\u7d20Y\u5f62\u6210\u5316\u5408\u7269$X_2Y_2$\nC. \u5143\u7d20Y\u3001R\u5206\u522b\u4e0e\u5143\u7d20X\u5f62\u6210\u7684\u5316\u5408\u7269\u7684\u70ed\u7a33\u5b9a\u6027\uff1a$X_mY > X_mR$\nD. \u5143\u7d20W\u3001R\u7684\u6700\u9ad8\u4ef7\u6c27\u5316\u7269\u7684\u6c34\u5316\u7269\u90fd\u662f\u5f3a\u9178\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5bb6\u5ead\u5c0f\u5b9e\u9a8c\u6700\u5408\u7406\u7684\u662f____\nA. \u5c06\u9002\u91cf\u7684\u82cf\u6253\u7c89\u653e\u5728\u5bb9\u5668\u4e2d\u52a0\u70ed\uff0c\u89c2\u5bdf\u6c14\u4f53\u7684\u4ea7\u751f\nB. \u5728\u6d01\u51c0\u7684\u6c34\u676f\u4e2d\u5148\u52a0\u5165\u5c0f\u82cf\u6253\u7c89\uff0c\u518d\u52a0\u5165\u98df\u918b\uff0c\u89c2\u5bdf\u6c14\u4f53\u7684\u4ea7\u751f\nC. \u5f80\u7a00\u767d\u7ca5\u4e2d\u52a0\u5165\u5c11\u91cf\u52a0\u7898\u98df\u76d0\uff0c\u68c0\u9a8c\u52a0\u7898\u98df\u76d0\u4e2d\u542b\u6709$I_2$\nD. \u5728\u4e00\u74e3\u6a58\u5b50\u4e0a\u63d2\u5165\u4e24\u6839\u94dc\u7ebf\u5e76\u4e0e\u5c0f\u706f\u6ce1\u8fde\u63a5\uff0c\u9a8c\u8bc1\u7535\u6d41\u7684\u4ea7\u751f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35612055499370676, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5132583971902459, "HuggingFaceH4/zephyr-7b-beta": 0.8614908734928519, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.49309194331935696, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5289798398319322}}, {"question": "\u4e0b\u5217\u53cd\u5e94\u7684\u79bb\u5b50\u65b9\u7a0b\u5f0f\u4e2d\u6b63\u786e\u7684\u662f____\nA. \u6c2f\u6c14\u4e0e\u6c34\u53cd\u5e94:$Cl_2+H_2O = 2H^+ + Cl^- + ClO^-$\nB. \u6c2f\u6c14\u901a\u5165\u51b7\u7684\u6c22\u6c27\u5316\u94a0\u6eb6\u6db2\u4e2d\uff1a$2Cl_2+2OH^- = 3Cl^- + ClO^- +H_2O$\nC. \u6c2f\u5316\u4e9a\u94c1\u6eb6\u6db2\u4e2d\u6ef4\u52a0\u8fc7\u91cf\u65b0\u5236\u6c2f\u6c34\uff1a$2Fe^{2+} + Cl_2 = 2Fe^{3+} + 2Cl^-$\nD. \u5c11\u91cf\u78b3\u9178\u9499\u56fa\u4f53\u52a0\u5165\u8db3\u91cf\u7a00\u76d0\u9178\u4e2d\uff1a$CO_3^{2-}+2H^+ = CO_2\\uparrow +H_2O$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.34239623393788804, "itpossible/Chinese-Mistral-7B-v0.1": 0.2920177551543942, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.49720788327098414, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8440334897367525}}, {"question": "\u4e0b\u5217\u7269\u8d28\u5c5e\u4e8e\u5408\u6210\u805a\u5408\u7269\u7684\u662f____\nA. \u86cb\u767d\u8d28\nB. \u4eba\u9020\u4e1d\nC. \u4eba\u9020\u68c9\nD. \u805a\u6c2f\u4e59\u70ef\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5926726293599184, "meta-math/MetaMath-Mistral-7B": 0.8597904952892929, "itpossible/Chinese-Mistral-7B-v0.1": 0.3615085256056106, "HuggingFaceH4/zephyr-7b-beta": 0.9876185107720882, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6159436354824533, "meta-llama/Meta-Llama-3-8B": 0.4609240305306871, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9225543022804045}}, {"question": "\u6c2f\u7684\u539f\u5b50\u5e8f\u6570\u4e3a17\uff0c$^{35}Cl$\u662f\u6c2f\u7684\u4e00\u79cd\u6838\u7d20\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. $^{35}Cl$\u539f\u5b50\u6240\u542b\u8d28\u5b50\u6570\u4e3a18\nB. $\\frac{1}{18}$\u7684$^1H^{35}Cl$\u5206\u5b50\u6240\u542b\u4e2d\u5b50\u6570\u7ea6\u4e3a$6.02 \\times 10^23$\nC. 3.5g$^{35}Cl_{2}$\u6c14\u4f53\u7684\u4f53\u79ef\u7ea6\u4e3a22.4L\nD. $^{35}Cl_{2}$\u6c14\u4f53\u7684\u6469\u5c14\u8d28\u91cf\u4e3a70g\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4661507515762775, "meta-math/MetaMath-Mistral-7B": 0.6146419890003175, "itpossible/Chinese-Mistral-7B-v0.1": 0.47981478338514477, "HuggingFaceH4/zephyr-7b-beta": 0.9418369862956125, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40252653667223387, "meta-llama/Meta-Llama-3-8B": 0.33620111756034343, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.44154372939914516}}, {"question": "\u67d0\u6709\u673a\u7269\u5728\u6c27\u6c14\u4e2d\u71c3\u70e7\u751f\u6210\u6c34\u84b8\u6c14\u548c\u4e8c\u6c27\u5316\u78b3\u7684\u7269\u8d28\u7684\u91cf\u4e4b\u6bd4\u4e3a 1\uff1a1\uff0c\u7531\u6b64\u5f97\u51fa\u7684\u7ed3\u8bba\u662f____\nA. \u8be5\u6709\u673a\u7269\u5206\u5b50\u4e2d C\uff1aH\uff1aO \u539f\u5b50\u4e2a\u6570\u6bd4\u4e3a 1\uff1a2\uff1a3\nB. \u8be5\u6709\u673a\u7269\u5206\u5b50\u4e2d C\uff1aH \u539f\u5b50\u4e2a\u6570\u6bd4\u4e3a 1\uff1a1\nC. \u8be5\u6709\u673a\u7269\u4e2d\u5fc5\u5b9a\u542b\u6c27\nD. \u65e0\u6cd5\u5224\u65ad\u8be5\u6709\u673a\u7269\u4e2d\u662f\u5426\u542b\u6c27\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2821833983601388, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.34478590299221606, "HuggingFaceH4/zephyr-7b-beta": 0.5459240105785086, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e3b\u65cf\u5143\u7d20W\u3001X\u3001Y\u3001Z\u7684\u539f\u5b50\u5e8f\u6570\u4f9d\u6b21\u589e\u52a0\uff0c\u4e14\u5747\u4e0d\u5927\u4e8e20\u3002W\u3001X\u3001Y\u6700\u5916\u5c42\u7535\u5b50\u6570\u4e4b\u548c\u4e3a11\uff0cW\u4e0eY\u540c\u65cf\u4e14\u90fd\u662f\u590d\u5408\u5316\u80a5\u7684\u8425\u517b\u5143\u7d20\uff0cZ\u7684\u6c22\u5316\u7269\u9047\u6c34\u53ef\u4ea7\u751f\u6700\u8f7b\u7684\u6c14\u4f53\u3002\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684____\nA. \u5e38\u6e29\u5e38\u538b\u4e0bX\u7684\u5355\u8d28\u4e3a\u6c14\u6001\nB. \u7b80\u5355\u6c14\u6001\u6c22\u5316\u7269\u7684\u70ed\u7a33\u5b9a\u6027\uff1aY>W\nC. Z\u7684\u6c22\u5316\u7269\u542b\u6709\u5171\u4ef7\u952e\nD. \u7b80\u5355\u79bb\u5b50\u534a\u5f84\uff1aW>X\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c2f\u5316\u94dc\u7684\u7a00\u6eb6\u6db2\u5728\u76d0\u9178\u4e2d\u5448\u9ec4\u7eff\u8272\uff0c\u5b58\u5728\u7684\u5316\u5b66\u5e73\u8861$Cu(H_2O)_4]^{2+}\uff08\u6de1\u84dd\u8272\uff09+4Cl^- \\rightleftharpoons(CuCl4)^{2\u2014}\uff08\u9ec4\u7eff\u8272\uff09+4H_2O$\uff0c\u4e0b\u5217\u53ef\u4f7f\u6eb6\u6db2\u53d8\u6210\u6de1\u84dd\u8272\u7684\u65b9\u6cd5\u662f____\nA. \u51cf\u5c11\u84b8\u998f\u6c34\nB. \u52a0\u785d\u9178\u94f6\u6eb6\u6db2\nC. \u52a0\u6c2f\u5316\u94a0\u56fa\u4f53\nD. \u52a0\u786b\u9178\u94a0\u56fa\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3663757006245303, "meta-math/MetaMath-Mistral-7B": 0.540162145577072, "itpossible/Chinese-Mistral-7B-v0.1": 0.4403307308948633, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3460058095032025, "meta-llama/Meta-Llama-3-8B": 0.5501667601118083, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6330268662160711}}, {"question": "\u4e0b\u5217\u7269\u8d28\u8f6c\u5316\u9700\u8981\u52a0\u5165\u8fd8\u539f\u5242\u624d\u80fd\u5b9e\u73b0\u7684\u662f____\nA. $SO_3^{2-}$\u2192$SO_2$\nB. $HCl$\u2192$Cl_2$\nC. $Na$\u2192$Na^+$\nD. $SO_2$\u2192$S$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2966017332563093, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e00\u5b9a\u6e29\u5ea6\u4e0b\u7684\u6052\u5bb9\u5bc6\u95ed\u5bb9\u5668\u4e2d\uff0c\u5f53\u4e0b\u5217\u54ea\u4e9b\u7269\u7406\u91cf\u4e0d\u518d\u53d1\u751f\u53d8\u5316\u65f6\uff0c\u8868\u660e\u4e0b\u8ff0\u53cd\u5e94\uff1a$A(s) + 2B(g) \\rightleftharpoons C(g)+D(g)$\u5df2\u8fbe\u5230\u5e73\u8861\u72b6\u6001____\r\n\u2460\u6df7\u5408\u6c14\u4f53\u7684\u538b\u5f3a   \u2461\u6df7\u5408\u6c14\u4f53\u7684\u5bc6\u5ea6   \u2462B\u7684\u7269\u8d28\u7684\u91cf\u6d53\u5ea6 \u2463\u6c14\u4f53\u7684\u603b\u7269\u8d28\u7684\u91cf\r\n\u2464\u6df7\u5408\u6c14\u4f53\u603b\u8d28\u91cf\nA. \u2461\u2462\u2464\nB. \u2460\u2461\u2462\nC. \u2461\u2462\u2463\nD. \u2460\u2462\u2463\u2464\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2994509091275924, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3818183186472589, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bd7\u53e5\u201c\u6625\u8695\u5230\u6b7b\u4e1d\u65b9\u5c3d\uff0c\u8721\u70db\u6210\u7070\u6cea\u59cb\u5e72\u201d\u4e2d\u201c\u4e1d\u201d\u548c\u201c\u6cea\u201d\u5206\u522b\u6307____\nA. \u7ea4\u7ef4\u7d20  \u6cb9\u8102\nB. \u86cb\u767d\u8d28  \u70c3\u7c7b\nC. \u6dc0\u7c89  \u6cb9\u8102\nD. \u86cb\u767d\u8d28  \u6cb9\u8102\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u7269\u8d28\u4e2d\u65e2\u5c5e\u4e8e\u6709\u673a\u7269\uff0c\u53c8\u5c5e\u4e8e\u9178\u7684\u662f____\nA. $H_2CO_3$\nB. $CH_3OH$\nC. $CH_3CH_2OH $\nD. $CH_3COOH$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6785771992351742, "meta-math/MetaMath-Mistral-7B": 0.8150194835440626, "itpossible/Chinese-Mistral-7B-v0.1": 0.6442571541253089, "HuggingFaceH4/zephyr-7b-beta": 0.9835299406642102, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47343779217226123, "meta-llama/Meta-Llama-3-8B": 0.9100219090706949, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8362225895998794}}, {"question": "\u4e0b\u5217\u7269\u8d28\u4e0d\u80fd\u4e0e\u6c22\u6c27\u5316\u94a0\u6eb6\u6db2\u53d1\u751f\u53cd\u5e94\u7684\u662f____\nA. \u6c2f\u6c14\nB. \u78b3\u9178\u6c22\u94a0\nC. \u4e8c\u6c27\u5316\u7845\nD. \u9541\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3702580020579642, "meta-math/MetaMath-Mistral-7B": 0.333183235354062, "itpossible/Chinese-Mistral-7B-v0.1": 0.33863640659411287, "HuggingFaceH4/zephyr-7b-beta": 0.9121244413894849, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5347061522201987, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3993599025515597}}, {"question": "\u707c\u70e7\u7eff\u77fe\u7684\u53cd\u5e94\u65b9\u7a0b\u5f0f\u5982\u4e0b\uff1a$7(FeSO_4 \\cdot 7H_2O)\\stackrel{\u5f3a\u70ed}{=}Fe_2O_3 +SO_2\\uparrow + SO_3\\uparrow +14H_2O$;\u5c06\u751f\u6210\u7684\u6c14\u4f53\u901a\u5165BaCl2\u6eb6\u6db2\u4e2d\uff0c\u4e0b\u5217\u53d9\u8ff0\u4e2d\u6b63\u786e\u7684\u662f____\nA. \u6709$BaSO_4$\u751f\u6210\nB. \u6709$BaSO_3$\u751f\u6210\nC. \u540c\u65f6\u6709$BaSO_4$\u548c$BaSO_3$\u751f\u6210\nD. \u6709$SO_3$\u9038\u51fa\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.505549466378394, "meta-llama/Meta-Llama-3-8B": 0.35909976350004963, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u751f\u77f3\u7070\u4e2d\u542b\u6709\u78b3\u9178\u9499\u548c\u4e8c\u6c27\u5316\u7845\uff0c\u8981\u68c0\u9a8c\u8fd9\u4e24\u79cd\u6742\u8d28\u662f\u5426\u5b58\u5728\uff0c\u9009\u7528\u7684\u8bd5\u5242\u6700\u597d\u662f____\nA. \u7a00\u76d0\u9178\nB. \u6c34\nC. \u70e7\u78b1\u6eb6\u6db2\nD. \u7a00\u786b\u9178\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2739021323302521, "meta-math/MetaMath-Mistral-7B": 0.43589455442585096, "itpossible/Chinese-Mistral-7B-v0.1": 0.3499320087587727, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.461283705413579, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5$2SO_2(g) + O_2(g) \\rightleftharpoons  2SO_3(g)$(\u6b63\u53cd\u5e94\u653e\u70ed)\u3002\u82e5\u5728500\u2103\u548c\u50ac\u5316\u5242\u7684\u4f5c\u7528\u4e0b\uff0c\u8be5\u53cd\u5e94\u5728\u5bb9\u79ef\u56fa\u5b9a\u7684\u5bc6\u95ed\u5bb9\u5668\u4e2d\u8fdb\u884c\uff0c\u4e0b\u5217\u6709\u5173\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u82e5\u964d\u4f4e\u6e29\u5ea6\uff0c\u53ef\u4ee5\u52a0\u5feb\u53cd\u5e94\u901f\u7387\nB. \u4f7f\u7528\u50ac\u5316\u5242\u662f\u4e3a\u4e86\u52a0\u5feb\u53cd\u5e94\u901f\u7387\nC. \u5728\u4e0a\u8ff0\u6761\u4ef6\u4e0b\uff0c$SO_2$\u80fd\u5b8c\u5168\u8f6c\u5316\u4e3a$SO_3$\nD. \u8fbe\u5230\u5e73\u8861\u65f6\uff0c$SO_2$\u548c$SO_3$\u7684\u6d53\u5ea6\u4e00\u5b9a\u76f8\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4930923359310571, "meta-math/MetaMath-Mistral-7B": 0.6348420303292784, "itpossible/Chinese-Mistral-7B-v0.1": 0.38676649083459713, "HuggingFaceH4/zephyr-7b-beta": 0.9509201231008708, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8362602780778328, "meta-llama/Meta-Llama-3-8B": 0.40202865642572594, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8903508210169886}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u7269\u8d28\u7528\u9014\u7684\u53d9\u8ff0\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u7845\u53ef\u4ee5\u7528\u4f5c\u5236\u9020\u53d8\u538b\u5668\u7684\u94c1\u82af\u6750\u6599\nB. \u4e8c\u6c27\u5316\u7845\u53ef\u7528\u4e8e\u5236\u9020\u5149\u5bfc\u7ea4\u7ef4\nC. \u77f3\u58a8\u53ef\u7528\u505a\u7edd\u7f18\u6750\u6599\nD. \u77f3\u82f1\u73bb\u7483\u53ef\u7528\u4e8e\u5236\u9020\u5149\u5b66\u4eea\u5668\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4812866620456135, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5220127299408656, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7351250098119247, "meta-llama/Meta-Llama-3-8B": 0.46226550588276905, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5509811284459761}}, {"question": "\u4e0b\u5217\u53d9\u8ff0\u4e2d\u6700\u7b26\u5408\u81ea\u7531\u6c34\u751f\u7406\u529f\u80fd\u7684\u662f:____\nA. \u8fd0\u8f93\u8425\u517b\u7269\u8d28\u548c\u4ee3\u8c22\u5e9f\u7269\nB. \u4e0e\u7ec6\u80de\u5185\u7684\u5176\u4ed6\u7269\u8d28\u7ed3\u5408\nC. \u4f5c\u4e3a\u6eb6\u5242\uff0c\u4f7f\u65e0\u673a\u76d0\u6210\u4e3a\u79bb\u5b50\u72b6\u6001\nD. \u7ec6\u80de\u7ed3\u6784\u7684\u7ec4\u6210\u6210\u5206\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6031625571499379, "meta-math/MetaMath-Mistral-7B": 0.9961941547601953, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.655234817176813, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.696710067674638}}, {"question": "\u4e0b\u5217\u6709\u5173\u751f\u7269\u819c\u7cfb\u7edf\u7684\u53d9\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\nA. \u7ec6\u80de\u819c\u3001\u5c0f\u80a0\u9ecf\u819c\u7b49\u90fd\u5c5e\u4e8e\u7ec6\u80de\u7684\u751f\u7269\u819c\u7cfb\u7edf\nB. \u6240\u6709\u7684\u9176\u90fd\u9644\u7740\u5728\u751f\u7269\u819c\u4e0a\nC. \u5206\u6ccc\u86cb\u767d\u5408\u6210\u548c\u8fd0\u8f93\u8fc7\u7a0b\u4e2d\uff0c\u5185\u8d28\u7f51\u819c\u9762\u79ef\u51cf\u5c0f\uff0c\u7ec6\u80de\u819c\u7684\u9762\u79ef\u589e\u5927\nD. \u751f\u7269\u819c\u7684\u7ec4\u6210\u6210\u5206\u548c\u7ed3\u6784\u90fd\u662f\u4e00\u6837\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3325697001537494, "meta-math/MetaMath-Mistral-7B": 0.5709837681059596, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5658897665647834, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "A\uff08\u6297\u75c5\uff09\u5bf9a\uff08\u4e0d\u6297\u75c5\uff09\uff0cB\uff08\u9ad8\u6746\uff09\u5bf9b\uff08\u77ee\u6746\uff09\uff0c\u4eb2\u672c\u4e3aAAbb\u4e0eaaBB\uff0c\u6742\u4ea4\u540e\u5f97\u5230F1\uff0c\u5bf9F1\u6d4b\u4ea4\uff0c\u5b50\u4ee3\u4e2d\uff0c\u77ee\u6746\u6297\u75c5\u7684\u4e2a\u4f53\u7684\u57fa\u56e0\u578b\u4e3a____\nA. AaBb\nB. Aabb\nC. AAbb\nD. aabb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3331832353540621, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e0b\u5217\u5b9e\u4f8b\u4e2d\uff0c\u5206\u522b\u5c5e\u4e8e\u76f8\u5bf9\u6027\u72b6\u548c\u6027\u72b6\u5206\u79bb\u7684\u662f____\r\n\u2460\u7f8a\u7684\u957f\u89d2\u4e0e\u77ed\u817f\r\n\u2461\u6c34\u7a3b\u7684\u975e\u7cef\u6027\u548c\u7cef\u6027\r\n\u2462\u5154\u7684\u7c97\u6bdb\u548c\u72d7\u7684\u7ec6\u6bdb\r\n\u2463\u9ad8\u830e\u8c4c\u8c46\u4e0e\u77ee\u830e\u8c4c\u8c46\u6742\u4ea4,\u540e\u4ee3\u5168\u4e3a\u9ad8\u830e\u8c4c\u8c46\r\n\u2464\u5f00\u7ea2\u82b1\u7684\u7261\u4e39\u4e0e\u5f00\u767d\u82b1\u7684\u7261\u4e39\u6742\u4ea4,\u540e\u4ee3\u5168\u5f00\u7c89\u7ea2\u82b1\r\n\u2465\u767d\u6bdb\u5154\u4e0e\u767d\u6bdb\u5154\u6742\u4ea4\u540e\u4ee3\u4e2d\u51fa\u73b0\u4e86\u7070\u6bdb\u5154\nA. \u2461\u2465\nB. \u2461\u2463\nC. \u2460\u2464\nD. \u2462\u2464\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3824574411254739, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41181127447724375, "meta-llama/Meta-Llama-3-8B": 0.40252653667223387, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7022345863244053}}, {"question": "\u6709\u5173\u8bb0\u5fc6\u7ec6\u80de\u7684\u53d9\u8ff0\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u53d7\u540c\u4e00\u6297\u539f\u523a\u6fc0\u540e\uff0c\u8fc5\u901f\u5f62\u6210\u5927\u91cf\u7684\u6297\u4f53\nB. \u53d7\u540c\u4e00\u6297\u539f\u523a\u6fc0\u540e\uff0c\u8fc5\u901f\u5f62\u6210\u6d46\u7ec6\u80de\nC. \u53d7\u540c\u4e00\u6297\u539f\u523a\u6fc0\u540e\uff0c\u8fc5\u901f\u5f62\u6210\u6548\u5e94T\u7ec6\u80de\nD. \u662fB\u7ec6\u80de\u6216T\u7ec6\u80de\u589e\u6b96\u5206\u5316\u5f62\u6210\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u751f\u7269\u80b2\u79cd\u7684\u53d9\u8ff0\uff0c\u6b63\u786e\u7684\u662f____\nA. \u591a\u500d\u4f53\u80b2\u79cd\u4e0d\u80fd\u4ea7\u751f\u65b0\u7269\u79cd\nB. \u5355\u500d\u4f53\u80b2\u79cd\u4f1a\u4ea7\u751f\u5b9a\u5411\u53d8\u5f02\nC. \u6742\u4ea4\u80b2\u79cd\u7684\u5b50\u4ee3\u95f4\u4f1a\u4ea7\u751f\u751f\u6b96\u9694\u79bb\nD. \u8bf1\u53d8\u80b2\u79cd\u53ef\u6539\u53d8\u79cd\u7fa4\u57fa\u56e0\u9891\u7387\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.43876964226868426, "meta-math/MetaMath-Mistral-7B": 0.9153407502417353, "itpossible/Chinese-Mistral-7B-v0.1": 0.6315972772894597, "HuggingFaceH4/zephyr-7b-beta": 0.9986205624201975, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8830036109930877, "meta-llama/Meta-Llama-3-8B": 0.5808696861039492, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8133341384487536}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u8f83\u5927\u7684\u5206\u5b50\uff0c\u5982\u8461\u8404\u7cd6\u7b49\u53ea\u6709\u901a\u8fc7\u4e3b\u52a8\u8fd0\u8f93\u624d\u80fd\u8fdb\u5165\u7ec6\u80de\nB. \u6240\u6709\u7684\u7ec6\u80de\u90fd\u5177\u6709\u76f8\u540c\u7684\u7ec6\u80de\u819c\u7ed3\u6784\uff0c\u5373\u7531\u78f7\u8102\u5206\u5b50\u6784\u6210\u819c\u7684\u57fa\u672c\u652f\u67b6\uff0c\u201c\u5d4c\u5165\u201d\u652f\u67b6\u6216\u201c\u6f02\u6d6e\u201d\u5728\u652f\u67b6\u4e24\u4fa7\u7684\u86cb\u767d\u8d28\u7684\u79cd\u7c7b\u548c\u6570\u91cf\u76f8\u540c\nC. \u53f6\u7eff\u4f53\u4e2d\u7684\u8272\u7d20\u90fd\u6709\u5438\u6536\u5149\u80fd\u7684\u4f5c\u7528\nD. \u5728\u53f6\u7eff\u4f53\u7684\u5185\u819c\u3001\u7c7b\u56ca\u4f53\u4e0a\u548c\u57fa\u8d28\u4e2d\u542b\u6709\u591a\u79cd\u8fdb\u884c\u5149\u5408\u4f5c\u7528\u6240\u5fc5\u9700\u7684\u9176\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7369171943615368}}, {"question": "\u65b0\u51a0\u75c5\u6bd2\u521a\u521a\u7206\u53d1\u65f6\u68c0\u6d4b\u75c5\u60a3\u5e76\u53ca\u65f6\u9694\u79bb\u7684\u63aa\u65bd\u5c5e\u4e8e____\nA. \u6ce8\u5c04\u75ab\u82d7\nB. \u63a7\u5236\u4f20\u67d3\u6e90\nC. \u5207\u65ad\u4f20\u64ad\u9014\u5f84\nD. \u4fdd\u62a4\u6613\u611f\u4eba\u7fa4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9374151936409977, "meta-math/MetaMath-Mistral-7B": 0.9976768951405407, "itpossible/Chinese-Mistral-7B-v0.1": 0.8924890890549124, "HuggingFaceH4/zephyr-7b-beta": 0.9968043631536672, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9900554410137365, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6472716433342331}}, {"question": "\u7528\u666e\u901a\u5c0f\u9ea6\uff08\u4e3a\u516d\u500d\u4f53\uff09\u7684\u82b1\u7c89\u7ecf\u82b1\u836f\u79bb\u4f53\u57f9\u517b\u6280\u672f\u57f9\u80b2\u6210\u7684\u690d\u682a\u662f____\nA. \u5355\u500d\u4f53\uff0c\u4f53\u7ec6\u80de\u5185\u542b\u6709\u4e00\u4e2a\u67d3\u8272\u4f53\u7ec4\nB. \u5355\u500d\u4f53\uff0c\u4f53\u7ec6\u80de\u5185\u542b\u6709\u4e09\u4e2a\u67d3\u8272\u4f53\u7ec4\nC. \u4e09\u500d\u4f53\uff0c\u4f53\u7ec6\u80de\u5185\u542b\u6709\u4e09\u4e2a\u67d3\u8272\u4f53\u7ec4\nD. \u516d\u500d\u4f53\uff0c\u4f53\u7ec6\u80de\u5185\u542b\u6709\u516d\u4e2a\u67d3\u8272\u4f53\u7ec4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.27312720402870727, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u68c0\u6d4b\u67d0\u4e00\u7ec4\u7ec7\u7ec6\u80de\uff0c\u53d1\u73b0\u5176\u5206\u89e3\u6709\u673a\u7269\u901f\u7387\u51cf\u6162\uff0c\u4e14\u7ec6\u80de\u840e\u7f29\u3002\u8fd9\u8bf4\u660e\u8be5\u7ec6\u80de\u6b63\u5728____\nA. \u5206\u5316\nB. \u5206\u88c2\nC. \u8870\u8001\nD. \u764c\u53d8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6869712041170721, "meta-math/MetaMath-Mistral-7B": 0.8466154103827773, "itpossible/Chinese-Mistral-7B-v0.1": 0.4970893071311525, "HuggingFaceH4/zephyr-7b-beta": 0.9972629586218995, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9427137999803561, "meta-llama/Meta-Llama-3-8B": 0.9483694811954088, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9970609149304508}}, {"question": "\u5c0f\u9ea6\u6297\u9508\u75c5\u5bf9\u6613\u67d3\u75c5\u4e3a\u663e\u6027\u3002\u73b0\u6709\u7532\u3001\u4e59\u4e24\u79cd\u6297\u9508\u75c5\u5c0f\u9ea6\uff0c\u5176\u4e2d\u4e00\u79cd\u4e3a\u7eaf\u79cd\uff0c\u82e5\u8981\u9274\u522b\u548c\u4fdd\u7559\u7eaf\u5408\u7684\u6297\u9508\u75c5\u5c0f\u9ea6\uff0c\u4e0b\u5217\u6700\u7b80\u4fbf\u6613\u884c\u7684\u65b9\u6cd5\u662f____\nA. \u7532\u00d7\u4e59\nB. \u7532\u00d7\u4e59\u5f97F1\u518d\u81ea\u4ea4\nC. \u7532\u3001\u4e59\u5206\u522b\u548c\u9690\u6027\u7c7b\u578b\u6d4b\u4ea4\nD. \u7532\u00d7\u7532\u3001\u4e59\u00d7\u4e59\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6709\u5173\u7ec6\u80de\u4e0e\u7ec6\u80de\u7ed3\u6784\u7684\u53d9\u8ff0\u6b63\u786e\u7684\u662f____\nA. \u7ec6\u80de\u6838\u662f\u7ec6\u80de\u7684\u63a7\u5236\u4e2d\u5fc3,\u80fd\u63a7\u5236\u7ec6\u80de\u9057\u4f20\u548c\u4ee3\u8c22\nB. \u80fd\u5206\u89e3\u8870\u8001\u3001\u635f\u4f24\u7ec6\u80de\u5668\u7684\u9176\u662f\u5728\u6eb6\u9176\u4f53\u4e2d\u5408\u6210\u7684\nC. \u6838\u4ec1\u4e0etRNA\u7684\u5408\u6210\u6709\u5173\nD. \u53ef\u7528\u9ad8\u500d\u663e\u5fae\u955c\u89c2\u5bdf\u5185\u8d28\u7f51\u548c\u9ad8\u5c14\u57fa\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.49792126700363104, "meta-math/MetaMath-Mistral-7B": 0.728312457843245, "itpossible/Chinese-Mistral-7B-v0.1": 0.3084485246797386, "HuggingFaceH4/zephyr-7b-beta": 0.6013801733593884, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8836323405072312, "meta-llama/Meta-Llama-3-8B": 0.6804111291909692, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9352770426608344}}, {"question": "\u8428\u987f\u5047\u8bf4\u8ba4\u4e3a\u201c\u57fa\u56e0\u662f\u7531\u67d3\u8272\u4f53\u643a\u5e26\u7740\u4ece\u4eb2\u4ee3\u4f20\u9012\u7ed9\u5b50\u4ee3\u7684\".\u4e0b\u5217\u76f8\u5173\u63a8\u6d4b\u9519\u8bef\u7684\u662f____\nA. \u4f53\u7ec6\u80de\u4e2d\u57fa\u56e0\u548c\u67d3\u8272\u4f53\u662f\u6210\u5bf9\u5b58\u5728\u7684\nB. \u4f53\u7ec6\u80de\u4e2d\u6210\u5bf9\u7684\u57fa\u56e0\u4e00\u4e2a\u6765\u81ea\u7236\u65b9\uff0c\u53e6\u4e00\u4e2a\u6765\u81ea\u6bcd\u65b9\uff0c\u540c\u6e90\u67d3\u8272\u4f53\u4e5f\u662f\u5982\u6b64\nC. \u4e0d\u540c\u7269\u79cd\u7684\u7ec6\u80de\u4e2d\u57fa\u56e0\u6570\u91cf\u548c\u67d3\u8272\u4f53\u6570\u91cf\u7684\u6bd4\u503c\u662f\u4e00\u5b9a\u7684\nD. \u51cf\u6570\u5206\u88c2\u65f6,\u540c\u6e90\u67d3\u8272\u4f53\u4e0a\u7684\u975e\u7b49\u4f4d\u57fa\u56e0\u65e0\u6cd5\u81ea\u7531\u7ec4\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.48500161994872815, "meta-math/MetaMath-Mistral-7B": 0.7255908434677599, "itpossible/Chinese-Mistral-7B-v0.1": 0.4522196411850988, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7542800239279814, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.522950617935171}}, {"question": "\u5728\u7535\u5b50\u663e\u5fae\u955c\u4e0b\u89c2\u5bdf\u5230\u690d\u7269\u7ec6\u80de\u6709\u4e1d\u5206\u88c2\u672b\u671f\u7ec6\u80de\u677f\u7684\u5468\u56f4\u805a\u96c6\u7740\u8bb8\u591a\u5c0f\u56ca\u6ce1\uff0c\u8fd9\u4e9b\u5c0f\u56ca\u6ce1\u5c5e\u4e8e\u7ec6\u80de\u7684\u54ea\u79cd\u7ed3\u6784\uff1f\u5c0f\u56ca\u6ce1\u53ef\u80fd\u542b\u6709\u4f55\u79cd\u7269\u8d28____\nA. \u5185\u8d28\u7f51\u3000\u86cb\u767d\u8d28\u3001\u78f7\u8102\nB. \u9ad8\u5c14\u57fa\u4f53\u3000\u86cb\u767d\u8d28\u3001\u78f7\u8102\nC. \u5185\u8d28\u7f51\u3000\u7ea4\u7ef4\u7d20\u3001\u679c\u80f6\nD. \u9ad8\u5c14\u57fa\u4f53\u3000\u7ea4\u7ef4\u7d20\u3001\u679c\u80f6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u714e\u997a\u662f\u6211\u56fd\u5317\u65b9\u5730\u533a\u7279\u8272\u4f20\u7edf\u5c0f\u5403\u4e4b\u4e00\uff0c\u4ee5\u9762\u7c89\u548c\u8089\u9985\u4e3a\u4e3b\u8981\u98df\u6750\u5236\u4f5c\u6210\u6c34\u997a\uff0c\u6c34\u997a\u716e\u719f\u653e\u51c9\u540e\u7528\u690d\u7269\u6cb9\u714e\u5236\u800c\u6210\u3002\u714e\u997a\u8868\u9762\u9165\u9ec4\uff0c\u53e3\u611f\u9999\u8106\u3002\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u8089\u9985\u4e2d\u7684\u86cb\u767d\u8d28\u5728\u9ad8\u6e29\u52a0\u70ed\u8fc7\u7a0b\u4e2d\u80bd\u952e\u65ad\u88c2\u4f7f\u5176\u7ed3\u6784\u677e\u6563\uff0c\u5229\u4e8e\u4eba\u4f53\u6d88\u5316\nB. \u714e\u5236\u6c34\u997a\u65f6\u6240\u7528\u7684\u690d\u7269\u6cb9\u5927\u591a\u542b\u6709\u4e0d\u9971\u548c\u8102\u80aa\u9178\uff0c\u5728\u5ba4\u6e29\u4e0b\u5448\u6db2\u6001\nC. \u9762\u7c89\u4e2d\u5bcc\u542b\u7684\u690d\u7269\u591a\u7cd6\u5fc5\u987b\u7ecf\u8fc7\u6d88\u5316\u5206\u89e3\u6210\u8461\u8404\u7cd6\uff0c\u624d\u80fd\u88ab\u4eba\u4f53\u5438\u6536\nD. \u8089\u9985\u4e2d\u7684\u7cd6\u539f\u5c5e\u4e8e\u591a\u7cd6\uff0c\u4e0d\u80fd\u76f4\u63a5\u88ab\u7ec6\u80de\u5438\u6536\u5229\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e521\u56db\u4f53\u7684\u80da\u80ce\u4e0d\u80fd\u6210\u6d3b\u3002\u73b0\u6709\u4e00\u5bf9\u592b\u5987\u5747\u4e3a21\u4e09\u4f53\u7efc\u5408\u5f81\u60a3\u8005\uff0c\u5047\u8bbe\u4ed6\u4eec\u5728\u4ea7\u751f\u914d\u5b50\u65f6\uff0c\u7b2c21\u53f7\u7684\u4e09\u4f53\u67d3\u8272\u4f53\u4e00\u6761\u79fb\u5411\u7ec6\u80de\u7684\u4e00\u6781\uff0c\u4e24\u6761\u79fb\u5411\u53e6\u4e00\u6781,\u5219\u4ed6\u4eec\u751f\u51fa\u60a3\u75c5\u5973\u5b69\u7684\u6982\u7387\u662f____\nA.   1/2\nB.   1/3\nC.   2/3\nD.   1/4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.28343502843642576, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ec6\u80de\u7684\u751f\u957f\u3001\u589e\u6b96\u3001\u8870\u8001\u3001\u51cb\u4ea1\u7b49\u751f\u547d\u5386\u7a0b\u5bf9\u4eba\u4f53\u7684\u751f\u547d\u6d3b\u52a8\u800c\u8a00\u662f\u4e0d\u53ef\u6216\u7f3a\u7684\u3002\u4e0b\u5217\u76f8\u5173\u5224\u65ad\u6b63\u786e\u7684\u662f____\nA. \u7ec6\u80de\u5728\u751f\u957f\u8fc7\u7a0b\u4e2d\uff0c\u4f53\u79ef\u867d\u7136\u589e\u5927\uff0c\u4f46\u5176\u7269\u8d28\u8fd0\u8f93\u6548\u7387\u5e76\u6ca1\u6709\u589e\u5f3a\nB. \u4eba\u4f53\u53d1\u80b2\u8fc7\u7a0b\u4e2d\uff0c\u7ec6\u80de\u589e\u6b96\u6539\u53d8\u4e86\u5b50\u7ec6\u80de\u7684\u9057\u4f20\u7269\u8d28\u5bfc\u81f4\u4e86\u7ec6\u80de\u5206\u5316\nC. \u7ec6\u80de\u7684\u8870\u8001\u5bfc\u81f4\u4eba\u4f53\u7684\u8870\u8001\uff0c\u5ef6\u7f13\u4eba\u4f53\u8870\u8001\u5c31\u8981\u8bbe\u6cd5\u963b\u6b62\u7ec6\u80de\u7684\u8870\u8001\nD. \u7ec6\u80de\u51cb\u4ea1\u7531\u9057\u4f20\u7269\u8d28\u63a7\u5236\uff0c\u53ea\u53d1\u751f\u5728\u8001\u5e74\u4e2a\u4f53\uff0c\u80fd\u52a0\u901f\u4eba\u4f53\u7684\u8870\u8001\u6b7b\u4ea1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u6b63\u5728\u590d\u5236\u7684DNA\u5206\u5b50\uff0c\u89e3\u65cb\u7684\u65f6\u5019\u4e00\u6761\u94fe\u4e0a\u7684G\u53d8\u6210\u4e86C\uff0c\u5219\u6b64DNA\u5206\u5b50\u7ecfn\u6b21\u590d\u5236\u540e\uff0c\u53d1\u751f\u5dee\u9519\u7684DNA\u5360\u5b50\u4ee3DNA\u603b\u6570\u7684____\nA. $\\frac{1}{2}$\nB. $\\frac{1}{{2}^{n}-1}$\nC. $\\frac{1}{{2}^{n}}$\nD. $\\frac{1}{4}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6c34\u7a3b\u7ec6\u80de\u5185ATP\u7684\u53d9\u8ff0\uff0c\u9519\u8bef\u7684\u662f____\nA. \u80fd\u4e0eADP\u76f8\u4e92\u8f6c\u5316\nB. \u53ea\u80fd\u7531\u7ec6\u80de\u547c\u5438\u4ea7\u751f\nC. \u53ef\u4e3a\u7269\u8d28\u8de8\u819c\u8fd0\u8f93\u63d0\u4f9b\u80fd\u91cf\nD. \u91ca\u653e\u7684\u78f7\u9178\u57fa\u56e2\u80fd\u4e0e\u67d0\u4e9b\u86cb\u767d\u8d28\u7ed3\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5980229486660822, "meta-math/MetaMath-Mistral-7B": 0.9454750540244998, "itpossible/Chinese-Mistral-7B-v0.1": 0.6274251020882582, "HuggingFaceH4/zephyr-7b-beta": 0.9980589273298847, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9693298342311812, "meta-llama/Meta-Llama-3-8B": 0.8547308973953209, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9881324638392412}}, {"question": "\u5f53$x=-3$ \u65f6\uff0c\u4e0b\u5217\u5206\u5f0f\u65e0\u610f\u4e49\u7684\u662f____\nA. $\\frac{x-3}{x}$\nB. $\\frac{x+3}{x}$\nC. $\\frac{x}{x-3}$\nD. $\\frac{x}{x+3}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5982\u679c $x=3$\u662f\u5173\u4e8e x\u7684$2x+m=7$\u65b9\u7a0b \u7684\u89e3\uff0c\u90a3\u4e48 $m$\u7684\u503c\u4e3a____\nA. -1\nB. 2\nC. 1\nD. -2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34865081485179605, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3423962339378881, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u2299O\u662f\u4e00\u4e2a\u6b63n\u8fb9\u5f62\u7684\u5916\u63a5\u5706\uff0c\u82e5\u2299O\u7684\u534a\u5f84\u4e0e\u8fd9\u4e2a\u6b63n\u8fb9\u5f62\u7684\u8fb9\u957f\u76f8\u7b49\uff0c\u5219n\u7684\u503c\u4e3a____\nA. 3\nB. 4\nC. 5\nD. 6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u7b49\u5f0f\u53d8\u5f62\u9519\u8bef\u7684\u662f ____\nA. \u82e5$a=b$,\u5219$3a-1=3b-1$\nB. \u82e5$a=b$,\u5219$a c^{2}=b c^{2}$\nC. \u82e5$\\frac{a}{c^{2}}=\\frac{b}{c^{2}}$,\u5219$a =b $\nD. \u82e5$a c^{2}=b c^{2}$,\u5219$a=b$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3669210023858839, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3908307858432125, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3953514416370018, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u5783\u573e\u5206\u7c7b\u201d\u5df2\u7ecf\u5728\u5168\u56fd\u5f00\u5c55\u5f97\u5982\u706b\u5982\u837c\uff0c\u67d0\u56de\u6536\u516c\u53f8\u6709\u56db\u5305\u53ef\u56de\u6536\u5783\u573e\uff0c\u6bcf\u5305\u4ee5\u6807\u51c6\u514b\u6570\uff08 \u5343\u514b\uff09\u4e3a\u57fa\u51c6\uff0c\u8d85\u8fc7\u7684\u5343\u514b\u6570\u8bb0\u4f5c\u6b63\u6570\uff0c\u4e0d\u8db3\u7684\u5343\u514b\u6570\u8bb0\u4f5c\u8d1f\u6570\uff0c\u4ee5\u4e0b\u6570\u636e\u662f\u8bb0\u5f55\u7ed3\u679c\uff0c\u5176\u4e2d\u8868\u793a\u5b9e\u9645\u91cd\u91cf\u6700\u63a5\u8fd1\u6807\u51c6\u5343\u514b\u6570\u7684\u662f ____\nA. -1\nB. 2\nC. -0.5\nD. 0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.35732014339431784, "HuggingFaceH4/zephyr-7b-beta": 0.9870115763243925, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4488746704506832}}, {"question": "\u67d0\u65bd\u5de5\u961f\u627f\u63a5\u4e8660\u516c\u91cc\u7684\u4fee\u8def\u4efb\u52a1\uff0c\u4e3a\u4e86\u63d0\u524d\u5b8c\u6210\u4efb\u52a1\uff0c\u5b9e\u9645\u6bcf\u5929\u7684\u5de5\u4f5c\u6548\u7387\u6bd4\u539f\u8ba1\u5212\u63d0\u9ad8\u4e8625\uff05\uff0c\u7ed3\u679c\u63d0\u524d60\u5929\u5b8c\u6210\u4e86\u8fd9\u9879\u4efb\u52a1\uff0e\u8bbe\u539f\u8ba1\u5212\u6bcf\u5929\u4fee\u8defx\u516c\u91cc\uff0c\u6839\u636e\u9898\u610f\u5217\u51fa\u7684\u65b9\u7a0b\u6b63\u786e\u7684\u662f____\nA. $\\frac{60\\times (1+25 \\%)}{x} -\\frac{60}{x}=60$\nB. $\\frac{60}{x}-\\frac{60\\times (1+25 \\%)}{x} =60$\nC. $\\frac{60 }{ (1+25 \\%)x} -\\frac{60}{x}=60$\nD. $ \\frac{60}{x}-\\frac{60 }{ (1+25 \\%)x} =60$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.353703093539192, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7090251772195373, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.308176776288574, "meta-llama/Meta-Llama-3-8B": 0.29863342676099575, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ebf\u6bb5$AB=9$ \uff0c\u70b9C\u5728\u7ebf\u6bb5$AB$\u4e0a\uff0c\u4e14\u6709$AC=\\frac{1}{3}AB$ \uff0c M\u662fAB \u7684\u4e2d\u70b9\uff0c\u5219 MC\u7b49\u4e8e____\nA. $3$\nB. $\\frac{3}{2}$\nC. $\\frac{9}{2}$\nD. $\\frac{15}{2}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u547d\u9898\u6b63\u786e\u7684\u662f____\nA. \u4e09\u89d2\u5f62\u7684\u91cd\u5fc3\u662f\u4e09\u6761\u9ad8\u7ebf\u7684\u4ea4\u70b9\nB. \u7b49\u8170\u4e09\u89d2\u5f62\u5e95\u8fb9\u4e0a\u7684\u4e2d\u7ebf\u4e0d\u4e00\u5b9a\u5782\u76f4\u4e8e\u5e95\u8fb9\nC. \u7ebf\u6bb5\u5782\u76f4\u5e73\u5206\u7ebf\u4e0a\u7684\u70b9\u5230\u7ebf\u6bb5\u4e24\u7aef\u7684\u8ddd\u79bb\u76f8\u7b49\nD. \u542b\u6839\u53f7\u7684\u6570\u90fd\u662f\u65e0\u7406\u6570\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32022040830300297, "meta-math/MetaMath-Mistral-7B": 0.38453152086340425, "itpossible/Chinese-Mistral-7B-v0.1": 0.38167084872674917, "HuggingFaceH4/zephyr-7b-beta": 0.90026959168613, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4422988238069945, "meta-llama/Meta-Llama-3-8B": 0.533743622810805, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7504643668959075}}, {"question": "\u4e0b\u5217\u5404\u7ec4\u4ee3\u6570\u5f0f\u4e2d\u4e3a\u540c\u7c7b\u9879\u7684\u662f____\nA. $-2xy$\u4e0e$2x$\nB. $5x^2y$\u4e0e$-2xy^2$\nC. $5x^5y^4$\u4e0e$-5x^5z^4$\nD. $-xy$\u4e0e$\\frac{3}{2}y x$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3148300531811561, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u547d\u9898\u662f\u771f\u547d\u9898\u7684\u662f____\nA. \u4e24\u6761\u76f4\u7ebf\u88ab\u7b2c\u4e09\u6761\u76f4\u7ebf\u6240\u622a\uff0c\u540c\u65c1\u5185\u89d2\u4e92\u8865\nB. \u4e09\u89d2\u5f62\u5185\u89d2\u548c\u4e3a180\u00b0\nC. \u4e09\u89d2\u5f62\u7684\u4e00\u4e2a\u5916\u89d2\u7b49\u4e8e\u5b83\u7684\u4e24\u4e2a\u5185\u89d2\u4e4b\u548c\nD. \u540c\u89d2\u7684\u4f59\u89d2\u4e92\u8865\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.27240321009873075, "meta-math/MetaMath-Mistral-7B": 0.32205625344145955, "itpossible/Chinese-Mistral-7B-v0.1": 0.44432872455858613, "HuggingFaceH4/zephyr-7b-beta": 0.6447827740348097, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4097932749405994, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8501603932502617}}, {"question": "\u629b\u7269\u7ebf$y=-x^2+2x-2$\u7684\u9876\u70b9\u5750\u6807\u4e3a____\nA. (-1,1)\nB. (1,-1)\nC. (-1,-1)\nD. (1,-3)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.26560468668687814, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u5546\u573a\u9500\u552e\u7532\u3001\u4e59\u4e24\u79cd\u670d\u88c5\uff0c\u5df2\u77e5\u4e59\u670d\u88c5\u6bcf\u4ef6\u7684\u6210\u672c\u6bd4\u7532\u670d\u88c5\u8d3550\u5143\uff0c\u7532\u3001\u4e59\u670d\u88c5\u5747\u6309\u6210\u672c\u4ef7\u63d0\u9ad840\uff05   \u4f5c\u4e3a\u6807\u4ef7\u51fa\u552e.\u4e00\u6bb5\u65f6\u95f4\u540e\uff0c\u7532\u670d\u88c5\u5356\u51fa\u4e86350\u4ef6\uff0c\u4e59\u670d\u88c5\u5356\u51fa\u4e86200\u4ef6\uff0c\u9500\u552e\u91d1\u989d\u4e3a 129500\u5143\uff0c\u82e5\u7528\u65b9\u7a0b$350\\times1.4x+200\\times1.4\\times\\left(x+50\\right)=129500$   \u8868\u793a\u5176\u4e2d\u7684\u6570\u91cf\u5173\u7cfb\uff0c\u5219\u5f0f\u5b50\u4e2d \u6240\u8868\u793a\u7684\u91cf\u662f____\nA. \u7532\u670d\u88c5\u7684\u6807\u4ef7\nB. \u4e59\u670d\u88c5\u7684\u6807\u4ef7\nC. \u7532\u670d\u88c5\u7684\u6210\u672c\u4ef7\nD. \u4e59\u670d\u88c5\u7684\u6210\u672c\u4ef7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2938890773609541, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9374697810824408, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3354456100429363, "meta-llama/Meta-Llama-3-8B": 0.3060136256597631, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.431033945941338}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____(1)\u629b\u4e00\u679a\u786c\u5e01\uff0c\u6b63\u9762\u4e00\u5b9a\u671d\u4e0a\uff1b (2)\u63b7\u4e00\u9897\u9ab0\u5b50\uff0c\u70b9\u6570\u4e00\u5b9a\u4e0d\u5927\u4e8e6\uff1b(3)\u4e3a\u4e86\u89e3\u4e00\u79cd\u706f\u6ce1\u7684\u4f7f\u7528\u5bff\u547d\uff0c\u5b9c\u91c7\u7528\u666e\u67e5\u7684\u65b9\u6cd5\uff1b(4)\u201c\u660e\u5929\u7684\u964d\u6c34\u6982\u7387\u4e3a80%\u201d\uff0c\u8868\u793a\u660e\u5929\u4f1a\u670980\uff05\u7684\u5730\u65b9\u4e0b\u96e8\uff0e\nA. 1\u4e2a\nB. 2\u4e2a\nC. 3\u4e2a\nD. 4\u4e2a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u53e4\u4ee3\u6570\u5b66\u8457\u4f5c\u300a\u5b59\u5b50\u7b97\u7ecf\u300b\u4e2d\u6709\u4e00\u9053\u9898\uff1a\u201c\u4eca\u6709\u6728\uff0c\u4e0d\u77e5\u957f\u77ed\uff0c\u5f15\u7ef3\u5ea6\u4e4b\uff0c\u4f59\u7ef3\u56db\u5c3a\u4e94\uff0c\u5c48\u7ef3\u91cf\u4e4b\uff0c\u4e0d\u8db3\u4e00\u5c3a\uff0c\u95ee\u6728\u957f\u51e0\u4f55\uff1f\u201d\u5927\u81f4\u610f\u601d\u662f\uff1a\u201c\u7528\u4e00\u6839\u7ef3\u5b50\u53bb\u91cf\u4e00\u6839\u6728\u6761\uff0c\u7ef3\u5b50\u5269\u4f594.5\u5c3a\uff0c\u5c06\u7ef3\u5b50\u5bf9\u6298\u518d\u91cf\u6728\u6761\uff0c\u6728\u6761\u5269\u4f591\u5c3a\uff0c\u95ee\u6728\u6761\u957f\u591a\u5c11\u5c3a\uff1f\u201d\u8bbe\u7ef3\u5b50\u957fx\u5c3a\uff0c\u6728\u6761\u957fy\u5c3a\uff0c\u5219\u6839\u636e\u9898\u610f\u6240\u5217\u65b9\u7a0b\u7ec4\u6b63\u786e\u7684\u662f____\nA. $\\begin{cases}x-y=4.5,\\\\ \\dfrac{1}{2}x-y=1\\end{cases}$\nB. $\\begin{cases}x-y=4.5,\\\\ y-\\dfrac{1}{2}x=1\\end{cases}$\nC. $\\left\\{\\begin{matrix}x+y=4.5,\\\\ y-\\dfrac{1}{2}x=1\\end{matrix}\\right.$\nD. $\\left\\{\\begin{matrix}x-y=4.5,\\\\ x-\\frac{1}{2}y=1\\end{matrix}\\right.$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.40067966148457895, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u3001\u4e59\u4e24\u73ed\u5b66\u751f\u53c2\u52a0\u690d\u6811\u9020\u6797\uff0c\u5df2\u77e5\u7532\u73ed\u6bcf\u5929\u6bd4\u4e59\u73ed\u591a\u690d5\u68f5\u6811\uff0c\u7532\u73ed\u690d80\u68f5\u6811\u6240\u7528\u7684\u5929\u6570\u4e0e\u4e59\u73ed\u690d70\u68f5\u6811\u6240\u7528\u7684\u5929\u6570\u76f8\u7b49\uff0e\u82e5\u8bbe\u7532\u73ed\u6bcf\u5929\u690d\u6811x\u68f5\uff0c\u5219\u6839\u636e\u9898\u610f\u5f97\u51fa\u7684\u65b9\u7a0b\u662f____\nA. $\\frac{80}{x-5}=\\frac{70}{x}$\nB. $\\frac{80}{x}=\\frac{70}{x+5}$\nC. $\\frac{80}{x+5}=\\frac{70}{x}$\nD. $\\frac{80}{x}=\\frac{70}{x-5}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5224\u65ad\u9519\u8bef\u7684\u7684\u662f____\nA. $2x^{2}y^{2}$\u662f\u4e8c\u6b21\u5355\u9879\u5f0f\nB. \u5355\u9879\u5f0f $a$\u7684\u7cfb\u6570\u548c\u6b21\u6570\u90fd\u662f 1\nC. \u6570\u5b573\u662f\u5355\u9879\u5f0f\nD. $2\\pi r$\u7684\u7cfb\u6570\u662f$2\\pi$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u56fe\u5f62\u4e2d\u6709\u7a33\u5b9a\u6027\u7684\u662f____\nA. \u5e73\u884c\u56db\u8fb9\u5f62\nB. \u76f4\u89d2\u4e09\u89d2\u5f62\nC. \u957f\u65b9\u5f62\nD. \u6b63\u65b9\u5f62\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2893743369926839, "meta-math/MetaMath-Mistral-7B": 0.2953920515320701, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3354456100429363, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9633\u5149\u6587\u5177\u5e97\u51fa\u552e\u7b14\u888b\u548c\u6c34\u7b14\uff0c\u7b14\u888b\u6bcf\u4e2a12\u5143\uff0c\u6c34\u7b14\u6bcf\u4e2a2\u5143\uff0c\u4fc3\u9500\u671f\u95f4\u8d2d\u4e00\u4e2a\u7b14\u888b\u9001\u4e00\u4e2a\u6c34\u7b14\uff0c\u67d0\u4eba\u5171\u4ed8\u6b3e 150\u5143\uff0c\u8d2d\u5f97\u7b14\u888b\u3001\u6c34\u7b14\u5171 35\u4e2a\uff08\u542b\u8d60\u54c1\uff09\uff0c\u5219\u6b64\u4eba\u8d2d\u5f97\u7b14\u888b\u7684\u4e2a\u6570\u4e3a____\nA. 9\nB. 10\nC. 11\nD. 12\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2963332999770349, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u5143\u4e8c\u6b21\u65b9\u7a0b$x^2-3x=1$\u7684\u4e24\u4e2a\u5b9e\u6570\u6839\u4e3a$\\alpha$,$\\beta$,\u5219$\\alpha+\\beta$\u7684\u503c\u4e3a____\nA. 3\nB. -1\nC. -3\nD. 1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.3787890008316441, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3615085256056106, "meta-llama/Meta-Llama-3-8B": 0.38023923438064977, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8362603296843466}}, {"question": "\u8fd0\u7528\u9002\u5f53\u7684\u65b9\u6cd5\u53ef\u4ee5\u4fdd\u5b58\u98df\u54c1\u3002\u5c06\u65b0\u9c9c\u8611\u83c7\u5236\u6210\u5e72\u8611\u83c7\u91c7\u7528\u7684\u4fdd\u5b58\u65b9\u6cd5\u662f____\nA. \u4f4e\u6e29\u51b7\u85cf\nB. \u771f\u7a7a\u5305\u88c5\nC. \u8131\u6c34\u6cd5\nD. \u6dfb\u52a0\u9632\u8150\u5242\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6701107873725176, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.959339857173411, "HuggingFaceH4/zephyr-7b-beta": 0.9297956901007084, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8053041402156583, "meta-llama/Meta-Llama-3-8B": 0.7142583183349267, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9892250360562675}}, {"question": "\u52a8\u7269\u80fd\u4fc3\u8fdb\u751f\u6001\u7cfb\u7edf\u4e2d\u7684\u7269\u8d28\u5faa\u73af\uff0e\u8fd9\u91cc\u7684\u201c\u7269\u8d28\u5faa\u73af\u201d\u662f\u6307____\nA. \u52a8\u7269\u80fd\u5c06\u65e0\u673a\u7269\u8f6c\u5316\u4e3a\u6709\u673a\u7269\nB. \u52a8\u7269\u80fd\u5c06\u6709\u673a\u7269\u8f6c\u5316\u4e3a\u65e0\u673a\u7269\u56de\u5230\u81ea\u7136\u754c\u4e2d\nC. \u52a8\u7269\u80fd\u4e3a\u690d\u7269\u63d0\u4f9b\u7caa\u4fbf\uff0c\u4fc3\u8fdb\u690d\u7269\u751f\u957f\nD. \u52a8\u7269\u80fd\u6291\u5236\u690d\u7269\u7684\u751f\u957f\uff0c\u4fdd\u62a4\u81ea\u7136\u754c\u4e2d\u751f\u7269\u7684\u5e73\u8861\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.49302110061395055, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.7453295866753743, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9195264442974954, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5223676375162687}}, {"question": "\u4fdd\u62a4\u751f\u7269\u591a\u6837\u6027\u7684\u6700\u4e3a\u6709\u6548\u662f\u63aa\u65bd\u662f____\nA. \u8fc1\u5730\u4fdd\u62a4\nB. \u5c31\u5730\u4fdd\u62a4\nC. \u514b\u9686\nD. \u6cd5\u5236\u7ba1\u7406\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9436494742866568, "meta-math/MetaMath-Mistral-7B": 0.989748657988338, "itpossible/Chinese-Mistral-7B-v0.1": 0.9498315146913631, "HuggingFaceH4/zephyr-7b-beta": 0.999937839244856, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9808465217930319, "meta-llama/Meta-Llama-3-8B": 0.9448967593284804, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9816668471933283}}, {"question": "\u80ce\u513f\u5728\u6bcd\u4f53\u5185\u7684\u751f\u957f\u53d1\u80b2\u9700\u8981\u8425\u517b\u7269\u8d28\u548c\u6392\u51fa\u5e9f\u7269\uff0c\u80ce\u513f\u4e0e\u6bcd\u4f53\u4e4b\u95f4\u8fdb\u884c\u7269\u8d28\u4ea4\u6362\u7684\u5668\u5b98\u662f____\nA. \u5375\u5de2\nB. \u8f93\u5375\u7ba1\nC. \u80ce\u76d8\nD. \u5b50\u5bab\u5185\u819c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6648308162686369, "meta-math/MetaMath-Mistral-7B": 0.8899394159373096, "itpossible/Chinese-Mistral-7B-v0.1": 0.9742248205707856, "HuggingFaceH4/zephyr-7b-beta": 0.9806342982836147, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9502154340129858, "meta-llama/Meta-Llama-3-8B": 0.9933310921359957, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9994589319804809}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u4e00\u4f4d\u5987\u5973\u9885\u5185\u5927\u8111\u76ae\u5c42\u4e0a\u957f\u4e86\u80bf\u7624\u5bfc\u81f4\u5979\u5931\u660e\uff0c\u662f\u7531\u4e8e\u80bf\u7624\u538b\u8feb\u4e86\u53cd\u5c04\u5b64\u7684\u795e\u7ecf\u4e2d\u67a2\nB. \u9189\u9152\u9a7e\u8f66\u6781\u6613\u53d1\u751f\u4ea4\u901a\u4e8b\u6545\uff0c\u662f\u56e0\u4e3a\u9152\u7cbe\u4e3b\u8981\u9ebb\u9189\u4e86\u9152\u9a7e\u8005\u7684\u8111\u5e72\nC. \u8d5b\u573a\u4e0a\u9009\u624b\u542c\u5230\u53d1\u4ee4\u67aa\u58f0\u540e\u8fc5\u901f\u8d77\u8dd1\u5c5e\u4e8e\u7b80\u5355\u53cd\u5c04\nD. \u4eba\u4f53\u7684\u751f\u547d\u6d3b\u52a8\u4e3b\u8981\u53d7\u5230\u6fc0\u7d20\u8c03\u8282\u7684\u5f71\u54cd\uff0c\u4e5f\u53d7\u5230\u795e\u7ecf\u7cfb\u7edf\u7684\u8c03\u8282\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5556499687537041, "meta-math/MetaMath-Mistral-7B": 0.8207130953308096, "itpossible/Chinese-Mistral-7B-v0.1": 0.5377747962127981, "HuggingFaceH4/zephyr-7b-beta": 0.9160582985089303, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.784547986021684, "meta-llama/Meta-Llama-3-8B": 0.9031706650846005, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u88f8\u5b50\u690d\u7269\u548c\u88ab\u5b50\u690d\u7269\u90fd\u5c5e\u4e8e\u79cd\u5b50\u690d\u7269\uff0c\u4e24\u8005\u4e4b\u95f4\u7684\u4e3b\u8981\u533a\u522b\u662f____\nA. \u751f\u957f\u73af\u5883\u4e0d\u540c\nB. \u79cd\u5b50\u5916\u9762\u662f\u5426\u6709\u679c\u76ae\u5305\u88ab\nC. \u5728\u5730\u7403\u4e0a\u51fa\u73b0\u7684\u5e74\u4ee3\u4e0d\u540c\nD. \u5206\u5e03\u7684\u8303\u56f4\u4e0d\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9628760927602313, "meta-math/MetaMath-Mistral-7B": 0.9979493078285842, "itpossible/Chinese-Mistral-7B-v0.1": 0.8910561930904269, "HuggingFaceH4/zephyr-7b-beta": 0.9999933252880248, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9328565276314666, "meta-llama/Meta-Llama-3-8B": 0.9648780901118256, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.999313190474351}}, {"question": "\u6d0b\u8471\u8868\u76ae\u7ec6\u80de\u4e0e\u4eba\u7684\u53e3\u8154\u4e0a\u76ae\u7ec6\u80de\u7684\u533a\u522b\u662f\u540e\u8005\u6ca1\u6709\u7684\u662f____\nA. \u7ec6\u80de\u58c1\nB. \u7ec6\u80de\u819c\nC. \u7ec6\u80de\u6838\nD. \u7ec6\u80de\u8d28\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4006796757977685, "HuggingFaceH4/zephyr-7b-beta": 0.4818199471728603, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40267108286059333, "meta-llama/Meta-Llama-3-8B": 0.6719167860502958, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u5bc2\u9759\u7684\u6625\u5929\u300b\u662f\u4e00\u672c\u5f15\u53d1\u4e86\u5168\u4e16\u754c\u73af\u5883\u4fdd\u62a4\u4e8b\u4e1a\u7684\u4e66\uff0c\u4e66\u4e2d\u63cf\u8ff0\u4eba\u7c7b\u53ef\u80fd\u5c06\u9762\u4e34\u4e00\u4e2a\u6ca1\u6709\u9e1f\u3001\u871c\u8702\u548c\u8774\u8776\u7684\u4e16\u754c\uff0c\u6b63\u662f\u8fd9\u672c\u4e0d\u5bfb\u5e38\u7684\u4e66\uff0c\u5728\u4e16\u754c\u8303\u56f4\u5185\u5f15\u8d77\u4eba\u4eec\u5bf9\u91ce\u751f\u52a8\u7269\u7684\u5173\u6ce8\uff0c\u5524\u8d77\u4e86\u4eba\u4eec\u7684\u73af\u5883\u610f\u8bc6\uff0c\u52a8\u7269\u5728\u751f\u7269\u5708\u4e2d\u5177\u6709\u7684\u91cd\u8981\u4f5c\u7528\u7684\u662f____\r\n\r\n\u2460\u7ef4\u6301\u751f\u6001\u5e73\u8861 \u2461\u6d88\u706d\u75c5\u866b\u5bb3 \u2462\u5e2e\u52a9\u690d\u7269\u4f20\u7c89\u3001\u4f20\u64ad\u79cd\u5b50 \u2463\u4fc3\u8fdb\u7269\u8d28\u5faa\u73af\uff0e\nA. \u2460\u2461\u2462\nB. \u2461\u2462\u2463\nC. \u2460\u2462\u2463\nD. \u2460\u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3060136256597631, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.40322669517609055, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6b63\u5728\u7ed3\u897f\u74dc\u7684\u690d\u682a\uff0c\u5176\u5438\u6536\u7684\u6c34\u5206\u4e3b\u8981\u7528\u4e8e____\nA. \u5149\u5408\u4f5c\u7528\nB. \u84b8\u817e\u4f5c\u7528\nC. \u547c\u5438\u4f5c\u7528\nD. \u5438\u6536\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4115736623779203, "meta-math/MetaMath-Mistral-7B": 0.6320813964507669, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9980467034507013, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u54c8\u7ef4\u7684\u4e3b\u8981\u8d21\u732e\u662f____\nA. \u53d1\u73b0\u4e86DNA\u7684\u53cc\u87ba\u65cb\u7ed3\u6784\nB. \u53d1\u73b0\u4e86\u8840\u6db2\u5faa\u73af\nC. \u521b\u7acb\u4e86\u751f\u7269\u8fdb\u5316\u8bba\nD. \u521b\u7acb\u4e86\u7edf\u4e00\u7684\u751f\u7269\u547d\u540d\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u690d\u7269\u7684\u5149\u5408\u4f5c\u7528\u548c\u547c\u5438\u4f5c\u7528\u7684\u53d9\u8ff0\u6b63\u786e\u7684\u662f____\nA. \u53f6\u7eff\u7d20\u662f\u7eff\u53f6\u8fdb\u884c\u5149\u5408\u4f5c\u7528\u7684\u4e3b\u8981\u573a\u6240\nB. \u4f4e\u6e29\u80fd\u4fdd\u9c9c\u852c\u83dc\u3001\u6c34\u679c\u662f\u56e0\u4e3a\u4f4e\u6e29\u80fd\u964d\u4f4e\u690d\u7269\u7ec6\u80de\u7684\u547c\u5438\u4f5c\u7528\nC. \u7eff\u8272\u690d\u7269\u901a\u8fc7\u547c\u5438\u4f5c\u7528\uff0c\u6765\u7ef4\u6301\u751f\u7269\u5708\u4e2d\u4e8c\u6c27\u5316\u78b3\u548c\u6c27\u6c14\u7684\u76f8\u5bf9\u5e73\u8861\nD. \u519c\u4e1a\u751f\u4ea7\u4e0a\u8981\u63d0\u9ad8\u519c\u4f5c\u7269\u7684\u4ea7\u91cf\uff0c\u53ea\u9700\u52a0\u5f3a\u519c\u4f5c\u7269\u7684\u5149\u5408\u4f5c\u7528\u65e0\u9700\u8003\u8651\u5176\u547c\u5438\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.968729280773756, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.48369359422605884, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u751f\u7269\u4f53\u7ed3\u6784\u548c\u529f\u80fd\u662f\u76f8\u9002\u5e94\u7684\u3002\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u6709\u5229\u4e8e\u7ec4\u7ec7\u7ec6\u80de\u83b7\u5f97\u6c27\u6c14\u7684\u662f____\nA. \u5c0f\u80a0\u5185\u8868\u9762\u5177\u6709\u8bb8\u591a\u76b1\u895e\u548c\u7ed2\u6bdb\nB. \u6bdb\u7ec6\u8840\u7ba1\u58c1\u7531\u4e00\u5c42\u6241\u5e73\u4e0a\u76ae\u7ec6\u80de\u6784\u6210\nC. \u52a8\u8109\u8840\u7ba1\u548c\u9759\u8109\u8840\u7ba1\u5185\u90fd\u6709\u74e3\u819c\nD. \u80be\u5c0f\u7403\u7531\u8bb8\u591a\u6bdb\u7ec6\u8840\u7ba1\u7f20\u7ed5\u800c\u6210\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6280777816947021, "meta-math/MetaMath-Mistral-7B": 0.666450817982265, "itpossible/Chinese-Mistral-7B-v0.1": 0.41342934444660134, "HuggingFaceH4/zephyr-7b-beta": 0.9901984185665863, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4430784992054178, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6355\u8747\u8349\u548c\u8747\u5728\u7ec6\u80de\u57fa\u672c\u7ed3\u6784\u4e0a\u7684\u533a\u522b\u662f\u6355\u8747\u8349\u7684\u7ec6\u80de\u4e2d\u5177\u6709____\nA. \u7ec6\u80de\u8d28\nB. \u7ec6\u80de\u819c\nC. \u7ec6\u80de\u6838\nD. \u7ec6\u80de\u58c1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8e\u75c5\u6bd2\u7684\u8ba4\u8bc6\u6b63\u786e\u7684\u662f\uff1a____\nA. \u75c5\u6bd2\u5bf9\u4eba\u7c7b\u90fd\u662f\u6709\u5bb3\u7684\uff0c\u6beb\u65e0\u5229\u7528\u4ef7\u503c\nB. \u75c5\u6bd2\u4e00\u65e6\u6d78\u5165\u4eba\u4f53\uff0c\u5c31\u4f1a\u4f7f\u4eba\u60a3\u75c5\nC. \u75c5\u6bd2\u7684\u4e2a\u4f53\u5f88\u5c0f\uff0c\u8981\u7528\u7535\u5b50\u663e\u5fae\u955c\u624d\u80fd\u89c2\u5bdf\u5230\nD. \u52a8\u7269\u75c5\u6bd2\u4e5f\u53ef\u4ee5\u5bc4\u751f\u5728\u690d\u7269\u7ec6\u80de\u91cc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.46822199916419005, "meta-math/MetaMath-Mistral-7B": 0.9495348363245154, "itpossible/Chinese-Mistral-7B-v0.1": 0.4845303553205471, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9019129933461516, "meta-llama/Meta-Llama-3-8B": 0.8889911995196627, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9876603840816252}}, {"question": "\u5806\u653e\u65f6\u95f4\u8f83\u957f\u7684\u852c\u83dc\u4f1a\u56e0\u4ea7\u70ed\u800c\u8150\u70c2\uff0c\u4e0e\u7ec6\u80de\u4ea7\u70ed\u76f4\u63a5\u76f8\u5173\u7684\u751f\u7406\u8fc7\u7a0b\u662f____\nA. \u547c\u5438\u4f5c\u7528\nB. \u84b8\u817e\u4f5c\u7528\nC. \u5149\u5408\u4f5c\u7528\nD. \u8fd0\u8f93\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8175216802496839, "HuggingFaceH4/zephyr-7b-beta": 0.5521787370228214, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.738221213103322, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u679c\u9152\u7684\u5236\u4f5c\u9700\u8981____\nA. \u9175\u6bcd\u83cc\nB. \u4e73\u9178\u83cc\nC. \u9709\u83cc\nD. \u918b\u9178\u83cc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6471407107759366, "meta-math/MetaMath-Mistral-7B": 0.9716238049480025, "itpossible/Chinese-Mistral-7B-v0.1": 0.3908304890519639, "HuggingFaceH4/zephyr-7b-beta": 0.9702316351081024, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8726946965854563, "meta-llama/Meta-Llama-3-8B": 0.5208125011242347, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.718154899790027}}, {"question": "\u201c\u690d\u7269\u4eba\u201d\u6709\u5fc3\u773a\u3001\u547c\u5438\uff0c\u4e0d\u80fd\u81ea\u4e3b\u6d3b\u52a8\u3001\u65e0\u610f\u8bc6\uff0c\u53ef\u786e\u5b9a\u795e\u7ecf\u7cfb\u7edf\u53d7\u5230\u635f\u4f24\u7684\u662f____\nA. \u5927\u8111\nB. \u5c0f\u8111\nC. \u8111\u5e72\nD. \u810a\u9ac4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3534716292209113, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u7d27\u6025\u60c5\u51b5\u4e0b\uff0c\u58c1\u864e\u7684\u5c3e\u5df4\u80fd\u81ea\u52a8\u65ad\u843d\uff0c\u65ad\u843d\u90e8\u5206\u8fd8\u80fd\u505a\u5c48\u66f2\u8fd0\u52a8\u3002\u8725\u8734\u7684\u8fd9\u79cd\u884c\u4e3a\u662f\u52a8\u7269\u7684____\nA. \u653b\u51fb\u884c\u4e3a\nB. \u7e41\u6b96\u884c\u4e3a\nC. \u793e\u4f1a\u884c\u4e3a\nD. \u9632\u5fa1\u884c\u4e3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9715737596296283, "meta-math/MetaMath-Mistral-7B": 0.9954091829418333, "itpossible/Chinese-Mistral-7B-v0.1": 0.9779140901033561, "HuggingFaceH4/zephyr-7b-beta": 0.9999968564768383, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9838944552582196, "meta-llama/Meta-Llama-3-8B": 0.9880733292989738, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9997152382575141}}, {"question": "\u4e0b\u5217\u6709\u5173\u52a8\u7269\u7684\u5f62\u6001\u7ed3\u6784\u4e0e\u751f\u6d3b\u73af\u5883\u76f8\u9002\u5e94\u7684\u53d9\u8ff0\u9519\u8bef\u7684\u662f____\nA. \u5bb6\u9e3d\u524d\u80a2\u53d8\u6210\u7ffc\uff0c\u9002\u4e8e\u5728\u7a7a\u4e2d\u98de\u7fd4\nB. \u91ce\u5154\u795e\u7ecf\u7cfb\u7edf\u53d1\u8fbe\uff0c\u80fd\u8fc5\u901f\u53d1\u73b0\u5e76\u8eb2\u907f\u5929\u654c\nC. \u9cab\u9c7c\u8eab\u4f53\u5448\u7eba\u9524\u5f62\uff0c\u7528\u9cc3\u547c\u5438\uff0c\u9002\u4e8e\u5728\u6c34\u4e2d\u751f\u6d3b\nD. \u86af\u8693\u751f\u6d3b\u5728\u571f\u58e4\u4e2d\uff0c\u4f9d\u9760\u80ba\u8fdb\u884c\u547c\u5438\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9668200126226568, "meta-math/MetaMath-Mistral-7B": 0.9884715797690915, "itpossible/Chinese-Mistral-7B-v0.1": 0.7249409788713053, "HuggingFaceH4/zephyr-7b-beta": 0.9999974065258657, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9965893970962649, "meta-llama/Meta-Llama-3-8B": 0.9594518085090872, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6764172368761778}}, {"question": "\u4ee5\u4e0b\u6709\u5173\u8fbe\u5c14\u6587\u81ea\u7136\u9009\u62e9\u5b66\u8bf4\u7684\u53d9\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u8fd9\u79cd\u751f\u7269\u666e\u904d\u90fd\u5177\u6709\u5f88\u5f3a\u7684\u7e41\u6b96\u80fd\u529b\nB. \u751f\u7269\u8981\u751f\u5b58\u4e0b\u53bb\uff0c\u5c31\u5f97\u4e3a\u4e86\u83b7\u5f97\u98df\u7269\u548c\u7a7a\u95f4\u800c\u8fdb\u884c\u751f\u5b58\u6597\u4e89\nC. \u81ea\u7136\u9009\u62e9\u4fdd\u7559\u7684\u53d8\u5f02\u6c38\u8fdc\u90fd\u6709\u5229\u4e8e\u8be5\u751f\u7269\u7684\u751f\u5b58\nD. \u4e0d\u9002\u5e94\u73af\u5883\u7684\u751f\u7269\u5c06\u88ab\u6dd8\u6c70\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7433002219460636, "meta-math/MetaMath-Mistral-7B": 0.7596912938956681, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9832606241872459, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8077300791914842, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6709\u5173\u751f\u547d\u7684\u8d77\u6e90\u548c\u8fdb\u5316\u7684\u53d9\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u751f\u547d\u8d77\u6e90\u4e8e\u539f\u59cb\u9646\u5730\nB. \u5316\u77f3\u662f\u7814\u7a76\u751f\u7269\u8fdb\u5316\u7684\u6700\u76f4\u63a5\u8bc1\u636e\nC. \u7c73\u52d2\u5b9e\u9a8c\u8bf4\u660e\u539f\u59cb\u5730\u7403\u6761\u4ef6\u4e0b\u65e0\u673a\u5c0f\u5206\u5b50\u5f62\u6210\u6709\u673a\u5c0f\u5206\u5b50\u662f\u53ef\u80fd\u7684\nD. \u539f\u59cb\u751f\u547d\u8bde\u751f\u7684\u6807\u5fd7\u662f\u80fd\u4ece\u5916\u754c\u83b7\u53d6\u8425\u517b\u5e76\u6392\u51fa\u4ee3\u8c22\u5e9f\u7269\uff0c\u80fd\u8fdb\u884c\u751f\u957f\u548c\u7e41\u6b96\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.41983413510962153, "meta-math/MetaMath-Mistral-7B": 0.7675824889770834, "itpossible/Chinese-Mistral-7B-v0.1": 0.39846432051933256, "HuggingFaceH4/zephyr-7b-beta": 0.999061452473907, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6011865570940355, "meta-llama/Meta-Llama-3-8B": 0.8584223243213606, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.943697717683757}}, {"question": "\u5728\u5168\u56fd\u4e2d\u5c0f\u5b66\u5b89\u5168\u6559\u80b2\u5e73\u53f0\u4e2d\uff0c\u5b89\u5168\u7528\u7535\u5e38\u8bc6\u662f\u5176\u4e2d\u4e00\u9879\u91cd\u8981\u7684\u6559\u80b2\u5185\u5bb9\u3002\u4e0b\u5217\u505a\u6cd5\u7b26\u5408\u5b89\u5168\u7528\u7535\u8981\u6c42\u7684\u662f____\nA. \u7528\u94dc\u4e1d\u66ff\u4ee3\u4fdd\u9669\u4e1d\nB. \u66f4\u6362\u706f\u6ce1\u65f6\u65ad\u5f00\u7535\u6e90\u5f00\u5173\nC. \u5f00\u5173\u63a5\u5728\u706f\u6ce1\u548c\u96f6\u7ebf\u4e4b\u95f4\nD. \u4f7f\u7528\u6d4b\u7535\u7b14\u65f6\u624b\u63a5\u89e6\u7b14\u5c16\u91d1\u5c5e\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.757994476010476, "meta-math/MetaMath-Mistral-7B": 0.9677461129038689, "itpossible/Chinese-Mistral-7B-v0.1": 0.8649797707280815, "HuggingFaceH4/zephyr-7b-beta": 0.9583065355179196, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9798942707445945, "meta-llama/Meta-Llama-3-8B": 0.8853334456428033, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9549306926212704}}, {"question": "\u56db\u51b2\u7a0b\u67f4\u6cb9\u673a\u5728\u5de5\u4f5c\u8fc7\u7a0b\u4e2d\uff0c\u5c06\u5185\u80fd\u8f6c\u5316\u4e3a\u673a\u68b0\u80fd\u7684\u51b2\u7a0b\u662f____\nA. \u5438\u6c14\u51b2\u7a0b\nB. \u538b\u7f29\u51b2\u7a0b\nC. \u505a\u529f\u51b2\u7a0b\nD. \u6392\u6c14\u51b2\u7a0b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4368681907114195, "meta-math/MetaMath-Mistral-7B": 0.4001685433004844, "itpossible/Chinese-Mistral-7B-v0.1": 0.9134955335303431, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4391305220915006, "meta-llama/Meta-Llama-3-8B": 0.691546429614599, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7156638398832164}}, {"question": "\u6b4c\u8bcd\u201c\u5c0f\u5c0f\u7af9\u6392\u6c5f\u4e2d\u6e38\uff0c\u5dcd\u5dcd\u9752\u5c71\u4e24\u5cb8\u8d70\u201d\uff0c\u524d\u53e5\u63cf\u8ff0\u7684\u8fd0\u52a8\u7269\u4f53\u548c\u540e\u4e00\u53e5\u7684\u53c2\u7167\u7269\u5206\u522b\u662f____\nA. \u9752\u5c71 \u9752\u5c71\nB. \u7af9\u6392 \u9752\u5c71\nC. \u7af9\u6392 \u7af9\u6392\nD. \u9752\u5c71 \u7af9\u6392\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5934\u7403\uff08\u8fd0\u52a8\u5458\u7528\u5934\u78b0\u649e\u98de\u884c\u4e2d\u7684\u8db3\u7403\uff09\u662f\u8db3\u7403\u6bd4\u8d5b\u4e2d\u5e38\u7528\u7684\u6280\u672f\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u5934\u7403\u8fc7\u7a0b\u4e2d\uff0c\u5934\u5bf9\u8db3\u7403\u7684\u529b\u6539\u53d8\u4e86\u8db3\u7403\u7684\u8fd0\u52a8\u72b6\u6001\nB. \u8db3\u7403\u88ab\u9876\u98de\uff0c\u662f\u56e0\u4e3a\u5934\u5bf9\u8db3\u7403\u7684\u529b\u5927\u4e8e\u8db3\u7403\u5bf9\u5934\u7684\u529b\nC. \u5934\u5bf9\u8db3\u7403\u7684\u4f5c\u7528\u529b\u6d88\u5931\u65f6\uff0c\u8db3\u7403\u7684\u60ef\u6027\u4e5f\u6d88\u5931\nD. \u8db3\u7403\u5728\u7a7a\u4e2d\u98de\u884c\u65f6\uff0c\u4ee5\u8fd0\u52a8\u5458\u4e3a\u53c2\u7167\u7269\uff0c\u8db3\u7403\u662f\u9759\u6b62\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.623940806542763, "itpossible/Chinese-Mistral-7B-v0.1": 0.39133442932588053, "HuggingFaceH4/zephyr-7b-beta": 0.9503475167770341, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7396843118045512, "meta-llama/Meta-Llama-3-8B": 0.37897240084120326, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.789285900874043}}, {"question": "\u81ea\u884c\u8f66\u7684\u5404\u4e2a\u90e8\u5206\u4e2d\uff0c\u51cf\u5c0f\u4e86\u6709\u5bb3\u6469\u64e6\u7684\u662f____\nA. \u8f66\u80ce\nB. \u8f66\u628a\nC. \u8f66\u8f74\nD. \u811a\u8e0f\u677f\u9762\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7145209307237649, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3744479663667915, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6334848184130204}}, {"question": "\u4e0b\u5217\u5b9e\u4f8b\u4e2d\u5173\u4e8e\u538b\u5f3a\u548c\u6469\u64e6\u529b\u7684\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u8f74\u627f\u4e2d\u88c5\u6709\u6eda\u73e0\u662f\u4e3a\u4e86\u589e\u5927\u6469\u64e6\nB. \u78c1\u60ac\u6d6e\u5217\u8f66\u60ac\u6d6e\u884c\u9a76\u662f\u4e3a\u4e86\u589e\u5927\u6469\u64e6\nC. \u9e1f\u7684\u5634\u5f88\u5c16\u7ec6\uff0c\u5728\u51ff\u6811\u65f6\u53ef\u4ee5\u51cf\u5c0f\u538b\u5f3a\nD. \u6708\u7403\u8f66\u88c5\u6709\u5f88\u591a\u8f6e\u5b50\u662f\u4e3a\u4e86\u51cf\u5c0f\u538b\u5f3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u4e8e\u9759\u6b62\u5728\u6c34\u5e73\u8f68\u9053\u4e0a\u7684\u201c\u590d\u5174\u53f7\u201d\u5217\u8f66\uff0c\u4e0b\u5217\u5206\u6790\u4e2d\u6b63\u786e\u7684\u662f____\nA. \u5217\u8f66\u6240\u53d7\u91cd\u529b\u548c\u5217\u8f66\u5bf9\u94c1\u8f68\u7684\u538b\u529b\u662f\u4e00\u5bf9\u76f8\u4e92\u4f5c\u7528\u529b\nB. \u5217\u519b\u6240\u53d7\u91cd\u529b\u548c\u94c1\u8f68\u5bf9\u5217\u8f66\u7684\u652f\u6301\u529b\u662f\u4e00\u5bf9\u76f8\u4e92\u4f5c\u7528\u529b\nC. \u5217\u8f66\u6240\u53d7\u91cd\u529b\u548c\u94c1\u8f68\u5bf9\u5217\u8f66\u7684\u652f\u6301\u529b\u662f\u4e00\u5bf9\u5e73\u8861\u529b\nD. \u5217\u8f66\u5bf9\u94c1\u8f68\u7684\u538b\u529b\u548c\u94c1\u8f68\u5bf9\u5217\u8f66\u7684\u652f\u6301\u529b\u662f\u4e00\u5bf9\u5e73\u8861\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3461131492142801, "meta-math/MetaMath-Mistral-7B": 0.6756017988346191, "itpossible/Chinese-Mistral-7B-v0.1": 0.29068935354339714, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4964649904232265, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u4e07\u7269\u751f\u957f\u9760\u592a\u9633\u201d\uff0c\u7eff\u8272\u690d\u7269\u7684\u751f\u957f\u9700\u8981\u9633\u5149\u3002\u7269\u7406\u5b66\u7814\u7a76\u8868\u660e\uff0c\u4e0d\u900f\u660e\u7269\u4f53\u7684\u989c\u8272\u662f\u7531\u5b83\u53cd\u5c04\u7684\u8272\u5149\u51b3\u5b9a\u7684\uff0c\u7531\u6b64\u53ef\u4ee5\u63a8\u6d4b\uff0c\u4e0d\u5229\u4e8e\u7eff\u8272\u690d\u7269\u751f\u957f\u7684\u5149\u662f____\nA. \u7ea2\u5149\nB. \u9ec4\u5149\nC. \u7eff\u5149\nD. \u7d2b\u5149\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6623504429703331, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8fc7\u7a0b\uff0c\u5c5e\u4e8e\u5185\u80fd\u8f6c\u5316\u4e3a\u673a\u68b0\u80fd\u7684\u662f____\nA. \u4ece\u6ed1\u68af\u4e0a\u6ed1\u4e0b\u65f6\u81c0\u90e8\u53d1\u70ed\nB. \u7535\u70ed\u6c34\u58f6\u70e7\u6c34\nC. \u5185\u71c3\u673a\u7684\u505a\u529f\u51b2\u7a0b\nD. \u5411\u4e0b\u538b\u6d3b\u585e\u5f15\u71c3\u68c9\u82b1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30736363908074527, "meta-math/MetaMath-Mistral-7B": 0.6187099353279804, "itpossible/Chinese-Mistral-7B-v0.1": 0.5436656961367015, "HuggingFaceH4/zephyr-7b-beta": 0.9785558545110498, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8154297114444802, "meta-llama/Meta-Llama-3-8B": 0.5590617288222927, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8983713078021076}}, {"question": "\u80fd\u89e3\u91ca\u201c\u5012\u5f71\u201d\u5f62\u6210\u7684\u662f____\nA. \u5149\u7684\u8272\u6563\nB. \u5149\u7684\u6298\u5c04\nC. \u5149\u7684\u53cd\u5c04\nD. \u5149\u7684\u76f4\u7ebf\u4f20\u64ad\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8695741589330065, "meta-math/MetaMath-Mistral-7B": 0.9899817197414535, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.999153996913531, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9521031374605519, "meta-llama/Meta-Llama-3-8B": 0.9581399452287989, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6484871190496735}}, {"question": "\u4e2d\u56fd\u56fd\u5bb6\u822a\u5929\u5c40\u5ba3\u5e03\uff0c2018\u5e745\u670821\u65e55\u65f628\u5206\uff0c\u6211\u56fd\u5728\u897f\u660c\u536b\u661f\u53d1\u5c04\u4e2d\u5fc3\u7528\u201c\u957f\u5f81\u56db\u53f7\u4e19\u201d\u8fd0\u8f7d\u706b\u7bad\uff0c\u6210\u529f\u5c06\u201c\u9e4a\u6865\u53f7\u201d\u4e2d\u7ee7\u661f\u53d1\u5c04\u5347\u7a7a\uff0c\u4e3a\u201c\u5ae6\u5a25\u56db\u53f7\u201d\u6708\u7403\u63a2\u6d4b\u4efb\u52a1\u63d0\u4f9b\u5730\u6708\u95f4\u7684\u4e2d\u7ee7\u901a\u4fe1\uff0c\u8d1f\u8d23\u5730\u7403\u4e0e\u672a\u6765\u201c\u5ae6\u5a25\u56db\u53f7\u201d\u901a\u4fe1\u7684\u4e2d\u7ee7\u63a5\u529b\u3002\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u4e2d\u7ee7\u661f\u4e0e\u5730\u6708\u95f4\u4e0d\u53ef\u80fd\u9760\u7535\u78c1\u6ce2\u901a\u4fe1\nB. \u5730\u7403\u548c\u592a\u9633\u7cfb\u4e2d\u7684\u5176\u4ed6\u884c\u661f\u8d77\u6e90\u4e8e\u4e0d\u540c\u7684\u661f\u4e91\nC. \u53d1\u5c04\u5f53\u5929\u5730\u7403\u8fd0\u884c\u5728\u7ed5\u592a\u9633\u516c\u8f6c\u8f68\u9053\u4e2d\u7684\u590f\u81f3\u4e0e\u79cb\u5206\u4e4b\u95f4\nD. \u6708\u7403\u7684\u81ea\u8f6c\u5468\u671f\u548c\u516c\u8f6c\u5468\u671f\u76f8\u540c\uff0c\u4eba\u7c7b\u53ea\u80fd\u770b\u5230\u6708\u7403\u7684\u6b63\u9762\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3040237055469986, "meta-math/MetaMath-Mistral-7B": 0.2906893535433972, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u751f\u6d3b\u5904\u5904\u6709\u7269\u7406\uff0c\u4ee5\u4e0b\u4f30\u6d4b\u6700\u63a5\u8fd1\u751f\u6d3b\u5b9e\u9645\u7684\u662f____\nA. \u5bbf\u8fc1\u516d\u6708\u4efd\u5e73\u5747\u6c14\u6e29\u7ea6\u4e3a10 \u00b0C\nB. \u521d\u4e2d\u751f\u80cc\u8d1f\u6c89\u91cd\u7684\u4e66\u5305\u4e0a\u5b66\uff0c\u4e66\u5305\u5e73\u5747\u91cd300 N\nC. \u521d\u4e2d\u751f\u8bfe\u684c\u9ad8\u5ea6\u7ea6\u4e3a75 cm\nD. \u4e2d\u8003\u4f53\u80b2\u8003\u8bd5\u4e2d\u67d0\u540c\u5b6650 m\u77ed\u8dd1\u6210\u7ee9\u7ea6\u4e3a4 s\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5835536469131417}}, {"question": "\u4e0b\u5217\u5b9e\u4f8b\u4e2d\uff0c\u5c5e\u4e8e\u589e\u5927\u6469\u64e6\u7684\u662f____\nA. \u5f80\u81ea\u884c\u8f66\u8f74\u627f\u4e2d\u52a0\u6da6\u6ed1\u6cb9\nB. \u884c\u674e\u7bb1\u4e0b\u5b89\u88c5\u6eda\u52a8\u8f6e\u5b50\nC. \u9a91\u81ea\u884c\u8f66\u5239\u8f66\u65f6\u7528\u529b\u634f\u95f8\nD. \u5c06\u6ed1\u68af\u7684\u6ed1\u9053\u505a\u5f97\u5149\u6ed1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.41951873699531794, "meta-math/MetaMath-Mistral-7B": 0.7781231374650592, "itpossible/Chinese-Mistral-7B-v0.1": 0.5567495354558331, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5538808795261961, "meta-llama/Meta-Llama-3-8B": 0.6126103831107214, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5089979070625381}}, {"question": "\u4e0b\u5217\u505a\u6cd5\u4e2d\uff0c\u7b26\u5408\u5b89\u5168\u7528\u7535\u539f\u5219\u7684\u662f____\nA. \u9ad8\u538b\u7ebf\u4e0b\u9493\u9c7c\nB. \u673a\u58f3\u6ca1\u6709\u63a5\u5730\nC. \u7edd\u7f18\u76ae\u7834\u635f\nD. \u5b89\u88c5\u907f\u96f7\u9488\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6355678838445145, "meta-math/MetaMath-Mistral-7B": 0.8579024055503794, "itpossible/Chinese-Mistral-7B-v0.1": 0.4430448286815293, "HuggingFaceH4/zephyr-7b-beta": 0.9011226106782569, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8588641427198804, "meta-llama/Meta-Llama-3-8B": 0.9601197618731752, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9894891566445384}}, {"question": "\u8d85\u5bfc\u73b0\u8c61\u662f\u6307\u67d0\u4e9b\u7269\u8d28\u5728\u6e29\u5ea6\u5f88\u4f4e\u65f6\u7535\u963b\u53d8\u4e3a\u96f6\u7684\u73b0\u8c61\u3002\u5982\u679c\u67d0\u79cd\u8d85\u5bfc\u6750\u6599\u80fd\u5e94\u7528\u4e8e\u5b9e\u9645\uff0c\u6700\u9002\u5408\u7528\u6765\u5236\u4f5c____\nA. \u4fdd\u9669\u4e1d\nB. \u8f93\u7535\u5bfc\u7ebf\nC. \u7535\u7089\u4e1d\nD. \u53d8\u963b\u5668\u7684\u7535\u963b\u4e1d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9098677022451003, "meta-math/MetaMath-Mistral-7B": 0.9945759794005368, "itpossible/Chinese-Mistral-7B-v0.1": 0.9653442832842895, "HuggingFaceH4/zephyr-7b-beta": 0.9996903501749106, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9922310442418901, "meta-llama/Meta-Llama-3-8B": 0.9448967597164087, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9940687521215444}}, {"question": "\u68d2\u7403\u6bd4\u8d5b\u65f6\uff0c\u5411\u659c\u4e0a\u65b9\u51fb\u7403\u65f6\u7684\u60c5\u666f\u4e2d\uff0c\u4e0b\u5217\u6709\u5173\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u51fb\u7403\u7684\u4e00\u77ac\u95f4\uff0c\u68d2\u5bf9\u7403\u7684\u529b\u5927\u4e8e\u7403\u5bf9\u68d2\u7684\u529b\nB. \u7403\u5728\u4e0a\u5347\u8fc7\u7a0b\u4e2d\uff0c\u91cd\u529b\u52bf\u80fd\u8f6c\u5316\u4e3a\u52a8\u80fd\nC. \u7403\u4e0a\u5347\u5230\u6700\u9ad8\u70b9\u65f6\uff0c\u82e5\u6240\u53d7\u529b\u5168\u90e8\u6d88\u5931\uff0c\u7403\u5c06\u505a\u51cf\u901f\u76f4\u7ebf\u8fd0\u52a8\nD. \u7403\u4e0b\u843d\u8fc7\u7a0b\u4e2d\u901f\u5ea6\u8d8a\u6765\u8d8a\u5927\uff0c\u56e0\u4e3a\u91cd\u529b\u6539\u53d8\u4e86\u7403\u7684\u8fd0\u52a8\u72b6\u6001\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u529b\u548c\u8fd0\u52a8\u7684\u8bf4\u6cd5\uff0c\u6b63\u786e\u7684\u662f____\nA. \u7269\u4f53\u8fd0\u52a8\u72b6\u6001\u53d1\u751f\u6539\u53d8\uff0c\u4e00\u5b9a\u53d7\u5230\u529b\u7684\u4f5c\u7528\nB. \u884c\u9a76\u7684\u6c7d\u8f66\u6025\u5239\u8f66\u65f6\uff0c\u4e58\u5ba2\u4f1a\u51fa\u73b0\u5411\u540e\u503e\u7684\u73b0\u8c61\nC. \u7528\u529b\u63a8\u684c\u5b50\uff0c\u684c\u5b50\u9759\u6b62\u4e0d\u52a8\uff0c\u56e0\u4e3a\u63a8\u529b\u5c0f\u4e8e\u6469\u64e6\u963b\u529b\nD. \u8e22\u51fa\u53bb\u7684\u8db3\u7403\u80fd\u5728\u7a7a\u4e2d\u98de\u884c\uff0c\u662f\u56e0\u4e3a\u8db3\u7403\u6ca1\u6709\u53d7\u5230\u529b\u7684\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4922767503043119, "meta-math/MetaMath-Mistral-7B": 0.5789938192052227, "itpossible/Chinese-Mistral-7B-v0.1": 0.4101473660506143, "HuggingFaceH4/zephyr-7b-beta": 0.8072686707598223, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5089979150675865, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5407528620082465}}, {"question": "\u58f0\u97f3\u53ef\u4ee5\u8868\u8fbe\u60c5\u611f\uff0c\u4f20\u9012\u4fe1\u606f\uff0c\u5bf9\u4e8e\u58f0\u73b0\u8c61\u7684\u7406\u89e3\u6b63\u786e\u7684\u662f____\nA. \u6559\u5e08\u8bb2\u8bfe\u7684\u58f0\u97f3\u662f\u7531\u58f0\u5e26\u632f\u52a8\u4ea7\u751f\u7684\nB. \u201c\u9759\u6b62\u9e23\u7b1b\u201d\u662f\u5728\u4f20\u64ad\u8fc7\u7a0b\u4e2d\u51cf\u5f31\u566a\u97f3\nC. \u58f0\u97f3\u7684\u632f\u5e45\u8d8a\u5927\uff0c\u97f3\u8c03\u8d8a\u9ad8\nD. \u53ea\u8981\u7269\u4f53\u5728\u632f\u52a8\uff0c\u6211\u4eec\u5c31\u80fd\u542c\u5230\u58f0\u97f3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3079967554453033, "meta-math/MetaMath-Mistral-7B": 0.32473768334465647, "itpossible/Chinese-Mistral-7B-v0.1": 0.4828014249941028, "HuggingFaceH4/zephyr-7b-beta": 0.8378200787427456, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.713129323873155, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7684312327986105}}, {"question": "\u4e3a\u52a0\u5f3a\u6821\u56ed\u5b89\u5168\u7ba1\u7406\uff0c\u5728\u6821\u5185\u5b89\u88c5\u76d1\u63a7\u6444\u50cf\u673a\uff0c\u6765\u81ea\u7269\u4f53\u7684\u5149\u7ecf\u8fc7\u6444\u50cf\u673a\u7684\u955c\u5934\u540e\u5f62\u6210____\nA. \u5012\u7acb\u3001\u7f29\u5c0f\u7684\u5b9e\u50cf\nB. \u6b63\u7acb\u3001\u653e\u5927\u7684\u5b9e\u50cf\nC. \u5012\u7acb\u3001\u653e\u5927\u7684\u865a\u50cf\nD. \u6b63\u7acb\u3001\u7f29\u5c0f\u7684\u865a\u50cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7269\u8d28\u7684\u6027\u8d28\u51b3\u5b9a\u7269\u8d28\u7684\u7528\u9014\uff0c\u4e0b\u5217\u7269\u8d28\u7684\u7528\u9014\u4e0e\u5316\u5b66\u6027\u8d28\u76f8\u5173\u7684\u662f____\nA. \u94dc\u4e1d\u7528\u4f5c\u5bfc\u7ebf\nB. \u91d1\u521a\u77f3\u7528\u4e8e\u5207\u5272\u73bb\u7483\nC. \u5e72\u51b0\u7528\u4e8e\u4eba\u5de5\u964d\u96e8\nD. \u719f\u77f3\u7070\u7528\u4e8e\u6539\u826f\u9178\u6027\u571f\u58e4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3967757634198264, "meta-math/MetaMath-Mistral-7B": 0.4125232597554662, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9681887719629538, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.882970884240498, "meta-llama/Meta-Llama-3-8B": 0.8344542072388647, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5806709267888635}}, {"question": "\u5316\u5b66\u4e0e\u751f\u4ea7\u3001\u751f\u6d3b\u5bc6\u5207\u76f8\u5173\uff0c\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u4eba\u4f53\u7f3a\u7898\u4f1a\u5f15\u8d77\u8d2b\u8840\nB. \u78b3\u9178\u6c22\u94f5\uff08$NH_4HCO_3$\uff09\u662f\u4e00\u79cd\u6c2e\u80a5\nC. \u7092\u83dc\u65f6\u6cb9\u9505\u7740\u706b\uff0c\u7528\u9505\u76d6\u76d6\u706d\nD. \u94c1\u5236\u54c1\u8868\u9762\u5237\u6f06\u53ef\u9632\u6b62\u751f\u9508\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7a7a\u6c14\u662f\u4eba\u7c7b\u751f\u5b58\u6240\u5fc5\u9700\u7684\u91cd\u8981\u8d44\u6e90\uff0c\u7a7a\u6c14\u4e2d\u6700\u591a\u7684\u6c14\u4f53\u662f____\nA. $\\text{N}_2$\nB. $\\text{O}_2$\nC. $\\text{CO}_2$\nD. $\\text{H}_2 \\text{O}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9976720712118121, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5017688075787022, "meta-llama/Meta-Llama-3-8B": 0.8631693718840275, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9394120185800694}}, {"question": "\u63a8\u7406\u662f\u5b66\u4e60\u5316\u5b66\u7684\u91cd\u8981\u65b9\u6cd5\u4e4b\u4e00\uff0c\u4f46\u76f2\u76ee\u5730\u7c7b\u6467\u53c8\u53ef\u80fd\u5f97\u51fa\u9519\u8bef\u7ed3\u8bba\u3002\u4e0b\u5217\u7c7b\u63a8\u6b63\u786e\u7684\u662f____\nA. \u786b\u548c\u6c27\u6c14\u7684\u53cd\u5e94\u65e2\u662f\u6c27\u5316\u53cd\u5e94\u4e5f\u662f\u5316\u5408\u53cd\u5e94\uff0c\u5219\u7269\u8d28\u548c\u6c27\u6c14\u7684\u53cd\u5e94\u5747\u662f\u5316\u5408\u53cd\u5e94\nB. \u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u5408\u91d1\u7684\u7194\u70b9\u548c\u786c\u5ea6\u90fd\u6bd4\u7ec4\u6210\u5408\u91d1\u7684\u7eaf\u91d1\u5c5e\u7684\u9ad8\nC. \u78b1\u7684\u6eb6\u6db2\u80fd\u4f7f\u915a\u915e\u6eb6\u6db2\u53d8\u7ea2\uff0c\u4f46\u80fd\u4f7f\u915a\u915e\u6eb6\u6db2\u53d8\u7ea2\u7684\u6eb6\u6db2\u4e0d\u4e00\u5b9a\u662f\u78b1\u7684\u6eb6\u6db2\nD. \u950c\u80fd\u4e0e\u7a00\u786b\u9178\u53cd\u5e94\u653e\u51fa\u6c22\u6c14\uff0c\u5219\u94dc\u4e5f\u80fd\u4e0e\u7a00\u786b\u9178\u53cd\u5e94\u653e\u51fa\u6c22\u6c14\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37057701774160007, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.31483005318115603, "HuggingFaceH4/zephyr-7b-beta": 0.5926223081310921, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7011919794344413, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8771356317667603}}, {"question": "2022\u5e742\u67084\u65e5\uff0c\u5317\u4eac\u51ac\u5965\u4f1a\u706b\u70ac\u9996\u6b21\u91c7\u7528\u201c\u7eff\u6c22\u201d\u4f5c\u4e3a\u706b\u70ac\u71c3\u6599\uff0c\u5176\u50a8\u5b58\u91c7\u7528\u4e86\u9ad8\u538b\u50a8\u6c14\u7684\u65b9\u5f0f\u3002\u4e0b\u5217\u5173\u4e8e\u8be5\u50a8\u6c14\u8fc7\u7a0b\u7684\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u6c22\u5206\u5b50\u7684\u4f53\u79ef\u53d8\u5c0f\nB. \u6c22\u5206\u5b50\u7684\u8d28\u91cf\u53d8\u5c0f\nC. \u6c22\u5206\u5b50\u7684\u6570\u76ee\u53d8\u5c11\nD. \u6c22\u5206\u5b50\u95f4\u7684\u95f4\u9694\u53d8\u5c0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5816750657552481, "itpossible/Chinese-Mistral-7B-v0.1": 0.31483005318115603, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.43507648098819773, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8184174290457145}}, {"question": "\u5316\u5b66\u4e0e\u73af\u5883\u4fdd\u62a4\u3001\u4eba\u4f53\u952e\u5eb7\u606f\u606f\u76f8\u5173\u3002\u4e0b\u5217\u53d9\u8ff0\u9519\u8bef\u7684\u662f____\nA. \u5929\u7136\u6c14\u662f\u6bd4\u8f83\u6e05\u6d01\u7684\u5316\u77f3\u71c3\u6599\nB. \u7814\u53d1\u9ad8\u6548\u4f4e\u6bd2\u519c\u836f\u6709\u52a9\u4e8e\u4fdd\u969c\u7cae\u98df\u5b89\u5168\nC. \u751f\u6d3b\u6c61\u6c34\u96c6\u4e2d\u5904\u7406\u8fbe\u6807\u540e\u6392\u653e\nD. \u84b8\u716e\u80fd\u5b8c\u5168\u6e05\u9664\u9709\u53d8\u98df\u7269\u4e2d\u7684\u6709\u5bb3\u7269\u8d28\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6509986146396184, "meta-math/MetaMath-Mistral-7B": 0.921166165185467, "itpossible/Chinese-Mistral-7B-v0.1": 0.6027603439651981, "HuggingFaceH4/zephyr-7b-beta": 0.9997859307289378, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9666742135527511, "meta-llama/Meta-Llama-3-8B": 0.6061547765489288, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6304843970759716}}, {"question": "2022\u5e746\u67085\u65e5\u662f\u7b2c51\u4e2a\u4e16\u754c\u73af\u5883\u65e5\uff0c\u4e2d\u56fd\u4e3b\u9898\u4e3a\u201c\u5171\u5efa\u6e05\u6d01\u7f8e\u4e3d\u4e16\u754c\u201d\uff0c\u4e0b\u5217\u63aa\u65bd\u4e0e\u8be5\u4e3b\u9898\u4e0d\u76f8\u7b26\u7684\u662f____\nA. \u7eff\u8272\u51fa\u884c\uff0c\u79ef\u6781\u8df5\u884c\u201c\u4f4e\u78b3\u751f\u6d3b\u201d\nB. \u7528\u5e03\u888b\u4ee3\u66ff\u5851\u6599\u888b\uff0c\u51cf\u5c11\u201c\u767d\u8272\u6c61\u67d3\u201d\nC. \u690d\u6811\u9020\u6797\uff0c\u52aa\u529b\u8425\u9020\u201c\u7eff\u6c34\u9752\u5c71\u201d\nD. \u5927\u91cf\u5f00\u91c7\u5229\u7528\u5316\u77f3\u71c3\u6599\uff0c\u7f13\u89e3\u201c\u80fd\u6e90\u5371\u673a\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9779945748226286, "meta-math/MetaMath-Mistral-7B": 0.9977587893027076, "itpossible/Chinese-Mistral-7B-v0.1": 0.9883779774227056, "HuggingFaceH4/zephyr-7b-beta": 0.9999842311039975, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9996252382445034, "meta-llama/Meta-Llama-3-8B": 0.9493663016429054, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9633202945461159}}, {"question": "\u4e0b\u5217\u6210\u8bed\u4e2d\u4e0d\u6d89\u53ca\u5316\u5b66\u53d8\u5316\u7684\u662f____\nA. \u661f\u706b\u71ce\u539f\nB. \u62ab\u8346\u65a9\u68d8\nC. \u6b7b\u7070\u590d\u71c3\nD. \u767e\u70bc\u6210\u94a2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37170378917573094, "meta-math/MetaMath-Mistral-7B": 0.5473827549186275, "itpossible/Chinese-Mistral-7B-v0.1": 0.5265984790634276, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7240196738488613, "meta-llama/Meta-Llama-3-8B": 0.6837774440531145, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7488321102945614}}, {"question": "\u903b\u8f91\u63a8\u7406\u662f\u5b66\u4e60\u5316\u5b66\u5e38\u7528\u7684\u601d\u7ef4\u65b9\u6cd5\uff0c\u4e0b\u5217\u63a8\u7406\u6b63\u786e\u7684\u662f____\nA. \u7269\u8d28\u71c3\u70e7\u90fd\u80fd\u653e\u70ed\uff0c\u80fd\u653e\u70ed\u7684\u5316\u5b66\u53cd\u5e94\u90fd\u662f\u71c3\u70e7\nB. \u6709\u673a\u5316\u5408\u7269\u90fd\u542b\u6709\u78b3\u5143\u7d20\uff0c\u5219\u542b\u6709\u78b3\u5143\u7d20\u7684\u5316\u5408\u7269\u90fd\u662f\u6709\u673a\u7269\nC. \u78b1\u6027\u6eb6\u6db2\u53ef\u4ee5\u4f7f\u77f3\u854a\u6eb6\u6db2\u53d8\u84dd\uff0c\u5219\u80fd\u4f7f\u77f3\u854a\u6eb6\u6db2\u53d8\u84dd\u7684\u6eb6\u6db2\u90fd\u663e\u78b1\u6027\nD. \u4e2d\u548c\u53cd\u5e94\u751f\u6210\u76d0\u548c\u6c34\uff0c\u5219\u751f\u6210\u76d0\u548c\u6c34\u7684\u53cd\u5e94\u90fd\u662f\u4e2d\u548c\u53cd\u5e94\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.31851505670204755, "meta-math/MetaMath-Mistral-7B": 0.43871174352757186, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9955097962506874, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.34182412994643, "meta-llama/Meta-Llama-3-8B": 0.34239623393788804, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7958788403246653}}, {"question": "$Na_2CO_3$\u4fd7\u79f0\u7eaf\u78b1\uff0c\u4faf\u5fb7\u699c\u4e3a\u7eaf\u78b1\u5de5\u4e1a\u7684\u53d1\u5c55\u505a\u51fa\u4e86\u6770\u51fa\u8d21\u732e\u3002$Na_2CO_3$\u5c5e\u4e8e____\nA. \u6c27\u5316\u7269\nB. \u76d0\nC. \u6709\u673a\u7269\nD. \u6df7\u5408\u7269\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4627525367278995, "meta-math/MetaMath-Mistral-7B": 0.541655424851048, "itpossible/Chinese-Mistral-7B-v0.1": 0.7781231168838703, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8898774599491392, "meta-llama/Meta-Llama-3-8B": 0.7901157302156807, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9751038664870425}}, {"question": "\u4e0b\u5217\u6709\u5173\u6eb6\u6db2\u7684\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u5747\u4e00\u3001\u7a33\u5b9a\u7684\u6db2\u4f53\u4e00\u5b9a\u662f\u6eb6\u6db2\nB. \u6d17\u6da4\u5242\u80fd\u6d17\u53bb\u8863\u670d\u4e0a\u7684\u6cb9\u6c61\uff0c\u539f\u56e0\u662f\u6d17\u6da4\u5242\u5177\u6709\u6eb6\u89e3\u4f5c\u7528\nC. \u6eb6\u6db2\u4e2d\u7684\u6eb6\u8d28\u53ef\u4ee5\u662f\u56fa\u4f53\u3001\u6db2\u4f53\u6216\u6c14\u4f53\nD. \u5b9e\u9a8c\u5ba4\u5229\u7528\u6c2f\u5316\u94a0\u56fa\u4f53\u548c\u6c34\u914d\u523650g\u8d28\u91cf\u5206\u6570\u4e3a6%\u7684\u6c2f\u5316\u94a0\u6eb6\u6db2\u7684\u6b65\u9aa4\u662f\uff1a\u8ba1\u7b97\u3001\u91cf\u53d6\u3001\u6eb6\u89e3\u3001\u8d2e\u5b58\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0.9932379039201936, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4921435359265435, "meta-llama/Meta-Llama-3-8B": 0.45751604600647444, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.44304358184070847}}, {"question": "\u5c06100mL\u6c34\u4e0e100mL\u9152\u7cbe\u6df7\u5408\uff0c\u6240\u5f97\u6eb6\u6db2\u4f53\u79ef\u5c0f\u4e8e200mL\u3002\u4e0b\u5217\u5bf9\u6b64\u73b0\u8c61\u7684\u89e3\u91ca\u6700\u5408\u7406\u7684\u662f____\nA. \u5206\u5b50\u662f\u7531\u539f\u5b50\u6784\u6210\u7684\nB. \u5206\u5b50\u7684\u8d28\u91cf\u548c\u4f53\u79ef\u90fd\u662f\u5f88\u5c0f\u7684\nC. \u5206\u5b50\u662f\u4e0d\u65ad\u8fd0\u52a8\u7684\nD. \u5206\u5b50\u95f4\u662f\u6709\u95f4\u9694\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8070396837483131, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u540c\u5b66\u7528pH\u8ba1\u6d4b\u5f97\u751f\u6d3b\u4e2d\u4e00\u4e9b\u7269\u8d28\u7684pH\u503c\u5982\u4e0b\u3001\u5176\u4e2d\u9178\u6027\u6700\u5f3a\u7684\u662f____\nA. \u80a5\u7682\u6c34pH\uff1a10.2\nB. \u6599\u9152pH\uff1a6.5\nC. \u897f\u74dc\u6c41pH\uff1a5.8\nD. \u82f9\u679c\u6c41pH\uff1a2.4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6004460910189735, "meta-math/MetaMath-Mistral-7B": 0.8149384824722902, "itpossible/Chinese-Mistral-7B-v0.1": 0.8407843221576724, "HuggingFaceH4/zephyr-7b-beta": 0.9977940651244053, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9505501668679419, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9970145556974186}}, {"question": "\u4e3a\u4e86\u63a2\u7a76\u67d0\u7a00\u76d0\u9178\u4e2d\u6eb6\u8d28\u7684\u8d28\u91cf\u5206\u6570\uff0c\u7532\u3001\u4e59\u4e24\u540c\u5b66\u5206\u522b\u53d6\u6eb6\u8d28\u8d28\u91cf\u5206\u6570\u76f8\u7b49\u7684\u7a00\u76d0\u9178100g\uff0c\u7532\u540c\u5b66\u5411\u5176\u4e2d\u52a0\u5165\u6c27\u5316\u94dc8g\uff0c\u53cd\u5e94\u7ed3\u675f\u540e\u89c2\u5bdf\u5230\u56fa\u4f53\u5168\u90e8\u6d88\u5931\uff1b\u4e59\u540c\u5b66\u5411\u5176\u4e2d\u52a0\u5165\u6c27\u5316\u94dc16g\uff0c\u53cd\u5e94\u7ed3\u675f\u540e\u89c2\u5bdf\u5230\u56fa\u4f53\u6709\u5269\u4f59\u3002\u4e0b\u5217\u6709\u5173\u5b9e\u9a8c\u7684\u63a8\u65ad\u6b63\u786e\u7684\u662f____\nA. \u53cd\u5e94\u540e\u4e59\u540c\u5b66\u6240\u5f97\u6eb6\u6db2\u4e2d\u4e00\u5b9a\u5305\u542b\u76d0\u9178\nB. \u53cd\u5e94\u540e\u5411\u7532\u540c\u5b66\u6240\u5f97\u7684\u6eb6\u6db2\u4e2d\u6ef4\u52a0\u5c11\u91cf\u6c22\u6c27\u5316\u94a0\u6eb6\u6db2\uff0c\u4e00\u5b9a\u4f1a\u6709\u84dd\u8272\u6c89\u6dc0\u751f\u6210\nC. \u53cd\u5e94\u540e\u7532\u3001\u4e59\u4e24\u540c\u5b66\u6240\u5f97\u7684\u6eb6\u6db2\u4e2d\u6eb6\u8d28\u7684\u8d28\u91cf\u5206\u6570\u53ef\u80fd\u76f8\u7b49\nD. \u539f\u7a00\u76d0\u9178\u4e2d\u6eb6\u8d28\u7684\u8d28\u91cf\u5206\u6570\u4e00\u5b9a\u5927\u4e8e7.3%\u5c0f\u4e8e14.6%\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.491439829767676, "meta-llama/Meta-Llama-3-8B": 0.31649016643535544, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6057240717941538}}, {"question": "\u5783\u573e\u5206\u7c7b\u5df2\u6210\u4e3a\u65b0\u65f6\u5c1a\u3002\u4e0b\u5217\u7269\u8d28\u5e94\u8be5\u653e\u5165\u53ef\u56de\u6536\u5783\u573e\u7bb1\u7684\u662f____\nA. \u77ff\u6cc9\u6c34\u74f6\nB. \u679c\u76ae\nC. \u5e9f\u7535\u6c60\nD. \u5e9f\u53e3\u7f69\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.9283914969060516, "itpossible/Chinese-Mistral-7B-v0.1": 0.6366933617806214, "HuggingFaceH4/zephyr-7b-beta": 0.993543684731808, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9774934738079163, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u75ab\u60c5\u671f\u95f4\uff0c\u6559\u5ba4\u55b7\u6d12\u201c84\u6d88\u6bd2\u6db2\u201d\u8fdb\u884c\u6d88\u6bd2\u65f6\uff0c\u53ef\u95fb\u5230\u523a\u9f3b\u7684\u6c14\u5473\uff0c\u8bf4\u660e\u4e86____\nA. \u5206\u5b50\u6570\u76ee\u53d8\u5927\nB. \u5206\u5b50\u4e4b\u95f4\u6709\u95f4\u9694\nC. \u5206\u5b50\u5728\u4e0d\u65ad\u8fd0\u52a8\nD. \u53cd\u5e94\u751f\u6210\u65b0\u7269\u8d28\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37179718365712183, "meta-math/MetaMath-Mistral-7B": 0.7963047843108825, "itpossible/Chinese-Mistral-7B-v0.1": 0.371068906204966, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6481865476294665, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5316\u5b66\u7528\u8bed\u65e2\u80fd\u8868\u793a\u4e00\u79cd\u5143\u7d20\uff0c\u53c8\u80fd\u8868\u793a\u4e00\u4e2a\u539f\u5b50\uff0c\u8fd8\u80fd\u8868\u793a\u4e00\u79cd\u7269\u8d28\u7684\u662f____\nA. O\nB. Cu\nC. N\nD. $CO_2$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3331832353540621, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u7092\u83dc\u65f6\u6cb9\u9505\u4e2d\u7684\u6cb9\u4e0d\u614e\u7740\u706b\uff0c\u53ef\u7528\u9505\u76d6\u76d6\u706d\nB. \u5ba4\u5185\u7740\u706b\uff0c\u5e94\u7acb\u5373\u6253\u5f00\u95e8\u7a97\uff0c\u8ba9\u98ce\u5439\u706d\u706b\u7130\nC. \u4e9a\u785d\u9178\u94a0\u662f\u4e00\u79cd\u5de5\u4e1a\u7528\u76d0\uff0c\u5bf9\u4eba\u4f53\u6709\u5bb3\uff0c\u4e0d\u80fd\u7528\u4e8e\u70f9\u8c03\nD. \u5bb6\u7528\u7164\u6c14\u4e2d\u63ba\u5165\u5fae\u91cf\u96be\u95fb\u6027\u6c14\u4f53\uff0c\u5229\u4e8e\u53d1\u73b0\u7164\u6c14\u6cc4\u6f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.43921757655972987, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.47255279236616415}}, {"question": "\u6cbb\u7597\u80c3\u9178\u8fc7\u591a\u836f\u7269\u94dd\u78b3\u9178\u9541\u7247[\u4e3b\u8981\u6210\u5206$Al_2Mg_6(OH)_{16}CO_3\u00b74H_2O$]\u4e0d\u80fd\u957f\u671f\u670d\u7528\uff0c\u662f\u56e0\u4e3a\u5176\u4e2d\u542b\u6709\u4eba\u4f53\u975e\u5fc5\u9700\u5143\u7d20____\nA. Mg\nB. Hg\nC. C\nD. Al\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3893872971790877, "meta-math/MetaMath-Mistral-7B": 0.4114752894671105, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6537251587289165, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4382091167752509, "meta-llama/Meta-Llama-3-8B": 0.48280111371476736, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u73b0\u8c61\u7684\u5fae\u89c2\u89e3\u91ca\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u98df\u7269\u8150\u8d25----\u5206\u5b50\u6027\u8d28\u53d1\u751f\u53d8\u5316\nB. \u70ed\u80c0\u51b7\u7f29----\u5206\u5b50\u5927\u5c0f\u968f\u6e29\u5ea6\u53d8\u5316\u800c\u53d8\u5316\nC. \u590f\u5929\u708e\u70ed\uff0c\u81ea\u884c\u8f66\u6613\u7206\u80ce-----\u6e29\u5ea6\u5347\u9ad8\uff0c\u5206\u5b50\u95f4\u7684\u95f4\u9694\u53d8\u5927\nD. \u7f09\u6bd2\u72ac\u53ef\u4ee5\u55c5\u51fa\u6bd2\u54c1\u85cf\u533f\u5904----\u5206\u5b50\u4e0d\u505c\u5730\u8fd0\u52a8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.38812073416459414, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3348234986789106, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u65e2\u5728\u7cd6\u9175\u89e3\u53c8\u5728\u8461\u8404\u7cd6\u5f02\u751f\u4f5c\u7528\u4e2d\u8d77\u4f5c\u7528\u3002\nA. \u4e19\u916e\u9178\u6fc0\u9176\nB. 3-\u78f7\u9178\u7518\u6cb9\u919b\u8131\u6c22\u9176\nC. 1\uff0c6-\u4e8c\u78f7\u9178\u679c\u7cd6\u6fc0\u9176\nD. \u5df1\u7cd6\u6fc0\u9176\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4716472028482283, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5c06RNA\u8f6c\u79fb\u5230\u785d\u57fa\u7ea4\u7ef4\u7d20\u819c\u4e0a\u7684\u6280\u672f\u53eb____\u3002\nA. Southern\u5370\u8ff9\nB. Northern\u5370\u8ff9\nC. Western\u5370\u8ff9\nD. Eastern\u5370\u8ff9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9135858910573752, "meta-math/MetaMath-Mistral-7B": 0.8494076256833796, "itpossible/Chinese-Mistral-7B-v0.1": 0.7034389634182221, "HuggingFaceH4/zephyr-7b-beta": 0.6240341789206619, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.78520346760363, "meta-llama/Meta-Llama-3-8B": 0.6694837696039038, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u4e0d\u662f\u86cb\u767d\u8d28\u7684\u6027\u8d28\u4e4b\u4e00\u3002\nA. \u5904\u4e8e\u7b49\u7535\u72b6\u6001\u65f6\u6eb6\u89e3\u5ea6\u6700\u5c0f\nB. \u52a0\u5165\u5c11\u91cf\u4e2d\u6027\u76d0\u6eb6\u89e3\u5ea6\u589e\u52a0\nC. \u53d8\u6027\u86cb\u767d\u8d28\u7684\u6eb6\u89e3\u5ea6\u589e\u52a0\nD. \u6709\u7d2b\u5916\u5438\u6536\u7279\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u9176\u7684\u5206\u79bb\u7eaf\u5316\u4e2d\u6700\u7406\u60f3\u7684\u5b9e\u9a8c\u7ed3\u679c\u662f____\u3002\nA. \u7eaf\u5316\u500d\u6570\u9ad8\uff0c\u56de\u6536\u7387\u9ad8\nB. \u86cb\u767d\u56de\u6536\u7387\u9ad8\nC. \u56de\u6536\u7387\u5c0f\uff0c\u4f46\u7eaf\u5316\u500d\u6570\u9ad8\nD. \u6bd4\u6d3b\u529b\u6700\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.47913318913140934, "meta-math/MetaMath-Mistral-7B": 0.6581115979618184, "itpossible/Chinese-Mistral-7B-v0.1": 0.34966087665839624, "HuggingFaceH4/zephyr-7b-beta": 0.9999316109400734, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8303532334450795, "meta-llama/Meta-Llama-3-8B": 0.4097932893567426, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8929821644080714}}, {"question": "\u52a8\u7269\u4f53\u5185\u7ec4\u6210\u7684\u5316\u5b66\u5143\u7d20\u4e2d\uff0c\u4e0b\u5217\u6240\u5360\u6bd4\u4f8b\u6700\u591a\u7684\u662f____\nA. \u78b3\nB. \u6c2f\nC. \u94a0\nD. \u6c22\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8057023956410538, "meta-math/MetaMath-Mistral-7B": 0.9782443905218732, "itpossible/Chinese-Mistral-7B-v0.1": 0.45607757413101757, "HuggingFaceH4/zephyr-7b-beta": 0.9558378635460628, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8158315381001126, "meta-llama/Meta-Llama-3-8B": 0.7740800359650163, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8211365017014532}}, {"question": "\u9176\u7684\u50ac\u5316\u7279\u70b9\u4e0d\u5177\u6709____\nA. \u9ad8\u6548\u6027\nB. \u591a\u529f\u80fd\u6027\nC. \u53ef\u8c03\u8282\u6027\nD. \u9176\u86cb\u767d\u6613\u53d8\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u751f\u7269\u7d20\u662f____\u7684\u8f85\u9176\u3002\nA. \u4e19\u916e\u9178\u8131\u6c22\u9176\nB. \u4e19\u916e\u9178\u6fc0\u9176\nC. \u4e19\u916e\u9178\u8131\u6c22\u9176\u7cfb\nD. \u4e19\u916e\u9178\u7fa7\u5316\u9176\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u86cb\u767d\u8d28\u4e0d\u80fd\u5438\u6536\u53ef\u89c1\u5149\uff0c\u4f46\u80fd\u5438\u6536\u4e00\u5b9a\u6ce2\u957f\u8303\u56f4\u5185\u7684\u7d2b\u5916\u5149\u3002\u5927\u591a\u6570\u86cb\u767d\u8d28\u5728280nm\u6ce2\u957f\u9644\u8fd1\u6709\u4e00\u4e2a\u5438\u6536\u5cf0\uff0c\u8fd9\u4e3b\u8981\u4e0e\u86cb\u767d\u8d28\u4e2d____\u7684\u7d2b\u5916\u5438\u6536\u6709\u5173\u3002\u56e0\u6b64\uff0c\u53ef\u4ee5\u5229\u7528\u7d2b\u5916\u5438\u6536\u6cd5\uff0c\u6839\u636e\u86cb\u767d\u8d28\u6eb6\u6db2\u5728280nm\u6ce2\u957f\u7684\u5438\u6536\u503c\u6d4b\u5b9a\u86cb\u767d\u8d28\u6d53\u5ea6\nA. \u78b1\u6027\u6c28\u57fa\u9178\nB. \u9178\u6027\u6c28\u57fa\u9178\nC. \u542b\u786b\u6c28\u57fa\u9178\nD. \u82b3\u9999\u65cf\u6c28\u57fa\u9178\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6715164484818853, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.32205625344145955, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u51775 \" -CpGpGpTpAp-3 \" \u987a\u5e8f\u7684\u5355\u94feDNA\u80fd\u4e0e\u4e0b\u5217____RNA\u6742\u4ea4\nA. 5 \" -GpCpCpApTp3 \"\nB. 5 \" -GpCpCpUp-3 \"\nC. 5 \" -UpApCpCpGp-3 \"\nD. 5 \" -TpApCpGp-3 \"\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2986334267609957, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9176\u7684\u975e\u7ade\u4e89\u6027\u6291\u5236\u5242\u5bf9\u9176\u4fc3\u53cd\u5e94\u7684\u5f71\u54cd\u662f____\u3002\nA. $\u03bd_{max}$ \u4e0d\u53d8\uff0c$K_m$ \u589e\u5927\nB. $\u03bd_{max}$\u4e0d\u53d8\uff0c$K_m$\u51cf\u5c0f\nC. $\u03bd_{max}$\u589e\u5927\uff0c$K_m$\u4e0d\u53d8\nD. $\u03bd_{max}$\u51cf\u5c0f\uff0c$K_m$\u4e0d\u53d8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c34\u6eb6\u6027\u7ef4\u751f\u7d20\u5e38\u662f\u8f85\u9176\u6216\u8f85\u57fa\u7684\u7ec4\u6210\u90e8\u5206\uff0c\u5982____\u3002\nA. \u8f85\u9176A\u542b\u5c3c\u514b\u9170\u80fa\nB. FAD\u542b\u6709\u5421\u54c6\u919b\nC. $FH_4$ \u542b\u6709\u53f6\u9178\nD. \u8131\u7fa7\u8f85\u9176\u542b\u751f\u7269\u7d20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4124578920239483, "HuggingFaceH4/zephyr-7b-beta": 0.9963850863335393, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6838\u9178\u53d8\u6027\u540e\uff0c\u53ef\u53d1\u751f\u7684\u6548\u5e94\u662f____\u3002\nA. \u51cf\u8272\u6548\u5e94\nB. \u589e\u8272\u6548\u5e94\nC. \u5931\u53bb\u5bf9\u7d2b\u5916\u7ebf\u7684\u5438\u6536\u80fd\u529b\nD. \u6700\u5927\u5438\u6536\u5cf0\u6ce2\u957f\u53d1\u751f\u8f6c\u79fb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4412339898974871, "meta-math/MetaMath-Mistral-7B": 0.8291812106433964, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.31292412440670775, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217____\u4e0d\u662f\u7ec8\u6b62\u5bc6\u7801\u3002\nA. UAA\nB. 15AC\nC. UAG\nD. UGA\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6616658144337598, "meta-math/MetaMath-Mistral-7B": 0.8364400333937783, "itpossible/Chinese-Mistral-7B-v0.1": 0.46589231241240625, "HuggingFaceH4/zephyr-7b-beta": 0.9600967606161952, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9516925377610295, "meta-llama/Meta-Llama-3-8B": 0.7078945174106756, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9151959885469906}}, {"question": "\u5173\u4e8e\u9176\u5076\u8054\u53d7\u4f53\u7684\u53d9\u8ff0\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u9176\u5076\u8054\u53d7\u4f53\u5c5e\u4e8e\u7ec6\u80de\u8868\u9762\u53d7\u4f53\nB. \u9176\u5076\u8054\u53d7\u4f53\u7684\u914d\u4f53\u7ed3\u5408\u533a\u5728\u7ec6\u80de\u819c\u5185\u4fa7\uff0c\u9176\u6d3b\u6027\u533a\u5728\u7ec6\u80de\u819c\u5916\u4fa7\nC. \u9176\u5076\u8054\u53d7\u4f53\u4ecb\u5bfc\u7684\u662f\u975e\u7ecf\u5178\u8de8\u8d28\u819c\u4e0e\u80de\u5185\u4fe1\u53f7\u9014\u5f84\uff0c\u53ef\u4ee5\u5355\u72ec\u5b8c\u6210\u4fe1\u53f7\u4f20\u9012\uff0c\u80de\u5185\u4fe1\u53f7\u4f20\u9012\u4e0d\u4ea7\u751f\u7ecf\u5178\u610f\u4e49\u4e0a\u7684\u7b2c\u4e8c\u4fe1\u4f7f\nD. \u591a\u6570\u9176\u5076\u8054\u53d7\u4f53\u5177\u6709\u78f7\u9178\u5316\u9176\u7684\u6d3b\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e3b\u8981\u5206\u5e03\u5728\u809d\u810f\u7684\u662f____\u3002\nA. \u78b1\u6027\u78f7\u9178\u9176\nB. \u9178\u6027\u78f7\u9178\u9176\nC. \u5355\u80fa\u6c27\u5316\u9176\nD. \u8c37\u4e19\u8f6c\u6c28\u9176\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3248694388439252, "HuggingFaceH4/zephyr-7b-beta": 0.7102142109023082, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9DNA\u7247\u6bb5\u4f5c\u7269\u7406\u56fe\u8c31\u5206\u6790\uff0c\u9700\u8981\u7528____\u3002\nA. \u6838\u9178\u5916\u5207\u9176\nB. DNAseI\nC. \u9650\u5236\u6027\u5185\u5207\u9176\nD. DNA\u805a\u5408\u9176I\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6002222106648862, "meta-math/MetaMath-Mistral-7B": 0.8710900333528325, "itpossible/Chinese-Mistral-7B-v0.1": 0.4734044326799291, "HuggingFaceH4/zephyr-7b-beta": 0.8781785286402336, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7393069891363212, "meta-llama/Meta-Llama-3-8B": 0.8368780012682007, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9868827901477576}}, {"question": "____\u4e0d\u662f\u80c6\u8272\u7d20\u3002\nA. \u8840\u7ea2\u7d20\nB. \u80c6\u7eff\u7d20\nC. \u80c6\u7ea2\u7d20\nD. \u80c6\u7d20\u539f\u65cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.31283638571410965, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2656046866868781, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8f6c\u5f55\u662f\u6307____\nA. DNA\u7684\u81ea\u6211\u590d\u5236\u8fc7\u7a0b\nB. RNA\u7684\u81ea\u6211\u590d\u5236\u8fc7\u7a0b\nC. \u4ee5DNA\u4e3a\u6a21\u677f\u5408\u6210RNA\u7684\u8fc7\u7a0b\nD. \u4ee5RNA\u4e3a\u6a21\u677f\u5408\u6210DNA\u7684\u8fc7\u7a0b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.864520886906074, "meta-math/MetaMath-Mistral-7B": 0.9929511416979379, "itpossible/Chinese-Mistral-7B-v0.1": 0.8244496399274848, "HuggingFaceH4/zephyr-7b-beta": 0.9995643085984955, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9673605044784913, "meta-llama/Meta-Llama-3-8B": 0.9639325729234833, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9958714206979506}}, {"question": "\u8840\u6db2\u975e\u86cb\u767d\u6c2e\u4e2d\u542b\u91cf\u6700\u591a\u7684\u7269\u8d28\u662f____\u3002\nA. \u5c3f\u7d20\nB. \u808c\u9178\nC. \u86cb\u767d\u8d28\nD. \u5c3f\u9178\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.762669237720187, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7706960512420803, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6659810286346436}}, {"question": "\u6c28\u57fa\u9178\u5206\u5b50\u65e2\u542b\u6709\u9178\u6027\u7684\u7fa7\u57fa(\u4e00COOH)\uff0c\u53c8\u542b\u6709\u78b1\u6027\u7684\u6c28\u57fa(\u4e00$NH_2$ )\u3002\u524d\u8005\u80fd\u63d0\u4f9b\u8d28\u5b50\u53d8\u6210\u4e00COO\u4e00\uff1b\u540e\u8005\u80fd\u63a5\u53d7\u8d28\u5b50\u53d8\u6210\u4e00$NH_3^+$ \u3002\u6709\u7684\u6c28\u57fa\u9178\u8fd8\u6709\u53ef\u89e3\u79bb\u7684\u4fa7\u94fe\u57fa\u56e2\u3002\u56e0\u6b64\uff0c\u6c28\u57fa\u9178\u662f\u4e24\u6027\u7535\u89e3\u8d28\u3002\u5176\u89e3\u79bb\u72b6\u6001\u4e0e\u6eb6\u6db2\u7684pH\u503c\u6709\u76f4\u63a5\u5173\u7cfb\uff0c\u5f53pH\u503c\u7b49\u4e8epI\u65f6\uff0c\u86cb\u767d\u8d28____\nA. \u5e26\u6b63\u7535\u8377\nB. \u5e26\u8d1f\u7535\u8377\nC. \u6240\u5e26\u7535\u8377\u4e0d\u786e\u5b9a\nD. \u6240\u5e26\u6b63\u3001\u8d1f\u7535\u8377\u76f8\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3842715136219864, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2821833983601388, "HuggingFaceH4/zephyr-7b-beta": 0.9999407549007752, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7759396096727076, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u86cb\u767d\u8d28\u5206\u5b50\u662f\u7ed3\u6784\u6781\u5176\u590d\u6742\u7684\u751f\u7269\u5927\u5206\u5b50\u3002\u6709\u7684\u86cb\u767d\u8d28\u5206\u5b50\u53ea\u5305\u542b\u4e00\u6761\u591a\u80bd\u94fe\uff1b\u6709\u7684\u5219\u5305\u542b\u6570\u6761\u591a\u80bd\u94fe\u3002\u901a\u5e38\u5c06\u86cb\u767d\u8d28\u7684\u7ed3\u6784\u5212\u5206\u4e3a\u51e0\u4e2a\u5c42\u6b21\uff0c\u6709\u4e00\u79cd\u7ed3\u6784\u5c42\u6b21\u51fa\u73b0\u5728\u4e00\u6761\u591a\u80bd\u94fe\u7684\u5185\u90e8\uff0c\u662f\u591a\u80bd\u94fe\u5c40\u90e8\u7684\u6240\u6709\u539f\u5b50\u53ca\u539f\u5b50\u56e2\u5f62\u6210\u7684\u6709\u89c4\u5f8b\u7684\u6784\u8c61\uff0c\u8be5\u6784\u8c61\u4e00\u822c\u6210\u7403\u72b6\u7ed3\u6784\uff0c\u6267\u884c\u4e00\u5b9a\u7684\u529f\u80fd\uff0c\u8be5\u7ed3\u6784\u662f____\nA. \u7ed3\u6784\u57df\nB. \u8d85\u4e8c\u7ea7\u7ed3\u6784\nC. \u4e8c\u7ea7\u7ed3\u6784\nD. \u4e09\u7ea7\u7ed3\u6784\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4349598892232299, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u86cb\u767d\u8d28\u751f\u7269\u5408\u6210\u4e2d\u591a\u80bd\u7684\u6c28\u57fa\u9178\u6392\u5217\u987a\u5e8f\u53d6\u51b3\u4e8e____\u3002\nA. \u76f8\u5e94tRNA\u7684\u4e13\u4e00\u6027\nB. \u76f8\u5e94\u6c28\u9170tR-NA\u5408\u6210\u9176\u7684\u4e13\u4e00\u6027\nC. \u76f8\u5e94mRNA\u4e2d\u6838\u82f7\u9178\u6392\u5217\u987a\u5e8f\nD. \u76f8\u5e94tRNA\u4e0a\u7684\u53cd\u5bc6\u7801\u5b50\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8270396553908596, "meta-math/MetaMath-Mistral-7B": 0.9012172883958587, "itpossible/Chinese-Mistral-7B-v0.1": 0.5190768592430574, "HuggingFaceH4/zephyr-7b-beta": 0.9985808776959957, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7366893313150519, "meta-llama/Meta-Llama-3-8B": 0.7446434693023546, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5523332604290753}}, {"question": "\u7a00\u6709\u6838\u82f7\u9178\u78b1\u57fa\u4e3b\u8981\u89c1\u4e8e____\u3002\nA. DNA\nB. mRNA\nC. tRNA\nD. rRNA\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30748613245592255, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3742744353722653, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5941354397199209, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u5b8c\u5168\u7ade\u4e89\u5382\u5546\u7684\u77ed\u671f\u5747\u8861\u4ea7\u91cf\u4e0a\uff0cAR\u5c0f\u4e8eSAC\u4f46\u5927\u4e8eAVC\uff0c\u5219\u5382\u5546____\nA. \u4e8f\u635f\uff0c\u7acb\u5373\u505c\u4ea7\nB. \u4e8f\u635f\uff0c\u4f46\u5e94\u7ee7\u7eed\u751f\u4ea7\nC. \u4e8f\u635f\uff0c\u751f\u4ea7\u6216\u4e0d\u751f\u4ea7\u90fd\u53ef\u4ee5\nD. \u83b7\u5f97\u6b63\u5e38\u5229\u6da6\uff0c\u7ee7\u7eed\u751f\u4ea7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4280201266346246, "meta-math/MetaMath-Mistral-7B": 0.7413593845666274, "itpossible/Chinese-Mistral-7B-v0.1": 0.36617639865290497, "HuggingFaceH4/zephyr-7b-beta": 0.832998511847646, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5262386627528425, "meta-llama/Meta-Llama-3-8B": 0.4269884613235059, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e00\u822c\u60c5\u51b5\u4e0b\uff0c\u4f9b\u7ed9\u66f2\u7ebf____\nA. \u5411\u53f3\u4e0a\u65b9\u503e\u659c\nB. \u5411\u53f3\u4e0b\u65b9\u503e\u659c\nC. \u659c\u7387\u4e3a\u6b63\nD. \u659c\u7387\u4e3a\u8d1f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6278602375560276, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65e0\u5dee\u5f02\u66f2\u7ebf\u4e0a\u4efb\u4e00\u70b9\u659c\u7387\u7684\u7edd\u5bf9\u503c\u4ee3\u8868\u4e86____\nA. \u6d88\u8d39\u8005\u4e3a\u4e86\u63d0\u9ad8\u6548\u7528\u800c\u83b7\u5f97\u53e6\u4e00\u4e9b\u5546\u54c1\u65f6\u613f\u610f\u653e\u5f03\u7684\u67d0\u4e00\u79cd\u5546\u54c1\u7684\u6570\u91cf\nB. \u6d88\u8d39\u8005\u82b1\u5728\u5404\u79cd\u5546\u54c1\u4e0a\u7684\u8d27\u5e01\u603b\u503c\nC. \u4e24\u79cd\u5546\u54c1\u7684\u4ef7\u683c\u7684\u4ef7\u683c\u6bd4\u7387\nD. \u5728\u786e\u4fdd\u6d88\u8d39\u8005\u6548\u7528\u4e0d\u53d8\u7684\u60c5\u51b5\u4e0b\uff0c\u4e00\u79cd\u5546\u54c1\u548c\u53e6\u4e00\u79cd\u5546\u54c1\u7684\u4ea4\u6362\u6bd4\u7387\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4316057235791016, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9839276758088151, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6527204574948517, "meta-llama/Meta-Llama-3-8B": 0.6608265948572645, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82e5\u4f9b\u7ed9\u66f2\u7ebf\u4e0a\u6bcf\u4e00\u70b9\u7684\u70b9\u5f39\u6027\u90fd\u7b49\u4e8e1\uff0c\u5219\u4f9b\u7ed9\u66f2\u7ebf\u53ea\u80fd\u662f\u4e00\u6761____\nA. \u8fc7\u539f\u70b9\u768445\u7ebf\nB. \u8fc7\u539f\u70b9\u7684\u76f4\u7ebf\nC. \u5e73\u884c\u4e8e\u6a2a\u8f74\u7684\u76f4\u7ebf\nD. \u5782\u76f4\u4e8e\u6a2a\u8f74\u7684\u76f4\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28779674254221166, "meta-math/MetaMath-Mistral-7B": 0.6476287020919946, "itpossible/Chinese-Mistral-7B-v0.1": 0.3331832353540621, "HuggingFaceH4/zephyr-7b-beta": 0.4606796658671747, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4584207781205197, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6280\u672f\u8fdb\u6b65\u4e00\u822c\u4f1a\u5bfc\u81f4____\nA. \u4f9b\u7ed9\u66f2\u7ebf\u53f3\u79fb\nB. \u4f9b\u7ed9\u91cf\u6cbf\u7740\u4f9b\u7ed9\u66f2\u7ebf\u51cf\u5c11\nC. \u4e00\u4e2a\u4eba\u589e\u52a0\u4ed6\u6240\u6d88\u8d39\u7684\u6240\u6709\u5546\u54c1\u7684\u6570\u91cf\nD. \u4f9b\u7ed9\u91cf\u6cbf\u7740\u4f9b\u7ed9\u66f2\u7ebf\u589e\u52a0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6938002920445032, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7442721061894052, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5511358439056652}}, {"question": "\u5170\u5fb7\u53ea\u4e70\u6fc0\u5149\u5531\u7247\u548c\u68d2\u68d2\u7cd6\uff0c\u4ed6\u6709\u56fa\u5b9a\u6536\u5165\uff0c\u4e0d\u80fd\u501f\u94b1\uff0c\u5f53\u4ed6\u6cbf\u7740\u9884\u7b97\u7ea6\u675f\u79fb\u52a8\u65f6____\nA. \u6fc0\u5149\u5531\u7247\u7684\u4ef7\u683c\u5728\u6539\u53d8\uff0c\u800c\u5176\u6536\u5165\u548c\u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u4e0d\u53d8\nB. \u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u5728\u6539\u53d8\uff0c\u800c\u5176\u6536\u5165\u548c\u6fc0\u5149\u5531\u7247\u7684\u4ef7\u683c\u4e0d\u53d8\nC. \u6fc0\u5149\u5531\u7247\u548c\u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u5728\u6539\u53d8\uff0c\u800c\u5176\u6536\u5165\u4e0d\u53d8\nD. \u6fc0\u5149\u5531\u7247\u548c\u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u53ca\u5176\u6536\u5165\u90fd\u4e0d\u53d8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6456277545339962, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u5b8f\u89c2\u7ecf\u6d4e\u653f\u7b56\u7684\u9009\u62e9\uff0c\u4e0b\u5217\u8bf4\u6cd5\u4e2d\u9519\u8bef\u7684\u662f____\u3002\nA. \u5f53\u7ecf\u6d4e\u9677\u5165\u6d41\u52a8\u6027\u9677\u9631\u65f6\uff0c\u5efa\u8bae\u91c7\u7528\u8d22\u653f\u653f\u7b56\u800c\u975e\u8d27\u5e01\u653f\u7b56\nB. \u5f53\u6324\u51fa\u6548\u5e94\u5f88\u660e\u663e\u65f6\uff0c\u91c7\u53d6\u8d27\u5e01\u653f\u7b56\u66f4\u80fd\u591f\u6210\u529f\nC. \u5728\u53e4\u5178\u4e16\u754c\u91cc\uff0c\u5e94\u8be5\u91c7\u7528\u8d27\u5e01\u653f\u7b56\u800c\u4e0d\u662f\u8d22\u653f\u653f\u7b56\nD. \u5728\u53e4\u5178\u4e16\u754c\u91cc\uff0c\u7ed9\u5b9a\u7684\u8d27\u5e01\u6570\u91cf\u7684\u53d8\u5316\u5bf9\u6536\u5165\u6c34\u5e73\u7684\u5f71\u54cd\u6700\u5c0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3893866642530732, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.33424000363035195, "HuggingFaceH4/zephyr-7b-beta": 0.999558006847092, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6321109519478744, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u957f\u671f\u5e73\u5747\u6210\u672c\u66f2\u7ebf\u5448U\u5f62\u7684\u539f\u56e0\u5728\u4e8e____\nA. \u8fb9\u9645\u6548\u7528\u9012\u51cf\u89c4\u5f8b\nB. \u8fb9\u9645\u751f\u4ea7\u529b\u9012\u51cf\u89c4\u5f8b\nC. \u751f\u4ea7\u7531\u89c4\u6a21\u7ecf\u6d4e\u5411\u89c4\u6a21\u4e0d\u7ecf\u6d4e\u53d8\u52a8\nD. \u751f\u4ea7\u7684\u4e00\u822c\u89c4\u5f8b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35812374299748184, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9897105745693653, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6594839618827847, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8503830592186564}}, {"question": "\u52b3\u52a8\u5e02\u573a\u4e0a\u5b58\u5728\u4e09\u4e2a\u5de5\u4eba\uff0c\u6bcf\u4eba\u7684\u4fdd\u7559\u5de5\u8d44\u5206\u522b\u4e3a2000\u5143/\u6708\u30011800\u5143/\u6708\u30011500\u5143/\u6708\uff0c\u5e76\u4e14\u5728\u52b3\u52a8\u5e02\u573a\u4e0a\u4e09\u4eba\u7684\u8981\u6c42\u5de5\u8d44\u5747\u4e3a\u4fdd\u7559\u5de5\u8d44\u3002\u5982\u679c\u5382\u5546\u540c\u65f6\u96c7\u4f63\u8fd9\u4e09\u4e2a\u4eba\uff0c\u6708\u5de5\u8d44\u4e3a2000\u5143/\u6708\u3002\u8fd9\u4e09\u4e2a\u5de5\u4eba\u80fd\u5f97\u5230\u7684\u7ecf\u6d4e\u79df\u4e3a____\u5143\u3002\nA. 0\u3001200\u3001500\nB. \u5747\u4e3a500\nC. \u5747\u4e3a200\nD. \u5747\u4e3a0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3436615088034303, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31483005318115603, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4052820801728963}}, {"question": "\u4e0b\u5217\u54ea\u4e00\u9879\u4e0d\u5217\u5165\u56fd\u5185\u751f\u4ea7\u603b\u503c\u7684\u6838\u7b97\uff1f____\nA. \u51fa\u53e3\u5230\u56fd\u5916\u7684\u4e00\u6279\u8d27\u7269\nB. \u7ecf\u7eaa\u4eba\u4e3a\u4e00\u5ea7\u65e7\u623f\u4e70\u5356\u6536\u53d6\u7684\u4e00\u7b14\u4f63\u91d1\nC. \u653f\u5e9c\u7ed9\u8d2b\u56f0\u5bb6\u5ead\u53d1\u653e\u7684\u4e00\u7b14\u6551\u6d4e\u91d1\nD. \u4fdd\u9669\u516c\u53f8\u6536\u5230\u4e00\u7b14\u5bb6\u5ead\u8d22\u4ea7\u4fdd\u9669\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5140406332527597, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5982\u679c\u67d0\u4e00\u79cd\u5546\u54c1\u7684\u4ef7\u683c\u4e0b\u8dcc10%,\u7531\u6b64\u5bfc\u81f4\u4eba\u4eec\u7528\u4e8e\u8d2d\u4e70\u8be5\u5546\u54c1\u7684\u8d27\u5e01\u652f\u51fa\u589e\u52a05%,\u5219\u9700\u6c42\u66f2\u7ebf\u5728\u8fd9\u4e00\u533a\u57df\u5185\u7684\u9700\u6c42\u4ef7\u683c\u5f39\u6027\u4e3a____\nA. \u5bcc\u6709\u5f39\u6027\nB. \u5b8c\u5168\u65e0\u5f39\u6027\nC. \u7f3a\u4e4f\u5f39\u6027\uff0c\u4f46\u4e0d\u662f\u5b8c\u5168\u65e0\u5f39\u6027\nD. \u5177\u6709\u5355\u4f4d\u5f39\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5048101931999623, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4e24\u79cd\u5546\u54c1\u4e2d\u4e00\u79cd\u5546\u54c1\u7684\u4ef7\u683c\u53d1\u751f\u53d8\u52a8\u65f6\uff0c\u8fd9\u4e24\u79cd\u5546\u54c1\u7684\u9700\u6c42\u91cf\u90fd\u540c\u65f6\u589e\u52a0\u6216\u51cf\u5c11\uff0c\u5219\u8fd9\u4e24\u79cd\u5546\u54c1\u7684\u9700\u6c42\u4ea4\u53c9\u4ef7\u683c\u5f39\u6027\u4e3a____\nA. \u6b63\u503c\nB. \u8d1f\u503c\nC. 0\nD. 1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u793e\u4f1a\u6280\u672f\u8fdb\u6b65\u5bfc\u81f4\u90e8\u5206\u4eba\u4e0d\u9002\u5e94\u5de5\u4f5c\u5c97\u4f4d\u8981\u6c42\uff0c\u7531\u6b64\u4ea7\u751f\u7684\u5931\u4e1a\u5c5e\u4e8e____\u3002\nA. \u81ea\u613f\u6027\u5931\u4e1a\nB. \u7ed3\u6784\u6027\u5931\u4e1a\nC. \u9700\u6c42\u4e0d\u8db3\u7684\u5931\u4e1a\nD. \u6469\u64e6\u6027\u5931\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45749069287538463, "meta-math/MetaMath-Mistral-7B": 0.5739477175302213, "itpossible/Chinese-Mistral-7B-v0.1": 0.8017390075912502, "HuggingFaceH4/zephyr-7b-beta": 0.49004394209134344, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8919751914695606, "meta-llama/Meta-Llama-3-8B": 0.4776726733375625, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9201206574831108}}, {"question": "\u79d1\u65af\u5b9a\u7406\u5047\u8bbe\u4ea4\u6613\u6210\u672c\u4e3a____\nA. 0\nB. 1\nC. \u5927\u4e8e1\nD. \u5927\u4e8e0\u5c0f\u4e8e1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f9b\u7ed9\u7684\u589e\u52a0\u4f1a\u964d\u4f4e\u4ef7\u683c\uff0c\u9664\u975e____\u3002\nA. \u4f9b\u7ed9\u662f\u5b8c\u5168\u65e0\u5f39\u6027\u7684\nB. \u9700\u6c42\u662f\u5b8c\u5168\u6709\u5f39\u6027\u7684\nC. \u9700\u6c42\u91cf\u589e\u52a0\nD. \u9700\u6c42\u9ad8\u5ea6\u7f3a\u4e4f\u5f39\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2906893535433972, "meta-math/MetaMath-Mistral-7B": 0.4930919582176738, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3306562312783846, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u8d39\u96ea\u7684\u6d88\u8d39\u7406\u8bba\uff0c\u5982\u679c\u5b9e\u9645\u5229\u7387\u4e3a\u6b63\uff0c\u90a3\u4e48____\u3002\nA. \u7528\u7b2c\u4e00\u671f\u7684\u6536\u5165\u8861\u91cf\u7684\u7b2c\u4e8c\u671f\u6d88\u8d39\u6210\u672c\u4f4e\u4e8e\u540c\u7b49\u6570\u91cf\u7684\u7b2c\u4e00\u671f\u6d88\u8d39\nB. \u7b2c\u4e8c\u671f\u7684\u6536\u5165\u6bd4\u7b2c\u4e00\u671f\u7684\u540c\u7b49\u6570\u91cf\u7684\u6536\u5165\u503c\u5f97\u66f4\u591a\nC. \u6d88\u8d39\u8005\u5c06\u4e0d\u613f\u501f\u94b1\uff0c\u4ece\u800c\u5176\u7b2c\u4e00\u671f\u7684\u6d88\u8d39\u5c0f\u4e8e\u7b2c\u4e00\u671f\u7684\u6536\u5165\nD. A\u3001B\u3001C\u5747\u6b63\u786e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u52b3\u52a8\u529b\u53c2\u4e0e\u7387\u53cd\u6620\u7684\u662f____\u3002\nA. \u6210\u5e74\u52b3\u52a8\u529b\u5360\u6210\u5e74\u4eba\u53e3\u7684\u6bd4\u7387\nB. \u6210\u5e74\u4eba\u5c31\u4e1a\u6bd4\u7387\nC. \u52b3\u52a8\u529b\u5c31\u4e1a\u6bd4\u7387\nD. \u52b3\u52a8\u529b\u5c31\u4e1a\u6bd4\u7387\u4e0e\u5931\u4e1a\u6bd4\u7387\u4e4b\u548c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32214924591241917, "meta-math/MetaMath-Mistral-7B": 0.735982993470619, "itpossible/Chinese-Mistral-7B-v0.1": 0.3919626083521393, "HuggingFaceH4/zephyr-7b-beta": 0.9997937218993047, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31828968051251794, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8570689984926338}}, {"question": "\u8d22\u653f\u653f\u7b56\u548c\u8d27\u5e01\u653f\u7b56\u7684\u6709\u6548\u6027\u5728\u5f88\u5927\u7a0b\u5ea6\u4e0a\u53d6\u51b3\u4e8e____\u3002\nA. \u51b3\u7b56\u4eba\u7684\u610f\u613f\nB. IS\u548cLM\u66f2\u7ebf\u7684\u4ea4\u70b9\nC. IS\u548cLM\u66f2\u7ebf\u7684\u659c\u7387\nD. \u8d27\u5e01\u4f9b\u5e94\u91cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f7f\u7528\u81ea\u6709\u8d44\u91d1\u4e5f\u5e94\u8ba1\u7b97\u5229\u606f\u6536\u5165\uff0c\u8fd9\u79cd\u5229\u606f\u4ece\u6210\u672c\u89d2\u5ea6\u770b\u662f____\nA. \u56fa\u5b9a\u6210\u672c\nB. \u9690\u542b\u6210\u672c\nC. \u4f1a\u8ba1\u6210\u672c\nD. \u751f\u4ea7\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4238867136252512, "meta-math/MetaMath-Mistral-7B": 0.8182401769376532, "itpossible/Chinese-Mistral-7B-v0.1": 0.46331119565501916, "HuggingFaceH4/zephyr-7b-beta": 0.9451700100296127, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.571719680155505, "meta-llama/Meta-Llama-3-8B": 0.5940327246278464, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8078236056458473}}, {"question": "\u65e0\u5dee\u5f02\u66f2\u7ebf\u662f\u4e00\u6761\u5177\u6709\u8d1f\u659c\u7387\u7684\u76f4\u7ebf\uff0c\u5219\u8bf4\u660e____\u3002\nA. \u5546\u54c1\u662f\u5b8c\u5168\u66ff\u4ee3\u7684\nB. \u8fb9\u9645\u6548\u7528\u4e0d\u518d\u9012\u51cf\nC. \u504f\u597d\u662f\u975e\u51f8\u7684\nD. \u504f\u597d\u4e0d\u5177\u6709\u5355\u8c03\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5190768741225268, "HuggingFaceH4/zephyr-7b-beta": 0.8228818325837097, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4e00\u56fd\u4eba\u5747GDP\u6781\u4f4e\u65f6____\nA. \u5b83\u6ce8\u5b9a\u8981\u6c38\u8fdc\u7a77\u4e0b\u53bb\nB. \u5b83\u5fc5\u5b9a\u662f\u4e00\u4e2a\u5c0f\u56fd\nC. \u7531\u4e8e\u201c\u8ffd\u6c42\u6548\u5e94\u201c\uff0c\u5b83\u6709\u8f83\u8fc5\u901f\u589e\u957f\u7684\u6f5c\u529b\nD. \u8d44\u672c\u589e\u52a0\u5bf9\u4ea7\u91cf\u7684\u5f71\u54cd\u5fae\u4e4e\u5176\u5fae\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9552012188686007, "meta-math/MetaMath-Mistral-7B": 0.9969955728922725, "itpossible/Chinese-Mistral-7B-v0.1": 0.726707315446755, "HuggingFaceH4/zephyr-7b-beta": 0.9989238600861285, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9870040470863962, "meta-llama/Meta-Llama-3-8B": 0.7386320644954362, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9494230690786536}}, {"question": "\u5fae\u89c2\u7ecf\u6d4e\u5b66\u7684\u57fa\u672c\u5047\u8bbe\u4e4b\u4e00\u662f____\u5047\u8bbe\nA. \u7ecf\u6d4e\u4eba\nB. \u793e\u4f1a\u4eba\nC. \u81ea\u6211\u5b9e\u73b0\u4eba\nD. \u590d\u6742\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.49350231245570375, "meta-math/MetaMath-Mistral-7B": 0.855074803028768, "itpossible/Chinese-Mistral-7B-v0.1": 0.8897419454582332, "HuggingFaceH4/zephyr-7b-beta": 0.9997165036069496, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7968528497933248, "meta-llama/Meta-Llama-3-8B": 0.9365138838801165, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9843829389271933}}, {"question": "I=Px\u00b7X+Py\u00b7Y\u662f\u6d88\u8d39\u8005\u7684____\nA. \u9700\u6c42\u51fd\u6570\nB. \u6548\u7528\u51fd\u6570\nC. \u9884\u7b97\u7ea6\u675f\u65b9\u7a0b\nD. \u4e0d\u786e\u5b9a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45534737832926375, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4536094356115961, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8204937914572789, "meta-llama/Meta-Llama-3-8B": 0.5649968904380586, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9712912579924908}}, {"question": "\u5b8c\u5168\u7ade\u4e89\u5e02\u573a\u4e2d\uff0c\u884c\u4e1a\u9762\u4e34\u7684\u9700\u6c42\u66f2\u7ebf\u662f____\u3002\nA. \u4e00\u6761\u5411\u53f3\u4e0b\u65b9\u503e\u659c\u7684\u66f2\u7ebf\nB. \u4e00\u6761\u5411\u53f3\u4e0a\u65b9\u503e\u659c\u7684\u66f2\u7ebf\nC. \u4e00\u6761\u6c34\u5e73\u7ebf\nD. \u4e00\u6761\u5411\u5de6\u4e0a\u65b9\u503e\u659c\u7684\u66f2\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.45739275392821127, "itpossible/Chinese-Mistral-7B-v0.1": 0.3583275789139464, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u5b8c\u5168\u7ade\u4e89\u5e02\u573a\u7684\u6761\u4ef6\uff0c\u4ee5\u4e0b\u54ea\u4e9b\u884c\u4e1a\u6700\u63a5\u8fd1\u5b8c\u5168\u7ade\u4e89\u884c\u4e1a____\nA. \u5bb6\u7535\u884c\u4e1a\nB. \u6c7d\u8f66\u884c\u4e1a\nC. \u852c\u83dc\u884c\u4e1a\nD. \u7389\u7c73\u884c\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6224391366063731, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u5f97\u51fa\u68c9\u82b1\u79cd\u690d\u6237\u7684\u4f9b\u7ed9\u66f2\u7ebf\u65f6\uff0c\u4e0b\u5217\u9664\u54ea\u4e00\u4e2a\u56e0\u7d20\u4ee5\u5916\uff0c\u5176\u4f59\u5747\u4fdd\u6301\u4e3a\u5e38\u6570____\nA. \u571f\u58e4\u7684\u80a5\u6c83\u7a0b\u5ea6\nB. \u68c9\u82b1\u79cd\u690d\u9762\u79ef\nC. \u6280\u672f\u6c34\u5e73\nD. \u68c9\u82b1\u7684\u4ef7\u683c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65b0\u51ef\u6069\u65af\u4e3b\u4e49\u8005\u8ba4\u4e3a\uff0c\u52b3\u52a8\u4f9b\u8fc7\u4e8e\u6c42\u65f6\uff0c____\u3002\nA. \u4f1a\u4ea7\u751f\u975e\u81ea\u613f\u6027\u5931\u4e1a\nB. \u5de5\u8d44\u4f1a\u8dcc\u843d\nC. \u4e00\u65b9\u9762\u4f1a\u4ea7\u751f\u975e\u81ea\u613f\u6027\u5931\u4e1a\uff0c\u4e00\u65b9\u9762\u5de5\u8d44\u4f1a\u8dcc\u843d\nD. \u5de5\u8d44\u5e76\u4e0d\u4f1a\u8dcc\u843d\uff0c\u975e\u81ea\u613f\u6027\u5931\u4e1a\u4e5f\u4e0d\u4f1a\u4ea7\u751f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9398885850457868, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6d88\u8d39\u8005\u7684\u6839\u672c\u95ee\u9898\u662f____\nA. \u5728\u9884\u7b97\u7ea6\u675f\u5185\u5b9e\u73b0\u6548\u7528\u6700\u5927\u5316\nB. \u5728\u4e00\u5b9a\u7684\u6548\u7528\u6c34\u5e73\u5185\u5b9e\u73b0\u9884\u7b97\u7ea6\u675f\u6700\u5c0f\u5316\nC. \u5728\u9884\u7b97\u7ea6\u675f\u5185\u5b9e\u73b0\u6548\u7528\u6700\u5c0f\u5316\nD. \u5728\u4e00\u5b9a\u7684\u6548\u7528\u6c34\u5e73\u5185\u5b9e\u73b0\u9884\u7b97\u7ea6\u675f\u6700\u5927\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8772742176534075, "meta-math/MetaMath-Mistral-7B": 0.9871842583571825, "itpossible/Chinese-Mistral-7B-v0.1": 0.8258809154282596, "HuggingFaceH4/zephyr-7b-beta": 0.9923300932096281, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9622524752012991, "meta-llama/Meta-Llama-3-8B": 0.8997158220741628, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u8ba1\u5212\u7ecf\u6d4e\u65f6\u4ee3\uff0c\u8bb8\u591a\u5546\u54c1\u7ecf\u5e38\u77ed\u7f3a\u3002\u5728\u5e02\u573a\u7ecf\u6d4e\u65f6\u4ee3\uff0c\u4eba\u4eec\u901a\u5e38\u80fd\u591f\u4e70\u5230\u9700\u8981\u7684\u5546\u54c1\u3002\u8fd9\u662f\u56e0\u4e3a\uff1a____\nA. \u8ba1\u5212\u7ecf\u6d4e\u65f6\u4ee3\u6bd4\u5e02\u573a\u7ecf\u6d4e\u65f6\u4ee3\u7684\u751f\u4ea7\u80fd\u529b\u66f4\u4f4e\nB. \u8ba1\u5212\u7ecf\u6d4e\u65f6\u4ee3\u6bd4\u5e02\u573a\u7ecf\u6d4e\u65f6\u4ee3\u7684\u6d88\u8d39\u6c34\u5e73\u66f4\u9ad8\nC. \u5e02\u573a\u7ecf\u6d4e\u65f6\u4ee3\u751f\u4ea7\u8005\u7684\u9053\u5fb7\u66f4\u52a0\u9ad8\u5c1a\uff0c\u5904\u5904\u4e3a\u6d88\u8d39\u8005\u7740\u60f3\nD. \u5e02\u573a\u4ef7\u683c\u5f15\u5bfc\u4e86\u751f\u4ea7\u8005\u548c\u9700\u6c42\u8005\u7684\u81ea\u5229\u884c\u4e3a\uff0c\u8fbe\u5230\u4eba\u4eec\u6ee1\u610f\u7684\u7a0b\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9462762117188905, "meta-math/MetaMath-Mistral-7B": 0.9961976202578834, "itpossible/Chinese-Mistral-7B-v0.1": 0.9575681629727162, "HuggingFaceH4/zephyr-7b-beta": 0.999981403848299, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9932839509170556, "meta-llama/Meta-Llama-3-8B": 0.9363034103129529, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9791786199823421}}, {"question": "\u4e0b\u5217\u54ea\u79cd\u60c5\u51b5\u4f7f\u603b\u6536\u76ca\u589e\u52a0\uff1f____\nA. \u9700\u6c42\u7f3a\u4e4f\u5f39\u6027\uff0c\u63d0\u9ad8\u4ef7\u683c\nB. \u9700\u6c42\u7f3a\u4e4f\u5f39\u6027\uff0c\u964d\u4f4e\u4ef7\u683c\nC. \u9700\u6c42\u5bcc\u6709\u5f39\u6027\uff0c\u63d0\u9ad8\u4ef7\u683c\nD. \u9700\u6c42\u5355\u4f4d\u5f39\u6027\uff0c\u964d\u4f4e\u4ef7\u683c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u5747\u8861\u4ef7\u683c\u4e0b____\nA. \u4ef7\u683c\u8d8b\u4e8e\u4e0b\u964d\nB. \u4f9b\u7ed9\u91cf\u8d85\u8fc7\u9700\u6c42\u91cf\nC. \u4ef7\u683c\u8d8b\u4e8e\u4e0a\u5347\nD. \u4ef7\u683c\u4e0d\u5e94\u53d8\u52a8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.8054346075028233, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9565025293977263, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9530319087251564, "meta-llama/Meta-Llama-3-8B": 0.48533996353149345, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u8d44\u672c\u5b8c\u5168\u6d41\u52a8\u7684\u6761\u4ef6\u4e0b\uff0c\u5982\u679c\u4e00\u56fd\u5916\u6c47\u5e02\u573a\u5b9e\u884c\u95f4\u63a5\u6807\u4ef7\u6cd5\uff0c\u800c\u4e14\u8be5\u7ecf\u6d4e\u53ef\u4ee5\u7528\u6d6e\u52a8\u6c47\u7387\u7684\u8499\u4ee3\u5c14-\u5f17\u83b1\u660e\u6a21\u578b\u51c6\u786e\u63cf\u8ff0\uff0c\u90a3\u4e48\uff0c\u5728\u5747\u8861\u72b6\u6001\u4e0b\uff0c\u7ed9\u5b9a\u5176\u4ed6\u6761\u4ef6\u4e0d\u53d8\uff0c\u5f53\u56fd\u5185\u7a0e\u6536\u589e\u52a0\u65f6\uff0c\u4f1a\u5bfc\u81f4____\u3002\nA. \u603b\u6536\u5165\u4e0b\u964d\uff0c\u6c47\u7387\u4e0a\u5347\uff0c\u8d38\u6613\u4f59\u989d\u4e0a\u5347\nB. \u603b\u6536\u5165\u4e0d\u53d8\uff0c\u6c47\u7387\u4e0a\u5347\uff0c\u8d38\u6613\u4f59\u989d\u4e0b\u964d\nC. \u603b\u6536\u5165\u4e0a\u5347\uff0c\u6c47\u7387\u4e0b\u964d\uff0c\u8d38\u6613\u4f59\u989d\u4e0a\u5347\nD. \u603b\u6536\u5165\u4e0d\u53d8\uff0c\u6c47\u7387\u4e0b\u964d\uff0c\u8d38\u6613\u4f59\u989d\u4e0a\u5347\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5798514427558119, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f01\u4e1a\u8d2d\u4e70\u751f\u4ea7\u8981\u7d20\u6240\u5f15\u8d77\u7684\u6210\u672c\u4e3a____\nA. \u663e\u6210\u672c\nB. \u9690\u6210\u672c\nC. \u56fa\u5b9a\u6210\u672c\nD. \u673a\u4f1a\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.48367803888260275, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7083823381093193, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4775906960723433, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u5382\u5546\u7684\u751f\u4ea7\u51fd\u6570\u4e3af(x\uff0cy\uff0cz)=(x+y)0.5z0.5\uff0c\u4e09\u79cd\u8981\u7d20x\uff0cy\uff0cz\u7684\u4ef7\u683c\u4e3a1\uff0c2\uff0c3\u3002\u5047\u5982y\u4ef7\u683c\u5347\u4e3a\u539f\u6765\u76842\u500d\uff0c\u5176\u4ed6\u4e24\u79cd\u7684\u4ef7\u683c\u4e0d\u53d8\uff0c\u5219\u603b\u7684\u751f\u4ea7\u6210\u672c____\u3002\nA. \u589e\u52a0\u4e8650%\nB. \u589e\u52a0\u4e862\u500d\nC. \u4e0d\u53d8\nD. \u4ee5\u4e0a\u8bf4\u6cd5\u90fd\u4e0d\u5bf9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3615088271021877, "meta-math/MetaMath-Mistral-7B": 0.49088002129634783, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8375487862880011, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.32871459371036227, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5982\u679c\u589e\u52a0\u4e00\u5355\u4f4d\u52b3\u52a8\u53ef\u51cf\u5c11\u4e09\u5355\u4f4d\u8d44\u672c\u4e14\u80fd\u4f7f\u4ea7\u91cf\u4e0d\u53d8\uff0c\u5219MRTSLK\u4e3a____\nA. 1/3\nB. 3\nC. 1\nD. 6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u67d0\u5546\u54c1\u7684\u9700\u6c42\u91cf\u589e\u52a080%\uff0c\u800c\u540c\u671f\u6d88\u8d39\u8005\u7684\u6536\u5165\u5374\u589e\u52a0\u4e8640%\uff0c\u5219\u8be5\u5546\u54c1\u5f88\u53ef\u80fd\u662f____\u3002\nA. \u5fc5\u9700\u54c1\nB. \u5962\u4f88\u54c1\nC. \u4e00\u822c\u4f4e\u6863\u5546\u54c1\nD. \u5409\u82ac\u5546\u54c1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.47504225691409335, "meta-math/MetaMath-Mistral-7B": 0.5837367234394677, "itpossible/Chinese-Mistral-7B-v0.1": 0.3164901664353555, "HuggingFaceH4/zephyr-7b-beta": 0.8969665508594165, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6061547449349209, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.515882430540393}}, {"question": "\u5047\u5b9a\u672c\u56fd\u7684\u91cd\u8981\u8d38\u6613\u4f19\u4f34\u7531\u4e8e\u5b9e\u884c\u8d27\u5e01\u6269\u5f20\u800c\u53d1\u751f\u4e86\u8f83\u4e3a\u4e25\u91cd\u7684\u901a\u8d27\u81a8\u80c0\uff0c\u5728\u56fa\u5b9a\u6c47\u7387\u5236\u5ea6\u4e4b\u4e0b\uff0c\u4e0b\u9762\u54ea\u79cd\u60c5\u51b5\u63cf\u8ff0\u7684\u662f\u5408\u7406\u7684?____\nA. \u672c\u56fd\u8d38\u6613\u9006\u5dee\nB. \u653f\u5e9c\u91c7\u53d6\u63aa\u65bd\u4ee4\u8d27\u5e01\u8d2c\u503c\nC. \u6295\u673a\u884c\u4e3a\u5c06\u4f1a\u7a33\u5b9a\u6c47\u7387\nD. \u672c\u56fd\u8d27\u5e01\u4f9b\u7ed9\u51cf\u5c11\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.47020124817608666, "meta-math/MetaMath-Mistral-7B": 0.6783880193134556, "itpossible/Chinese-Mistral-7B-v0.1": 0.39845851868824184, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.880436589612636, "meta-llama/Meta-Llama-3-8B": 0.4377363940461576, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9487208962944639}}, {"question": "\u5f53\u5382\u5546\u652f\u4ed8\u9ad8\u4e8e\u5e02\u573a\u5de5\u8d44\u7684\u6548\u7387\u5de5\u8d44\u65f6____\u3002\nA. \u7ecf\u6d4e\u5728\u5145\u5206\u5c31\u4e1a\u7684\u72b6\u6001\u4e0b\u8fd0\u884c\nB. \u5b58\u5728\u5bf9\u52b3\u52a8\u529b\u7684\u8fc7\u5269\u4f9b\u7ed9\nC. \u4e0d\u5b58\u5728\u975e\u81ea\u613f\u6027\u5931\u4e1a\nD. \u52b3\u52a8\u529b\u5e02\u573a\u5728\u6548\u7387\u5de5\u8d44\u6c34\u5e73\u4e0b\u51fa\u6e05\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29258944112561125, "HuggingFaceH4/zephyr-7b-beta": 0.9966105041602562, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7131773611849976, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6210\u672c\u51fd\u6570[C=f\uff08Q\uff09]\u8868\u793a\u7684\u662f____\nA. \u652f\u51fa\u4e00\u5b9a\u6210\u672c\u4e0e\u5728\u4e00\u5b9a\u4ef7\u683c\u4e0b\u7684\u4e0d\u540c\u8981\u7d20\u6700\u5927\u8d2d\u4e70\u91cf\u95f4\u7684\u5173\u7cfb\nB. \u6210\u672c\u4e0e\u4ea7\u91cf\u4e4b\u95f4\u7684\u5173\u7cfb\nC. \u6210\u672c\u968f\u4ea7\u91cf\u7684\u53d8\u5316\u800c\u53d8\u5316\nD. \u4ea7\u91cf\u968f\u7740\u6210\u672c\u7684\u53d8\u5316\u800c\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u516c\u53f8\u662f\u5784\u65ad\u5382\u5546\uff0c\u5229\u6da6\u4e3a100\u4e07\u5143\u3002\u73b0\u6709\u4e59\u516c\u53f8\uff0c\u6b32\u8fdb\u5165\u540c\u4e00\u5e02\u573a\u3002\u5982\u679c\u4e59\u516c\u53f8\u4e0d\u8fdb\u5165\uff0c\u81ea\u7136\u6ca1\u6709\u6536\u76ca\u3002\u5982\u679c\u4e59\u516c\u53f8\u9009\u62e9\u8fdb\u5165\uff0c\u7532\u516c\u53f8\u53ef\u4ee5\u9009\u62e9\u63a5\u7eb3\u548c\u963b\u6320\uff0c\u5982\u679c\u9009\u62e9\u5bb9\u7eb3\uff0c\u5219\u4e24\u4e2a\u516c\u53f8\u90fd\u53ef\u4ee5\u83b7\u5f97\u5229\u6da650\u4e07\u5143\uff0c\u5982\u679c\u9009\u62e9\u963b\u6320\uff0c\u5219\u4e24\u5bb6\u516c\u53f8\u90fd\u4f1a\u635f\u801750\u4e07\u5143\uff0c\u8fd9\u4e2a\u535a\u5f08\u7684\u5747\u8861\u89e3\u4e3a____\u3002\nA. \u4e59\u516c\u53f8\u8fdb\u5165\uff0c\u7532\u516c\u53f8\u63a5\u7eb3\nB. \u4e59\u516c\u53f8\u4e0d\u8fdb\u5165\uff0c\u7532\u516c\u53f8\u63a5\u7eb3\nC. \u4e59\u516c\u53f8\u8fdb\u5165\uff0c\u7532\u516c\u53f8\u963b\u6320\nD. \u4e59\u516c\u53f8\u4e0d\u8fdb\u5165\uff0c\u7532\u516c\u53f8\u963b\u6320\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4777635491413946, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7471981813371231}}, {"question": "\u653f\u5e9c\u5bf9\u9910\u9986\u7684\u8425\u4e1a\u6536\u5165\u5f81\u653620%\u7684\u8425\u4e1a\u7a0e\uff1b\u8425\u4e1a\u6536\u5165\u4ee5\u9910\u9986\u5411\u987e\u5ba2\u5f00\u5177\u53d1\u7968\u7684\u603b\u91d1\u989d\u6765\u786e\u5b9a\u3002\u6cd5\u5f8b\u89c4\u5b9a\u987e\u5ba2\u6709\u6743\u7d22\u53d6\u53d1\u7968\u3002\u5047\u5b9a\u53d1\u7968\u5bf9\u4e8e\u987e\u5ba2\u6ca1\u6709\u4efb\u4f55\u4ef7\u503c\uff0c\u56e0\u6b64\u987e\u5ba2\u90fd\u4e0d\u5f00\u53d1\u7968\u3002\u8fd9\u65f6\uff0c\u653f\u5e9c\u4e3a\u4e86\u589e\u52a0\u7a0e\u6536\uff0c\u63a8\u51fa\u4e86\u53d1\u7968\u62bd\u5956\u7684\u6d3b\u52a8\u3002\u6bcf\u5f00\u5177100\u5143\u7684\u53d1\u7968\uff0c\u987e\u5ba2\u53ef\u4ece\u653f\u5e9c\u90a3\u91cc\u5f97\u5230\u7684\u4e2d\u5956\u6536\u5165\u4e3a10\u5143\u3002\u6839\u636e\u79d1\u65af\u5b9a\u7406\u5e76\u8fd0\u7528\u4f9b\u6c42\u7406\u8bba\uff0c\u4f60\u9884\u8ba1\u653f\u5e9c\u5f15\u5165\u8fd9\u4e00\u505a\u6cd5\u7684\u540e\u679c\u662f\uff1a____\nA. \u987e\u5ba2\u5f00\u53d1\u7968\uff1b\u653f\u5e9c\u7a0e\u6536\u589e\u52a0\uff0c\u9910\u9986\u6536\u5165\u4e0b\u964d\nB. \u987e\u5ba2\u4e0d\u5f00\u53d1\u7968\uff0c\u653f\u5e9c\u7a0e\u6536\u4e0d\u53d8\uff0c\u9910\u9986\u6536\u5165\u4e0b\u964d\nC. \u987e\u5ba2\u4e0d\u5f00\u53d1\u7968\uff0c\u653f\u5e9c\u7a0e\u6536\u4e0d\u53d8\uff0c\u9910\u9986\u6536\u5165\u4e0d\u53d8\nD. \u987e\u5ba2\u5f00\u53d1\u7968\uff0c\u653f\u5e9c\u7a0e\u6536\u4e0d\u53d8\uff0c\u9910\u9986\u6536\u5165\u4e0d\u53d8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e00\u6761\u72ed\u7a84\u7684\u5df7\u5b50\u91cc\uff0c\u4e24\u4e2a\u5e74\u8f7b\u4eba\u9a91\u7740\u81ea\u884c\u8f66\u76f8\u5411\u800c\u884c\uff0c\u6bcf\u4e2a\u4eba\u90fd\u6709\u4e24\u4e2a\u7b56\u7565\uff0c\u5373\u6216\u8005\u9009\u62e9\u201c\u51b2\u8fc7\u53bb\u201d\uff0c\u6216\u8005\u9009\u62e9\u201c\u907f\u8ba9\u201d\u3002\u5982\u679c\u9009\u62e9\u907f\u8ba9\uff0c\u4e0d\u7ba1\u5bf9\u65b9\u91c7\u53d6\u4ec0\u4e48\u7b56\u7565\uff0c\u4ed6\u5f97\u5230\u7684\u6536\u76ca\u90fd\u662f0\uff0c\u5982\u679c\u4e00\u4eba\u91c7\u53d6\u201c\u51b2\u8fc7\u53bb\u201d\u7684\u6218\u7565\uff0c\u90a3\u4e48\u5982\u679c\u5bf9\u65b9\u91c7\u53d6\u201c\u907f\u8ba9\u201d\uff0c\u4ed6\u5f97\u5230\u7684\u6536\u76ca\u662f9\uff1b\u5982\u679c\u5bf9\u65b9\u4e0d\u907f\u8ba9\uff0c\u4ed6\u5f97\u5230\u7684\u6536\u76ca\u662f-36\u3002\u8fd9\u4e2a\u535a\u5f08\u6709\u4e24\u4e2a\u7eaf\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\u548c____\u3002\nA. \u4e00\u4e2a\u6df7\u5408\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\uff0c\u5373\u4e24\u4e2a\u4eba\u90fd\u4ee580%\u7684\u6982\u7387\u9009\u62e9\u201c\u907f\u8ba9\u201d\uff0c\u4ee520%\u7684\u6982\u7387\u9009\u62e9\u201c\u51b2\u8fc7\u53bb\u201d\nB. \u4e00\u4e2a\u6df7\u5408\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\uff0c\u5373\u4e00\u4e2a\u4eba\u4ee520%\u7684\u6982\u7387\u9009\u62e9\u201c\u907f\u8ba9\u201d\uff0c\u53e6\u4e00\u4e2a\u4eba\u4ee580%\u7684\u6982\u7387\u9009\u62e9\u201c\u51b2\u8fc7\u53bb\u201d\nC. \u4e00\u4e2a\u6df7\u5408\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\uff0c\u5373\u4e24\u4e2a\u4eba\u90fd\u4ee540%\u7684\u6982\u7387\u9009\u62e9\u201c\u907f\u8ba9\u201d\uff0c\u4ee560%\u7684\u6982\u7387\u9009\u62e9\u201c\u51b2\u8fc7\u53bb\u201d\nD. \u6ca1\u6709\u6df7\u5408\u7b56\u7565\u7eb3\u4ec0\u5747\u8861\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4799561017076586, "meta-llama/Meta-Llama-3-8B": 0.37106892011530584, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8009512265560875}}, {"question": "\u5047\u8bbe\u4e00\u56fd\u7684\u03b2=0.8\uff0c\u653f\u5e9c\u8d2d\u4e70\u652f\u51fa\u51cf\u5c11\u4e86100\u4ebf\u5143\uff0c\u7531\u6b64\u4ea7\u751f\u7684\u653f\u5e9c\u8d22\u653f\u76c8\u4f59\u901a\u8fc7\u51cf\u5c11\u7b49\u989d\u7684\u7a0e\u6536\u6765\u62b5\u6d88\u3002\u90a3\u4e48\uff0c\u5bf9\u56fd\u6c11\u6536\u5165\u7684\u5f71\u54cd\u4e3a____\u3002\nA. \u589e\u52a0500\u4ebf\u5143\nB. \u589e\u52a0400\u4ebf\u5143\nC. \u51cf\u5c11100\u4ebf\u5143\nD. \u653f\u5e9c\u8d2d\u4e70\u652f\u51fa\u51cf\u5c11\u989d\u4e3a\u7a0e\u6536\u6240\u62b5\u6d88\uff0c\u6545\u5bf9\u56fd\u6c11\u6536\u5165\u6ca1\u6709\u5f71\u54cd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.35347162922091135, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5982\u56fe\u6240\u793a\uff0c\u4e24\u4e2a\u6d88\u8d39\u8005\u7684\u65e0\u5dee\u5f02\u66f2\u7ebf\u76f8\u5207\u4e8eE1\u3001E2\u3001E3\uff0c\u8fd9\u610f\u5473\u7740____\u3002\nA. \u5bf9\u4e8e\u6d88\u8d39\u80051\u800c\u8a00\uff0cE1\u7684\u6548\u7528\u6c34\u5e73\u9ad8\u4e8eE2\nB. \u5bf9\u4e8e\u6d88\u8d39\u80052\u800c\u8a00\uff0cE3\u7684\u6548\u7528\u6c34\u5e73\u9ad8\u4e8eE2\nC. E2\u5c5e\u4e8e\u5e15\u7d2f\u6258\u6700\u4f18\u72b6\u6001\uff0cE1\u548cE3\u4e0d\u5c5e\u4e8e\u5e15\u7d2f\u6258\u6700\u4f18\u72b6\u6001\nD. E1\u3001E2\u3001E3\u90fd\u5c5e\u4e8e\u5e15\u7d2f\u6258\u6700\u4f18\u72b6\u6001\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9677477056182922, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6d1b\u4f26\u5179\u66f2\u7ebf\u8d8a\u662f\u5411\u6a2a\u8f74\u51f8\u51fa____\nA. \u57fa\u5c3c\u7cfb\u6570\u5c31\u8d8a\u5927\uff0c\u6536\u5165\u5c31\u8d8a\u4e0d\u5e73\u7b49\nB. \u57fa\u5c3c\u7cfb\u6570\u5c31\u8d8a\u5927\uff0c\u6536\u5165\u5c31\u8d8a\u5e73\u7b49\nC. \u57fa\u5c3c\u7cfb\u6570\u5c31\u8d8a\u5c0f\uff0c\u6536\u5165\u5c31\u8d8a\u4e0d\u5e73\u7b49\nD. \u57fa\u5c3c\u7cfb\u6570\u5c31\u8d8a\u5c0f\uff0c\u6536\u5165\u5c31\u8d8a\u5e73\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3451965101036009, "meta-math/MetaMath-Mistral-7B": 0.37727078344562215, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8008523629638097, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3965792336840251, "meta-llama/Meta-Llama-3-8B": 0.6379189580705046, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9563167781173557}}, {"question": "\u5e8f\u6570\u6548\u7528\u8bba\u5bf9\u6d88\u8d39\u8005\u504f\u597d\u7684\u5047\u8bbe\u5305\u62ec____\nA. \u8fb9\u9645\u6548\u7528\u9012\u51cf\nB. \u8d27\u5e01\u8fb9\u9645\u6548\u7528\u4e0d\u53d8\nC. \u4f20\u9012\u6027\nD. \u4e0d\u9971\u548c\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3404063339940579, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e0d\u8003\u8651\u7a0e\u6536\u548c\u8865\u8d34\u7684\u60c5\u51b5\u4e0b\uff0c\u4f01\u4e1a\u5c06\u8d44\u672c\u7684\u79df\u91d1\u6210\u672c\u8ba1\u7b97\u4e3a____\u3002\nA. \u5b9e\u9645\u5229\u7387\nB. \u8d44\u672c\u54c1\u4ef7\u683c\u00d7(\u540d\u4e49\u5229\u7387\u51cf\u53bb\u901a\u8d27\u81a8\u80c0\u7387\u518d\u52a0\u4e0a\u6298\u65e7\u7387)\nC. \u540d\u4e49\u5229\u7387\u51cf\u53bb\u6298\u65e7\u7387\nD. \u540d\u4e49\u5229\u7387\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.7433685862153326, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41450855768209555, "meta-llama/Meta-Llama-3-8B": 0.5015219506515167, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9480754480163354}}, {"question": "\u82e5\u5728d\u66f2\u7ebf\u4e0a\u67d0\u4e00\u70b9\u7684Ed=3\uff0cP=6\uff0c\u5219\u76f8\u5e94\u7684MR\u4e3a____\nA. MR=2\nB. MR=4\nC. MR=18\nD. MR=1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3548205732608228, "meta-math/MetaMath-Mistral-7B": 0.45775675064356536, "itpossible/Chinese-Mistral-7B-v0.1": 0.31712010892822357, "HuggingFaceH4/zephyr-7b-beta": 0.620582128360112, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3973062479607977, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5784\u65ad\u7ade\u4e89\u5382\u5546\u83b7\u5f97\u6700\u5927\u5229\u6da6\u7684\u65b9\u6cd5\u6709____\nA. \u8d28\u91cf\u7ade\u4e89\nB. \u8c03\u6574\u4ef7\u683c\u4ece\u800c\u786e\u5b9a\u4ea7\u91cf\nC. \u5e7f\u544a\u7ade\u4e89\nD. \u4e0a\u8ff0\u65b9\u6cd5\u90fd\u53ef\u4ee5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6383389249186722, "meta-math/MetaMath-Mistral-7B": 0.656107385664403, "itpossible/Chinese-Mistral-7B-v0.1": 0.5099803739829025, "HuggingFaceH4/zephyr-7b-beta": 0.6727623125004696, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8555864400553518, "meta-llama/Meta-Llama-3-8B": 0.5428968144723807, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8477928901398069}}, {"question": "\u6839\u636e\u751f\u547d\u5468\u671f\u5047\u8bf4\uff0c\u6d88\u8d39\u8005\u7684\u6d88\u8d39\u5bf9\u79ef\u7d2f\u7684\u8d22\u5bcc\u7684\u6bd4\u7387\u7684\u53d8\u5316\u60c5\u51b5\u662f____\u3002\nA. \u5728\u9000\u4f11\u524d\uff0c\u8fd9\u4e2a\u6bd4\u7387\u662f\u4e0a\u5347\u7684\uff0c\u9000\u4f11\u540e\uff0c\u8fd9\u4e2a\u6bd4\u7387\u662f\u4e0b\u964d\u7684\nB. \u5728\u9000\u4f11\u524d\u540e\uff0c\u8fd9\u4e2a\u6bd4\u7387\u4fdd\u6301\u4e0d\u53d8\nC. \u5728\u9000\u4f11\u524d\u540e\uff0c\u8fd9\u4e2a\u6bd4\u7387\u90fd\u4e0b\u964d\nD. \u5728\u9000\u4f11\u524d\uff0c\u8fd9\u4e2a\u6bd4\u7387\u4e0b\u964d\uff0c\u9000\u4f11\u540e\uff0c\u5219\u4f1a\u4e0a\u5347\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u80a1\u7968\u7684\u03b2\u503c\u4e3a1.8\uff0c\u80a1\u7968\u5e02\u573a\u62a5\u916c\u7387\u662f10%\uff0c\u5e02\u573a\u65e0\u98ce\u9669\u62a5\u916c\u7387\u4e3a6%\u3002\u6309\u7167\u8d44\u672c\u8d44\u4ea7\u5b9a\u4ef7\u6a21\u578b\uff0c\u8be5\u80a1\u7968\u7684\u9884\u671f\u62a5\u916c\u7387\u662f____\u3002\nA. 0.122\nB. 0.132\nC. 0.142\nD. 0.152\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5604220049089867, "itpossible/Chinese-Mistral-7B-v0.1": 0.325455072595945, "HuggingFaceH4/zephyr-7b-beta": 0.653511455594776, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e0d\u5c5e\u4e8e\u653f\u5e9c\u8d2d\u4e70\u7684\u662f____\u3002\nA. \u5730\u65b9\u653f\u5e9c\u529e\u4e09\u6240\u4e2d\u5b66\nB. \u653f\u5e9c\u7ed9\u4f4e\u6536\u5165\u8005\u63d0\u4f9b\u4e00\u7b14\u4f4f\u623f\u8865\u8d34\nC. \u653f\u5e9c\u8ba2\u8d2d\u4e00\u6279\u519b\u706b\nD. \u653f\u5e9c\u5efa\u9020\u529e\u516c\u5927\u697c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5808696715925967, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.787717092924915}}, {"question": "\u5784\u65ad\u7ade\u4e89\u5382\u5546\u7684\u957f\u671f\u5747\u8861\u4e0e\u77ed\u671f\u5747\u8861\u7684\u533a\u522b\u662f\u957f\u671f\u5747\u8861\u7684____\nA. P=ACmin\nB. \u5382\u5546\u7684\u4e3b\u89c2\u9700\u6c42\u66f2\u7ebf\u4e0e\u957f\u671f\u5e73\u5747\u6210\u672c\u66f2\u7ebf\u76f8\u5207\nC. P=AC\nD. \u4e3b\u89c2\u9700\u6c42\u66f2\u7ebf\u4e0e\u5ba2\u89c2\u9700\u6c42\u66f2\u7ebf\u76f8\u4ea4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5665817161789983, "meta-math/MetaMath-Mistral-7B": 0.7128185994432568, "itpossible/Chinese-Mistral-7B-v0.1": 0.6061550883787997, "HuggingFaceH4/zephyr-7b-beta": 0.9938418321456136, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8472389630058359, "meta-llama/Meta-Llama-3-8B": 0.3376787962540697, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.755298571180002}}, {"question": "\u5916\u90e8\u6548\u5e94\u53ef\u4ee5\u4ea7\u751f\u4e8e____\nA. \u4eba\u7684\u6d88\u8d39\u884c\u4e3a\u800c\u975e\u751f\u4ea7\u884c\u4e3a\nB. \u4eba\u7684\u751f\u4ea7\u884c\u4e3a\u800c\u975e\u6d88\u8d39\u884c\u4e3a\nC. \u4eba\u7684\u751f\u4ea7\u884c\u4e3a\u548c\u6d88\u8d39\u884c\u4e3a\nD. \u4ee5\u4e0a\u90fd\u4e0d\u662f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.580869657081244, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6391153470587037, "meta-llama/Meta-Llama-3-8B": 0.5512254303198422, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.963174645256175}}, {"question": "\u5170\u5fb7\u53ea\u4e70\u6fc0\u5149\u5531\u7247\u548c\u68d2\u68d2\u7cd6\uff0c\u4ed6\u6709\u56fa\u5b9a\u6536\u5165\uff0c\u4e0d\u80fd\u501f\u94b1\uff0c\u5f53\u4ed6\u6cbf\u7740\u9884\u7b97\u7ea6\u675f\u79fb\u52a8\u65f6____\nA. \u6fc0\u5149\u5531\u7247\u7684\u4ef7\u683c\u5728\u6539\u53d8\uff0c\u800c\u5176\u6536\u5165\u548c\u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u4e0d\u53d8\nB. \u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u5728\u6539\u53d8\uff0c\u800c\u5176\u6536\u5165\u548c\u6fc0\u5149\u5531\u7247\u7684\u4ef7\u683c\u4e0d\u53d8\nC. \u6fc0\u5149\u5531\u7247\u548c\u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u5728\u6539\u53d8\uff0c\u800c\u5176\u6536\u5165\u4e0d\u53d8\nD. \u6fc0\u5149\u5531\u7247\u548c\u68d2\u68d2\u7cd6\u7684\u4ef7\u683c\u53ca\u5176\u6536\u5165\u90fd\u4e0d\u53d8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5277410454445566, "meta-math/MetaMath-Mistral-7B": 0.7050335216456776, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5434540965980945, "meta-llama/Meta-Llama-3-8B": 0.4451323593242925, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5577580730018756}}, {"question": "\u6700\u65e9\u5bf9\u7ba1\u7406\u7684\u5177\u4f53\u804c\u80fd\u52a0\u4ee5\u6982\u62ec\u548c\u7cfb\u7edf\u8bba\u8ff0\u7684\u662f____\u3002\nA. \u6cf0\u7f57\nB. \u6cd5\u7ea6\u5c14\nC. \u5b54\u8328\nD. \u97e6\u4f2f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3160424181481997, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.33003647588489426, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5190768741225268}}, {"question": "\u6d88\u8d39\u8005\u4e0d\u77e5\u9053\uff0c\u6216\u8005\u867d\u7136\u77e5\u9053\u4f46\u6ca1\u6709\u5174\u8da3\u8d2d\u4e70\u7684\u7269\u54c1\u4e3a____\u3002\nA. \u4fbf\u5229\u54c1\nB. \u9009\u8d2d\u54c1\nC. \u7279\u6b8a\u54c1\nD. \u975e\u6e34\u6c42\u54c1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5700425313147408, "meta-math/MetaMath-Mistral-7B": 0.8483894030297767, "itpossible/Chinese-Mistral-7B-v0.1": 0.7466118889057977, "HuggingFaceH4/zephyr-7b-beta": 0.9985509094357294, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9402748804734222, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9932189453188901}}, {"question": "\u5f53\u6240\u5728\u884c\u4e1a\u5904\u4e8e\u5bff\u547d\u5468\u671f\u7684\u6210\u719f\u671f\u65f6\uff0c\u5927\u4f01\u4e1a\u5e94\u91c7\u53d6\u7684\u7ade\u4e89\u6218\u7565\u662f____\u3002\nA. \u96c6\u4e2d\u5316\u6218\u7565\nB. \u6210\u672c\u96c6\u805a\u6218\u7565\nC. \u7a33\u5b9a\u578b\u6218\u7565\nD. \u5dee\u5f02\u5316\u6218\u7565\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6509424950115215, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\uff0c\u5bf9\u4e00\u822c\u7eb3\u7a0e\u4f01\u4e1a\u6765\u8bf4\uff0c\u4e00\u822c\u4e0d\u6784\u6210\u5916\u8d2d\u5b58\u8d27\u6210\u672c\u7684\u662f____\u3002\nA. \u5165\u5e93\u524d\u7684\u4ed3\u50a8\u8d39\nB. \u8fdb\u53e3\u5173\u7a0e\nC. \u652f\u4ed8\u7684\u589e\u503c\u7a0e\nD. \u8fd0\u8f93\u8d39\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6061547623194425, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4287649028625185, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7094916784324344}}, {"question": "\u300a\u4ef7\u683c\u6cd5\u300b\u5e76\u6ca1\u6709\u5bf9\u6240\u6709\u7684\u4ef7\u683c\u6b67\u89c6\u90fd\u52a0\u4ee5\u7981\u6b62\uff0c\u5e94\u52a0\u4ee5\u7981\u6b62\u7684\u4ef7\u683c\u6b67\u89c6\u884c\u4e3a\u662f____\nA. \u7532\u4f01\u4e1a\u5bf9\u4e59\u4f01\u4e1a\u548c\u4e19\u4f01\u4e1a\u63d0\u4f9b\u76f8\u540c\u7684\u5546\u54c1\u6216\u670d\u52a1\uff0c\u4f46\u5b9e\u884c\u4e0d\u540c\u7684\u4ef7\u683c\nB. \u8fd0\u8f93\u4f01\u4e1a\u5bf9\u8001\u4eba\u3001\u5728\u5c97\u4eba\u5458\u548c\u5b66\u751f\u5236\u5b9a\u4e0d\u540c\u7684\u4ef7\u683c\nC. \u5bd2\u6691\u5047\u671f\u95f4\uff0c\u6c11\u822a\u5bf9\u4e58\u5750\u98de\u673a\u7684\u6559\u5e08\u53ef\u51ed\u6559\u5e08\u8bc1\u7ed9\u4e887\u6298\u4f18\u60e0\nD. \u7535\u4fe1\u90e8\u95e8\u5bf9\u5355\u4f4d\u7528\u5e02\u8bdd\u548c\u5bb6\u5ead\u7528\u5e02\u8bdd\u5236\u5b9a\u4e0d\u540c\u7684\u6536\u8d39\u6807\u51c6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44513234878341673, "meta-math/MetaMath-Mistral-7B": 0.6711776164320303, "itpossible/Chinese-Mistral-7B-v0.1": 0.4032266808331313, "HuggingFaceH4/zephyr-7b-beta": 0.9906059334965734, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7271183670996166, "meta-llama/Meta-Llama-3-8B": 0.4423863496854548, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.43439970499757213}}, {"question": "\u67d0\u4f01\u4e1a\u751f\u4ea7A\u3001B\u548cC\u4e09\u79cd\u5546\u54c1\uff0c\u9884\u8ba1\u5404\u81ea\u7684\u9500\u552e\u91cf\u4e3a1000\u4ef6\u3001500\u4ef6\u548c500\u4ef6\uff0c\u4e09\u79cd\u4ea7\u54c1\u7684\u5355\u4f4d\u8fb9\u9645\u8d21\u732e\u5206\u522b\u4e3a10\u30018\u548c6\uff0c\u4f01\u4e1a\u7684\u56fa\u5b9a\u6210\u672c\u4e3a340000\u5143\u3002\u4ee5\u4e0b\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u4ea7\u54c1\u7ec4\u5408\u4ea7\u751f\u7684\u52a0\u6743\u8fb9\u9645\u8d21\u732e\u4e3a34\nB. \u82e5\u4f9d\u7167\u9884\u8ba1\u9500\u91cf\u7684\u6bd4\u4f8b\u8fdb\u884c\u9500\u552e\uff0c\u5219\u4fdd\u672c\u70b9\u7684\u9500\u552e\u989d\u4e3a800000\u5143\nC. \u4ea7\u54c1\u7ec4\u5408\u4ea7\u751f\u7684\u52a0\u6743\u8fb9\u9645\u8d21\u732e\u4e3a8.5\nD. \u4ea7\u54c1\u7ec4\u5408\u7684\u5355\u4f4d\u9500\u552e\u4ef7\u683c\u4e3a80\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.35125369870111733, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6116408101275953}}, {"question": "\u5bf9\u4e8e\u81ea\u884c\u5f00\u53d1\u53d6\u5f97\u7684\u65e0\u5f62\u8d44\u4ea7\uff0c\u5728\u7814\u7a76\u9636\u6bb5\u53d1\u751f\u7684\u652f\u51fa\u5e94\u8ba1\u5165____\u3002\nA. \u65e0\u5f62\u8d44\u4ea7\u7684\u6210\u672c\nB. \u5f53\u671f\u635f\u76ca\nC. \u6295\u8d44\u6536\u76ca\nD. \u5176\u4ed6\u4e1a\u52a1\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29863342676099575, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4702008361011121, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.40870097338816036, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u4e0d\u5b58\u5728\u51cf\u503c\u8ff9\u8c61\u7684\u53ef\u4f9b\u51fa\u552e\u91d1\u878d\u8d44\u4ea7\u4f1a\u8ba1\u5904\u7406\u7684\u8868\u8ff0\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u53d6\u5f97\u65f6\u5c06\u53d1\u751f\u7684\u76f8\u5173\u4ea4\u6613\u8d39\u7528\u8ba1\u5165\u5f53\u671f\u635f\u76ca\nB. \u5c06\u51fa\u552e\u7684\u5269\u4f59\u90e8\u5206\u91cd\u5206\u7c7b\u4e3a\u4ea4\u6613\u6027\u91d1\u878d\u8d44\u4ea7\nC. \u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\u5c06\u516c\u5141\u4ef7\u503c\u4e0e\u8d26\u9762\u4ef7\u503c\u7684\u5dee\u989d\u8ba1\u5165\u5f53\u671f\u635f\u76ca\nD. \u5c06\u51fa\u552e\u65f6\u5b9e\u9645\u6536\u5230\u7684\u91d1\u989d\u4e0e\u8d26\u9762\u4ef7\u503c\u4e4b\u95f4\u7684\u5dee\u989d\u8ba1\u5165\u5f53\u671f\u635f\u76ca\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.2986334267609957, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7646358623891729, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5667288424361497, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u91d1\u878d\u8d44\u4ea7\u7684\u540e\u7eed\u8ba1\u91cf\u7684\u8bf4\u6cd5\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\uff0c\u4f01\u4e1a\u5e94\u4ee5\u516c\u5141\u4ef7\u503c\u8ba1\u91cf\uff0c\u4e14\u5176\u53d8\u52a8\u8ba1\u5165\u5f53\u671f\u635f\u76ca\u7684\u91d1\u878d\u8d44\u4ea7\u7684\u516c\u5141\u4ef7\u503c\u53d8\u52a8\u8ba1\u5165\u5f53\u671f\u635f\u76ca\nB. \u4ee5\u644a\u4f59\u6210\u672c\u8ba1\u91cf\u7684\u91d1\u878d\u8d44\u4ea7\u5728\u6301\u6709\u671f\u95f4\u5e94\u5f53\u6309\u7167\u644a\u4f59\u6210\u672c\u548c\u5b9e\u9645\u5229\u7387\u8ba1\u7b97\u786e\u8ba4\u5229\u606f\u6536\u5165\uff0c\u8ba1\u5165\u6295\u8d44\u6536\u76ca\nC. \u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\uff0c\u4ee5\u516c\u5141\u4ef7\u503c\u8ba1\u91cf\u4e14\u5176\u53d8\u52a8\u8ba1\u5165\u5176\u4ed6\u7efc\u5408\u6536\u76ca\u7684\u91d1\u878d\u8d44\u4ea7\u5e94\u5f53\u4ee5\u516c\u5141\u4ef7\u503c\u8ba1\u91cf\uff0c\u516c\u5141\u4ef7\u503c\u5927\u4e8e\u53d6\u5f97\u6210\u672c\u7684\u5dee\u989d\u8ba1\u5165\u5176\u4ed6\u7efc\u5408\u6536\u76ca\nD. \u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\uff0c\u4ee5\u516c\u5141\u4ef7\u503c\u8ba1\u91cf\u4e14\u5176\u53d8\u52a8\u8ba1\u5165\u5176\u4ed6\u7efc\u5408\u6536\u76ca\u7684\u91d1\u878d\u8d44\u4ea7\u5e94\u5f53\u4ee5\u516c\u5141\u4ef7\u503c\u8ba1\u91cf\uff0c\u4e14\u5176\u516c\u5141\u4ef7\u503c\u53d8\u52a8\u8ba1\u5165\u5f53\u671f\u635f\u76ca\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.44670213442737516, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8202677147660684, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.47369844409714335}}, {"question": "\u7ecf\u8425\u6218\u7565\u7684\u672c\u8d28\u662f____\u3002\nA. \u76ee\u6807\u4e0e\u76ee\u7684\nB. \u8d44\u6e90\nC. \u516c\u53f8\u8fdc\u666f\nD. \u7ec4\u7ec7\u7ed3\u6784\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.44670213442737516, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u6295\u8d44\u9879\u76ee\u73b0\u91d1\u6d41\u51fa\u91cf\u5185\u5bb9\u7684\u662f____\u3002\nA. \u56fa\u5b9a\u8d44\u4ea7\u6295\u8d44\nB. \u6298\u65e7\u4e0e\u644a\u9500\nC. \u65e0\u5f62\u8d44\u4ea7\u6295\u8d44\nD. \u65b0\u589e\u7ecf\u8425\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3349017772288393, "HuggingFaceH4/zephyr-7b-beta": 0.6428768423200969, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34040633907578005, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5047\u8bbe\u4e1a\u52a1\u53d1\u751f\u524d\u901f\u52a8\u6bd4\u7387\u5927\u4e8e1\uff0c\u507f\u8fd8\u5e94\u4ed8\u8d26\u6b3e\u82e5\u5e72\uff0c\u5c06\u4f1a____\u3002\nA. \u589e\u5927\u6d41\u52a8\u6bd4\u7387\uff0c\u4e0d\u5f71\u54cd\u901f\u52a8\u6bd4\u7387\nB. \u589e\u5927\u901f\u52a8\u6bd4\u7387\uff0c\u4e0d\u5f71\u54cd\u6d41\u52a8\u6bd4\u7387\nC. \u589e\u5927\u6d41\u52a8\u6bd4\u7387\uff0c\u4e5f\u589e\u5927\u901f\u52a8\u6bd4\u7387\nD. \u964d\u4f4e\u6d41\u52a8\u6bd4\u7387\uff0c\u4e5f\u964d\u4f4e\u901f\u52a8\u6bd4\u7387\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4740701836236387, "meta-math/MetaMath-Mistral-7B": 0.6692186977759048, "itpossible/Chinese-Mistral-7B-v0.1": 0.325455072595945, "HuggingFaceH4/zephyr-7b-beta": 0.7108923360191666, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5667617237191022, "meta-llama/Meta-Llama-3-8B": 0.3881207341645942, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4933842006694412}}, {"question": "\u5f53\u4e24\u4e2a\u6295\u8d44\u65b9\u6848\u4e3a\u4e92\u65a5\u9009\u62e9\u65f6\uff0c\u5e94\u4f18\u5148\u9009\u62e9____\u3002\nA. \u51c0\u73b0\u503c\u5927\u7684\u65b9\u6848\nB. \u73b0\u503c\u6307\u6570\u5927\u7684\u65b9\u6848\nC. \u5185\u542b\u62a5\u916c\u7387\u5927\u7684\u65b9\u6848\nD. \u6295\u8d44\u989d\u5c0f\u7684\u65b9\u6848\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45138529903970087, "meta-math/MetaMath-Mistral-7B": 0.4440340683943228, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.708962679331087, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5820226728469899, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6518775818530134}}, {"question": "\u5df2\u77e5\u67d0\u4f01\u4e1a\u751f\u4ea7\u9500\u552e\u7532\u3001\u4e59\u4e24\u79cd\u4ea7\u54c1\uff0c2005\u5e74\u9500\u552e\u91cf\u5206\u522b\u4e3a10\u4e07\u4ef6\u548c15\u4e07\u4ef6\uff0c\u5355\u4ef7\u5206\u522b\u4e3a20\u5143\u548c30\u5143\uff0c\u5355\u4f4d\u53d8\u52a8\u6210\u672c\u5206\u522b\u4e3a12\u5143\u548c15\u5143\uff0c\u5355\u4f4d\u53d8\u52a8\u9500\u552e\u6210\u672c\u5206\u522b\u4e3a10\u5143\u548c12\u5143\uff0c\u56fa\u5b9a\u6210\u672c\u603b\u989d\u4e3a100\u4e07\u5143\uff0c\u5219\u4e0b\u5217\u8bf4\u6cd5\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u52a0\u6743\u5e73\u5747\u8fb9\u9645\u8d21\u732e\u738756\nB. \u52a0\u6743\u5e73\u5747\u8fb9\u9645\u8d21\u732e\u7387\u4e3a46\nC. \u76c8\u4e8f\u4e34\u754c\u70b9\u9500\u552e\u989d\u4e3a213\nD. \u7532\u4ea7\u54c1\u76c8\u4e8f\u4e34\u754c\u70b9\u9500\u552e\u91cf\u4e3a3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.264634220591857, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.364715132252004}}, {"question": "\u5bf9\u4e8e\u4e0b\u5217\u957f\u671f\u80a1\u6743\u6295\u8d44\uff0c\u5e94\u91c7\u7528\u6743\u76ca\u6cd5\u6838\u7b97\u7684\u662f____\u3002\nA. \u5bf9\u8054\u8425\u4f01\u4e1a\u7684\u6295\u8d44\nB. \u4e0d\u5177\u6709\u5171\u540c\u63a7\u5236\u6216\u91cd\u5927\u5f71\u54cd\u5173\u7cfb\u4e14\u5728\u6d3b\u8dc3\u7684\u5e02\u573a\u4e2d\u6ca1\u6709\u62a5\u4ef7\u3001\u516c\u5141\u4ef7\u503c\uff0c\u4e0d\u80fd\u53ef\u9760\u8ba1\u91cf\u7684\u6295\u8d44\nC. \u5bf9\u63a7\u80a1\u5b50\u516c\u53f8\u7684\u6295\u8d44\nD. \u4e0d\u5177\u6709\u5171\u540c\u63a7\u5236\u6216\u91cd\u5927\u5f71\u54cd\u5173\u7cfb\uff0c\u4f46\u5728\u6d3b\u8dc3\u7684\u5e02\u573a\u4e2d\u6709\u62a5\u4ef7\u3001\u516c\u5141\u4ef7\u503c\uff0c\u80fd\u591f\u53ef\u9760\u8ba1\u91cf\u7684\u6295\u8d44\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4f01\u4e1a\u53ea\u751f\u4ea7\u4e00\u79cd\u4ea7\u54c1\uff0c\u5355\u4ef75\u5143\uff0c\u9500\u91cf100\u4ef6\uff0c\u53d8\u52a8\u6210\u672c\u738730%\uff0c\u5219\u8d21\u732e\u8fb9\u9645\u4e3a____\u3002\nA. 150\u5143\nB. 250\u5143\nC. 350\u5143\nD. 450\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.371068906204966, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.31283638571410965, "HuggingFaceH4/zephyr-7b-beta": 0.47001127285496247, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.398556353954811, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.42276109586836896}}, {"question": "\u5df2\u77e5\u67d0\u6295\u8d44\u9879\u76ee\u7684\u539f\u59cb\u6295\u8d44\u989d\u4e3a1500\u4e07\u5143\uff0c\u5efa\u8bbe\u671f2\u5e74\uff0c\u6295\u4ea7\u540e\u7b2c1\u5e74\u5230\u7b2c5\u5e74\u6bcf\u5e74\u51c0\u73b0\u91d1\u6d41\u91cf\u4e3a50\u4e07\u5143\uff0c\u7b2c6\u5e74\u5230\u7b2c10\u5e74\u6bcf\u5e74\u51c0\u73b0\u91d1\u6d41\u91cf\u4e3a80\u4e07\u5143\uff0c\u5219\u8be5\u9879\u76ee\u5305\u62ec\u5efa\u8bbe\u671f\u7684\u9759\u6001\u6295\u8d44\u56de\u6536\u671f\u4e3a____\u5e74\u3002\nA. 6.375\nB. 8.375\nC. 5.625\nD. 7.625\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fb9\u9645\u8d21\u732e\u7387\u548c\u53d8\u52a8\u6210\u672c\u7387____\u3002\nA. \u53cd\u65b9\u5411\u53d8\u5316\nB. \u540c\u65b9\u5411\u53d8\u5316\nC. \u540c\u6bd4\u4f8b\u53d8\u5316\nD. \u53cd\u6bd4\u4f8b\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4289004471859509, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.48312117712076247, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f01\u4e1a\u5185\u90e8\u73af\u5883\u5206\u6790\u7684\u6838\u5fc3\u662f\u5bf9\u4f01\u4e1a____\u7684\u5206\u6790\u3002\nA. \u8d22\u52a1\u72b6\u51b5\nB. \u7814\u7a76\u4e0e\u5f00\u53d1\u80fd\u529b\nC. \u6838\u5fc3\u80fd\u529b\nD. \u7ba1\u7406\u4eba\u5458\u6570\u91cf\u53ca\u7d20\u8d28\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8689892466720064, "meta-math/MetaMath-Mistral-7B": 0.98794020262903, "itpossible/Chinese-Mistral-7B-v0.1": 0.7450747090268928, "HuggingFaceH4/zephyr-7b-beta": 0.9997796013757376, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8395174385855309, "meta-llama/Meta-Llama-3-8B": 0.7961833447436204, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9550008607282151}}, {"question": "\u5b58\u8d27\u7684\u53ef\u53d8\u73b0\u51c0\u503c\u662f\u6307____\u3002\nA. \u9884\u8ba1\u552e\u4ef7\nB. \u73b0\u65f6\u7684\u91cd\u7f6e\u6210\u672c\nC. \u9884\u8ba1\u552e\u4ef7\u51cf\u53bb\u8fdb\u4e00\u6b65\u52a0\u5de5\u7684\u6210\u672c\u548c\u9884\u8ba1\u9500\u552e\u8d39\u7528\nD. \u5b58\u8d27\u7684\u6298\u73b0\u503c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.70663485487411, "meta-math/MetaMath-Mistral-7B": 0.8773309336923957, "itpossible/Chinese-Mistral-7B-v0.1": 0.555363569482486, "HuggingFaceH4/zephyr-7b-beta": 0.9986895262326274, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8585193248628898, "meta-llama/Meta-Llama-3-8B": 0.750818163194875, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8849950732791567}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u5c5e\u4e8e\u72ed\u4e49\u5728\u4ea7\u54c1\u7684\u662f____\u3002\nA. \u6b63\u5728\u8f66\u95f4\u52a0\u5de5\u7684\u5728\u5236\u54c1\nB. \u672c\u6b65\u9aa4\u5df2\u5b8c\u5de5\uff0c\u4f46\u8fd8\u9700\u7ee7\u7eed\u52a0\u5de5\u7684\u534a\u6210\u54c1\nC. \u5df2\u5b8c\u5de5\uff0c\u4f46\u5c1a\u672a\u9a8c\u6536\u5165\u5e93\u7684\u4ea7\u6210\u54c1\nD. \u5df2\u5b8c\u5de5\uff0c\u4f46\u9700\u5bf9\u5916\u9500\u552e\u7684\u81ea\u5236\u534a\u6210\u54c1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u635f\u5931\uff0c\u4e0b\u5217\u8bf4\u6cd5\u4e2d\u6b63\u786e\u7684\u662f____\u3002\nA. \u635f\u5931\u662f\u6307\u7531\u4f01\u4e1a\u65e5\u5e38\u6d3b\u52a8\u6240\u53d1\u751f\u7684\u3001\u4f1a\u5bfc\u81f4\u6240\u6709\u8005\u6743\u76ca\u51cf\u5c11\u7684\u7ecf\u6d4e\u5229\u76ca\u7684\u6d41\u51fa\nB. \u635f\u5931\u53ea\u80fd\u8ba1\u5165\u6240\u6709\u8005\u6743\u76ca\u9879\u76ee\uff0c\u4e0d\u80fd\u8ba1\u5165\u5f53\u671f\u635f\u76ca\nC. \u635f\u5931\u662f\u6307\u7531\u4f01\u4e1a\u975e\u65e5\u5e38\u6d3b\u52a8\u6240\u53d1\u751f\u7684\u3001\u4f1a\u5bfc\u81f4\u6240\u6709\u8005\u6743\u76ca\u51cf\u5c11\u7684\u3001\u4e0e\u5411\u6240\u6709\u8005\u5206\u914d\u5229\u6da6\u65e0\u5173\u7684\u7ecf\u6d4e\u5229\u76ca\u7684\u6d41\u51fa\nD. \u635f\u5931\u53ea\u80fd\u8ba1\u5165\u5f53\u671f\u635f\u76ca\uff0c\u4e0d\u80fd\u8ba1\u5165\u6240\u6709\u8005\u6743\u76ca\u9879\u76ee\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6165871605546532, "meta-math/MetaMath-Mistral-7B": 0.8660004947800735, "itpossible/Chinese-Mistral-7B-v0.1": 0.3749196223738779, "HuggingFaceH4/zephyr-7b-beta": 0.9892131905582008, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5374779395107208, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5229\u6da6\u662f\u8fb9\u9645\u8d21\u732e\u548c____\u7684\u5dee\u989d\u3002\nA. \u53d8\u52a8\u6210\u672c\nB. \u56fa\u5b9a\u6210\u672c\u603b\u989d\nC. \u9500\u552e\u6536\u5165\nD. \u6210\u672c\u603b\u989d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36321227331295963, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u91c7\u7528\u6743\u76ca\u6cd5\u6838\u7b97\u957f\u671f\u80a1\u6743\u6295\u8d44\u65f6\uff0c\u5bf9\u4e8e\u88ab\u6295\u8d44\u4f01\u4e1a\u56e0\u5916\u5e01\u8d44\u672c\u7ed3\u7b97\u5f15\u8d77\u7684\u6240\u6709\u8005\u6743\u76ca\u7684\u589e\u52a0\uff0c\u6295\u8d44\u4f01\u4e1a\u5e94\u6309\u6240\u62e5\u6709\u7684\u8868\u51b3\u6743\u8d44\u672c\u7684\u6bd4\u4f8b\u8ba1\u7b97\u5e94\u4eab\u6709\u7684\u4efd\u989d\uff0c\u5c06\u5176\u8ba1\u5165____\u3002\nA. \u8d44\u672c\u516c\u79ef\nB. \u6295\u8d44\u6536\u76ca\nC. \u5176\u4ed6\u4e1a\u52a1\u6536\u5165\nD. \u8425\u4e1a\u5916\u6536\u5165\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e24\u4e2a\u65b9\u6848\u7684\u9009\u62e9\u4e2d\uff0c\u7531\u4e8e\u9009\u62e9\u4e00\u4e2a\u65b9\u6848\u800c\u653e\u5f03\u53e6\u4e00\u4e2a\u65b9\u6848\u6240\u5931\u53bb\u7684\u53ef\u80fd\u6536\u76ca\u5c31\u662f\u6240\u9009\u65b9\u6848\u7684____\u3002\nA. \u5dee\u91cf\u6210\u672c\nB. \u673a\u4f1a\u6210\u672c\nC. \u8fb9\u9645\u6210\u672c\nD. \u91cd\u7f6e\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8856228756060455, "meta-math/MetaMath-Mistral-7B": 0.9733258572890103, "itpossible/Chinese-Mistral-7B-v0.1": 0.9197201724446122, "HuggingFaceH4/zephyr-7b-beta": 0.9990024300275375, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9721018411535751, "meta-llama/Meta-Llama-3-8B": 0.9443083915825868, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9984860172253834}}, {"question": "\u67d0\u80a1\u4efd\u6709\u9650\u516c\u53f8\u5bf9\u671f\u672b\u5b58\u8d27\u91c7\u7528\u6210\u672c\u4e0e\u53ef\u53d8\u73b0\u51c0\u503c\u5b70\u4f4e\u6cd5\u8ba1\u4ef7\uff0c2011\u5e7412\u670831\u65e5A\u5e93\u5b58\u5546\u54c1\u7684\u5b9e\u9645\u6210\u672c\u4e3a40\u4e07\u5143\uff0c\u9884\u8ba1\u8fdb\u4e00\u6b65\u52a0\u5de5\u6240\u9700\u8d39\u7528\u4e3a16\u4e07\u5143\uff0c\u9884\u8ba1\u9500\u552e\u8d39\u7528\u53ca\u7a0e\u91d1\u4e3a8\u4e07\u5143\u3002\u8be5\u5e93\u5b58\u5546\u54c1\u7684\u5e02\u573a\u9500\u552e\u4ef7\u683c\u4e3a60\u4e07\u5143\u3002\u5047\u5b9a\u8be5\u516c\u53f8\u4ee5\u524d\u5e74\u5ea6\u672a\u8ba1\u63d0\u5b58\u8d27\u8dcc\u4ef7\u51c6\u5907\uff0c\u52192011\u5e7412\u670831\u65e5\u8be5\u9879\u5b58\u8d27\u5e94\u8ba1\u63d0\u7684\u8dcc\u4ef7\u51c6\u5907\u4e3a____\u4e07\u5143\u3002\nA. 0\nB. 4\nC. 16\nD. 20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.303006867405966, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u516c\u53f82001\u5e744\u67083\u65e5\u4ee5448000\u5143\u7684\u4ef7\u683c\uff0c\u4e0d\u51c6\u5907\u957f\u671f\u6301\u6709\u7684A\u516c\u53f8\u53d1\u884c\u5728\u5916\u7684\u666e\u901a\u80a1200000\u80a1\uff0c\u53e6\u652f\u4ed8\u76f8\u5173\u7a0e\u8d391000\u5143\u3002A\u516c\u53f8\u5df2\u4e8e2001\u5e743\u670831\u65e5\u5ba3\u544a\u53d1\u653e\u73b0\u91d1\u80a1\u52290.2\u5143/\u80a1\uff0c\u5e76\u4e8e5\u67088\u65e5\u652f\u4ed8\uff0cA\u516c\u53f8\u4e8e2002\u5e743\u670831\u65e5\u5ba3\u544a\u53d1\u653e\u73b0\u91d1\u80a1\u52290.3\u5143/\u80a1\uff0c\u67d0\u516c\u53f8\u4e8e2002\u5e744\u67083\u65e5\u5c06\u8be5\u80a1\u7968\u8f6c\u8ba9\uff0c\u5219\u67d0\u516c\u53f8\u8f6c\u8ba9\u80a1\u7968\u65f6\u6210\u672c\u4ef7\u4e3a____\u5143\u3002\nA. 408000\nB. 409000\nC. 448000\nD. 349000\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3348234986789106, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.28966338381871215, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.34686667406054084}}, {"question": "\u7532\u4f01\u4e1a\u4ee5\u878d\u8d44\u79df\u8d41\u65b9\u5f0f\u79df\u5165\u4e59\u4f01\u4e1a\u7684\u4e00\u53f0\u673a\u68b0\u8bbe\u5907\uff0c\u5219\u4e0b\u5217\u5bf9\u8be5\u8bbe\u5907\u8ba1\u63d0\u6298\u65e7\u7684\u53d9\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u7532\u4f01\u4e1a\u5bf9\u8be5\u8bbe\u5907\u4e0d\u8ba1\u63d0\u6298\u65e7\nB. \u7532\u4f01\u4e1a\u5e94\u91c7\u7528\u4e0e\u81ea\u6709\u8d44\u4ea7\u76f8\u4e00\u81f4\u7684\u4f1a\u8ba1\u653f\u7b56\nC. \u5982\u679c\u80fd\u591f\u5408\u7406\u786e\u5b9a\u8be5\u8bbe\u5907\u5728\u79df\u8d41\u671f\u5c4a\u6ee1\u65f6\u7532\u4f01\u4e1a\u5c06\u4f1a\u53d6\u5f97\u6b64\u8bbe\u5907\u7684\u6240\u6709\u6743\uff0c\u5219\u5e94\u4ee5\u8be5\u8bbe\u5907\u5168\u65b0\u65f6\u7684\u9884\u8ba1\u4f7f\u7528\u5e74\u9650\u4f5c\u4e3a\u6298\u65e7\u671f\u95f4\nD. \u8be5\u8bbe\u5907\u7684\u6298\u65e7\u65b9\u6cd5\u548c\u6298\u65e7\u5e74\u9650\u5e94\u6309\u4e59\u4f01\u4e1a\u6709\u5173\u8d44\u4ea7\u7684\u6298\u65e7\u65b9\u6cd5\u548c\u6298\u65e7\u5e74\u9650\u5904\u7406\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3387392219693854, "meta-math/MetaMath-Mistral-7B": 0.5528630957959901, "itpossible/Chinese-Mistral-7B-v0.1": 0.2801288226217134, "HuggingFaceH4/zephyr-7b-beta": 0.4529445166614936, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bc1\u5238\u5e02\u573a\u7ebf\u53ef\u4ee5\u7528\u6765\u63cf\u8ff0\u5e02\u573a\u5747\u8861\u6761\u4ef6\u4e0b\u5355\u9879\u8d44\u4ea7\u6216\u8d44\u4ea7\u7ec4\u5408\u7684\u671f\u671b\u6536\u76ca\u4e0e\u98ce\u9669\u4e4b\u95f4\u7684\u5173\u7cfb\u3002\u5f53\u6295\u8d44\u8005\u7684\u98ce\u9669\u538c\u6076\u611f\u666e\u904d\u51cf\u5f31\u65f6\uff0c\u4f1a\u5bfc\u81f4\u8bc1\u5238\u5e02\u573a\u7ebf____\u3002\nA. \u5411\u4e0b\u5e73\u884c\u79fb\u52a8\nB. \u659c\u7387\u4e0a\u5347\nC. \u659c\u7387\u4e0b\u964d\nD. \u5411\u4e0a\u5e73\u884c\u79fb\u52a8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5723591664815613, "meta-math/MetaMath-Mistral-7B": 0.52267340291517, "itpossible/Chinese-Mistral-7B-v0.1": 0.4182951982433899, "HuggingFaceH4/zephyr-7b-beta": 0.707300540755812, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6986243836833774, "meta-llama/Meta-Llama-3-8B": 0.35888231301687173, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6012955214409982}}, {"question": "\u5982\u679c\u884c\u4e1a\u7684\u4e70\u65b9\u96c6\u4e2d\u5ea6\u9ad8\uff0c\u7531\u5c11\u6570\u51e0\u5bb6\u4f01\u4e1a\u63a7\u5236\uff0c\u90a3\u4e48\u5b83\u4eec\u5728\u4ef7\u683c\u8c08\u5224\u4e2d\u4f1a\u5904\u4e8e\u7684\u5730\u4f4d\u662f____\u3002\nA. \u5341\u5206\u4e0d\u5229\nB. \u76f8\u5bf9\u4e0d\u5229\nC. \u76f8\u5bf9\u6709\u5229\nD. \u5341\u5206\u6709\u5229\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28966338381871215, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u9884\u4ed8\u8d26\u6b3e\u201d\u79d1\u76ee\u660e\u7ec6\u8d26\u4e2d\u82e5\u6709\u8d37\u65b9\u4f59\u989d\uff0c\u5e94\u8ba1\u5165\u8d44\u4ea7\u8d1f\u503a\u8868\u4e2d\u7684____\u9879\u76ee\u3002\nA. \u5e94\u6536\u8d26\u6b3e\nB. \u5e94\u4ed8\u8d26\u6b3e\nC. \u9884\u6536\u8d26\u6b3e\nD. \u9884\u4ed8\u8d26\u6b3e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u57fa\u5c42\u7ec4\u7ec7\u7684\u7ba1\u7406\u8005\u4e3b\u8981\u627f\u62c5____\u3002\nA. \u51b3\u7b56\u804c\u80fd\nB. \u63a7\u5236\u804c\u80fd\nC. \u627f\u4e0a\u542f\u4e0b\u7684\u804c\u80fd\u4f5c\u7528\nD. \u534f\u8c03\u804c\u80fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3790504848994995, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ea7\u54c1\u7ec4\u5408\u7684\u957f\u5ea6\u662f____\u3002\nA. \u4ea7\u54c1\u5927\u7c7b\u7684\u6570\u91cf\nB. \u4ea7\u54c1\u9879\u76ee\u7684\u6570\u91cf\nC. \u4ea7\u54c1\u5927\u7c7b\u7684\u76f8\u5173\u7a0b\u5ea6\nD. \u4ea7\u54c1\u5927\u7c7b\u7684\u5e8f\u5217\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7471176172678912, "meta-math/MetaMath-Mistral-7B": 0.9244749819269747, "itpossible/Chinese-Mistral-7B-v0.1": 0.567384078484277, "HuggingFaceH4/zephyr-7b-beta": 0.9547470672827629, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8120075693773459, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9785214409114564}}, {"question": "\u201c\u5750\u5730\u65e5\u884c\u516b\u4e07\u91cc\uff0c\u5de1\u516d\u9065\u770b\u4e00\u5343\u6cb3\u201d\uff0c\u8fd9\u4e00\u8457\u540d\u8bd7\u53e5\u5305\u542b\u7684\u54f2\u7406\u662f____\nA. \u7269\u8d28\u8fd0\u52a8\u7684\u5ba2\u89c2\u6027\u548c\u65f6\u7a7a\u7684\u4e3b\u89c2\u6027\u7684\u7edf\u4e00\nB. \u7269\u8d28\u8fd0\u52a8\u7684\u65e0\u9650\u6027\u548c\u65f6\u7a7a\u7684\u6709\u9650\u6027\u7684\u7edf\u4e00\nC. \u65f6\u7a7a\u7684\u65e0\u9650\u6027\u548c\u6709\u9650\u6027\u7684\u7edf\u4e00\nD. \u8fd0\u52a8\u7684\u7edd\u5bf9\u6027\u548c\u9759\u6b62\u7684\u76f8\u5bf9\u6027\u7684\u7edf\u4e00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u515a\u4e00\u8d2f\u5021\u5bfc\u5e76\u957f\u671f\u4fdd\u6301\u7684\u4f18\u826f\u5b66\u98ce\u662f____\nA. \u8270\u82e6\u594b\u6597\nB. \u5b9e\u4e8b\u6c42\u662f\nC. \u7406\u8bba\u8054\u7cfb\u5b9e\u9645\nD. \u52e4\u4fed\u8282\u7ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.928144624994889}}, {"question": "\u9a6c\u514b\u601d\u4e3b\u4e49\u54f2\u5b66\u8ba4\u4e3a\uff0c\u4e16\u754c\u5728\u672c\u8d28\u4e0a\u662f____\nA. \u5404\u79cd\u5b9e\u7269\u7684\u603b\u548c\nB. \u7269\u8d28\u548c\u7cbe\u795e\u7684\u7edf\u4e00\nC. \u591a\u6837\u6027\u7684\u7269\u8d28\u7edf\u4e00\nD. \u4e3b\u89c2\u4e0e\u5ba2\u4f53\u7684\u7edf\u4e00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44423694553166887, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5160880631080904, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e8b\u7269\u7684\u8d28\u662f\u6307____\nA. \u6784\u6210\u4e8b\u7269\u5185\u5728\u8981\u7d20\u7684\u603b\u548c\nB. \u7ec4\u6210\u4e8b\u7269\u57fa\u672c\u8981\u7d20\u7684\u5185\u5728\u8054\u7cfb\nC. \u4e00\u4e8b\u7269\u533a\u522b\u4e0e\u5176\u4ed6\u4e8b\u7269\u7684\u5185\u5728\u89c4\u5b9a\u6027\nD. \u4e8b\u7269\u7684\u89c4\u6a21\u3001\u53d1\u5c55\u7a0b\u5ea6\u548c\u901f\u5ea6\u7b49\u89c4\u5b9a\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7753605555552386, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6696586619125323}}, {"question": "\u5217\u5b81\u5bf9\u8fa9\u8bc1\u552f\u7269\u4e3b\u4e49\u7269\u8d28\u8303\u7574\u7684\u5b9a\u4e49\u662f\u901a\u8fc7____\u754c\u5b9a\u7684\nA. \u7269\u8d28\u548c\u610f\u8bc6\u7684\u5173\u7cfb\nB. \u4e2a\u522b\u4e0e\u4e00\u822c\u7684\u5173\u7cfb\nC. \u54f2\u5b66\u4e0e\u5177\u4f53\u79d1\u5b66\u7684\u5173\u7cfb\nD. \u8ba4\u8bc6\u4e0e\u5b9e\u8df5\u7684\u5173\u7cfb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3023937904843768, "meta-math/MetaMath-Mistral-7B": 0.36978650104694816, "itpossible/Chinese-Mistral-7B-v0.1": 0.4820192779702721, "HuggingFaceH4/zephyr-7b-beta": 0.7580334779123542, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5219539930894546}}, {"question": "\u5728\u9a6c\u514b\u601d\u4e3b\u4e49\u666e\u904d\u539f\u7406\u6307\u5bfc\u4e0b\uff0c\u4ece\u4e2d\u56fd\u7684\u57fa\u672c\u56fd\u60c5\u51fa\u53d1\uff0c\u8d70\u5efa\u8bbe\u6709\u4e2d\u56fd\u7279\u8272\u793e\u4f1a\u4e3b\u4e49\u9053\u8def\u3002\u8fd9\u4f53\u73b0\u4e86____\nA. \u77db\u76fe\u7684\u540c\u4e00\u6027\u548c\u6597\u4e89\u6027\u7684\u7edf\u4e00\nB. \u77db\u76fe\u7684\u666e\u904d\u6027\u548c\u7279\u6b8a\u6027\u7684\u7edf\u4e00\nC. \u4e8b\u7269\u53d1\u5c55\u7684\u91cf\u53d8\u548c\u8d28\u53d8\u7684\u7edf\u4e00\nD. \u4e8b\u7269\u53d1\u5c55\u7684\u524d\u8fdb\u6027\u548c\u66f2\u6298\u6027\u7684\u7edf\u4e00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5398816163696979, "meta-math/MetaMath-Mistral-7B": 0.3785916633064981, "itpossible/Chinese-Mistral-7B-v0.1": 0.7182771005337985, "HuggingFaceH4/zephyr-7b-beta": 0.49338418577088883, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49056251683383517, "meta-llama/Meta-Llama-3-8B": 0.3444545218043904, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6072888072767474}}, {"question": "\u8bbe\u60f3\u8131\u79bb\u7269\u8d28\u7684\u8fd0\u52a8\u5fc5\u7136\u5bfc\u81f4____\nA. \u552f\u5fc3\u4e3b\u4e49\nB. \u4e8c\u5143\u8bba\nC. \u8fa9\u8bc1\u552f\u7269\u4e3b\u4e49\nD. \u5f62\u800c\u4e0a\u5b66\u552f\u7269\u4e3b\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5534002134727397, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ecf\u6d4e\u793e\u4f1a\u5f62\u6001____\nA. \u662f\u76f4\u63a5\u6216\u95f4\u63a5\u4ee5\u751f\u4ea7\u5173\u7cfb\u6027\u8d28\u5212\u5206\nB. \u662f\u4ee5\u751f\u4ea7\u529b\u548c\u751f\u4ea7\u5173\u7cfb\u7684\u7edf\u4e00\u7a0b\u5ea6\u5212\u5206\nC. \u662f\u4ee5\u5982\u4f55\u8fdb\u884c\u4ea7\u54c1\u5206\u914d\u5212\u5206\nD. \u662f\u4ee5\u751f\u4ea7\u529b\u548c\u6280\u672f\u53d1\u5c55\u6c34\u5e73\u5212\u5206\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u6ca1\u6709\u9769\u547d\u7684\u7406\u8bba\uff0c\u5c31\u6ca1\u6709\u4e8b\u547d\u7684\u8fd0\u52a8\u201d\uff0c\u8fd9\u53e5\u8bdd\u76f4\u63a5\u4f53\u73b0\u7684\u54f2\u5b66\u539f\u578b\u662f____\nA. \u610f\u8bc6\u6709\u80fd\u52a8\u4f5c\u7528\nB. \u8ba4\u8bc6\u6709\u80fd\u52a8\u4f5c\u7528\nC. \u79d1\u5b66\u7406\u8bba\u5bf9\u5b9e\u8df5\u6709\u5de8\u5927\u6307\u5bfc\u4f5c\u7528\nD. \u7269\u8d28\u51b3\u5b9a\u610f\u8bc6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7310637826412696, "meta-math/MetaMath-Mistral-7B": 0.9394312788081643, "itpossible/Chinese-Mistral-7B-v0.1": 0.6720011432671795, "HuggingFaceH4/zephyr-7b-beta": 0.8176605781669957, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6198310913920405, "meta-llama/Meta-Llama-3-8B": 0.7399534019235524, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7255908672033745}}, {"question": "\u793e\u4f1a\u89c4\u5f8b\u4e0e\u81ea\u7136\u89c4\u5f8b\u7684\u533a\u522b\u5728\u4e8e____\nA. \u81ea\u7136\u89c4\u5f8b\u662f\u5ba2\u89c2\u7684\uff0c\u793e\u4f1a\u89c4\u5f8b\u662f\u4e3b\u89c2\u7684\nB. \u81ea\u7136\u89c4\u5f8b\u662f\u81ea\u53d1\u8d77\u4f5c\u7528\u7684\uff0c\u793e\u4f1a\u89c4\u5f8b\u5219\u662f\u901a\u8fc7\u4eba\u7684\u6709\u610f\u8bc6\u7684\u6d3b\u52a8\u5b9e\u73b0\u7684\nC. \u81ea\u7136\u89c4\u5f8b\u662f\u53ef\u4ee5\u88ab\u8ba4\u8bc6\u7684\uff0c\u793e\u4f1a\u89c4\u5f8b\u5219\u662f\u4e0d\u53ef\u6349\u6478\u7684\nD. \u81ea\u7136\u89c4\u5f8b\u6ca1\u6709\u653f\u6cbb\u503e\u5411\uff0c\u793e\u4f1a\u89c4\u5f8b\u6709\u653f\u6cbb\u503e\u5411\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9131709584766994, "meta-math/MetaMath-Mistral-7B": 0.9933296985410116, "itpossible/Chinese-Mistral-7B-v0.1": 0.6804114381174461, "HuggingFaceH4/zephyr-7b-beta": 0.9992051147625454, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9046327142743465, "meta-llama/Meta-Llama-3-8B": 0.7220500567506172, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8729444743767172}}, {"question": "\u8d44\u4ea7\u9636\u7ea7\u6240\u5ba3\u626c\u7684\u201c\u4e00\u822c\u6c11\u4e3b\u201d\u7684\u552f\u5fc3\u53f2\u89c2\u57fa\u7840\u662f____\nA. \u5929\u8d4b\u4eba\u6743\u8bba\nB. \u62bd\u8c61\u4eba\u6027\u8bba\nC. \u793e\u4f1a\u5951\u7ea6\u8bba\nD. \u4e09\u6743\u5206\u7acb\u8bba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4885558929212937, "meta-math/MetaMath-Mistral-7B": 0.7997423906328082, "itpossible/Chinese-Mistral-7B-v0.1": 0.8258041426980144, "HuggingFaceH4/zephyr-7b-beta": 0.7603510758987696, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4244886562125046}}, {"question": "\u6211\u56fd\u6539\u9769\u5f00\u653e20\u591a\u5e74\u6765\u53d1\u751f\u4e86\u5386\u53f2\u6027\u7684\u5de8\u53d8\uff0c\u4f46\u4ecd\u7136\u662f\u4e00\u4e2a\u53d1\u5c55\u4e2d\u56fd\u5bb6\uff0c\u8fd9\u4f53\u73b0\u4e86____\nA. \u4e16\u754c\u7684\u7269\u8d28\u7edf\u4e00\u6027\u539f\u7406\nB. \u7269\u8d28\u548c\u610f\u8bc6\u7684\u8fa9\u8bc1\u5173\u7cfb\u539f\u7406\nC. \u7269\u8d28\u8fd0\u52a8\u548c\u65f6\u7a7a\u4e0d\u53ef\u5206\u5272\u7684\u89c2\u70b9\nD. \u8fd0\u52a8\u548c\u9759\u6b62\u76f8\u7edf\u4e00\u7684\u89c2\u70b9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.33762049688160123, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8861\u91cf\u4e00\u4e2a\u4eba\u7684\u4eba\u751f\u4ef7\u503c\u5e94\u6839\u636e\u4ed6____\nA. \u5bf9\u793e\u4f1a\u7684\u8d21\u732e\nB. \u80fd\u529b\u5927\u5c0f\nC. \u793e\u4f1a\u5730\u4f4d\u7684\u9ad8\u4f4e\nD. \u62e5\u6709\u7684\u91d1\u94b1\u8d22\u5bcc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9853199389787272, "meta-math/MetaMath-Mistral-7B": 0.9994519159283715, "itpossible/Chinese-Mistral-7B-v0.1": 0.9769742715943942, "HuggingFaceH4/zephyr-7b-beta": 0.9994672296647527, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9949212565880426, "meta-llama/Meta-Llama-3-8B": 0.9658374985535244, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.965837502855638}}, {"question": "\u8d44\u672c\u4e3b\u4e49\u7684\u751f\u4ea7\u8fc7\u7a0b\u662f____\nA. \u52b3\u52a8\u8fc7\u7a0b\u548c\u4ef7\u503c\u589e\u6b96\u8fc7\u7a0b\u7684\u7edf\u4e00\nB. \u52b3\u52a8\u8fc7\u7a0b\u548c\u4ef7\u503c\u5f62\u6210\u8fc7\u7a0b\u7684\u7edf\u4e00\nC. \u4ef7\u503c\u5f62\u6210\u8fc7\u7a0b\u548c\u4ef7\u503c\u589e\u6b96\u8fc7\u7a0b\u7684\u7edf\u4e00\nD. \u4ef7\u503c\u8f6c\u79fb\u8fc7\u7a0b\u548c\u4ef7\u503c\u5f62\u6210\u8fc7\u7a0b\u7684\u7edf\u4e00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4569088787329105, "meta-math/MetaMath-Mistral-7B": 0.47733941061629354, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7823888601032065, "meta-llama/Meta-Llama-3-8B": 0.5908620017366488, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ecf\u9a8c\u8bba\u662f____\nA. \u552f\u5fc3\u4e3b\u4e49\u7684\nB. \u552f\u7269\u4e3b\u4e49\u7684\nC. \u65e2\u53ef\u662f\u552f\u5fc3\u4e3b\u4e49\u7684\uff0c\u4e5f\u53ef\u80fd\u662f\u552f\u7269\u4e3b\u4e49\u7684\nD. \u4e8c\u5143\u8bba\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4528728233058935, "HuggingFaceH4/zephyr-7b-beta": 0.8516550505388537, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5212\u5206\u552f\u7269\u4e3b\u4e49\u540c\u552f\u5fc3\u4e3b\u4e49\u7684\u552f\u4e00\u7684\u6807\u51c6\u662f____\nA. \u4e16\u754c\u662f\u5426\u53ef\u77e5\u7684\u95ee\u9898\nB. \u601d\u7ef4\u548c\u5b58\u5728\u4f55\u8005\u7b2c\u4e00\u6027\u7684\u95ee\u9898\nC. \u4e16\u754c\u662f\u5426\u8fd0\u52a8\u53d8\u5316\u7684\u95ee\u9898\nD. \u662f\u5426\u627f\u8ba4\u4e16\u754c\u7edf\u4e00\u7684\u95ee\u9898\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3000356017547507, "meta-math/MetaMath-Mistral-7B": 0.4863146515454336, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u771f\u7406\u4e0e\u8c2c\u8bef\u5728\u4e00\u5b9a\u6761\u4ef6\u4e0b\u53ef\u4ee5\u76f8\u4e92\u8f6c\u5316\uff0c\u662f\u56e0\u4e3a____\nA. \u771f\u7406\u4e0e\u8c2c\u8bef\u672c\u8eab\u6ca1\u6709\u4e25\u683c\u7684\u754c\u9650\nB. \u771f\u7406\u4e0e\u8c2c\u8bef\u7684\u533a\u522b\u662f\u4e3b\u89c2\u9519\u8bef\u9020\u6210\u7684\nC. \u8c2c\u8bef\u4e2d\u5305\u542b\u7740\u771f\u7406\u7684\u56e0\u7d20\nD. \u771f\u7406\u4e0e\u8c2c\u8bef\u5177\u6709\u540c\u4e00\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9a6c\u514b\u601d\u4e3b\u4e49\u8ba4\u8bc6\u8bba\u89d2\u5ea6\u6765\u770b\uff0c\u4eba\u7c7b\u8ba4\u8bc6\u53d1\u5c55\u7684\u52a8\u529b\u5728\u4e8e____\nA. \u4eba\u7c7b\u7684\u9700\u8981\nB. \u4eba\u7c7b\u7684\u521b\u9020\u529b\nC. \u4eba\u7c7b\u7684\u793e\u4f1a\u5b9e\u8df5\u7684\u53d1\u5c55\nD. \u4eba\u7c7b\u7684\u6b63\u786e\u8ba4\u8bc6\u8def\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6139794680778508, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8112722501325894, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8182836478226184}}, {"question": "\u552f\u7269\u4e3b\u4e49\u7684\u57fa\u672c\u524d\u63d0\u662f____\nA. \u7269\u8d28\u5bf9\u610f\u8bc6\u7684\u5148\u5728\u6027\u3001\u5ba2\u89c2\u6027\u3001\u72ec\u7acb\u6027\nB. \u610f\u8bc6\u5bf9\u7269\u8d28\u7684\u6d3e\u751f\u6027\u3001\u53ef\u77e5\u6027\nC. \u610f\u8bc6\u5bf9\u7269\u8d28\u7684\u80fd\u52a8\u6027\nD. \u610f\u8bc6\u5bf9\u7269\u8d28\u7684\u4e3b\u89c2\u6027\u3001\u72ec\u7acb\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7548495052115981, "meta-math/MetaMath-Mistral-7B": 0.9666707593675272, "itpossible/Chinese-Mistral-7B-v0.1": 0.6216532084603517, "HuggingFaceH4/zephyr-7b-beta": 0.9987440267521515, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9590912442116529, "meta-llama/Meta-Llama-3-8B": 0.8981876588118526, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8772742208620498}}, {"question": "\u6211\u56fd\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u5236\u5ea6\u7ec4\u7ec7\u548c\u6d3b\u52a8\u7684\u57fa\u672c\u539f\u5219\u662f____\nA. \u4eba\u6c11\u5f53\u5bb6\u4f5c\u4e3b\u7684\u539f\u5219\nB. \u6c11\u4e3b\u96c6\u4e2d\u5236\u7684\u539f\u5219\nC. \u5728\u5baa\u6cd5\u548c\u6cd5\u5f8b\u8303\u56f4\u5185\u6d3b\u52a8\u7684\u539f\u5219\nD. \u516c\u5e73\u3001\u516c\u6b63\u3001\u516c\u5f00\u7684\u539f\u5219\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36010898878387526, "meta-math/MetaMath-Mistral-7B": 0.4382091198732689, "itpossible/Chinese-Mistral-7B-v0.1": 0.5367333915390547, "HuggingFaceH4/zephyr-7b-beta": 0.6961327426005932, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6563789630298217, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6565706630911361}}, {"question": "\u793e\u4f1a\u4e3b\u4e49\u548c\u8c10\u793e\u4f1a\u7684\u6838\u5fc3\u4ef7\u503c\u662f____\nA. \u4ee5\u4eba\u4e3a\u672c\nB. \u4ee5\u6c11\u4e3a\u672c\nC. \u793e\u4f1a\u516c\u5e73\nD. \u516c\u5e73\u548c\u6b63\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "21\u4e16\u7eaa\u524d10\u5e74\uff0c\u6211\u56fd\u7ecf\u6d4e\u4f53\u5236\u5fc5\u987b\u89e3\u51b3\u597d\u7684\u5386\u53f2\u8bfe\u9898\u662f____\nA. \u5b9e\u65bd\u79d1\u6559\u5174\u56fd\u6218\u7565\u548c\u53ef\u6301\u7eed\u53d1\u5c55\u6218\u7565\nB. \u4fc3\u8fdb\u56fd\u6c11\u7ecf\u6d4e\u6301\u7eed\u5feb\u901f\u5065\u5eb7\u53d1\u5c55\nC. \u5927\u591a\u6570\u56fd\u6709\u5927\u4e2d\u578b\u9aa8\u5e72\u4f01\u4e1a\u5efa\u7acb\u73b0\u4ee3\u4f01\u4e1a\u5236\u5ea6\nD. \u5efa\u7acb\u6bd4\u8f83\u5b8c\u5584\u7684\u793e\u4f1a\u4e3b\u4e49\u5e02\u573a\u7ecf\u6d4e\u4f53\u5236\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.43782999927931787, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.48332955340533307, "HuggingFaceH4/zephyr-7b-beta": 0.9838520740707278, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5236882854811112, "meta-llama/Meta-Llama-3-8B": 0.6147665829428273, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9520453625068113}}, {"question": "\u9996\u6b21\u4ee5\u201c\u53f0\u6e7e\u56de\u5230\u7956\u56fd\u6000\u62b1\uff0c\u5b9e\u73b0\u7edf\u4e00\u5927\u4e1a\u201d\u6765\u4ee3\u66ff\u201c\u89e3\u653e\u53f0\u6e7e\u201d\u7684\u63d0\u6cd5\u7684\u662f____\nA. 1978\u5e7412\u6708\u515a\u7684\u5341\u4e00\u5c4a\u4e09\u4e2d\u5168\u4f1a\u516c\u62a5\nB. 1979\u5e74\u5143\u65e6\u5168\u56fd\u4eba\u5927\u5e38\u59d4\u4f1a\u53d1\u8868\u300a\u544a\u53f0\u6e7e\u540c\u80de\u4e66\u300b\nC. 1981\u5e749\u6708\u53f6\u5251\u82f1\u5bf9\u65b0\u534e\u793e\u8bb0\u8005\u53d1\u8868\u7684\u88ab\u79f0\u4e3a\u201c\u53f6\u4e5d\u6761\u201d\u7684\u8c08\u8bdd\nD. 1982\u5e74\u4e2d\u56fd\u5171\u4ea7\u515a\u5341\u4e8c\u5927\u653f\u6cbb\u62a5\u544a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4087009733881603, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6bdb\u6cfd\u4e1c\u601d\u60f3\u8fbe\u5230\u6210\u719f\u7684\u6807\u5fd7\u662f____\nA. \u65b0\u6c11\u4e3b\u4e3b\u4e49\u7406\u8bba\u79d1\u5b66\u4f53\u7cfb\u7684\u5f62\u6210\nB. \u519c\u6751\u5305\u56f4\u57ce\u5e02\u9769\u547d\u9053\u8def\u7406\u8bba\u7684\u5f62\u6210\nC. \u65b0\u6c11\u4e3b\u4e3b\u4e49\u9769\u547d\u57fa\u672c\u7ecf\u9a8c\u7684\u63d0\u51fa\nD. \u6bdb\u6cfd\u4e1c\u519b\u4e8b\u8def\u7ebf\u7684\u5b8c\u6574\u5f62\u6210\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37897238681311185, "meta-math/MetaMath-Mistral-7B": 0.5770318098916876, "itpossible/Chinese-Mistral-7B-v0.1": 0.4118112658317745, "HuggingFaceH4/zephyr-7b-beta": 0.9855604053231586, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7534614023684931, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5efa\u8bbe\u548c\u8c10\u6587\u5316\u7684\u6839\u672c\u662f____\nA. \u575a\u6301\u9a6c\u514b\u601d\u4e3b\u4e49\u7684\u6307\u5bfc\nB. \u53d1\u5c55\u79d1\u5b66\u548c\u6559\u80b2\nC. \u575a\u6301\u793e\u4f1a\u4e3b\u4e49\u6838\u5fc3\u4ef7\u503c\u4f53\u7cfb\nD. \u63a8\u8fdb\u6587\u5316\u4f53\u5236\u6539\u9769\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6662147880100467, "meta-math/MetaMath-Mistral-7B": 0.8181482921038586, "itpossible/Chinese-Mistral-7B-v0.1": 0.5820229548495929, "HuggingFaceH4/zephyr-7b-beta": 0.9990828071539986, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8571698352463231, "meta-llama/Meta-Llama-3-8B": 0.9394900802872932, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9885966413674704}}, {"question": "\u6784\u5efa\u793e\u4f1a\u4e3b\u4e49\u548c\u8c10\u793e\u4f1a\u7684\u91cd\u70b9\u662f____\nA. \u575a\u6301\u4ee5\u9a6c\u5217\u4e3b\u4e49\u3001\u6bdb\u6cfd\u4e1c\u601d\u60f3\u3001\u9093\u5c0f\u5e73\u7406\u8bba\u548c\u201c\u4e09\u4e2a\u4ee3\u8868\u201d\u91cd\u8981\u601d\u60f3\u4e3a\u6307\u5bfc\nB. \u6c11\u4e3b\u6cd5\u5236\u3001\u516c\u5e73\u6b63\u4e49\u3001\u8bda\u4fe1\u53cb\u7231\u3001\u5145\u6ee1\u6d3b\u529b\u3001\u5b89\u5b9a\u6709\u5e8f\u3001\u4eba\u4e0e\u81ea\u7136\u548c\u8c10\u76f8\u5904\nC. \u89e3\u51b3\u4eba\u6c11\u7fa4\u4f17\u6700\u5173\u5fc3\u3001\u6700\u76f4\u63a5\u3001\u6700\u73b0\u5b9e\u7684\u5229\u76ca\u95ee\u9898\nD. \u52302020\u5e74\u5b8c\u5168\u5b9e\u73b0\u793e\u4f1a\u4e3b\u4e49\u548c\u8c10\u793e\u4f1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.870243984365846, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u53f0\u6e7e\u95ee\u9898\u7684\u672c\u8d28\u662f____\nA. \u4e2d\u56fd\u7684\u5185\u653f\u95ee\u9898\nB. \u4e2d\u56fd\u540c\u7f8e\u56fd\u7684\u5173\u7cfb\u95ee\u9898\nC. \u4e2d\u56fd\u540c\u65e5\u672c\u7684\u5173\u7cfb\u95ee\u9898\nD. \u5171\u4ea7\u515a\u4e0e\u56fd\u6c11\u515a\u7684\u5173\u7cfb\u95ee\u9898\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9004828216541745, "meta-math/MetaMath-Mistral-7B": 0.9895307276361782, "itpossible/Chinese-Mistral-7B-v0.1": 0.9554729706306031, "HuggingFaceH4/zephyr-7b-beta": 0.999998319299046, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8776738723618265, "meta-llama/Meta-Llama-3-8B": 0.42886486310629984, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e2d\u56fd\u5171\u4ea7\u515a\u5386\u53f2\u4e0a\uff0c\u6700\u65e9\u63d0\u51fa\u201c\u9a6c\u514b\u601d\u4e3b\u4e49\u4e2d\u56fd\u5316\u201d\u8fd9\u4e2a\u547d\u9898\u7684\u662f____\nA. \u674e\u5927\u948a\nB. \u9648\u72ec\nC. \u6bdb\u6cfd\u4e1c\nD. \u5f20\u95fb\u5929\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6659643300061222, "meta-math/MetaMath-Mistral-7B": 0.9352466164760895, "itpossible/Chinese-Mistral-7B-v0.1": 0.37491960840523747, "HuggingFaceH4/zephyr-7b-beta": 0.9939058110220794, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9104979623985197, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7261430956648605}}, {"question": "\u515a\u7684\u5341\u516b\u5927\u63d0\u51fa\uff0c\u9762\u5bf9\u8d44\u6e90\u7ea6\u675f\u8d8b\u7d27\u3001\u73af\u5883\u6c61\u67d3\u4e25\u91cd\u3001\u751f\u6001\u7cfb\u7edf\u9000\u5316\u7684\u4e25\u5cfb\u5f62\u52bf\uff0c\u5fc5\u987b\u6811\u7acb\u5c0a\u91cd\u81ea\u7136\u3001\u987a\u5e94\u81ea\u7136\u3001\u4fdd\u62a4\u81ea\u7136\u7684\u751f\u6001\u6587\u660e\u7406\u5ff5\u3002\u4eba\u4e0e\u81ea\u7136\u76f8\u5904\u65f6\u5e94\u79c9\u6301\u7684\u9996\u8981\u6001\u5ea6\u662f____\nA. \u5c0a\u91cd\u81ea\u7136\nB. \u987a\u5e94\u81ea\u7136\nC. \u4fdd\u62a4\u81ea\u7136\nD. \u5f81\u670d\u81ea\u7136\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9188652477985744, "meta-math/MetaMath-Mistral-7B": 0.9707219129456136, "itpossible/Chinese-Mistral-7B-v0.1": 0.9246393809943745, "HuggingFaceH4/zephyr-7b-beta": 0.9999557507815643, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9250887681177948, "meta-llama/Meta-Llama-3-8B": 0.5272420334552773, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u56fd\u9769\u547d\u7684\u7279\u70b9\u548c\u4f18\u70b9\u662f____\nA. \u7531\u4e2d\u56fd\u5171\u4ea7\u515a\u9886\u5bfc\u7684\u4eba\u6c11\u6218\u4e89\nB. \u76ee\u6807\u662f\u4e89\u53d6\u6c11\u65cf\u72ec\u7acb\u3001\u4eba\u6c11\u89e3\u653e\uff0c\u6700\u7ec8\u5b9e\u73b0\u56fd\u5bb6\u7684\u7e41\u8363\u5bcc\u5f3a\nC. \u4ee5\u53cd\u5e1d\u53cd\u5c01\u5efa\u4f5c\u4e3a\u4e24\u5927\u9769\u547d\u4efb\u52a1\nD. \u4ee5\u6b66\u88c5\u7684\u9769\u547d\u53cd\u5bf9\u6b66\u88c5\u7684\u53cd\u9769\u547d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9999\u6e2f\u7279\u522b\u884c\u653f\u533a\u7684\u9ad8\u5ea6\u81ea\u6cbb\u6743\u7684\u552f\u4e00\u6765\u6e90\u662f____\nA. \u4e2d\u592e\u6388\u6743\nB. \u9999\u6e2f\u7279\u522b\u884c\u653f\u533a\u672c\u8eab\u56fa\u6709\u7684\nC. \u300a\u4e2d\u82f1\u8054\u5408\u58f0\u660e\u300b\nD. \u4e2d\u592e\u6388\u6743\u4e4b\u5916\u7684\u5269\u4f59\u6743\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36694471738720585, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u5b9e\u65bd\u6539\u9769\u7684\u76ee\u7684\u662f____\nA. \u5de9\u56fa\u793e\u4f1a\u4e3b\u4e49\u5236\u5ea6\nB. \u53d1\u626c\u793e\u4f1a\u4e3b\u4e49\u6c11\u4e3b\nC. \u8c03\u52a8\u5e7f\u5927\u4eba\u6c11\u7fa4\u4f17\u7684\u79ef\u6781\u6027\nD. \u53d1\u5c55\u793e\u4f1a\u4e3b\u4e49\u7684\u751f\u4ea7\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40463997558826925, "meta-math/MetaMath-Mistral-7B": 0.6484778296162579, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7784091668675062, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65b0\u6c11\u4e3b\u4e3b\u4e49\u9769\u547d\u603b\u8def\u7ebf\u7684\u6838\u5fc3\u662f____\nA. \u65e0\u4ea7\u9636\u7ea7\u7684\u9886\u5bfc\nB. \u4eba\u6c11\u5927\u4f17\u7684\u53c2\u4e0e\nC. \u53cd\u5e1d\u53cd\u5c01\u5efa\nD. \u53cd\u5b98\u50da\u8d44\u672c\u4e3b\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34031470637689565, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4431036684222986, "meta-llama/Meta-Llama-3-8B": 0.40724795536268843, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e5d\u5c4a\u4eba\u5927\u4e8c\u6b21\u4f1a\u8bae\u6b63\u5f0f\u5c06\u201c\u4f9d\u6cd5\u6cbb\u56fd\u201d\u5199\u5165\u5baa\u6cd5\uff0c\u8fd9\u4e00\u653f\u7b56\u7684\u6838\u5fc3\u662f____\nA. \u4eba\u6c11\u5f53\u5bb6\u4f5c\u4e3b\nB. \u6c11\u4e3b\u4e0e\u6cd5\u5236\u7684\u7ed3\u5408\nC. \u6cd5\u6cbb\u4ee3\u66ff\u4eba\u6cbb\nD. \u6709\u6cd5\u53ef\u4f9d\uff0c\u6709\u6cd5\u5fc5\u4f9d\uff0c\u6267\u6cd5\u5fc5\u4e25\uff0c\u8fdd\u6cd5\u5fc5\u7a76\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u793e\u4f1a\u4e3b\u4e49\u521d\u7ea7\u9636\u6bb5\uff0c\u975e\u516c\u6709\u5236\u7ecf\u6d4e\u662f____\nA. \u793e\u4f1a\u4e3b\u4e49\u516c\u6709\u5236\u7ecf\u6d4e\u7684\u8865\u5145\nB. \u793e\u4f1a\u4e3b\u4e49\u5e02\u573a\u7ecf\u6d4e\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\nC. \u5177\u6709\u516c\u6709\u6027\u8d28\u7684\u7ecf\u6d4e\nD. \u9010\u6b65\u5411\u516c\u6709\u5236\u8fc7\u6e21\u7684\u7ecf\u6d4e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8701271726539237, "meta-math/MetaMath-Mistral-7B": 0.9637534884947565, "itpossible/Chinese-Mistral-7B-v0.1": 0.9337757304444885, "HuggingFaceH4/zephyr-7b-beta": 0.9999523484784797, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7513176503855455, "meta-llama/Meta-Llama-3-8B": 0.857784473532318, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9697154109412397}}, {"question": "\u8fc7\u6e21\u65f6\u671f\u603b\u8def\u7ebf\u7684\u7279\u5f81\u662f____\nA. \u91cd\u89c6\u5de5\u4e1a\u5efa\u8bbe\nB. \u5f3a\u8c03\u4e09\u5927\u6539\u9020\nC. \u793e\u4f1a\u4e3b\u4e49\u5efa\u8bbe\u548c\u793e\u4f1a\u4e3b\u4e49\u6539\u9020\u540c\u65f6\u5e76\u4e3e\nD. \u5c24\u5176\u91cd\u89c6\u5bf9\u8d44\u672c\u4e3b\u4e49\u5de5\u5546\u4e1a\u7684\u6539\u9020\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4596211482447842, "meta-math/MetaMath-Mistral-7B": 0.5229793416762657, "itpossible/Chinese-Mistral-7B-v0.1": 0.45787069407560355, "HuggingFaceH4/zephyr-7b-beta": 0.5925351829318313, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7708483736110475, "meta-llama/Meta-Llama-3-8B": 0.7616494175588194, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9454800822884707}}, {"question": "\u6bdb\u6cfd\u4e1c\u601d\u60f3\u5f00\u59cb\u5f62\u6210\u662f\u5728____\nA. \u56fd\u6c11\u9769\u547d\u65f6\u671f\nB. \u571f\u5730\u9769\u547d\u6218\u4e89\u65f6\u671f\nC. \u89e3\u653e\u6218\u4e89\u65f6\u671f\nD. \u6297\u65e5\u6218\u4e89\u65f6\u671f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3908304748611699, "itpossible/Chinese-Mistral-7B-v0.1": 0.4124578775795746, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6191819462343124, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4eca\u65f6\u4ee3\u7684\u4e3b\u9898\u662f____\nA. \u6218\u4e89\u4e0e\u9769\u547d\nB. \u548c\u5e73\u4e0e\u53d1\u5c55\nC. \u5f00\u653e\u4e0e\u5408\u4f5c\nD. \u548c\u8c10\u4e0e\u5171\u8d62\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7684675837142818, "itpossible/Chinese-Mistral-7B-v0.1": 0.8651374302334445, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47226560787672506, "meta-llama/Meta-Llama-3-8B": 0.48817636486149857, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6b63\u5f0f\u628a\u6bdb\u6cfd\u4e1c\u601d\u60f3\u786e\u7acb\u4e3a\u515a\u7684\u6307\u5bfc\u601d\u60f3\u5e76\u9996\u6b21\u5199\u8fdb\u515a\u7ae0\u7684\u662f____\nA. \u4e2d\u5171\u516d\u5927\nB. \u4e2d\u5171\u4e03\u5927\nC. \u4e2d\u5171\u516b\u5927\nD. \u4e2d\u5171\u5341\u4e8c\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5110391347635618, "itpossible/Chinese-Mistral-7B-v0.1": 0.3895746993979434, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.39846433498836364, "meta-llama/Meta-Llama-3-8B": 0.31122966560092724, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6bdb\u6cfd\u4e1c\u601d\u60f3\u8fbe\u5230\u6210\u719f\u7684\u4e3b\u8981\u6807\u5fd7\u662f____\nA. \u65b0\u6c11\u4e3b\u4e3b\u4e49\u9769\u547d\u7406\u8bba\u7684\u521b\u7acb\nB. \u4e2d\u56fd\u9769\u547d\u9053\u8def\u7406\u8bba\u7684\u63d0\u51fa\nC. \u9769\u547d\u519b\u961f\u5efa\u8bbe\u548c\u519b\u4e8b\u6218\u7565\u7684\u7406\u8bba\u7684\u521b\u7acb\nD. \u515a\u7684\u5efa\u8bbe\u7406\u8bba\u7684\u521b\u7acb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2866128117777278, "meta-math/MetaMath-Mistral-7B": 0.4862379151072533, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6cd5\u5f8b\u662f\u6cbb\u56fd\u4e4b\u91cd\u5668\uff0c\u826f\u6cd5\u662f\u5584\u6cbb\u4e4b\u524d\u63d0\u3002\u5efa\u8bbe\u4e2d\u56fd\u7279\u8272\u793e\u4f1a\u4e3b\u4e49\u6cd5\u6cbb\u4f53\u7cfb\uff0c\u5fc5\u987b\u575a\u6301\u5148\u884c\u7684\u662f____\nA. \u7acb\u6cd5\nB. \u6267\u6cd5\nC. \u53f8\u6cd5\nD. \u5b88\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5816505948564128, "meta-math/MetaMath-Mistral-7B": 0.801615914973108, "itpossible/Chinese-Mistral-7B-v0.1": 0.6737258953358427, "HuggingFaceH4/zephyr-7b-beta": 0.8148099434369682, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7849554141693248, "meta-llama/Meta-Llama-3-8B": 0.3898952941975325, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4189648137325259}}, {"question": "\u4e2d\u56fd\u5171\u4ea7\u515a\u6b63\u5f0f\u63d0\u51fa\u201c\u9093\u5c0f\u5e73\u7406\u8bba\u201d\u8fd9\u4e00\u79d1\u5b66\u6982\u5ff5\uff0c\u5e76\u79d1\u5b66\u9610\u8ff0\u4e86\u9093\u5c0f\u5e73\u7406\u8bba\u7684\u5386\u53f2\u5730\u4f4d\u548c\u6307\u5bfc\u610f\u4e49\uff0c\u90d1\u91cd\u5730\u628a\u9093\u5c0f\u5e73\u7406\u8bba\u540c\u9a6c\u514b\u601d\u5217\u5b81\u4e3b\u4e49\u3001\u6bdb\u6cfd\u4e1c\u601d\u60f3\u4e00\u8d77\uff0c\u786e\u5b9a\u4e3a\u515a\u5728\u4e00\u5207\u5de5\u4f5c\u4e2d\u7684\u6307\u5bfc\u601d\u60f3\u5e76\u5199\u5165\u515a\u7ae0\u7684\u4f1a\u8bae\u662f____\nA. \u515a\u7684\u5341\u4e09\u5927\nB. \u515a\u7684\u5341\u56db\u5927\nC. \u515a\u7684\u5341\u4e94\u5927\nD. \u515a\u7684\u5341\u516d\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34458732107001494, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9093\u5c0f\u5e73\u6307\u51fa\uff1a\u201c\u8d2b\u7a77\u4e0d\u662f\u793e\u4f1a\u4e3b\u4e49\uff0c\u793e\u4f1a\u4e3b\u4e49\u8981\u6d88\u706d\u8d2b\u7a77\u3002\u201d\u8fd9\u4e2a\u8bba\u65ad____\nA. \u6307\u51fa\u4e86\u793e\u4f1a\u4e3b\u4e49\u7684\u6839\u672c\u4efb\u52a1\nB. \u6982\u62ec\u4e86\u793e\u4f1a\u4e3b\u4e49\u5efa\u8bbe\u7684\u76ee\u6807\nC. \u660e\u786e\u4e86\u793e\u4f1a\u4e3b\u4e49\u7684\u53d1\u5c55\u65b9\u5411\nD. \u4f53\u73b0\u4e86\u793e\u4f1a\u4e3b\u4e49\u672c\u8d28\u7684\u8981\u6c42\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36078609119776345, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u662f\u9ad8\u7b49\u5b66\u6821\u7684\u4e2d\u5fc3\u5de5\u4f5c\uff0c\u662f\u5b9e\u73b0\u4e00\u5b9a\u7684\u6559\u80b2\u76ee\u7684\u548c\u4eba\u624d\u57f9\u517b\u76ee\u6807\u7684\u57fa\u672c\u9014\u5f84\u3002\nA. \u7ba1\u7406\nB. \u6559\u5b66\nC. \u8bfe\u7a0b\nD. \u79d1\u7814\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9011406147807001, "meta-math/MetaMath-Mistral-7B": 0.9871325068317448, "itpossible/Chinese-Mistral-7B-v0.1": 0.9724332996251009, "HuggingFaceH4/zephyr-7b-beta": 0.9995775342149728, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.982825570391764, "meta-llama/Meta-Llama-3-8B": 0.9577657865216198, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9988077718971132}}, {"question": "\u4f9d\u6d3b\u52a8\u8fc7\u7a0b\u7684\u7279\u70b9\uff0c\u53ef\u4ee5\u5c06\u52a8\u673a\u5206\u4e3a____\u3002\nA. \u4ea4\u5f80\u52a8\u673a\u548c\u5a01\u4fe1\u52a8\u673a\nB. \u793e\u4f1a\u52a8\u673a\u548c\u5c40\u90e8\u52a8\u673a\nC. \u5916\u90e8\u52a8\u673a\u548c\u5185\u90e8\u52a8\u673a\nD. \u8fd1\u666f\u52a8\u673a\u548c\u8fdc\u666f\u52a8\u673a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u628a\u591a\u79cd\u5b66\u79d1\u7684\u76f8\u5173\u5185\u5bb9\u878d\u5408\u5728\u4e00\u8d77\uff0c\u6784\u6210\u65b0\u7684\u8bfe\u7a0b\uff0c\u8fd9\u662f____\nA. \u6d3b\u52a8\u8bfe\u7a0b\nB. \u7efc\u5408\u8bfe\u7a0b\nC. \u5b66\u79d1\u8bfe\u7a0b\nD. \u5fc5\u4fee\u8bfe\u7a0b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9441282546354525, "meta-math/MetaMath-Mistral-7B": 0.997349173916432, "itpossible/Chinese-Mistral-7B-v0.1": 0.9599942315053005, "HuggingFaceH4/zephyr-7b-beta": 0.9973670600308611, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9818069876412606, "meta-llama/Meta-Llama-3-8B": 0.9554828914122736, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9998257146047486}}, {"question": "\u6839\u636e\u5b66\u4e60\u52a8\u673a\u7684\u793e\u4f1a\u610f\u4e49\uff0c\u53ef\u4ee5\u628a\u5b66\u4e60\u52a8\u673a\u5206\u4e3a____\u3002\nA. \u793e\u4f1a\u52a8\u673a\u4e0e\u4e2a\u4eba\u52a8\u673a\nB. \u5de5\u4f5c\u52a8\u673a\u4e0e\u63d0\u9ad8\u52a8\u673a\nC. \u9ad8\u5c1a\u52a8\u673a\u4e0e\u4f4e\u7ea7\u52a8\u673a\nD. \u4ea4\u5f80\u52a8\u673a\u4e0e\u8363\u8a89\u52a8\u673a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3588823130168717, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u73b0\u4ee3\u5b66\u4f4d\u5236\u5ea6\u786e\u7acb\u7684\u6807\u5fd7\u662f\u5fb7\u56fd\u67cf\u6797\u5927\u5b66\u521b\u8bbe\u7684____\u3002\nA. \u6587\u5b66\u535a\u58eb\u5b66\u4f4d\nB. \u533b\u5b66\u535a\u58eb\u5b66\u4f4d\nC. \u7406\u5b66\u535a\u58eb\u5b66\u4f4d\nD. \u54f2\u5b66\u535a\u58eb\u5b66\u4f4d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34031470637689565, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e25\u590d\u63d0\u5021\u7684\u4e09\u80b2\u8bba\u4e0d\u5305\u62ec____\u3002\nA. \u667a\u80b2\nB. \u4f53\u80b2\nC. \u5fb7\u80b2\nD. \u7f8e\u80b2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5657475803039151, "meta-math/MetaMath-Mistral-7B": 0.8627087041276419, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8207130953308096, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6613525410224182, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u73ed\u7ea7\u91cc\u7684\u5c0f\u96c6\u56e2\u5c5e\u4e8e____\u3002\nA. \u8054\u5408\u7fa4\u4f53\nB. \u6b63\u5f0f\u7fa4\u4f53\nC. \u677e\u6563\u7fa4\u4f53\nD. \u975e\u6b63\u5f0f\u7fa4\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7860486569479338, "itpossible/Chinese-Mistral-7B-v0.1": 0.3681585634507254, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9881115019798297}}, {"question": "\u6574\u4e2a\u793e\u4f1a\u5b9e\u8df5\u6d3b\u52a8\u8fc7\u7a0b\u4e2d\uff0c____\u5f97\u5230\u5145\u5206\u4f53\u73b0\u3002\nA. \u6559\u5e08\u7684\u4e3b\u4f53\u6027\nB. \u5b66\u751f\u7684\u4e3b\u4f53\u6027\nC. \u6559\u5e08\u7684\u6307\u5bfc\u4f5c\u7528\nD. \u6d3b\u52a8\u7684\u7075\u6d3b\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8303497170368199, "meta-math/MetaMath-Mistral-7B": 0.9578980008315516, "itpossible/Chinese-Mistral-7B-v0.1": 0.881058085762021, "HuggingFaceH4/zephyr-7b-beta": 0.9972244478442895, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9617912451994981, "meta-llama/Meta-Llama-3-8B": 0.8344029614549916, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7445456058722123}}, {"question": "\u4e2a\u4f53\u54c1\u5fb7\u7684\u6838\u5fc3\u90e8\u5206\u662f____\u3002\nA. \u9053\u5fb7\u8ba4\u77e5\nB. \u9053\u5fb7\u89c2\u5ff5\nC. \u9053\u5fb7\u60c5\u611f\nD. \u9053\u5fb7\u884c\u4e3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3248694388439253, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u6709\u5173\u5386\u53f2\u751f\u6d3b\u7684\u9886\u4f1a\uff0c\u4e0d\u80fd\u7f3a\u5c11____\u3002\nA. \u8a00\u8bed\u76f4\u89c2\nB. \u5f62\u8c61\u76f4\u89c2\nC. \u611f\u77e5\u76f4\u89c2\nD. \u8868\u8c61\u76f4\u89c2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5b9e\u9a8c\u7814\u7a76\u7684\u60c5\u5883\u548c\u88ab\u8bd5\u7684\u4ee3\u8868\u6027\u4e3b\u8981\u5f71\u54cd\u5b9e\u9a8c\u7684____\u3002\nA. \u5185\u5728\u6548\u5ea6\nB. \u5916\u5728\u6548\u5ea6\nC. \u96be\u5ea6\nD. \u533a\u5206\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7411824440041648, "meta-math/MetaMath-Mistral-7B": 0.8973313224762176, "itpossible/Chinese-Mistral-7B-v0.1": 0.7897725929655611, "HuggingFaceH4/zephyr-7b-beta": 0.9222153331724565, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8253849269615188, "meta-llama/Meta-Llama-3-8B": 0.44039831228401727, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6559\u80b2\u5fc3\u7406\u5b66\u7814\u7a76\u7684\u6839\u672c\u4efb\u52a1\u5728\u4e8e____\u3002\nA. \u7814\u7a76\u5fc3\u7406\u73b0\u8c61\nB. \u5bf9\u5fc3\u7406\u8fdb\u884c\u6d4b\u91cf\nC. \u83b7\u53d6\u5fc3\u7406\u6570\u636e\uff0c\u533a\u5206\u5fc3\u7406\u9ad8\u4e0b\nD. \u7814\u7a76\u3001\u63ed\u793a\u6559\u80b2\u8fc7\u7a0b\u4e2d\u5b66\u751f\u5b66\u4e60\u7684\u6027\u8d28\u3001\u7279\u70b9\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9344609832326047, "meta-math/MetaMath-Mistral-7B": 0.9865290842885004, "itpossible/Chinese-Mistral-7B-v0.1": 0.9537383542837777, "HuggingFaceH4/zephyr-7b-beta": 0.9992927348294318, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9599171952762089, "meta-llama/Meta-Llama-3-8B": 0.8694592682729443, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9973149568980124}}, {"question": "\u5317\u4eac\u5927\u5b66\u7684\u524d\u8eab\u662f____\u3002\nA. \u4eac\u5e08\u5927\u5b66\u5802\nB. \u4eac\u5e08\u540c\u6587\u9986\nC. \u5929\u6d25\u4e2d\u897f\u5b66\u5802\nD. \u65f6\u52a1\u5b66\u5802\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3824574376918888, "itpossible/Chinese-Mistral-7B-v0.1": 0.7167233424288736, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9281287145825475, "meta-llama/Meta-Llama-3-8B": 0.6319848942973493, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9551034598266622}}, {"question": "\u7f57\u6770\u65af\u63d0\u51fa\u7684\u5b66\u4e60\u52a8\u673a\u7406\u8bba\u662f____\u3002\nA. \u9700\u8981\u5c42\u6b21\u8bba\nB. \u5f3a\u5316\u7406\u8bba\nC. \u81ea\u6211\u6548\u80fd\u611f\u7406\u8bba\nD. \u81ea\u7531\u5b66\u4e60\u7406\u8bba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.470389574003656, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9727645672712871}}, {"question": "\u4ee5\u4e0b\u5173\u4e8e\u8fc1\u79fb\u7684\u7406\u89e3\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u4ece\u4e00\u822c\u5e73\u884c\u56db\u8fb9\u5f62\u6709\u5173\u5185\u5bb9\u7684\u638c\u63e1\u5f71\u54cd\u83f1\u5f62\u7684\u5b66\u4e60\uff0c\u5c5e\u4e8e\u81ea\u4e0a\u800c\u4e0b\u7684\u5782\u76f4\u8fc1\u79fb\nB. \u5728\u540c\u5316\u8fc1\u79fb\u4e2d\uff0c\u539f\u6709\u8ba4\u77e5\u7ed3\u6784\u5728\u8fc1\u79fb\u4e2d\u4e0d\u53d1\u751f\u5b9e\u8d28\u6027\u6539\u53d8\uff0c\u53ea\u5f97\u5230\u67d0\u79cd\u5145\u5b9e\nC. \u5904\u4e8e\u540c\u4e00\u6982\u62ec\u6c34\u5e73\u7684\u7ecf\u9a8c\u4e4b\u95f4\u7684\u76f8\u4e92\u5f71\u54cd\u662f\u5782\u76f4\u8fc1\u79fb\nD. \u5b9a\u52bf\u8fc1\u79fb\u7684\u5f71\u54cd\u8868\u73b0\u4e3a\u4fc3\u8fdb\u548c\u963b\u788d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30748613245592255, "meta-math/MetaMath-Mistral-7B": 0.6485131549793489, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.47733939773552564, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4243461747046515, "meta-llama/Meta-Llama-3-8B": 0.35686329776860143, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u660e\u786e\u63d0\u51fa\u6559\u80b2\u76ee\u7684\u662f\u4e3a\u201c\u5b8c\u6ee1\u7684\u751f\u6d3b\u201d\u505a\u51c6\u5907\u7684\u6559\u80b2\u5bb6\u662f____\nA. \u675c\u5a01\nB. \u65af\u5bbe\u585e\nC. \u9676\u884c\u77e5\nD. \u9648\u9e64\u7434\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u901a\u8fc7\u5b66\u4e60\u800c\u5f62\u6210\u7684\u5408\u4e4e\u6cd5\u5219\u7684\u5fc3\u667a\u6d3b\u52a8\u65b9\u5f0f\u5373\u662f____\u3002\nA. \u667a\u529b\u6280\u80fd\nB. \u77e5\u8bc6\u8fc1\u79fb\nC. \u667a\u529b\nD. \u601d\u7ef4\u7a0b\u5e8f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5359319802365388, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8994280703831725}}, {"question": "19\u4e16\u7eaa\uff0c\u7f8e\u56fd\u4e2d\u7b49\u6559\u80b2\u6700\u4e3b\u8981\u7684\u5f62\u5f0f\u662f____\u3002\nA. \u6587\u79d1\u4e2d\u5b66\nB. \u6587\u5b9e\u4e2d\u5b66\nC. \u516c\u7acb\u4e2d\u5b66\nD. \u6587\u6cd5\u5b66\u6821\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.39564235197810277, "itpossible/Chinese-Mistral-7B-v0.1": 0.39845853297483913, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3030891829477218, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u5c5e\u4e8e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6559\u5e08\u6cd5\u300b\u660e\u786e\u89c4\u5b9a\u7684\u6559\u5e08\u4e13\u4e1a\u6743\u5229\u7684\u662f____\nA. \u6307\u5bfc\u5b66\u751f\u5b66\u4e60\u4e0e\u53d1\u5c55\u7684\u6743\u5229\nB. \u5bf9\u5b66\u6821\u8fdb\u884c\u7ba1\u7406\u4e0e\u9886\u5bfc\u7684\u6743\u5229\nC. \u9009\u62e9\u6559\u6750\u6559\u6cd5\u5f00\u5c55\u6559\u5b66\u5de5\u4f5c\u7684\u6743\u5229\nD. \u68c0\u67e5\u4e0e\u8bc4\u4ef7\u5b66\u751f\u54c1\u884c\u3001\u5b66\u4e1a\u3001\u8eab\u4f53\u7684\u6743\u5229\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.8319932463920704, "itpossible/Chinese-Mistral-7B-v0.1": 0.6921556252351793, "HuggingFaceH4/zephyr-7b-beta": 0.7236628155270738, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u5b66\u8005\u5f3a\u8c03\uff0c\u6559\u80b2\u8981\u6839\u636e\u4e00\u4e2a\u6c11\u65cf\u56fa\u6709\u7684\u7279\u5f81\u6765\u5b9a\uff0c\u8fd9\u79cd\u89c2\u70b9\u4f53\u73b0\u4e86____\nA. \u751f\u4ea7\u529b\u5bf9\u6559\u80b2\u7684\u5f71\u54cd\u548c\u5236\u7ea6\nB. \u653f\u6cbb\u5236\u5ea6\u5bf9\u6559\u80b2\u7684\u5f71\u54cd\u548c\u5236\u7ea6\nC. \u6587\u5316\u5bf9\u6559\u80b2\u7684\u5f71\u54cd\u548c\u5236\u7ea6\nD. \u7ecf\u6d4e\u5236\u5ea6\u5bf9\u6559\u80b2\u7684\u5f71\u54cd\u548c\u5236\u7ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9616453842919156, "meta-math/MetaMath-Mistral-7B": 0.9946549175240968, "itpossible/Chinese-Mistral-7B-v0.1": 0.8411063534111177, "HuggingFaceH4/zephyr-7b-beta": 0.9993368250541055, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9889441402457481, "meta-llama/Meta-Llama-3-8B": 0.9235903162969267, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.998449140078726}}, {"question": "\u6559\u5e08\u6559\u5b66\u53cd\u601d\u7684\u6210\u5206\u4e0d\u5305\u62ec____\u3002\nA. \u8ba4\u77e5\u6210\u5206\nB. \u601d\u7ef4\u6210\u5206\nC. \u6279\u5224\u6210\u5206\nD. \u6559\u5e08\u7684\u9648\u8ff0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4e0d\u5c5e\u4e8e\u6559\u80b2\u79d1\u5b66\u7814\u7a76\u65b9\u6cd5\u8bba\u539f\u5219\u7684\u662f____\u3002\nA. \u7406\u8bba\u8054\u7cfb\u5b9e\u9645\nB. \u6ce8\u610f\u7406\u8bba\u7684\u5c42\u6b21\u6027\nC. \u52a0\u5f3a\u7efc\u5408\u7814\u7a76\nD. \u6539\u8fdb\u7814\u7a76\u7684\u6548\u7387\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7862133667017525, "meta-math/MetaMath-Mistral-7B": 0.8559422314877688, "itpossible/Chinese-Mistral-7B-v0.1": 0.5451708165284831, "HuggingFaceH4/zephyr-7b-beta": 0.6508189558731521, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9096937331363322, "meta-llama/Meta-Llama-3-8B": 0.7743365041045303, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9471089532332424}}, {"question": "\u201c\u5929\u5c06\u964d\u5927\u4efb\u4e8e\u65af\u4eba\u4e5f\uff0c\u5fc5\u5148\u82e6\u5176\u5fc3\u5fd7\uff0c\u52b3\u5176\u7b4b\u9aa8\uff0c\u997f\u5176\u4f53\u80a4\uff0c\u7a7a\u4e4f\u5176\u8eab\uff0c\u884c\u62c2\u4e71\u5176\u6240\u4e3a\uff0c\u6240\u4ee5\u52a8\u5fc3\u5fcd\u6027\uff0c\u589e\u76ca\u5176\u6240\u4e0d\u80fd\u3002\u201d\u4f53\u73b0\u7684\u5fb7\u80b2\u65b9\u6cd5\u662f____\nA. \u8bf4\u670d\u6559\u80b2\nB. \u699c\u6837\u793a\u8303\nC. \u60c5\u611f\u9676\u51b6\nD. \u5b9e\u9645\u953b\u70bc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9207224109956913, "meta-math/MetaMath-Mistral-7B": 0.9929805199755172, "itpossible/Chinese-Mistral-7B-v0.1": 0.9202130897675306, "HuggingFaceH4/zephyr-7b-beta": 0.9973536990623538, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9939671208917877, "meta-llama/Meta-Llama-3-8B": 0.8676871472126992, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u5fb7\u80b2\u8fc7\u7a0b\u4e2d\uff0c\u53ea\u770b\u5230\u5b66\u751f\u5dee\u7684\u5730\u65b9\uff0c\u8ba4\u4e3a\u5176\u65e0\u53ef\u6551\u836f\uff0c\u8fd9\u8fdd\u80cc\u4e86\u5fb7\u80b2\u7684____\u539f\u5219\u3002\nA. \u77e5\u884c\u7edf\u4e00\nB. \u4e25\u683c\u8981\u6c42\u4e0e\u5c0a\u91cd\u4fe1\u4efb\u76f8\u7ed3\u5408\nC. \u7167\u987e\u5e74\u9f84\u7279\u70b9\u4e0e\u7167\u987e\u4e2a\u522b\u7279\u70b9\u76f8\u7ed3\u5408\nD. \u53d1\u6325\u79ef\u6781\u56e0\u7d20\u4e0e\u514b\u670d\u6d88\u6781\u56e0\u7d20\u76f8\u7ed3\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5557113084584708, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7264092379172371}}, {"question": "\u72ed\u4e49\u7684\u6559\u80b2\u4e3b\u8981\u662f\u6307____\u3002\nA. \u5bb6\u5ead\u6559\u80b2\nB. \u5b66\u6821\u6559\u80b2\nC. \u793e\u4f1a\u6559\u80b2\nD. \u804c\u4e1a\u6559\u80b2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.525283176559708, "meta-math/MetaMath-Mistral-7B": 0.8119830459139412, "itpossible/Chinese-Mistral-7B-v0.1": 0.6907044118266287, "HuggingFaceH4/zephyr-7b-beta": 0.9635329626418085, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8135069814675027, "meta-llama/Meta-Llama-3-8B": 0.9135649742779282, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9830534694116796}}, {"question": "\u6839\u636e\u5b66\u672f\u95e8\u7c7b\u5212\u5206\u6216\u804c\u4e1a\u95e8\u7c7b\u5212\u5206\uff0c\u5c06\u8bfe\u7a0b\u7ec4\u5408\u6210\u4e0d\u540c\u7684\u4e13\u95e8\u5316\u9886\u57df\uff0c\u8fd9\u4e9b\u7ec4\u5408\u88ab\u79f0\u4e3a____\u3002\nA. \u8bfe\u7a0b\nB. \u4e13\u4e1a\nC. \u6559\u5b66\u8ba1\u5212\nD. \u6559\u5b66\u5927\u7eb2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5042824200916275, "meta-math/MetaMath-Mistral-7B": 0.940485705346925, "itpossible/Chinese-Mistral-7B-v0.1": 0.8601568443225925, "HuggingFaceH4/zephyr-7b-beta": 0.9844771070386705, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9716256643112811, "meta-llama/Meta-Llama-3-8B": 0.8444007071674499, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9839159322751228}}, {"question": "\u989c\u5143\u5bf9\u4f20\u7edf\u6559\u80b2\u7684\u6279\u5224\uff0c\u4e0d\u5305\u62ec____\nA. \u63ed\u9732\u4f20\u7edf\u6559\u80b2\u4e25\u91cd\u8131\u79bb\u5b9e\u9645\nB. \u53cd\u5bf9\u5c01\u5efa\u4e13\u5236\u653f\u6743\nC. \u6279\u5224\u4f20\u7edf\u6559\u80b2\u7684\u4e49\u3001\u5229\u5bf9\u7acb\u89c2\nD. \u62a8\u51fb\u516b\u80a1\u53d6\u58eb\u5236\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2731272040287072, "HuggingFaceH4/zephyr-7b-beta": 0.5682212424429312, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7135112329192924, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f9d\u636e\u8d6b\u5c14\u5df4\u7279\u7684\u6559\u5b66\u9636\u6bb5\u8bba\uff0c\u5f53\u5b66\u751f\u7684\u5174\u8da3\u5904\u4e8e\u201c\u671f\u5f85\u201d\u65f6\uff0c\u6559\u5b66\u9636\u6bb5\u662f____\nA. \u660e\u4e86\nB. \u8054\u60f3\nC. \u7cfb\u7edf\nD. \u65b9\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.381476856740517, "meta-math/MetaMath-Mistral-7B": 0.6497350777604554, "itpossible/Chinese-Mistral-7B-v0.1": 0.5229506525454042, "HuggingFaceH4/zephyr-7b-beta": 0.49078424639115703, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6195196056080123, "meta-llama/Meta-Llama-3-8B": 0.3697865057172407, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82cf\u80541966\u5e74\u6559\u80b2\u6539\u9769\u7684\u4e3b\u8981\u4efb\u52a1\u662f____\nA. \u4f7f\u5b66\u751f\u83b7\u5f97\u7262\u56fa\u7684\u79d1\u5b66\u57fa\u7840\u77e5\u8bc6\uff0c\u5177\u6709\u9ad8\u5ea6\u7684\u89c9\u609f\uff0c\u57f9\u517b\u9752\u5e74\u9762\u5411\u751f\u6d3b\u5e76\u80fd\u81ea\u89c9\u5730\u9009\u62e9\u804c\u4e1a\nB. \u5b9e\u884c\u201c\u4eba\u9053\u4e3b\u4e49\u201d\u201c\u591a\u5143\u5316\u201d\u201c\u6c11\u4e3b\u5316\u201d\nC. \u4e3a\u9ad8\u4e00\u7ea7\u5b66\u6821\u57f9\u517b\u548c\u8f93\u9001\u5408\u683c\u7684\u6bd5\u4e1a\u751f\nD. \u5bf9\u666e\u901a\u6559\u80b2\u3001\u804c\u4e1a\u6559\u80b2\u3001\u6280\u672f\u6559\u80b2\u548c\u9ad8\u7b49\u6559\u80b2\u7684\u6539\u9769\u63d0\u51fa\u4e86\u5177\u4f53\u7684\u8981\u6c42\u548c\u63aa\u65bd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7397715238357095, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.940551958125343}}, {"question": "\u7f16\u5199\u4e2d\u5c0f\u5b66\u6559\u79d1\u4e66\u7684\u76f4\u63a5\u4f9d\u636e\u662f____\u3002\nA. \u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u6559\u80b2\u6cd5\u300b\nB. \u8bfe\u7a0b\u8ba1\u5212\nC. \u8bfe\u7a0b\u6807\u51c6\nD. \u8bfe\u7a0b\u8868\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44069147705059225, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6193844216384358, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6144193877589754, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u8bfe\u7a0b\u7684\u4e09\u79cd\u6587\u672c\u8868\u73b0\u5f62\u5f0f\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u8bfe\u7a0b\u8ba1\u5212\u662f\u7531\u5f53\u5730\u6559\u80b2\u4e3b\u7ba1\u90e8\u95e8\u5236\u8ba2\u7684\nB. \u8bfe\u7a0b\u6807\u51c6\u662f\u4f9d\u636e\u8bfe\u7a0b\u8ba1\u5212\u5236\u5b9a\u7684\nC. \u8bfe\u7a0b\u6807\u51c6\u7684\u6838\u5fc3\u662f\u5b9e\u65bd\u5efa\u8bae\nD. \u6559\u6750\u7f16\u5199\u7684\u57fa\u672c\u65b9\u5f0f\u6709\u76f4\u7ebf\u5f0f\u3001\u87ba\u65cb\u5f0f\u3001\u4ea4\u53c9\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4839879942290105, "HuggingFaceH4/zephyr-7b-beta": 0.8011531687533583, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u60a6\u60a6\u662f\u4e00\u540d\u53f3\u8033\u5931\u806a\u7684\u6b8b\u75be\u513f\u7ae5\uff0c\u6d3b\u52a8\u8bfe\u4e0a\u6709\u65f6\u4f1a\u542c\u4e0d\u6e05\u695a\u5468\u8001\u5e08\u6240\u8bb2\u7684\u5185\u5bb9\uff0c\u56e0\u6b64\u7ecf\u5e38\u63d0\u95ee\u9898\u3002\u5bf9\u6b64\uff0c\u5468\u8001\u5e08\u5e94\u5f53\u91c7\u53d6\u7684\u63aa\u65bd\u662f____\u3002\nA. \u7ed9\u4e88\u60a6\u60a6\u66f4\u591a\u7684\u5e2e\u52a9\u548c\u6307\u5bfc\nB. \u6307\u5bfc\u5bb6\u957f\u5e26\u60a6\u60a6\u56de\u5bb6\u81ea\u5b66\nC. \u5efa\u8bae\u5bb6\u957f\u5c06\u60a6\u60a6\u8f6c\u5230\u7279\u6b8a\u5e7c\u513f\u56ed\nD. \u7167\u987e\u5927\u591a\u6570\u5e7c\u513f\uff0c\u4e0d\u7406\u4f1a\u60a6\u60a6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5836040361616867, "meta-math/MetaMath-Mistral-7B": 0.9939641425325147, "itpossible/Chinese-Mistral-7B-v0.1": 0.6583106063452717, "HuggingFaceH4/zephyr-7b-beta": 0.9999909282305917, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9925878781578534, "meta-llama/Meta-Llama-3-8B": 0.6761375039864048, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8783975989640093}}, {"question": "\u5185\u6d41\u6cb3\u4e5f\u79f0\u201c\u5185\u9646\u6cb3\u201d\uff0c\u662f\u6307\u6ca1\u6709\u6d41\u5165\u6d77\u6d0b\u7684\u6cb3\u6d41\uff0c\u5927\u591a\u5206\u5e03\u5728\u5927\u9646\u5185\u90e8\u5e72\u71e5\u5730\u533a\uff0c\u4e0a\u6e38\u964d\u6c34\u6216\u51b0\u96ea\u878d\u6c34\u4e3a\u5176\u4e3b\u8981\u8865\u7ed9\u6c34\u6e90\uff0c\u6700\u7ec8\u6d88\u5931\u4e8e\u6c99\u6f20\u6216\u6ce8\u5165\u5185\u9646\u6e56\u6cca\u3002\u4e0b\u5217\u4e2d\u56fd\u5185\u6d41\u6cb3\u4e2d\uff0c\u6700\u957f\u7684\u662f____\u3002\nA. \u5854\u91cc\u6728\u6cb3\nB. \u67f4\u8fbe\u6728\u6cb3\nC. \u5c3c\u96c5\u6cb3\nD. \u758f\u52d2\u6cb3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3788721596190015, "meta-math/MetaMath-Mistral-7B": 0.5199028280849962, "itpossible/Chinese-Mistral-7B-v0.1": 0.5594256649813023, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49501293254875606, "meta-llama/Meta-Llama-3-8B": 0.5613323580077195, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5b66\u6821\u89c4\u5b9a\u5b66\u751f\u4e0d\u80fd\u70eb\u67d3\u5934\u53d1\uff0c\u4f46\u662f\u5c0f\u6587\u4e3a\u4e86\u5f70\u663e\u4e2a\u6027\uff0c\u5728\u5047\u671f\u628a\u5934\u53d1\u67d3\u6210\u4e86\u68d5\u8272\u3002\u9762\u5bf9\u5c0f\u6587\u7684\u60c5\u51b5\uff0c\u6559\u5e08\u5e94\u8be5\u600e\u6837\u5904\u7406\uff1f____\nA. \u5e74\u8f7b\u4eba\u8ffd\u6c42\u4e2a\u6027\u662f\u5408\u60c5\u5408\u7406\u7684\uff0c\u5e94\u8be5\u5bbd\u5bb9\u5bf9\u5f85\nB. \u8fdd\u53cd\u5b66\u6821\u7684\u6821\u89c4\uff0c\u5e94\u8be5\u4e25\u683c\u5904\u5206\nC. \u5f3a\u5236\u8981\u6c42\u5c0f\u6587\u5c06\u5934\u53d1\u989c\u8272\u67d3\u56de\u6765\u624d\u53ef\u4ee5\u8fdb\u6821\u95e8\nD. \u63a2\u660e\u5c0f\u6587\u8fdd\u53cd\u6821\u89c4\u7684\u539f\u56e0\uff0c\u5e76\u5bf9\u5176\u8fdb\u884c\u529d\u5bfc\u548c\u6559\u80b2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.91244733926714, "meta-math/MetaMath-Mistral-7B": 0.9944594024515117, "itpossible/Chinese-Mistral-7B-v0.1": 0.9800853944497667, "HuggingFaceH4/zephyr-7b-beta": 0.9962712584454865, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8913479555867608, "meta-llama/Meta-Llama-3-8B": 0.8494189542834364, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.841486248209628}}, {"question": "\u5f20\u8001\u5e08\u6839\u636e\u81ea\u5df1\u73ed\u7ea7\u7684\u60c5\u51b5\uff0c\u4e3a\u89e3\u51b3\u73ed\u7ea7\u5185\u90e8\u73ed\u5e72\u90e8\u7684\u4eba\u9645\u5173\u7cfb\u95ee\u9898\uff0c\u5efa\u7acb\u548c\u8c10\u878d\u6d3d\u7684\u73ed\u7ea7\u6c1b\u56f4\uff0c\u81ea\u4e3b\u5f00\u53d1\u4e86\u201c\u548c\u8c10\u4eba\u9645\u201d\u7684\u73ed\u7ea7\u8bfe\u7a0b\uff0c\u8fd9\u4f53\u73b0\u4e86\u6559\u5e08____\u3002\nA. \u662f\u6559\u80b2\u6559\u5b66\u7684\u7814\u7a76\u8005\nB. \u662f\u8bfe\u7a0b\u7684\u5efa\u8bbe\u8005\u548c\u5f00\u53d1\u8005\nC. \u662f\u5b66\u751f\u5b66\u4e60\u7684\u4fc3\u8fdb\u8005\nD. \u662f\u793e\u533a\u578b\u7684\u5f00\u653e\u6559\u5e08\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.56772284728874, "meta-math/MetaMath-Mistral-7B": 0.8950614429444311, "itpossible/Chinese-Mistral-7B-v0.1": 0.9418394498361694, "HuggingFaceH4/zephyr-7b-beta": 0.9994263815308263, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7927141137917537, "meta-llama/Meta-Llama-3-8B": 0.6837774376090819, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9929113378759198}}, {"question": "\u5218\u8001\u5e08\u5de5\u4f5c\u5f88\u8d1f\u8d23\uff0c\u5b66\u751f\u5728\u5b66\u6821\u51fa\u73b0\u4e00\u70b9\u95ee\u9898\u4ed6\u5c31\u4f1a\u4e0e\u5bb6\u957f\u8054\u7cfb\uff0c\u5728\u4e0e\u5bb6\u957f\u6c9f\u901a\u65f6\u4ed6\u7ecf\u5e38\u4ee5\u524d\u8f88\u7684\u59ff\u6001\u5bf9\u5f85\u5bb6\u957f\uff0c\u5bf9\u5bb6\u957f\u7684\u6559\u80b2\u65b9\u5f0f\u6307\u6307\u70b9\u70b9\u3002\u5218\u8001\u5e08\u7684\u505a\u6cd5____\u3002\nA. \u6b63\u786e\uff0c\u8001\u5e08\u5c31\u5e94\u8be5\u4e0e\u5bb6\u957f\u7ecf\u5e38\u6c9f\u901a\nB. \u6b63\u786e\uff0c\u8001\u5e08\u7684\u7ecf\u9a8c\u6bd4\u5bb6\u957f\u4e30\u5bcc\uff0c\u5e94\u8be5\u591a\u6307\u5bfc\u5bb6\u957f\nC. \u4e0d\u6b63\u786e\uff0c\u6559\u5e08\u6ca1\u6709\u6743\u5229\u6307\u5bfc\u5bb6\u957f\nD. \u4e0d\u6b63\u786e\uff0c\u6559\u5e08\u5e94\u8be5\u4e0e\u5bb6\u957f\u5efa\u7acb\u5e73\u7b49\u7684\u6c9f\u901a\u5173\u7cfb\uff0c\u5c0a\u91cd\u5bb6\u957f\u7684\u4eba\u683c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7695305616165715, "meta-math/MetaMath-Mistral-7B": 0.8698007115641297, "itpossible/Chinese-Mistral-7B-v0.1": 0.4478756187815991, "HuggingFaceH4/zephyr-7b-beta": 0.9462692394210094, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7093295513335099, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9477498568266796}}, {"question": "\u5728\u53e4\u4ee3\u5370\u5ea6\uff0c\u6709\u4e00\u6237\u4eba\u5bb6\u7ecf\u8425\u4e00\u5bb6\u68c9\u5e03\u5e97\u9500\u552e\u81ea\u5df1\u624b\u5de5\u5236\u4f5c\u7684\u8863\u670d\u3002\u4f60\u8ba4\u4e3a\u8fd9\u6237\u4eba\u5bb6\u5c5e\u4e8e\u54ea\u4e2a\u7b49\u7ea7\uff1f____\nA. \u5a46\u7f57\u95e8\nB. \u5239\u5e1d\u5229\nC. \u5420\u820d\nD. \u9996\u9640\u7f57\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4336207307032468, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5265984790634278, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4628413584354076}}, {"question": "\u201c\u5c0f\u578b\u5206\u6563\uff0c\u4fbf\u4e8e\u5f00\u5c55\u591a\u79cd\u591a\u6837\u7684\u6d3b\u52a8\uff0c\u6ee1\u8db3\u5b66\u751f\u4e0d\u540c\u7684\u5174\u8da3\u3001\u7231\u597d\uff0c\u53d1\u5c55\u5b66\u751f\u7684\u624d\u80fd\uff0c\u4f7f\u5b66\u751f\u5f97\u5230\u66f4\u591a\u7684\u5b66\u4e60\u548c\u953b\u70bc\u7684\u673a\u4f1a\u3002\u201d\u8fd9\u79cd\u8bfe\u5916\u6d3b\u52a8\u7684\u5f62\u5f0f\u662f____\u3002\nA. \u79d1\u6280\u6d3b\u52a8\nB. \u5b66\u79d1\u6d3b\u52a8\nC. \u4e2a\u4eba\u6d3b\u52a8\nD. \u5c0f\u7ec4\u6d3b\u52a8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8906470500915243, "meta-math/MetaMath-Mistral-7B": 0.9939243131042109, "itpossible/Chinese-Mistral-7B-v0.1": 0.8879261239810792, "HuggingFaceH4/zephyr-7b-beta": 0.9761454285446781, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9823317979067344, "meta-llama/Meta-Llama-3-8B": 0.7445456285455141, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9951844722682849}}, {"question": "\u5c0f\u7ea2\u6bcf\u5929\u665a\u4e0a\u4e34\u7761\u524d\u90fd\u8981\u591a\u6b21\u53cd\u590d\u68c0\u67e5\u81ea\u5df1\u7684\u4e66\u5305\uff0c\u786e\u4fdd\u5e26\u9f50\u4e86\u7b2c\u4e8c\u5929\u9700\u8981\u7528\u7684\u6559\u6750\u548c\u6587\u5177\u3002\u5979\u660e\u77e5\u9053\u6ca1\u6709\u8fd9\u4e2a\u5fc5\u8981\uff0c\u4f46\u5c31\u662f\u63a7\u5236\u4e0d\u4f4f\u3002\u5979\u53ef\u80fd\u51fa\u73b0\u4e86____\u3002\nA. \u6291\u90c1\u75c7\nB. \u7126\u8651\u75c7\nC. \u5f3a\u8feb\u75c7\nD. \u6050\u60e7\u75c7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9622304547321768, "meta-math/MetaMath-Mistral-7B": 0.9944848739445207, "itpossible/Chinese-Mistral-7B-v0.1": 0.9756577306199381, "HuggingFaceH4/zephyr-7b-beta": 0.9998516485923172, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9826386611492901, "meta-llama/Meta-Llama-3-8B": 0.9806196643429466, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9986640278464085}}, {"question": "\u56fd\u5bb6\u7ba1\u7406\u548c\u8bc4\u4ef7\u8bfe\u7a0b\u7684\u57fa\u7840\u662f____\u3002\nA. \u8bfe\u7a0b\u8ba1\u5212\nB. \u8bfe\u7a0b\u6807\u51c6\nC. \u6559\u5b66\u76ee\u6807\nD. \u6559\u80b2\u76ee\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.42276152507198483, "meta-math/MetaMath-Mistral-7B": 0.6949905070641157, "itpossible/Chinese-Mistral-7B-v0.1": 0.9400425598961871, "HuggingFaceH4/zephyr-7b-beta": 0.9412642969683145, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8238930855055108, "meta-llama/Meta-Llama-3-8B": 0.8953118392376548, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9652974582078871}}, {"question": "\u513f\u7ae5\u575a\u6301\u6027\u53d1\u751f\u660e\u663e\u8d28\u53d8\u7684\u5e74\u9f84\u7ea6\u5728____\nA. 3\uff5e4\u5c81\nB. 4\uff5e5\u5c81\nC. 5\uff5e6\u5c81\nD. 6\u5c81\u4ee5\u540e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.39948612502398734, "itpossible/Chinese-Mistral-7B-v0.1": 0.29660173325630934, "HuggingFaceH4/zephyr-7b-beta": 0.905015170048377, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u7ea2\u697c\u68a6\u300b\u4e2d\u4eba\u7269\u4f17\u591a\u3001\u5173\u7cfb\u7e41\u6742\u3002\u4e3a\u4e86\u5e2e\u52a9\u8bfb\u8005\u9605\u8bfb\uff0c\u8bb8\u591a\u7ea2\u5b66\u7231\u597d\u8005\u90fd\u5728\u7f51\u7edc\u4e0a\u53d1\u5e03\u4e86\u81ea\u5df1\u6574\u7406\u5236\u4f5c\u7684\u4e3b\u8981\u4eba\u7269\u5173\u7cfb\u56fe\u3002\u8fd9\u5c5e\u4e8e____\u3002\nA. \u7eb2\u8981\u7b56\u7565\nB. \u7cbe\u7ec6\u52a0\u5de5\u7b56\u7565\nC. \u8d44\u6e90\u7ba1\u7406\u7b56\u7565\nD. \u76d1\u63a7\u7b56\u7565\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6458809311656324, "meta-math/MetaMath-Mistral-7B": 0.6958151071308378, "itpossible/Chinese-Mistral-7B-v0.1": 0.37878899535834104, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6186605696180115, "meta-llama/Meta-Llama-3-8B": 0.49449535700214714, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7966509420570569}}, {"question": "\u5b66\u671f\u7ed3\u675f\u65f6\uff0c\u73ed\u4e3b\u4efb\u738b\u8001\u5e08\u4f1a\u5bf9\u5b66\u751f\u601d\u60f3\u54c1\u5fb7\u7684\u53d1\u5c55\u53d8\u5316\u60c5\u51b5\u8fdb\u884c\u8bc4\u4ef7\u3002\u8fd9\u9879\u5de5\u4f5c\u5c5e\u4e8e____\u3002\nA. \u5de5\u4f5c\u603b\u7ed3\nB. \u5de5\u4f5c\u8ba1\u5212\nC. \u64cd\u884c\u8bc4\u5b9a\nD. \u5efa\u7acb\u5b66\u751f\u6863\u6848\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6793296461149315, "meta-math/MetaMath-Mistral-7B": 0.97754806270256, "itpossible/Chinese-Mistral-7B-v0.1": 0.8649856334840986, "HuggingFaceH4/zephyr-7b-beta": 0.9715483639254674, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4808686875188171, "meta-llama/Meta-Llama-3-8B": 0.945653415360283, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9936201808110138}}, {"question": "\u4eba\u4eec\u5e38\u8bf4\uff1a\u201c\u6559\u5b66\u6709\u6cd5\u800c\u6559\u65e0\u5b9a\u6cd5\u3002\u201d\u8fd9\u53cd\u6620\u4e86\u6559\u5e08\u7684\u52b3\u52a8\u5177\u6709____\u3002\nA. \u8fde\u7eed\u6027\nB. \u793a\u8303\u6027\nC. \u957f\u671f\u6027\nD. \u521b\u9020\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8694592530514276, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6437934317634407, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8015276151153088}}, {"question": "\u53bf\u7ea7\u4ee5\u4e0a\u5730\u65b9\u5404\u7ea7\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u662f\u53bf\u7ea7\u4ee5\u4e0a\u5730\u65b9\u56fd\u5bb6\u6743\u529b\u673a\u5173\uff0c\u5176\u804c\u6743\u4e0d\u5305\u62ec____\u3002\nA. \u6539\u53d8\u6216\u64a4\u9500\u672c\u7ea7\u4eba\u5927\u5e38\u52a1\u59d4\u5458\u4f1a\u4e0d\u9002\u5f53\u7684\u51b3\u5b9a\nB. \u9009\u4e3e\u5e76\u6709\u6743\u7f62\u514d\u672c\u7ea7\u4eba\u6c11\u6cd5\u9662\u9662\u957f\nC. \u6279\u51c6\u672c\u884c\u653f\u533a\u57df\u5185\u7684\u9884\u7b97\u6267\u884c\u60c5\u51b5\u7684\u62a5\u544a\nD. \u51b3\u5b9a\u5e76\u5ba3\u5e03\u4e0b\u4e00\u7ea7\u884c\u653f\u533a\u57ce\u8fdb\u5165\u7d27\u6025\u72b6\u6001\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4121891791881366, "meta-math/MetaMath-Mistral-7B": 0.8125807435723533, "itpossible/Chinese-Mistral-7B-v0.1": 0.353703093539192, "HuggingFaceH4/zephyr-7b-beta": 0.8899134753514653, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.371068906204966, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u5fc3\u7406\u5065\u5eb7\u8bfe\u4e0a\uff0c\u540c\u4e00\u6279\u5b66\u751f\u5728\u7b2c\u4e8c\u6b21\u8fdb\u884c\u540c\u6837\u5185\u5bb9\u7684\u4eba\u683c\u6d4b\u9a8c\u65f6\u83b7\u5f97\u7684\u5206\u6570\u4e0e\u4e0a\u6b21\u6d4b\u9a8c\u5dee\u522b\u8f83\u5927\u3002\u8fd9\u8bf4\u660e\u8be5\u6d4b\u9a8c\u5b58\u5728\u7684\u95ee\u9898\u662f____\u3002\nA. \u4fe1\u5ea6\u95ee\u9898\nB. \u6548\u5ea6\u95ee\u9898\nC. \u96be\u5ea6\u95ee\u9898\nD. \u533a\u5206\u5ea6\u95ee\u9898\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.33065623127838467, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u674e\u8001\u5e08\u5728\u6559\u5b66\u751f\u533a\u5206\u5f62\u8fd1\u5b57\u201c\u6e34\u201d\u201c\u7aed\u201d\u201c\u78a3\u201d\u201c\u8c12\u201d\u65f6\uff0c\u5c06\u56db\u4e2a\u5b57\u76f8\u540c\u7684\u53f3\u534a\u90e8\u5206\u7528\u767d\u8272\u7c89\u7b14\u5199\u51fa\uff0c\u76f8\u5f02\u7684\u5de6\u534a\u90e8\u5206\u7528\u5f69\u8272\u7c89\u7b14\u5199\u51fa\u3002\u674e\u8001\u5e08\u8fd0\u7528\u4e86\u77e5\u89c9\u7684____\u3002\nA. \u6574\u4f53\u6027\nB. \u9009\u62e9\u6027\nC. \u7406\u89e3\u6027\nD. \u6052\u5e38\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8087865411489483, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.618100704978697, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8192632968721925}}, {"question": "\u5170\u5170\u5b66\u4f1a\u8d70\u8def\u540e,\u5c31\u8981\u5f88\u559c\u6b22\u5c1d\u8bd5\u81ea\u5df1\u7a7f\u8863\u3001\u5403\u996d\u3001\u6361\u4e1c\u897f,\u559c\u6b22\u63a2\u7d22\u5468\u56f4\u4e16\u754c\u3002\u6309\u7167\u57c3\u91cc\u514b\u68ee\u4eba\u683c\u53d1\u5c55\u9636\u6bb5\u7406\u8bba,\u5170\u5170\u6240\u5904\u7684\u53d1\u5c55\u9636\u6bb5\u662f____\nA. \u4fe1\u4efb\u5bf9\u6000\u7591\nB. \u81ea\u7acb\u5bf9\u7f9e\u602f\nC. \u4e3b\u52a8\u611f\u5bf9\u5185\u759a\u611f\nD. \u52e4\u594b\u611f\u5bf9\u81ea\u5351\u611f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5421412282778802, "meta-math/MetaMath-Mistral-7B": 0.7371646787469069, "itpossible/Chinese-Mistral-7B-v0.1": 0.6531655343511422, "HuggingFaceH4/zephyr-7b-beta": 0.9902360413642222, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.877918362040069, "meta-llama/Meta-Llama-3-8B": 0.3802392203343767, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7102142172976783}}, {"question": "\u6768\u8001\u5e08\u5728\u6559\u6388\u751f\u5b57\u8bcd\u7684\u8fc7\u7a0b\u4e2d\u53d1\u73b0\u90e8\u5206\u5b66\u751f\u6709\u7f3a\u7b14\u5c11\u753b\u7684\u73b0\u8c61\uff0c\u4e8e\u662f\u4ed6\u628a\u201c\u5c0f\u5b66\u751f\u7f3a\u7b14\u5c11\u753b\u73b0\u8c61\u7684\u539f\u56e0\u53ca\u5bf9\u7b56\u7814\u7a76\u201d\u4f5c\u4e3a\u7814\u7a76\u8bfe\u9898\uff0c\u62df\u8ba2\u76f8\u5e94\u7684\u7814\u7a76\u8ba1\u5212\uff0c\u5728\u5de5\u4f5c\u4e2d\u6536\u96c6\u3001\u6574\u7406\u76f8\u5173\u8d44\u6599\u5e76\u5b9e\u65bd\u6559\u5b66\u63aa\u65bd\uff0c\u6700\u540e\u6839\u636e\u53cd\u9988\u4fe1\u606f\u8c03\u6574\u6559\u5b66\u65b9\u6848\u3002\u8fd9\u79cd\u7814\u7a76\u65b9\u6cd5\u5c5e\u4e8e____\u3002\nA. \u6559\u80b2\u884c\u52a8\u7814\u7a76\u6cd5\nB. \u6559\u80b2\u5b9e\u9a8c\u6cd5\nC. \u6559\u80b2\u53d9\u4e8b\u7814\u7a76\u6cd5\nD. \u4e2a\u6848\u7814\u7a76\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5413075809461042, "meta-math/MetaMath-Mistral-7B": 0.8018741378810536, "itpossible/Chinese-Mistral-7B-v0.1": 0.5190768592430574, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.324791615632753, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7230180651862156}}, {"question": "\u5c0f\u9752\u7684\u6570\u5b66\u6210\u7ee9\u4e0d\u597d\uff0c\u5979\u8ba4\u4e3a\u8fd9\u662f\u56e0\u4e3a\u81ea\u5df1\u8111\u5b50\u7b28\uff0c\u4e0d\u662f\u5b66\u6570\u5b66\u7684\u6599\u3002\u5979\u7684\u8fd9\u79cd\u5f52\u56e0\u5c5e\u4e8e____\u3002\nA. \u5185\u90e8\u3001\u7a33\u5b9a\uff0c\u4e0d\u53ef\u63a7\u7684\u5f52\u56e0\nB. \u5916\u90e8\u3001\u7a33\u5b9a\u3001\u53ef\u63a7\u7684\u5f52\u56e0\nC. \u5185\u90e8\u3001\u4e0d\u7a33\u5b9a\uff0c\u53ef\u63a7\u7684\u5f52\u56e0\nD. \u5916\u90e8\uff0c\u4e0d\u7a33\u5b9a\uff0c\u4e0d\u53ef\u63a7\u7684\u5f52\u56e0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3478540423117713, "meta-math/MetaMath-Mistral-7B": 0.528122469862168, "itpossible/Chinese-Mistral-7B-v0.1": 0.3444545218043904, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6633513315425215, "meta-llama/Meta-Llama-3-8B": 0.34695068109082333, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u5c0f\u5b66\u6559\u79d1\u4e66\u4e0d\u540c\u4e8e\u5176\u4ed6\u4efb\u4f55\u4e66\u7c4d\u7684\u57fa\u672c\u7279\u70b9\u662f\u5185\u5bb9\u7684____\u3002\nA. \u51c6\u786e\u6027\nB. \u793a\u8303\u6027\nC. \u65b0\u9896\u6027\nD. \u57fa\u7840\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5110393452589354, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5554901936985471, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8076405190291543, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u738b\u8001\u5e08\u5728\u8bfe\u5802\u4e0a\u7ed9\u5b66\u751f\u6f14\u793a\u4e86\u4e0e\u77e5\u8bc6\u70b9\u6709\u5173\u7684\u51e0\u4e2a\u5b9e\u9a8c\u3002\u8fd9\u5c5e\u4e8e____\u3002\nA. \u5b9e\u7269\u76f4\u89c2\nB. \u6a21\u8c61\u76f4\u89c2\nC. \u8a00\u8bed\u76f4\u89c2\nD. \u601d\u7ef4\u76f4\u89c2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8394083568876217, "meta-math/MetaMath-Mistral-7B": 0.9974529027863354, "itpossible/Chinese-Mistral-7B-v0.1": 0.8257290489976084, "HuggingFaceH4/zephyr-7b-beta": 0.9999770133518139, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9956807134880056, "meta-llama/Meta-Llama-3-8B": 0.4120969428303184, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728Excel\u4e2d\uff0c\u5355\u5143\u683cA1, A2, A3\u4e2d\u7684\u5185\u5bb9\u4f9d\u6b21\u4e3a\u6570\u503c1\uff0c2\uff0c3\uff0c\u5355\u5143\u683cA4\u4e2d\u7684\u5185\u5bb9\u4e3a\u5b57\u7b26\u524d\u6dfb\u52a0\u4e86\u82f1\u6587\u5355\u6487\u53f7\u201c\uff0c\u201d\u7684\u6587\u672c\u5b57\u7b26\u201c3\u201d\uff0c\u5728\u5355\u5143\u683cA5\u7684\u7f16\u8f91\u680f\u8f93\u5165\u516c\u5f0f\u201c=COUNT( A1\uff1aA4) +12\u201d\u5e76\u70b9\u51fb\u56de\u8f66\u952e\uff0cA5\u5355\u5143\u683c\u7684\u5185\u5bb9\u4e3a____\u3002\nA. 15\nB. 21\nC. 12\nD. 18\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5510\u671d\u65f6\u5f62\u6210\u4e86\u201c\u7236\u6559\u5176\u5b50\uff0c\u5b50\u6559\u5176\u5f1f\u201d\u201c\u4e94\u5c3a\u7ae5\u5b50\u803b\u4e0d\u8a00\u6587\u58a8\u7109\u201d\u7684\u793e\u4f1a\u98ce\u5c1a\uff0c\u5b83\u7684\u5f62\u6210\u4e3b\u8981\u5f97\u76ca\u4e8e____\u3002\nA. \u793e\u4f1a\u7ecf\u6d4e\u7684\u7e41\u8363\nB. \u79d1\u4e3e\u5236\u5ea6\u7684\u63a8\u884c\nC. \u5b66\u6821\u4f53\u7cfb\u7684\u5b8c\u5907\nD. \u4e09\u7701\u516d\u90e8\u5236\u7684\u786e\u7acb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6839963473297971, "meta-math/MetaMath-Mistral-7B": 0.8704160028270759, "itpossible/Chinese-Mistral-7B-v0.1": 0.8551578587428275, "HuggingFaceH4/zephyr-7b-beta": 0.9994881257848927, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9705482214019623, "meta-llama/Meta-Llama-3-8B": 0.8321207903453538, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9938147854348156}}, {"question": "\u6559\u5bfc\u5904\u7684\u5218\u8001\u5e08\u6293\u5230\u4e24\u540d\u5b66\u751f\u85cf\u5728\u5395\u6240\u91cc\u5077\u5077\u62bd\u70df\uff0c\u4e8e\u662f\u628a\u4ed6\u4eec\u53eb\u5230\u529e\u516c\u5ba4\uff0c\u6162\u60a0\u60a0\u5730\u70b9\u71c3\u4e86\u4e00\u6839\u9999\u70df\uff0c\u51c6\u5907\u8010\u5fc3\u7ec6\u81f4\u5730\u7ed9\u4ed6\u4eec\u505a\u601d\u60f3\u5de5\u4f5c\u3002\u5bf9\u6b64\uff0c\u4ee5\u4e0b\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\u3002\nA. \u5218\u8001\u5e08\u65e2\u7981\u6b62\u5b66\u751f\u62bd\u70df\uff0c\u53c8\u80fd\u8010\u5fc3\u529d\u5bfc\uff0c\u4e25\u6148\u76f8\u6d4e\uff0c\u771f\u6b63\u505a\u5230\u4e86\u5173\u7231\u5b66\u751f\nB. \u5218\u8001\u5e08\u8981\u6c42\u5b66\u751f\u4e0d\u8981\u62bd\u70df\uff0c\u5374\u5728\u5b66\u751f\u9762\u524d\u62bd\u70df\uff0c\u8fdd\u80cc\u4e86\u4e3a\u4eba\u5e08\u8868\u7684\u8981\u6c42\nC. \u5218\u8001\u5e08\u7684\u62bd\u70df\u884c\u4e3a\u4e0e\u4ed6\u6559\u5bfc\u5b66\u751f\u4e0d\u80fd\u62bd\u70df\u7684\u8a00\u8bcd\u76f8\u6096\uff0c\u5f88\u5bb9\u6613\u635f\u5bb3\u81ea\u5df1\u7684\u5a01\u4fe1\nD. \u5218\u8001\u5e08\u7684\u884c\u4e3a\u8868\u660e\u6559\u5e08\u961f\u4f0d\u4e2d\u5b58\u5728\u4e00\u4e9b\u6559\u5e08\u9700\u8981\u5bf9\u5176\u52a0\u5f3a\u5e08\u98ce\u5e08\u5fb7\u5efa\u8bbe\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4853399784198446, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7788787296437097}}, {"question": "\u5c0f\u73ed\u5e7c\u513f\u770b\u6728\u5076\u5267\u8868\u6f14\u65f6\uff0c\u770b\u5230\u201c\u8001\u864e\u201d\u4f1a\u611f\u5230\u5bb3\u6015\u3002\u8fd9\u8bf4\u660e\u5e7c\u513f\u7684____\nA. \u60f3\u8c61\u8131\u79bb\u73b0\u5b9e\nB. \u60f3\u8c61\u4e0e\u73b0\u5b9e\u6df7\u6dc6\nC. \u60f3\u8c61\u5bb9\u6613\u53d7\u60c5\u7eea\u5f71\u54cd\nD. \u60f3\u8c61\u5185\u5bb9\u96f6\u6563\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5577484140774677, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8618204733245726, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8451639267192178, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u7684\u6210\u8bed\u4e0e\u5386\u53f2\u4eba\u7269\u5bc6\u5207\u76f8\u5173\u3002\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u4e0e\u201c\u72e1\u5154\u4e09\u7a9f\u201d\u76f8\u5173\u7684\u5386\u53f2\u4eba\u7269\u662f____\u3002\nA. \u7ba1\u4ef2\u4e0e\u9f50\u6853\u516c\nB. \u6bdb\u9042\u4e0e\u5e73\u539f\u541b\nC. \u51af\u8c16\u4e0e\u5b5f\u5c1d\u541b\nD. \u66f9\u523f\u4e0e\u9c81\u5e84\u516c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6159436381473287, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4124578775795746, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u738b\u6d69\u540c\u5b66\u6d3b\u52a8\u8fc7\u591a\u3001\u6ce8\u610f\u529b\u4e0d\u96c6\u4e2d\u3001\u51b2\u52a8\u884c\u4e3a\u591a\u3002\u8fd9\u79cd\u5fc3\u7406\u969c\u788d\u53ef\u80fd\u662f____\u3002\nA. \u591a\u52a8\u7efc\u5408\u5f81\nB. \u5b66\u4e60\u56f0\u96be\u7efc\u5408\u5f81\nC. \u513f\u7ae5\u538c\u5b66\u75c7\nD. \u513f\u7ae5\u5f3a\u8feb\u884c\u4e3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29609765597062143, "meta-math/MetaMath-Mistral-7B": 0.4010179314415979, "itpossible/Chinese-Mistral-7B-v0.1": 0.9430087200945767, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4482780958461334, "meta-llama/Meta-Llama-3-8B": 0.9545566920337059, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9923576289731386}}, {"question": "\u5728\u5bf9\u73ed\u7ea7\u5b66\u751f\u8fdb\u884c\u6559\u80b2\u65f6\uff0c\u73ed\u4e3b\u4efb\u674e\u8001\u5e08\u5f15\u5bfc\u5b66\u751f\u5bf9\u81ea\u5df1\u6bcf\u65e5\u7684\u5b66\u4e60\u3001\u884c\u4e3a\u8fdb\u884c\u53cd\u7701\u3002\u674e\u8001\u5e08\u4e3b\u8981\u8fd0\u7528\u7684\u5fb7\u80b2\u65b9\u6cd5\u662f____\u3002\nA. \u81ea\u6211\u4fee\u517b\u6cd5\nB. \u699c\u6837\u793a\u8303\u6cd5\nC. \u5b9e\u8df5\u953b\u70bc\u6cd5\nD. \u60c5\u611f\u9676\u51b6\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5967767892142968, "meta-math/MetaMath-Mistral-7B": 0.9231445702292989, "itpossible/Chinese-Mistral-7B-v0.1": 0.921999130666784, "HuggingFaceH4/zephyr-7b-beta": 0.9998350263889071, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6505759788020905, "meta-llama/Meta-Llama-3-8B": 0.6308803751577878, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u8bb2\u89e3\u65b9\u7a0b\u65f6\uff0c\u738b\u8001\u5e08\u5148\u8bb2\u4e00\u5143\u4e00\u6b21\u65b9\u7a0b\uff0c\u518d\u8bb2\u4e8c\u5143\u4e00\u6b21\u65b9\u7a0b\uff0c\u7136\u540e\u8bb2\u4e00\u5143\u4e8c\u6b21\u65b9\u7a0b\uff0c\u9010\u6b65\u52a0\u6df1\u96be\u5ea6\u3002\u8fd9\u79cd\u6559\u5b66\u65b9\u5f0f\u6240\u9075\u5faa\u7684\u539f\u5219\u662f____\u3002\nA. \u7406\u8bba\u8054\u7cfb\u5b9e\u9645\u539f\u5219\nB. \u542f\u53d1\u6027\u539f\u5219\nC. \u5faa\u5e8f\u6e10\u8fdb\u539f\u5219\nD. \u5de9\u56fa\u6027\u539f\u5219\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9527588262237962, "meta-math/MetaMath-Mistral-7B": 0.9967280920269569, "itpossible/Chinese-Mistral-7B-v0.1": 0.9346165717143382, "HuggingFaceH4/zephyr-7b-beta": 0.9995543720880097, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9900336635519312, "meta-llama/Meta-Llama-3-8B": 0.8505385861357455, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9791639883650066}}, {"question": "\u8fd1\u4ee3\u539f\u5b50\u6838\u7269\u7406\u5b66\u4e4b\u7236\u662f____\u3002\nA. \u666e\u6717\u514b\nB. \u5362\u745f\u798f\nC. \u73bb\u5c14\nD. \u970d\u91d1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9507281456855764, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7275889977213819}}, {"question": "\u5f88\u591a\u4eba\u56e0\u4e3a\u6709\u4e86\u53d7\u6559\u80b2\u7684\u673a\u4f1a\u800c\u5f97\u5230\u4e86\u548c\u7236\u8f88\u5b8c\u5168\u4e0d\u540c\u7684\u4eba\u751f\u53d1\u5c55\u673a\u9047\u3002\u8fd9\u8bf4\u660e\u6559\u80b2\u5728\u4eba\u7684\u53d1\u5c55\u4e2d\u8d77\u5230____\u3002\nA. \u8f85\u52a9\u4f5c\u7528\nB. \u51b3\u5b9a\u4f5c\u7528\nC. \u6b21\u8981\u4f5c\u7528\nD. \u4e3b\u5bfc\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5786281957996684, "meta-math/MetaMath-Mistral-7B": 0.5191567004501844, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9981419248965182, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5222842091079853, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u9762\u662f\u4e2d\u56fd\u53e4\u4ee3\u56db\u5927\u540d\u8457\u4e2d\u7684\u4eba\u7269\u4e0e\u60c5\u8282\uff0c\u5176\u4e2d\u642d\u914d\u4e0d\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u9c81\u667a\u6df1\u2014\u2014\u5012\u62d4\u5782\u6768\u67f3\nB. \u5b59\u609f\u7a7a\u2014\u2014\u5927\u95f9\u5929\u5bab\nC. \u5468\u745c\u2014\u2014\u4e09\u987e\u8305\u5e90\nD. \u5218\u59e5\u59e5\u2014\u2014\u8fdb\u5927\u89c2\u56ed\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4800666438699589, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u627e\u89c4\u5f8b\u586b\u6570\u5b57\u662f\u4e00\u9879\u5f88\u6709\u8da3\u7684\u6d3b\u52a8\uff0c\u7279\u522b\u953b\u70bc\u89c2\u5bdf\u548c\u601d\u8003\u80fd\u529b\u3002\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u586b\u5165\u6570\u5217\u201c1\u30017\u30018\u300157\u3001____\u300126050\u201d\u7a7a\u7f3a\u5904\u7684\u6570\u5b57\uff0c\u7b26\u5408\u8be5\u7ec4\u6570\u5b57\u6392\u5217\u89c4\u5f8b\u7684\u662f____\u3002\nA. 456\nB. 457\nC. 458\nD. 459\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32992629781713967, "meta-math/MetaMath-Mistral-7B": 0.8457102581417898, "itpossible/Chinese-Mistral-7B-v0.1": 0.3128363857141096, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5140406183633489, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4967046516222682}}, {"question": "\u6559\u80b2\u81ea\u8eab\u7684\u8bb8\u591a\u89c4\u5f8b\uff0c\u662f\u4eba\u7c7b\u957f\u671f\u6559\u80b2\u5b9e\u8df5\u8ba4\u8bc6\u7684\u7ed3\u679c\uff0c\u5b83\u4eec\u4e0d\u4f1a\u56e0\u653f\u6cbb\u7ecf\u6d4e\u5236\u5ea6\u548c\u5176\u4ed6\u6587\u5316\u7684\u53d1\u5c55\u800c\u8fc7\u65f6\uff0c\u66f4\u4e0d\u4f1a\u968f\u65f6\u4ee3\u7684\u53d1\u5c55\u800c\u88ab\u5426\u5b9a\u3002\u8fd9\u8bf4\u660e\u6559\u80b2\u5177\u6709____\u3002\nA. \u5386\u53f2\u6027\nB. \u6c38\u6052\u6027\nC. \u9636\u7ea7\u6027\nD. \u76f8\u5bf9\u72ec\u7acb\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9ad8\u4e2d\u6bd5\u4e1a\u4f1a\u8003\u662f\u4e00\u79cd\u8fbe\u6807\u8003\u8bd5\uff0c\u5c5e\u4e8e____\u3002\nA. \u5b9a\u91cf\u8bc4\u4ef7\nB. \u76f8\u5bf9\u6027\u8bc4\u4ef7\nC. \u5f62\u6210\u6027\u8bc4\u4ef7\nD. \u7edd\u5bf9\u6027\u8bc4\u4ef7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u4e0e\u201c\u56fe\u4e66\u201d\u548c\u201c\u97f3\u4e50\u4e66\u201d\u7684\u903b\u8f91\u5173\u7cfb\u76f8\u540c\u7684\u4e00\u7ec4\u662f____\u3002\nA. \u201c\u94a2\u7b14\u201d\u548c\u201c\u94c5\u7b14\u201d\nB. \u201c\u86cb\u7cd5\u201d\u548c\u201c\u9999\u6cb9\u201d\nC. \u201c\u6c34\u679c\u201d\u548c\u201c\u897f\u74dc\u201d\nD. \u201c\u767d\u83dc\u201d\u548c\u201c\u9ec4\u74dc\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2896633838187121, "HuggingFaceH4/zephyr-7b-beta": 0.8118758998625266, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5085730361764733, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bed\u6587\u6559\u5e08\u88f4\u8001\u5e08\u6bcf\u5929\u4e0b\u8bfe\u540e\u90fd\u4f1a\u5bf9\u81ea\u5df1\u4e00\u5929\u7684\u5de5\u4f5c\u8fdb\u884c\u603b\u7ed3\u53cd\u601d\uff0c\u5e76\u8bb0\u5f55\u4e0b\u6765\u3002\u8fd9\u5c5e\u4e8e\u5e03\u9c81\u5df4\u5947\u53cd\u601d\u65b9\u6cd5\u4e2d\u7684____\u3002\nA. \u53cd\u601d\u65e5\u8bb0\nB. \u8be6\u7ec6\u63cf\u8ff0\nC. \u4ea4\u6d41\u8ba8\u8bba\nD. \u884c\u52a8\u7814\u7a76\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9276310750791071, "meta-math/MetaMath-Mistral-7B": 0.9970736920022953, "itpossible/Chinese-Mistral-7B-v0.1": 0.8919034721362618, "HuggingFaceH4/zephyr-7b-beta": 0.9999902833213367, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9961884385805734, "meta-llama/Meta-Llama-3-8B": 0.7750097404109394, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9988149900281894}}, {"question": "\u4ee5\u4e0b\u5173\u4e8e\u5e7c\u513f\u6709\u610f\u6ce8\u610f\u53d1\u5c55\u7684\u8868\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u5e7c\u513f\u6709\u610f\u6ce8\u610f\u53d1\u5c55\u53d7\u5927\u8111\u53d1\u80b2\u6c34\u5e73\u5c40\u9650\nB. \u5e7c\u513f\u6709\u610f\u6ce8\u610f\u7684\u53d1\u5c55\u6c34\u5e73\u8f83\u4f4e\uff0c\u65e0\u6cd5\u4f9d\u9760\u6d3b\u52a8\u548c\u64cd\u4f5c\u6765\u7ef4\u6301\nC. \u5e7c\u513f\u5728\u5e7c\u513f\u56ed\u9700\u8981\u9075\u5b88\u5404\u79cd\u884c\u4e3a\u89c4\u5219\uff0c\u5b8c\u6210\u5404\u9879\u4efb\u52a1\uff0c\u8fd9\u90fd\u9700\u8981\u5e7c\u513f\u5f62\u6210\u6216\u53d1\u5c55\u6709\u610f\u6ce8\u610f\nD. \u6559\u5e08\u5728\u7ec4\u7ec7\u6d3b\u52a8\u65f6\uff0c\u8981\u6c42\u5e7c\u513f\u4fdd\u6301\u6ce8\u610f\u7684\u5bf9\u8c61\u5e94\u8be5\u662f\u5e7c\u513f\u8ba4\u77e5\u8303\u56f4\u4ee5\u5185\u6216\u5e7c\u513f\u6613\u4e8e\u7406\u89e3\u7684\u4e8b\u7269\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.308176776288574, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5284271800947281, "HuggingFaceH4/zephyr-7b-beta": 0.645934721108757, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8454793518650268, "meta-llama/Meta-Llama-3-8B": 0.3646363956912232, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7916459326105098}}, {"question": "\u67d0\u5e7c\u513f\u56ed\u6839\u636e\u5e7c\u513f\u7684\u53d1\u5c55\u60c5\u51b5\u5c06\u73ed\u7ea7\u5206\u4e3a\u5feb\u73ed\u3001\u4e2d\u73ed\u548c\u6162\u73ed\u3002\u5bf9\u4e8e\u5feb\u73ed\u7684\u5e7c\u513f\u5b89\u6392\u5927\u91cf\u4f18\u79c0\u5e08\u8d44\u548c\u5148\u8fdb\u8bbe\u5907\uff0c\u800c\u5bf9\u4e8e\u6162\u73ed\u7684\u5e7c\u513f\u5219\u7ed9\u4e88\u8f83\u5c11\u7684\u4f18\u826f\u6559\u80b2\u8d44\u6e90\u3002\u8be5\u5e7c\u513f\u56ed\u7684\u505a\u6cd5\u8fdd\u80cc\u4e86\u7d20\u8d28\u6559\u80b2\u5185\u6db5\u4e2d\u7684____\u3002\nA. \u4ee5\u63d0\u9ad8\u56fd\u6c11\u7d20\u8d28\u4e3a\u57fa\u672c\u5b97\u65e8\nB. \u9762\u5411\u5168\u4f53\u5e7c\u513f\nC. \u4fc3\u8fdb\u5e7c\u513f\u5168\u9762\u53d1\u5c55\nD. \u4fc3\u8fdb\u5e7c\u513f\u4e2a\u6027\u53d1\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3596728210507319, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8338769495164606, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f5c\u4e3a\u53e4\u57c3\u53ca\u6587\u660e\u7684\u8c61\u5f81\u4e4b\u4e00\uff0c____\u65e2\u5bc4\u6258\u4e86\u53e4\u57c3\u53ca\u4eba\u5bf9\u6b7b\u540e\u91cd\u751f\u7684\u5411\u5f80\uff0c\u53c8\u8bc1\u660e\u4e86\u65b0\u4e00\u4ee3\u6cd5\u8001\u738b\u6743\u7edf\u6cbb\u7684\u795e\u5723\u4e0d\u53ef\u4fb5\u72af\uff0c\u5145\u5206\u663e\u793a\u4e86\u53e4\u57c3\u53ca\u4eba\u7684\u9ad8\u5ea6\u667a\u6167\u548c\u7cbe\u6e5b\u7684\u5efa\u7b51\u827a\u672f\u3002\nA. \u91d1\u5b57\u5854\nB. \u5e15\u7279\u519c\u795e\u5e99\nC. \u5706\u5f62\u7ade\u6280\u573a\nD. \u9ea6\u52a0\u6e05\u771f\u5bfa\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9723670490944675, "meta-math/MetaMath-Mistral-7B": 0.999636426181457, "itpossible/Chinese-Mistral-7B-v0.1": 0.9246829801658603, "HuggingFaceH4/zephyr-7b-beta": 0.9999687307381642, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9966146301327463, "meta-llama/Meta-Llama-3-8B": 0.8851743327812067, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9973102317894066}}, {"question": "\u5728\u592a\u9633\u7cfb\u7684\u516b\u5927\u884c\u661f\u4e2d\uff0c\u8d28\u91cf\u6700\u5927\u548c\u6700\u5c0f\u7684\u884c\u661f\u5206\u522b\u662f____\u3002\nA. \u6728\u661f\uff1b\u6c34\u661f\nB. \u706b\u661f\uff1b\u5730\u7403\nC. \u91d1\u661f\uff1b\u6c34\u661f\nD. \u571f\u661f\uff1b\u5929\u738b\u661f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5044406685560363, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3035988665653362, "HuggingFaceH4/zephyr-7b-beta": 0.9977452759652256, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8486143613589621, "meta-llama/Meta-Llama-3-8B": 0.602015661775207, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9786584819876083}}, {"question": "\u636e\u8c03\u67e5\uff0c\u6559\u5e08\u5bf9\u5b66\u751f\u62f3\u6253\u811a\u8e22\u7684\u60c5\u51b5\u73b0\u5728\u5df2\u7ecf\u8f83\u5c11\u5b58\u5728\uff0c\u53d6\u800c\u4ee3\u4e4b\u7684\u662f\u201c\u5fc3\u7f5a\u201d\u3002\u6bd4\u5982\uff0c\u5bf9\u4e8e\u6210\u7ee9\u4e0d\u597d\u7684\u5b66\u751f\u7f5a\u505a\u9898\u76ee\u3001\u7f5a\u6284\u5355\u8bcd\u4e00\u767e\u904d\u3002\u6559\u5e08\u8fd9\u6837\u7684\u884c\u4e3a____\u3002\nA. \u662f\u6b63\u786e\u7684\uff0c\u6559\u80b2\u4e2d\u9002\u5f53\u7684\u60e9\u7f5a\u662f\u5fc5\u4e0d\u53ef\u5c11\u7684\nB. \u662f\u6b63\u786e\u7684\uff0c\u6559\u5e08\u6ca1\u6709\u4fb5\u72af\u5b66\u751f\u7684\u8eab\u4f53\u5065\u5eb7\nC. \u662f\u4e0d\u6b63\u786e\u7684\uff0c\u6559\u5e08\u6ca1\u80fd\u505a\u5230\u4f9d\u6cd5\u6267\u6559\nD. \u662f\u4e0d\u6b63\u786e\u7684\uff0c\u6559\u5e08\u6ca1\u80fd\u505a\u5230\u56e2\u7ed3\u5408\u4f5c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3815560888599673, "meta-math/MetaMath-Mistral-7B": 0.41605132742014833, "itpossible/Chinese-Mistral-7B-v0.1": 0.6355675951070776, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6774678199367639, "meta-llama/Meta-Llama-3-8B": 0.39083047486116995, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.911986263956213}}, {"question": "\u4eba\u7684\u672c\u8d28\u662f____\nA. \u6c38\u6052\u4e0d\u53d8\u7684\nB. \u968f\u4e3b\u89c2\u610f\u5fd7\u7684\u53d8\u5316\u800c\u53d8\u5316\u7684\nC. \u968f\u793e\u4f1a\u5173\u7cfb\u7684\u53d8\u5316\u800c\u53d8\u5316\u7684\nD. \u968f\u4e2a\u6027\u7684\u53d8\u5316\u800c\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37598848595513223, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8368008357623982, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7434356350406839, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f01\u4e1a\u8054\u5408\u662f\u6307\u4f01\u4e1a\u4e4b\u95f4\u4e3a\u589e\u5f3a\u5e02\u573a\u7ade\u4e89\u529b\u3001\u83b7\u53d6\u66f4\u5927\u7ecf\u6d4e\u6548\u76ca\u800c\u5b9e\u884c\u7684\u5408\u8425\u6216\u5408\u5e76\u3002\u5927\u4f01\u4e1a\u4e4b\u95f4\u7684\u8054\u5408\u901a\u5e38\u53eb\u5f3a\u5f3a\u8054\u5408\u3002\u4e0b\u5217\u7532\u4e59\u4e24\u516c\u53f8\u7684\u884c\u4e3a\u5c5e\u4e8e\u4f01\u4e1a\u5f3a\u5f3a\u8054\u5408\u7684\u662f____\n\u2460\u7532\u516c\u53f8\u5229\u7528\u4e59\u516c\u53f8\u7684\u751f\u4ea7\u6280\u672f\u529b\u91cf\uff0c\u6295\u8d44\u65b0\u9879\u76ee\n\u2461\u7532\u516c\u53f8\u901a\u8fc7\u8d44\u672c\u5e02\u573a\u6536\u8d2d\u4e59\u516c\u53f820%\u80a1\u4efd\n\u2462\u4e59\u516c\u53f8\u628a\u81ea\u6709\u8d44\u4ea7\u62b5\u62bc\u7ed9\u94f6\u884c\uff0c\u7528\u8d37\u6b3e\u6765\u8d2d\u4e70\u7532\u516c\u53f8\u7684\u8bbe\u5907\n\u2463\u4e59\u516c\u53f8\u4ea7\u54c1\u901a\u8fc7\u7532\u516c\u53f8\u7684\u9500\u552e\u7f51\u7edc\u8fc5\u901f\u8fdb\u5165\u56fd\u9645\u5e02\u573a\nA. \u2460\u2461\nB. \u2461\u2462\nC. \u2460\u2463\nD. \u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4166349235740665, "meta-math/MetaMath-Mistral-7B": 0.41270332593705616, "itpossible/Chinese-Mistral-7B-v0.1": 0.3287145937103622, "HuggingFaceH4/zephyr-7b-beta": 0.7469646550008039, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.48207416463793756, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u624b\u673a\u94b1\u5305\u201d \u662f\u5c06\u624b\u673a\u548c\u94f6\u884c\u5361\u5408\u4e8c\u4e3a\u4e00\u7684\u4e00\u79cd\u65b0\u578b\u4e1a\u52a1\uff0c\u5f00\u901a\u8be5\u4e1a\u52a1\u7684\u6d88\u8d39\u8005\u5728\u65e5\u5e38\u5c0f\u989d\u6d88\u8d39\u65f6\uff0c\u53ea\u9700\u8981\u5c06\u624b\u673a\u653e\u7f6e\u5728pos\u673a\u4e0a\u4e00\u5237\u5c31\u80fd\u4ed8\u6b3e\u3002\u201c\u624b\u673a\u94b1\u5305\u201d \u4e1a\u52a1____\n\u2460\u5ef6\u4f38\u4e86\u94f6\u884c\u4e1a\u52a1\u94fe\u6761  \u2461\u521b\u65b0\u4e86\u8f6c\u8d26\u7ed3\u7b97\u65b9\u5f0f  \u2462\u62d3\u5bbd\u4e86\u5c45\u6c11\u7406\u8d22\u6e20\u9053  \u2463\u964d\u4f4e\u4e86\u901a\u8d27\u81a8\u80c0\u98ce\u9669\u3002\nA. \u2460\u2461\nB. \u2462\u2463\nC. \u2460\u2462\nD. \u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.372614753228654, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6336657961425612, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fd1\u65e5\uff0c\u6559\u80b2\u90e8\u6b63\u5f0f\u5370\u53d1\u300a\u4e49\u52a1\u6559\u80b2\u8bfe\u7a0b\u65b9\u6848\u300b\uff0c\u5c06\u52b3\u52a8\u4ece\u539f\u6765\u7684\u7efc\u5408\u5b9e\u8df5\u6d3b\u52a8\u8bfe\u7a0b\u4e2d\u5b8c\u5168\u72ec\u7acb\u51fa\u6765\uff0c\u5e76\u53d1\u5e03\u300a\u4e49\n\u52a1\u6559\u80b2\u52b3\u52a8\u8bfe\u7a0b\u6807\u51c6\uff082022 \u5e74\u7248\uff09\u300b\u3002\u8fd9\u662f\u57fa\u4e8e____\n\u2460\u52b3\u52a8\u5728\u751f\u4ea7\u5173\u7cfb\u4e2d\u8d77\u7740\u51b3\u5b9a\u6027\u4f5c\u7528\n\u2461\u4eba\u4e16\u95f4\u7684\u7f8e\u597d\u68a6\u60f3\u53ea\u6709\u901a\u8fc7\u8bda\u5b9e\u52b3\u52a8\u624d\u80fd\u5b9e\u73b0\n\u2462\u52b3\u52a8\u6ca1\u6709\u9ad8\u4f4e\u8d35\u8d31\u4e4b\u5206\uff0c\u4efb\u4f55\u4e00\u4efd\u804c\u4e1a\u90fd\u5f88\u5149\u8363\n\u2463\u5728\u793e\u4f1a\u4e3b\u4e49\u793e\u4f1a\uff0c\u52b3\u52a8\u662f\u4fc3\u8fdb\u4eba\u7684\u81ea\u7531\u5168\u9762\u53d1\u5c55\u7684\u91cd\u8981\u624b\u6bb5\nA. \u2460\u2461\nB. \u2460\u2462\nC. \u2461\u2463\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3907616807792618, "meta-llama/Meta-Llama-3-8B": 0.33482349867891054, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5710154657568272}}, {"question": "\u56fd\u52a1\u9662\u5f3a\u8c032013\u5e74\u5de5\u4f5c\u91cd\u5fc3\u653e\u5230\u52a0\u5feb\u8f6c\u53d8\u7ecf\u6d4e\u53d1\u5c55\u65b9\u5f0f\u548c\u8c03\u6574\u7ecf\u6d4e\u7ed3\u6784\u4e0a\uff0c\u653e\u5230\u63d0\u9ad8\u7ecf\u6d4e\u589e\u957f\u7684\u8d28\u91cf\u548c\u6548\u76ca\u4e0a\uff0c\u63a8\u52a8\u7ecf\u6d4e\u6301\u7eed\u5065\u5eb7\u53d1\u5c55\u3002\u786e\u7acb\u4e0a\u8ff0\u5de5\u4f5c\u91cd\u5fc3\u7684\u6839\u672c\u76ee\u7684\u662f\uff1a____\nA. \u4f18\u5316\u4ea7\u4e1a\u7ed3\u6784\uff0c\u5b9e\u73b0\u56fd\u5bb6\u4ea7\u4e1a\u7ed3\u6784\u5e03\u5c40\u66f4\u8d8b\u5408\u7406\nB. \u589e\u5f3a\u6211\u56fd\u56fd\u9645\u7ade\u4e89\u529b\uff0c\u5e94\u5bf9\u7ecf\u6d4e\u5168\u7403\u5316\u5371\u673a\nC. \u8ba9\u5168\u4f53\u4eba\u6c11\u5171\u4eab\u6539\u9769\u53d1\u5c55\u6210\u679c\uff0c\u793e\u4f1a\u751f\u4ea7\u76ee\u7684\u7684\u843d\u5b9e\u5960\u5b9a\u7269\u8d28\u57fa\u7840\nD. \u589e\u52a0\u793e\u4f1a\u8d22\u5bcc\u4ee5\u63d0\u5347\u793e\u4f1a\u79ef\u7d2f\u7387\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7945261140047776, "meta-math/MetaMath-Mistral-7B": 0.9272269109149425, "itpossible/Chinese-Mistral-7B-v0.1": 0.4457208853090233, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7201170690573834, "meta-llama/Meta-Llama-3-8B": 0.7011919919229128, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8926284198210025}}, {"question": "\u5728\u53cd\u6620\u4eba\u6c11\u751f\u6d3b\u6c34\u5e73\u7684\u7edf\u8ba1\u6570\u636e\u4e2d\uff0c\u6211\u4eec\u7ecf\u5e38\u53ef\u4ee5\u770b\u5230\u8fd9\u6837\u4e00\u4e2a\u8bcd\uff1a\u4e2a\u4eba\u53ef\u652f\u914d\u6536\u5165\uff0c\u5b83\u6307\u7684\u662f\uff1a____\nA. \u7528\u4e8e\u6d88\u8d39\u7684\u4e2a\u4eba\u6536\u5165\nB. \u4e2a\u4eba\u6536\u5165\nC. \u5fc5\u987b\u6263\u9664\u9700\u8981\u7f34\u7eb3\u7684\u7a0e\u6536\u548c\u793e\u4f1a\u4fdd\u969c\u91d1\u4f59\u4e0b\u7684\u4e2a\u4eba\u6536\u5165\nD. \u7528\u4e8e\u50a8\u84c4\u7684\u90a3\u90e8\u5206\u4e2a\u4eba\u6536\u5165\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5969477063076561, "meta-math/MetaMath-Mistral-7B": 0.4964539270327071, "itpossible/Chinese-Mistral-7B-v0.1": 0.6561504916728849, "HuggingFaceH4/zephyr-7b-beta": 0.9988647311684823, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9490098248916105, "meta-llama/Meta-Llama-3-8B": 0.7651594359126936, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8479447792562038}}, {"question": "\u4e2d\u56fd\u53e4\u5178\u8bd7\u8bcd\u4e2d\u8574\u542b\u7740\u4e30\u5bcc\u7684\u54f2\u7406\u3002\u5bf9\u4e8e\u5317\u5b8b\u738b\u5b89\u77f3\u5728\u300a\u5143\u65e5\u300b\u4e2d\u201c\u5343\u95e8\u4e07\u6237\u66c8\u66c8\u65e5\uff0c\u603b\u628a\u65b0\u6843\u6362\u65e7\u7b26\u201d\u7684\u8bd7\u53e5\uff0c\u4eba\u4eec\u8033\u719f\u80fd\u8be6\u3002\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u4e0e\u5176\u8574\u542b\u76f8\u540c\u54f2\u7406\u7684\u8bd7\u53e5\u662f____\nA. \u9884\u652f\u4e94\u767e\u5e74\u65b0\u610f\uff0c\u5230\u4e86\u5343\u5e74\u53c8\u89c9\u9648\u2014\u2014\u6e05\u00b7\u8d75\u7ffc\u300a\u8bba\u8bd7\u4e94\u9996\u00b7\u5176\u4e00\u300b\nB. \u753b\u56fe\u4e34\u51fa\u79e6\u5ddd\u666f\uff0c\u4eb2\u5230\u957f\u5b89\u6709\u51e0\u4eba\u2014\u2014\u91d1\u00b7\u5143\u597d\u95ee\u300a\u8bba\u8bd7\u300b\nC. \u8349\u8424\u6709\u8000\u7ec8\u975e\u706b\uff0c\u8377\u9732\u867d\u56e2\u5c82\u662f\u73e0\u2014\u2014\u5510\u00b7\u767d\u5c45\u6613\u300a\u653e\u8a00\u4e94\u9996\u00b7\u5176\u4e00\u300b\nD. \u6df1\u5904\u79cd\u83f1\u6d45\u79cd\u7a3b\uff0c\u4e0d\u6df1\u4e0d\u6d45\u79cd\u8377\u82b1\u2014\u2014\u6e05\u00b7\u962e\u5143\u300a\u5434\u5174\u6742\u8bd7\u300b\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.356604126164406, "meta-math/MetaMath-Mistral-7B": 0.7535302449453114, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5497592326552321, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ee5\u4e0b\u9009\u9879\u80fd\u591f\u6b63\u786e\u53cd\u6620\u552f\u7269\u4e3b\u4e49\u4e09\u79cd\u57fa\u672c\u5f62\u6001\u6f14\u8fdb\u987a\u5e8f\u7684\u662f____\n\u2460\u5b58\u5728\u5c31\u662f\u88ab\u611f\u77e5\n\u2461\u4e16\u754c\u662f\u4e00\u56e2\u6c38\u6052\u7684\u6d3b\u706b\n\u2462\u4eba\u662f\u673a\u5668\uff0c\u601d\u60f3\u662f\u4eba\u8111\u7684\u7279\u6027\n\u2463\u7269\u8d28\u662f\u6807\u5fd7\u5ba2\u89c2\u5b9e\u5728\u7684\u54f2\u5b66\u8303\u7574\nA. \u2460\u2192\u2461\u2192\u2463\nB. \u2461\u2192\u2462\u2192\u2460\nC. \u2460\u2192\u2462\u2192\u2463\nD. \u2461\u2192\u2462\u2192\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u4e2d\u5171\u4e2d\u592e\u5173\u4e8e\u5168\u9762\u6df1\u5316\u6539\u9769\u82e5\u5e72\u91cd\u5927\u95ee\u9898\u7684\u51b3\u5b9a\u300b\u63d0\u51fa\uff0c\u79ef\u6781\u53d1\u5c55\u6df7\u5408\u6240\u6709\u5236\u7ecf\u6d4e\uff0c\u56fd\u6709\u8d44\u672c\u6295\u8d44\u9879\u76ee\u5141\u8bb8\u975e\u56fd\u6709\u8d44\u672c\u53c2\u4e0e\uff0c\u5141\u8bb8\u66f4\u591a\u56fd\u6709\u7ecf\u6d4e\u548c\u5176\u4ed6\u6240\u6709\u5236\u7ecf\u6d4e\u53d1\u5c55\u6210\u4e3a\u6df7\u5408\u6240\u6709\u5236\u7ecf\u6d4e\u3002\u8fd9\u4e00\u4e3e\u63aa\u6709\u5229\u4e8e____\n\u2460\u7ef4\u62a4\u5404\u79cd\u6240\u6709\u5236\u7ecf\u6d4e\u5728\u6240\u6709\u5236\u7ed3\u6784\u4e2d\u7684\u5e73\u7b49\u5730\u4f4d\n\u2461\u4fdd\u8bc1\u5404\u79cd\u6240\u6709\u5236\u7ecf\u6d4e\u4f9d\u6cd5\u5e73\u7b49\u4f7f\u7528\u751f\u4ea7\u8981\u7d20\u3001\u516c\u5e73\u53c2\u4e0e\u5e02\u573a\u7ade\u4e89\n\u2462\u5404\u79cd\u6240\u6709\u5236\u7ecf\u6d4e\u53d1\u6325\u5404\u81ea\u4f18\u52bf\uff0c\u5171\u540c\u53d1\u5c55\n\u2463\u5de9\u56fa\u516c\u6709\u5236\u4e3a\u4e3b\u4f53\u3001\u591a\u79cd\u6240\u6709\u5236\u7ecf\u6d4e\u5171\u540c\u53d1\u5c55\u8fd9\u4e00\u793e\u4f1a\u4e3b\u4e49\u7ecf\u6d4e\u5236\u5ea6\u7684\u57fa\u7840\nA. \u2460\u2461\nB. \u2460\u2463\nC. \u2461\u2462\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45077244158804636, "meta-math/MetaMath-Mistral-7B": 0.5074099707555233, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6218528541434896, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4562561246927508, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5510\u4ee3\u8457\u540d\u8bd7\u4eba\u675c\u8340\u9e64\u5728\u300a\u5c71\u4e2d\u5be1\u5987\u300b\u4e2d\u5199\u9053\uff1a\u201c\u4efb\u662f\u6df1\u5c71\u66f4\u6df1\u5904\uff0c\u4e5f\u5e94\u65e0\u8ba1\u907f\u5f81\u5fad\u3002\u201d\u8fd9\u53e5\u8bd7\u4e3b\u8981\u5f3a\u8c03\u4e86\u7a0e\u6536\u7684____\nA. \u65e0\u507f\u6027\nB. \u5f3a\u5236\u6027\nC. \u56fa\u5b9a\u6027\nD. \u6cd5\u5236\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9428402032943389, "meta-math/MetaMath-Mistral-7B": 0.9846550931840806, "itpossible/Chinese-Mistral-7B-v0.1": 0.9298043308707896, "HuggingFaceH4/zephyr-7b-beta": 0.9995349848967338, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9731041134118575, "meta-llama/Meta-Llama-3-8B": 0.8184174084681447, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9521829753239401}}, {"question": "\u8001\u5b57\u53f7\u627f\u8f7d\u7740\u4f18\u79c0\u7684\u4e2d\u534e\u6c11\u65cf\u6587\u5316\u3002\u67d0\u8001\u5b57\u53f7\u4f01\u4e1a\u63a8\u51fa\u7684\u7eff\u8c46\u51b0\u7cd5\uff0c\u53e3\u7891\u3001\u9500\u91cf\u53cc\u4e30\u6536\uff1b\u67d0\u8001\u5b57\u53f7\u4e73\u54c1\u4f01\u4e1a\u8ddf\u6f6e\u724c\u5408\u4f5c\u63a8\u51fa\u4e86\u8054\u540d\u4f20\u7edf\u670d\u9970\u7cfb\u5217\uff0c\u662f\u8001\u5b57\u53f7\u5b9e\u529b\u7684\u89c1\u8bc1\uff1b\u65b0\uff0c\u662f\u8001\u5b57\u53f7\u751f\u547d\u529b\u7684\u4fdd\u969c\u3002\u518d\u8001\u4e5f\u8981\u6709\u65b0\u7279\u8272\uff0c\u518d\u65b0\u4e5f\u4e0d\u80fd\u4e22\u4e86\u8001\u5473\u9053\uff0c\u5b88\u6b63\u521b\u65b0\uff0c\u8001\u5b57\u53f7\u624d\u80fd\u7ecf\u4e45\u4e0d\u8870\u3002\u8fd9\u8868\u660e____\n\u2460\u8001\u5b57\u53f7\u4f01\u4e1a\u4e5f\u8981\u575a\u6301\u7ecf\u6d4e\u6548\u76ca\u548c\u793e\u4f1a\u6548\u76ca\u76f8\u7edf\u4e00\n\u2461\u5411\u73b0\u4ee3\u9760\u62e2\u4e3a\u521b\u65b0\u800c\u521b\u65b0\uff0c\u8001\u5b57\u53f7\u5c31\u4f1a\u7ecf\u4e45\u4e0d\u8870\n\u2462\u5b88\u6b63\u521b\u65b0\u3001\u201c\u501a\u8001\u5356\u65b0\u201d\u4f53\u73b0\u51fa\u8fa9\u8bc1\u5426\u5b9a\u7684\u5b9e\u8d28\u5c31\u662f\u521b\u65b0\n\u2463\u8001\u548c\u65b0\u65e2\u5bf9\u7acb\u53c8\u7edf\u4e00\uff0c\u9053\u51fa\u4e00\u4e2a\u54c1\u724c\u4f55\u4ee5\u6210\u4e3a\u8001\u5b57\u53f7\u7684\u79d8\u5bc6\nA. \u2460\u2461\nB. \u2460\u2463\nC. \u2461\u2462\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.41245789202394834, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u4eba\u6c11\u6c11\u4e3b\u4e13\u653f\u7684\u6700\u5927\u7279\u70b9\u662f\uff1a____\nA. \u575a\u6301\u5de5\u4eba\u9636\u7ea7\u7684\u9886\u5bfc\nB. \u575a\u6301\u4ee5\u5de5\u519c\u8054\u76df\u4e3a\u57fa\u7840\nC. \u5728\u4eba\u6c11\u5185\u90e8\u5b9e\u884c\u6c11\u4e3b\uff0c\u5bf9\u6781\u5c11\u6570\u654c\u4eba\u5b9e\u884c\u4e13\u653f\nD. \u56fd\u5bb6\u653f\u6743\u5177\u6709\u5e7f\u6cdb\u7684\u793e\u4f1a\u57fa\u7840\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8121630652181241, "meta-math/MetaMath-Mistral-7B": 0.9856773996483097, "itpossible/Chinese-Mistral-7B-v0.1": 0.7148821941438046, "HuggingFaceH4/zephyr-7b-beta": 0.9713372202195912, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9570997314645551, "meta-llama/Meta-Llama-3-8B": 0.6091268351813598, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9711932707430156}}, {"question": "\u5de5\u4e1a\u9057\u4ea7\u4f5c\u4e3a\u57ce\u5e02\u5386\u53f2\u6587\u5316\u7684\u7f29\u5f71\uff0c\u5177\u5907\u5f97\u5929\u72ec\u539a\u7684\u57ce\u5e02\u5c5e\u6027\uff0c\u800c\u5de5\u4e1a\u9057\u4ea7\u7684\u53ef\u6301\u7eed\u5229\u7528\u5728\u5176\u91cd\u65b0\u5b9a\u4e49\u81ea\u8eab\u4ef7\u503c\u7684\u540c\u65f6\uff0c\u66f4\u80fd\u591f\u7ec7\u8865\u57ce\u5e02\u7a7a\u95f4\uff0c\u4e3a\u57ce\u5e02\u6ce8\u5165\u53d1\u5c55\u65b0\u52a8\u80fd\u3002\u4ee5\u65b0\u9996\u94a2\u56ed\u533a\u4e3a\u4ee3\u8868\uff0c\u5145\u5206\u6316\u6398\u5de5\u4e1a\u9057\u4ea7\u7684\u5386\u53f2\u6587\u5316\u548c\u65f6\u4ee3\u4ef7\u503c\uff0c\u690d\u5165\u51ac\u5965\u5143\u7d20\u548c\u6587\u5316\u529f\u80fd\uff0c\u4e3a\u5e02\u6c11\u521b\u9020\u65b0\u7684\u57ce\u5e02\u6d3b\u529b\u7a7a\u95f4\uff0c\u4ee5\u91cd\u5927\u8d5b\u4f1a\u5e26\u52a8\u533a\u57df\u7684\u6574\u4f53\u66f4\u65b0\u3002\u5982\u4eca\uff0c\u9996\u94a2\u56ed\u5df2\u7ecf\u7531\u8001\u65e7\u5de5\u4e1a\u5382\u623f\u8715\u53d8\u4e3a\u57ce\u5e02\u65b0\u5174\u7a7a\u95f4\uff0c\u6210\u4e3a\u5e02\u6c11\u4f11\u95f2\u5a31\u4e50\u7684\u201c\u7f51\u7ea2\u6253\u5361\u5730\u201d\u3002\u8fd9\u4e00\u505a\u6cd5\u6709\u5229\u4e8e____\n\u2460\u62d3\u5c55\u57ce\u5e02\u6587\u5316\u7a7a\u95f4\uff0c\u589e\u5f3a\u57ce\u5e02\u6587\u5316\u6c1b\u56f4\n\u2461\u79c9\u6301\u4fee\u65e7\u5982\u65e7\u539f\u5219\uff0c\u91cd\u65b0\u6062\u590d\u4f01\u4e1a\u539f\u8c8c\n\u2462\u6293\u4f4f\u5965\u8fd0\u5546\u673a\uff0c\u4fdd\u8bc1\u4f53\u80b2\u4ea7\u4e1a\u4f01\u4e1a\u76c8\u5229\n\u2463\u76d8\u6d3b\u539f\u6709\u8d44\u6e90\uff0c\u63d0\u5347\u516c\u5171\u6587\u5316\u670d\u52a1\u6c34\u5e73\nA. \u2460\u2462\nB. \u2460\u2463\nC. \u2461\u2462\nD. \u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33767905931288267, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4908800361925515, "HuggingFaceH4/zephyr-7b-beta": 0.3819020521205761, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5334257147313481, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5018413204058528}}, {"question": "2012\u5e74\u6211\u56fd\u7cae\u98df\u603b\u4ea7\u91cf\u8fbe58957\u4e07\u5428\uff0c\u6bd4\u4e0a\u5e74\u589e\u957f3.2%\u3002\u6211\u56fd\u7cae\u98df\u751f\u4ea7\u5df2\u5b9e\u73b0\u201c\u4e5d\u8fde\u4e30\u201d\u3002\u8fd9\u8868\u660e\u6211\u56fd____\n\u2460\u5403\u996d\u95ee\u9898\u5f97\u5230\u89e3\u51b3          \u2461\u4ea7\u4e1a\u7ed3\u6784\u53d1\u751f\u4e86\u53d8\u5316\n\u2462\u7cae\u98df\u5b89\u5168\u6ca1\u6709\u540e\u987e\u4e4b\u5fe7      \u2463\u56fd\u6c11\u7ecf\u6d4e\u7684\u57fa\u7840\u5730\u4f4d\u5f97\u5230\u5de9\u56fa\nA. \u2460\u2461\nB. \u2461\u2462\nC. \u2460\u2463\nD. \u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5472722668277283, "meta-math/MetaMath-Mistral-7B": 0.4025265304015081, "itpossible/Chinese-Mistral-7B-v0.1": 0.36476188275188565, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6072102150806179, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.43570191467834296}}, {"question": "\u57282012\u5e74\u4f26\u6566\u5965\u8fd0\u4f1a\u671f\u95f4\uff0c\u4e2d\u56fd\u6e38\u5ba2\u5e73\u5747\u6bcf\u7b14\u6d88\u8d39\u9ad8 \u8fbe203.04\u82f1\u9551\uff0c\u800c\u5bf9\u4e8e\u5962\u4f88\u54c1\uff0c\u4e2d\u56fd\u6e38\u5ba2\u7684\u8d2d\u4e70\u529b\u66f4\u662f\u60ca\u4eba\u3002\u56fd\u4eba\u5927\u591a\u6ce8\u91cd\u7684\u662f\u5962\u4f88\u54c1\u7684\u54c1\u724c\u4ef7\u503c\u548c\u8868\u9762\u6548\u5e94\u3002\u8bb8\u591a\u6d88\u8d39\u8005\u867d\u4e0d\u5177\u5907\u6d88\u8d39\u5962\u4f88\u54c1\u7684\u5bcc\u88d5\u6761\u4ef6\uff0c\u5374\u5728\u6d88\u8d39\u5962\u4f88\u54c1\uff0c\u8fd9\u662f\u4e00\u79cd\u201c\u5c0f\u5bcc\u5373\u5962\u201d\u5fc3\u7406\u3002\u5bf9\u4e8e\u8fd9\u4e9b\u6d88\u8d39\u8005\uff0c \u6b63\u786e\u7684\u6d88\u8d39\u5fc3\u6001\u5e94\u8be5\u662f____\n\u2460\u514b\u670d\u6500\u6bd4\u5fc3\u7406\uff0c\u575a\u6301\u9002\u5ea6\u6d88\u8d39        \u2461\u907f\u514d\u76f2\u76ee\u6d88\u8d39\uff0c\u575a\u6301\u7406\u6027\u6d88\u8d39\n\u2462\u575a\u6301\u91cf\u5165\u4e3a\u51fa\uff0c\u51cf\u5c11\u6d88\u8d39            \u2463\u514b\u670d\u6c42\u5f02\u5fc3\u7406\uff0c\u575a\u6301\u52e4\u4fed\u8282\u7ea6\nA. \u2460\u2461\nB. \u2461\u2462\nC. \u2460\u2462\nD. \u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35002889446029034, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8879647863063362, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.43137935567252805, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5201086191109423}}, {"question": "\u56fd\u5bb6\u90ae\u653f\u5c40\u8c03\u67e5\uff0c\u7535\u5b50\u5546\u52a1\u5df2\u6210\u4e3a\u6211\u56fd\u5feb\u9012\u4e1a\u53d1\u5c55\u7684\u5de8\u5927\u63a8\u52a8\u529b\uff0c\u5168\u56fd\u5feb\u9012\u4e1a1\uff0f3\u4e1a\u52a1\u91cf\u7531\u7535\u5b50\u5546\u52a1\u5e26\u52a8\u5b8c\u6210\u3002\u4ec5\u53bb\u5e74\u4e2d\u56fd\u7535\u5b50\u5546\u52a1\u5e26\u52a8\u7684\u5305\u88f9\u91cf\u5c31\u8d85\u8fc75\u4ebf\u4ef6\uff0c\u7535\u5b50\u5546\u52a1\u548c\u5feb\u9012\u7269\u6d41\u5df2\u7ecf\u8d8a\u6765\u8d8a\u6210\u4e3a\u4eba\u4eec\u751f\u6d3b\u4e2d\u4e0d\u53ef\u6216\u7f3a\u7684\u90e8\u5206\u3002\u5bf9\u6b64\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684____\n\u2460\u7535\u5b50\u5546\u52a1\u548c\u5feb\u9012\u7269\u6d41\u4e4b\u95f4\u5b58\u5728\u7740\u4e92\u4e3a\u66ff\u4ee3\u5173\u7cfb\n\u2461\u7535\u5b50\u5546\u52a1\u548c\u5feb\u9012\u7269\u6d41\u4e4b\u95f4\u5b58\u5728\u7740\u4e92\u8865\u5173\u7cfb\n\u2462\u7535\u5b50\u5546\u52a1\u548c\u5feb\u9012\u7269\u6d41\u7684\u53d1\u5c55\u6709\u52a9\u4e8e\u63a8\u52a8\u6211\u56fd\u4ea7\u4e1a\u7ed3\u6784\u7684\u8c03\u6574\n\u2463\u7535\u5b50\u5546\u52a1\u548c\u5feb\u9012\u7269\u6d41\u7684\u53d1\u5c55\u8868\u660e\u6211\u56fd\u5c45\u6c11\u6069\u683c\u5c14\u7cfb\u6570\u4e0d\u65ad\u63d0\u9ad8\nA. \u2460\u2462\nB. \u2461\u2463\nC. \u2461\u2462\nD. \u2460\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.8629318585228414, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.619519695679614, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7530043949760052}}, {"question": "\u8fd1\u5e74\u6765\uff0c\u5317\u4eac\u5e02\u63a8\u52a8\u8001\u65e7\u5382\u623f\u4ece\u201c\u4ea7\u4e1a\u56ed\u533a\u201d\u8fc8\u5411\u201c\u6587\u5316\u56ed\u533a\u201d\u3002\u57ce\u5e02\u7684\u5de5\u4e1a\u9057\u5b58\u5728\u65b0\u65f6\u4ee3\u91cc\u9010\u6e10\u878d\u5165\u4eba\u4eec\u7684\u751f\u6d3b\uff0c\u65e5\u76ca\u6210\u4e3a\u57ce\u5e02\u7684\u6587\u5316\u5bcc\u77ff\u3002\u8fd9\u8bf4\u660e\u4e8b\u7269____\nA. \u5728\u8fa9\u8bc1\u5426\u5b9a\u4e2d\u53d1\u5c55\nB. \u5728\u91cf\u53d8\u4e2d\u5b9e\u73b0\u8d28\u53d8\nC. \u5728\u66f2\u6298\u4e2d\u4e0d\u65ad\u524d\u8fdb\nD. \u5728\u5bf9\u7acb\u4e2d\u5b9e\u73b0\u7edf\u4e00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34161424112308736, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4430448139737191, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4eba\u5584\u8015\u800c\u4e0d\u5584\u7267\uff0c\u53e6\u4e00\u4eba\u5584\u7267\u800c\u4e0d\u5584\u8015\uff0c\u5584\u8015\u8005\u60f3\u4ee5\u8c37\u7269\u4e0e\u5584\u7267\u8005\u4ea4\u6362\u725b\u7f8a\uff0c\u5982\u679c\u5584\u7267\u8005\u62d2\u7edd\u4ea4\u6362\u7684\u8bdd\uff0c\u5219\u539f\u56e0\u53ef\u80fd\u662f____\n\u2460\u5584\u8015\u8005\u51fa\u4ef7\u592a\u4f4e                     \u2461\u8c37\u7269\u975e\u4ea4\u6362\u4e4b\u7269\n\u2462\u725b\u7f8a\u975e\u5269\u4f59\u4e4b\u7269                     \u2463\u725b\u7f8a\u975e\u4ea4\u6362\u4e4b\u7269\nA. \u2460\u2461\nB. \u2461\u2462\nC. \u2460\u2462\nD. \u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.42212200429507796, "meta-math/MetaMath-Mistral-7B": 0.6034309437228907, "itpossible/Chinese-Mistral-7B-v0.1": 0.2866128117777278, "HuggingFaceH4/zephyr-7b-beta": 0.8003930148668438, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4440338584426546}}, {"question": "\u4f01\u4e1a\u793e\u4f1a\u8d23\u4efb\u662f\u6307\u4f01\u4e1a\u5728\u8ffd\u6c42\u7ecf\u6d4e\u6548\u76ca\u3001\u5b9e\u73b0\u81ea\u6211\u53d1\u5c55\u7684\u540c\u65f6\uff0c\u8fd8\u5e94\u627f\u62c5\u5bf9\u7ecf\u6d4e\u3001\u73af\u5883\u548c\u793e\u4f1a\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u8d23\u4efb\u3002\u4ee5\u4e0b\u5c5e\u4e8e\u4f01\u4e1a\u793e\u4f1a\u8d23\u4efb\u7684\u6709____\n\u2460\u53d1\u5c55\u7ecf\u6d4e\uff0c\u7a33\u5b9a\u7269\u4ef7\n\u2461\u4ee5\u5229\u6da6\u4e3a\u76ee\u6807\uff0c\u5236\u5b9a\u6b63\u786e\u7684\u7ecf\u8425\u6218\u7565\n\u2462\u81ea\u89c9\u4f9d\u6cd5\u8bda\u4fe1\u7eb3\u7a0e\uff0c\u79ef\u6781\u53c2\u52a0\u793e\u4f1a\u516c\u76ca\u4e8b\u4e1a\n\u2463\u89c4\u8303\u751f\u4ea7\u7ecf\u8425\uff0c\u4e3a\u793e\u4f1a\u63d0\u4f9b\u4f18\u8d28\u7684\u5546\u54c1\u548c\u670d\u52a1\nA. \u2460\u2461\nB. \u2461\u2462\nC. \u2462\u2463\nD. \u2460\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.49364350462339407, "meta-math/MetaMath-Mistral-7B": 0.43291964698921276, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7129068815060767, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3938024329778055, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9081073594216863}}, {"question": "\u4e2d\u56fd\u5b9e\u884c\u53ef\u6301\u7eed\u53d1\u5c55\u7684\u6838\u5fc3\u662f\uff1a____\nA. \u53d1\u5c55\u662f\u5173\u952e\nB. \u7ecf\u6d4e\u589e\u957f\u4e3a\u4e3b\nC. \u4eba\u6c11\u751f\u6d3b\u6c34\u5e73\u63d0\u9ad8\nD. \u81ea\u7136\u8d44\u6e90\u5408\u7406\u5229\u7528B.\u5b63\u8282\u6027\u7279\u70b9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5172235498215516, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3248694335992318, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u91c7\u7528\u4e0b\u73bb\u7483\u6e29\u5ba4\u751f\u4ea7\u852c\u83dc\u3001\u82b1\u5349\uff0c\u5c5e\u4e8e\u519c\u4e1a\u5206\u7c7b\u4e2d\u7684\uff1a____\nA. \u7c97\u653e\u519c\u4e1a\nB. \u81ea\u7ed9\u519c\u4e1a\nC. \u79cd\u690d\u56ed\u519c\u4e1a\nD. \u5bc6\u96c6\u519c\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.48793556102267194, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5847717609975924, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.504860443503326}}, {"question": "\u4e0b\u5217\u6709\u5173\u663c\u591c\u957f\u77ed\u72b6\u51b5\u7684\u53d9\u8ff0\u6b63\u786e\u7684\u662f\uff1a____\nA. 9\u670823\u65e5\u8d64\u9053\u663c\u5927\u4e8e\u591c\nB. 12\u670822\u65e5\u5357\u534a\u7403\u663c\u5c0f\u4e8e\u591c\nC. 6\u670822\u65e5\u5317\u534a\u7403\u663c\u5927\u4e8e\u591c\nD. 3\u670821\u65e5\u6709\u5317\u6781\u5708\u4e0a\u51fa\u73b0\u6781\u663c\u73b0\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.41605129845793937, "meta-math/MetaMath-Mistral-7B": 0.6146051148739604, "itpossible/Chinese-Mistral-7B-v0.1": 0.4313184312322016, "HuggingFaceH4/zephyr-7b-beta": 0.918873766095177, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5016049096037529, "meta-llama/Meta-Llama-3-8B": 0.31483005318115603, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.49670475927393154}}, {"question": "\u6d0b\u6d41\u56e0\u4ea7\u751f\u7684\u52a8\u529b\u4e0d\u540c\uff0c\u53ef\u5206\u4e3a____\nA. \u98ce\u6d77\u6d41\u3001\u6696\u6d41\u3001\u5bd2\u6d41\nB. \u8865\u507f\u6d41\u3001\u6696\u6d41\u3001\u5bd2\u6d41\nC. \u5bc6\u5ea6\u6d41\u3001\u5bd2\u6d41\u3001\u6696\u6d41\nD. \u98ce\u6d77\u6d41\u3001\u8865\u507f\u6d41\u3001\u5bc6\u5ea6\u6d41\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3468666740605408, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8125040536121312}}, {"question": "\u5723\u8bde\u8282\u8fd9\u5929\uff0c\u4e0b\u5217\u57ce\u5e02\u4e2d\u767d\u663c\u6700\u77ed\u7684\u662f____\nA. \u5e7f\u5dde\nB. \u54c8\u5c14\u6ee8\nC. \u5317\u4eac\nD. \u4e0a\u6d77\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3789723923714367, "itpossible/Chinese-Mistral-7B-v0.1": 0.556749535455833, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6386946908509813, "meta-llama/Meta-Llama-3-8B": 0.48866530480037296, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u5173\u53f0\u98ce\u7684\u53d9\u8ff0\uff1a\u2460\u53f0\u98ce\u5e38\u53d1\u751f\u5728\u79cb\u51ac\u5b63\u8282\uff1b\u2461\u53f0\u98ce\u73b0\u8c61\u53ea\u53d1\u751f\u5728\u897f\u592a\u5e73\u6d0b\u4e0a\uff1b\u2462\u53f0\u98ce\u662f\u4e00\u79cd\u5f3a\u70c8\u53d1\u5c55\u7684\u6e29\u5e26\u950b\u9762\u6c14\u65cb\uff1b\u2463\u53f0\u98ce\u662f\u4e00\u79cd\u5728\u6d77\u9762\u4e0a\u5f3a\u70c8\u53d1\u5c55\u7684\u70ed\u5e26\u6c14\u65cb\uff1b\u2464\u98d3\u98ce\u548c\u53f0\u98ce\u90fd\u662f\u70ed\u5e26\u6c14\u65cb\uff0c\u53ea\u662f\u53d1\u751f\u7684\u6d77\u57df\u4e0d\u540c\u800c\u540d\u79f0\u5404\u5f02\u3002\u5176\u4e2d\u6b63\u786e\u7684\u662f____\nA. \u2460\u2461\u2462\nB. \u2461\u2462\u2463\nC. \u2460\u2464\nD. \u2463\u2464\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.33482349867891054, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.422846882465159, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7440535574521441}}, {"question": "\u4e0b\u5217\u4e0d\u4ee5\u79e6\u5cad\u2015\u2015\u6dee\u6cb3\u4e00\u7ebf\u4e3a\u5206\u754c\u7ebf\u7684\u662f____\nA. \u4e9a\u70ed\u5e26\u5b63\u98ce\u6c14\u5019\u548c\u6e29\u5e26\u5b63\u98ce\u6c14\u5019\nB. \u6c34\u7530\u519c\u4e1a\u548c\u65f1\u5730\u519c\u4e1a\nC. \u519c\u8015\u533a\u548c\u7267\u4e1a\u533a\nD. \u6e7f\u6da6\u5730\u533a\u4e0e\u534a\u6e7f\u6da6\u5730\u533a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3638582843838116, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.35096048266444385, "HuggingFaceH4/zephyr-7b-beta": 0.8121545049824276, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.30601362565976303, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9ad8\u6280\u672f\u5de5\u4e1a\u533a\u901a\u5e38\u7684\u7279\u70b9\u6709____\nA. \u7814\u7a76\u5f00\u53d1\u4eba\u5458\u591a\nB. \u751f\u4ea7\u4ea7\u54c1\u5168\u90e8\u9762\u5411\u56fd\u5185\u5e02\u573a\nC. \u4ea7\u54c1\u66f4\u65b0\u6362\u4ee3\u5feb\nD. \u4ece\u4e1a\u4eba\u5458\u5168\u90e8\u662f\u79d1\u5b66\u5bb6\u548c\u5de5\u7a0b\u5e08\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7197379309837966, "meta-math/MetaMath-Mistral-7B": 0.9245626900431816, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8343169406000708, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49444170643482144, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u519c\u4e1a\u793e\u4f1a\u65f6\u671f\uff0c\u722a\u54c7\u5c9b\u4e0a\u4eba\u53e3\u805a\u96c6\u7684\u539f\u56e0\u662f____\nA. \u6cb3\u6d41\u4f17\u591a\nB. \u571f\u58e4\u7684\u80a5\u529b\u9ad8\nC. \u4ea4\u901a\u4fbf\u5229\nD. \u6c14\u5019\u9002\u5b9c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5730\u7403\u5185\u90e8\u5708\u5c42\u5212\u5206\u7684\u4f9d\u636e\u662f____\nA. \u5730\u9707\u6ce2\u901f\u5ea6\u7684\u53d8\u5316\nB. \u6e29\u5ea6\u7684\u5782\u76f4\u53d8\u5316\nC. \u5185\u90e8\u538b\u529b\u7684\u53d8\u5316\nD. \u7269\u8d28\u5bc6\u5ea6\u7684\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.444033867089304, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8681950531694957}}, {"question": "\u4e9a\u6d32\u6c34\u7a3b\u79cd\u690d\u4e1a\u7684\u7279\u70b9\u662f____\nA. \u5355\u4ea7\u9ad8,\u5546\u54c1\u7387\u9ad8\nB. \u4eba\u5747\u8015\u5730\u8f83\u591a,\u591a\u5927\u89c4\u6a21\u7ecf\u8425\nC. \u4eba\u529b\u4e3a\u4e3b,\u673a\u68b0\u5316\u6c34\u5e73\u4f4e\nD. \u6c34\u70ed\u8d44\u6e90\u4e30\u5bcc,\u6c34\u5229\u5de5\u7a0b\u91cf\u5c0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.46423998180804377, "meta-math/MetaMath-Mistral-7B": 0.5731663125432124, "itpossible/Chinese-Mistral-7B-v0.1": 0.37354501646787847, "HuggingFaceH4/zephyr-7b-beta": 0.9415602367889847, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49184904385819384, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8be5\u53bf\u5883\u5185\u96c5\u9c81\u85cf\u5e03\u6c5f\u6cb3\u6bb5\u822a\u8fd0\u4ef7\u503c\u4f4e\uff0c\u5176\u4e3b\u8981\u539f\u56e0\u662f____\nA. \u5c01\u51bb\u671f\u957f\nB. \u843d\u5dee\u5927\nC. \u6d41\u91cf\u5c0f\nD. \u542b\u6c99\u91cf\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u53ef\u4ee5\u770b\u89c1\u4e0b\u5f26\u6708\u7684\u65f6\u95f4\u662f____\nA. \u4e0a\u534a\u591c\nB. \u4e0b\u534a\u591c\nC. \u5b50\u591c\u524d\u540e\nD. \u6574\u4e2a\u591c\u665a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3860362730051736, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fd9\u7247\u5e7f\u88a4\u7684\u9ec4\u571f\u5730\u5df2\u7ecf\u88ab\u6c34\u6d41\u8680\u5272\u5f97\u6c9f\u58d1\u7eb5\u6a2a\uff0c\u652f\u79bb\u7834\u788e\uff0c\u56db\u5206\u4e94\u88c2\uff0c\u50cf\u8001\u5e74\u4eba\u7684\u4e00\u5f20\u7c97\u7cd9\u7684\u76b1\u8138\u6bcf\u5e74\u6d41\u5165\u9ec4\u6cb3\u7684\u6ce5\u6c99\u5c31\u8fbe\u5341\u516d\u4ebf\u5428!\u5c31\u5728\u8fd9\u5927\u81ea\u7136\u65e0\u6570\u9ec4\u8272\u7684\u76b1\u8936\u4e2d\uff0c\u4e16\u4e16\u4ee3\u4ee3\u751f\u6d3b\u548c\u7e41\u884d\u7740\u5343\u5343\u4e07\u4e07\u7684\u4eba\u3002\u65e0\u8bba\u6cbf\u7740\u54ea\u4e00\u6761\u76b1\u7eb9\u8d70\u8fdb\u53bb\uff0c\u4f60\u90fd\u80fd\u78b0\u89c1\u6751\u843d\u548c\u4eba\u70df\uff0c\u800c\u4e14\u5bc6\u96c6\u5f97\u53eb\u4f60\u4e0d\u53ef\u601d\u8bae\u3002\u751f\u6d3b\u5728\u9ec4\u571f\u6240\u5728\u5730\u533a\u7684\u4eba\u4eec____\nA. \u53d7\u70ed\u91cf\u6761\u4ef6\u5236\u7ea6\uff0c\u9009\u62e9\u5728\u6cb3\u8c37\u5730\u533a\u4fee\u8def\u5efa\u6751\nB. \u501f\u9ec4\u571f\u80a5\u6c83\u4f18\u52bf\uff0c\u53d1\u5c55\u4e86\u5927\u89c4\u6a21\u673a\u68b0\u5316\u519c\u4e1a\nC. \u4e0d\u5408\u7406\u8015\u4f5c\u7834\u574f\u690d\u88ab\uff0c\u5bfc\u81f4\u77f3\u6f20\u5316\u73b0\u8c61\u4e25\u91cd\nD. \u901a\u8fc7\u690d\u6811\u79cd\u8349\u53ca\u6253\u575d\u6de4\u5730\u8fdb\u884c\u6709\u6548\u6c34\u571f\u4fdd\u6301\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4665623133447136, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4310339313236754, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7321163636567786}}, {"question": "\u9ec4\u571f\u9ad8\u539f\u6700\u5927\u7684\u73af\u5883\u95ee\u9898\u662f____\nA. \u8352\u6f20\u5316\nB. \u6c34\u571f\u6d41\u5931\nC. \u9178\u96e8\nD. \u6c14\u5019\u53d8\u6696\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8020753154953119, "meta-math/MetaMath-Mistral-7B": 0.9301273516126305, "itpossible/Chinese-Mistral-7B-v0.1": 0.9368383658016854, "HuggingFaceH4/zephyr-7b-beta": 0.9993339966659838, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8733010839744718, "meta-llama/Meta-Llama-3-8B": 0.9623903468747607, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9558183813146203}}, {"question": "\u8377\u5170\u51fa\u53e3\u7684\u82b1\u5349\u5360\u4e16\u754c\u82b1\u5349\u8d38\u6613\u603b\u989d\u768440%\u4ee5\u4e0a\uff0c\u8fd9\u5e76\u4e0d\u5f97\u76ca\u4e8e____\nA. \u4fdd\u9c9c\u3001\u51b7\u85cf\u6280\u672f\u7684\u53d1\u5c55\u548c\u4ea4\u901a\u8fd0\u8f93\u7684\u5b8c\u5584\nB. \u82b1\u5349\u54c1\u79cd\u4e0d\u65ad\u589e\u591a\uff0c\u8d28\u91cf\u4e0d\u65ad\u63d0\u9ad8\nC. \u4f9d\u9760\u79d1\u6280\u53d1\u5c55\u73bb\u7483\u6e29\u5ba4\uff0c\u6539\u9020\u81ea\u7136\u6761\u4ef6\nD. \u4ee5\u8f83\u4f4e\u7684\u4ef7\u683c\u8d62\u5f97\u5e02\u573a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6085790183486356, "meta-llama/Meta-Llama-3-8B": 0.3956423519781027, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.436930899750954}}, {"question": "\u4e0e\u5e7f\u897f\u76f8\u6bd4\uff0c\u5df4\u897f\u53d1\u5c55\u98df\u7cd6\u4e1a\u7684\u7a81\u51fa\u4f18\u52bf\u662f____\nA. \u751f\u4ea7\u6210\u672c\u4f4e\nB. \u4ea7\u54c1\u8d28\u91cf\u9ad8\nC. \u52a0\u5de5\u6280\u672f\u5148\u8fdb\nD. \u793e\u4f1a\u534f\u4f5c\u6761\u4ef6\u597d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3300364758848944, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5970437440024797, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.566728857071907}}, {"question": "1992\u5e74\u97e9\u56fd\u4e09\u661f\u7535\u5b50\u5728\u60e0\u5dde\u5efa\u5de5\u5382\u9996\u8981\u7684\u6709\u5229\u6761\u4ef6\u662f____\nA. \u52b3\u52a8\u529b\u5145\u8db3\uff0c\u85aa\u8d44\u6c34\u5e73\u4f4e\nB. \u6211\u56fd\u5e02\u573a\u5de8\u5927\nC. \u6cbb\u7406\u6c61\u67d3\u8d39\u7528\u8f83\u4f4e\nD. \u5730\u4ef7\u4fbf\u5b9c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5349679934739762, "meta-math/MetaMath-Mistral-7B": 0.7339638079383118, "itpossible/Chinese-Mistral-7B-v0.1": 0.501415785577916, "HuggingFaceH4/zephyr-7b-beta": 0.9945397703359444, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8784289467885655, "meta-llama/Meta-Llama-3-8B": 0.43932247058240037, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7659045088499097}}, {"question": "\u4e0b\u5217\u5929\u4f53\u7cfb\u7edf\u4e2d\u4e0d\u5305\u62ec\u5730\u7403\u7684\u662f____\nA. \u603b\u661f\u7cfb\nB. \u6cb3\u5916\u661f\u7cfb\nC. \u94f6\u6cb3\u7cfb\nD. \u592a\u9633\u7cfb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3819020718350194, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fd1\u65e5\uff0c\u6cf0\u5dde\u9996\u4e2a\u201c\u6cf0\u6709\u793c\u201d\u4e3b\u9898\u8857\u5728\u6d77\u9675\u533a\u57ce\u5317\u8857\u9053\u6b63\u5f0f\u4eae\u76f8\u3002\u4e3b\u9898\u8857\u4e0a\u8bbe\u7acb\u7684\u6587\u660e\u65b0\u98ce\u5c55\u793a\u724c\u548c\u4e3b\u9898\u96d5\u50cf\uff0c\u4f20\u9012\u7740\u7231\u56fd\u7231\u5bb6\u3001\u793c\u8ba9\u8c26\u606d\u3001\u8bda\u4fe1\u505a\u4e8b\u7684\u4e2d\u534e\u4f20\u7edf\u7f8e\u5fb7\u3002\u201c\u6cf0\u6709\u793c\u201d\u4e3b\u9898\u8857\u7684\u8bbe\u7acb\u6709\u5229\u4e8e____\r\n\r\n\u2460\u63d0\u5347\u5e02\u6c11\u7684\u6587\u660e\u7d20\u8d28  \u2461\u589e\u5f3a\u6c11\u65cf\u6587\u5316\u8ba4\u540c\u611f\r\n\u2462\u91cd\u5851\u653f\u5e9c\u7684\u826f\u597d\u5f62\u8c61  \u2463\u4f18\u5316\u57ce\u5e02\u7684\u4eba\u6587\u73af\u5883\nA. \u2460\u2463\nB. \u2460\u2461\u2463\nC. \u2460\u2461\nD. \u2461\u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7306461992743242, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.44304481397371914, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7653567738793323}}, {"question": "\u975e\u516c\u6709\u5236\u7ecf\u6d4e\u662f\u6211\u56fd\u793e\u4f1a\u4e3b\u4e49\u5e02\u573a\u7ecf\u6d4e\u7684\u91cd\u8981\u7ec4\u6210\u95ee\u9898\uff0c\u6211\u56fd\u9f13\u52b1\u3001\u652f\u6301\u3001\u5f15\u5bfc\u975e\u516c\u6709\u5236\u7ecf\u6d4e\u53d1\u5c55\u662f\u56e0\u4e3a\u975e\u516c\u6709\u5236\u7ecf\u6d4e____\r\n\r\n\u2460\u5e7f\u6cdb\u5438\u7eb3\u793e\u4f1a\u8d44\u91d1\uff0c\u662f\u56fd\u6c11\u7ecf\u6d4e\u7684\u4e3b\u5bfc\u529b\u91cf \u2461\u6709\u5229\u4e8e\u589e\u957f\u7a0e\u6536\u3001\u6269\u5927\u5c31\u4e1a\u3001\u4fc3\u8fdb\u7ecf\u6d4e\u589e\u957f\r\n\u2462\u662f\u6211\u56fd\u793e\u4f1a\u4e3b\u4e49\u7ecf\u6d4e\u5236\u5ea6\u7684\u57fa\u7840\uff0c\u5360\u4e3b\u4f53\u5730\u4f4d \u2463\u5728\u4fc3\u8fdb\u5927\u4f17\u521b\u4e1a\u548c\u4e07\u4f17\u521b\u65b0\u65b9\u9762\u53d1\u6325\u91cd\u8981\u4f5c\u7528\nA. \u2460\u2461\nB. \u2460\u2462\nC. \u2461\u2463\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8981\u575a\u6301\u5e02\u573a\u5728\u8d44\u6e90\u914d\u7f6e\u4e2d\u8d77\u51b3\u5b9a\u6027\u4f5c\u7528\uff0c\u5176\u539f\u56e0\u6709____ \r\n\r\n\u2460\u4e3a\u4e86\u4fdd\u6301\u7ecf\u6d4e\u53d1\u5c55\u7684\u6d3b\u529b \u2461\u5e02\u573a\u914d\u7f6e\u8d44\u6e90\u662f\u6700\u6709\u6548\u7387\u7684\u5f62\u5f0f\r\n\u2462\u653f\u5e9c\u5c65\u884c\u804c\u80fd\u53ef\u4ee5\u4fdd\u6301\u5b8f\u89c2\u7ecf\u6d4e\u7684\u7a33\u5b9a \u2463\u53ef\u4ee5\u52a0\u5f3a\u548c\u4f18\u5316\u516c\u5171\u670d\u52a1\uff0c\u4fc3\u8fdb\u5171\u540c\u5bcc\u88d5\nA. \u2460\u2461\nB. \u2460\u2462\nC. \u2461\u2463\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3271055990389261, "meta-math/MetaMath-Mistral-7B": 0.6267179953872665, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4173057303931505, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u573a\u666f\u4e2d\uff0c\u4f60\u8ba4\u4e3a\u7b26\u5408\u793c\u4eea\u8981\u6c42\u7684\u662f____\nA. \u5728\u535a\u7269\u9986\u53c2\u89c2\u8fb9\u542c\u8bb2\u89e3\u4eba\u5458\u8bb2\u89e3\uff0c\u8fb9\u5403\u9999\u751c\u5473\u91cd\u7684\u98df\u54c1\nB. \u5728\u697c\u9053\u91cc\u9047\u5230\u4e0d\u6559\u81ea\u5df1\u7684\u672c\u6821\u8001\u5e08\uff0c\u4e3b\u52a8\u95ee\u597d\nC. \u5bb6\u5ead\u805a\u4f1a\u65f6\uff0c\u521a\u4e00\u4e0a\u83dc\u5c31\u81ea\u987e\u81ea\u7684\u5403\u8d77\u6765\nD. \u5728\u56fe\u4e66\u9986\u9605\u8bfb\u533a\u57df\uff0c\u548c\u540c\u4f34\u79c1\u8bed\uff0c\u968f\u610f\u5927\u58f0\u63a5\u6253\u7535\u8bdd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7230968224088884, "meta-math/MetaMath-Mistral-7B": 0.9717655811502229, "itpossible/Chinese-Mistral-7B-v0.1": 0.7343978538476246, "HuggingFaceH4/zephyr-7b-beta": 0.998886170927009, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9918527616436957, "meta-llama/Meta-Llama-3-8B": 0.8588992335210612, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9869206549156098}}, {"question": "2018\u5e749\u670827\u65e5\uff0c\u4e60\u8fd1\u5e73\u5728\u89c6\u5bdf\u4e2d\u56fd\u77f3\u6cb9\u8fbd\u9633\u77f3\u5316\u516c\u53f8\u65f6\u5f3a\u8c03\uff0c\u56fd\u6709\u4f01\u4e1a\u5730\u4f4d\u91cd\u8981\u3001\u4f5c\u7528\u5173\u952e\u3001\u4e0d\u53ef\u66ff\u4ee3\uff0c\u662f\u515a\u548c\u56fd\u5bb6\u7684\u91cd\u8981\u4f9d\u9760\u529b\u91cf\u3002\u5bf9\u6b64\u8ba4\u8bc6\u6b63\u786e\u7684\u6709____\nA. \u56fd\u6709\u7ecf\u6d4e\u662f\u56fd\u6c11\u7ecf\u6d4e\u7684\u4e3b\u5bfc\u529b\u91cf\nB. \u56fd\u6709\u7ecf\u6d4e\u662f\u793e\u4f1a\u4e3b\u4e49\u7ecf\u6d4e\u5236\u5ea6\u7684\u57fa\u7840\nC. \u56fd\u5bb6\u9650\u5236\u56fd\u6709\u7ecf\u6d4e\u7684\u58ee\u5927\u548c\u53d1\u5c55\nD. \u56fd\u6709\u7ecf\u6d4e\u5c06\u53d6\u4ee3\u975e\u516c\u6709\u5236\u7ecf\u6d4e\u7684\u5730\u4f4d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6256508604014495, "HuggingFaceH4/zephyr-7b-beta": 0.7970455044893326, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4875785183518827, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65f6\u81f3\u8fd1\u65e5\uff0c\u4e2d\u7f8e\u7ecf\u5386\u4e86\u4e5d\u6b21\u7ecf\u8d38\u9ad8\u7ea7\u522b\u78cb\u5546\uff0c\u5e76\u53d6\u5f97\u5b9e\u8d28\u6027\u8fdb\u5c55\u3002\u8fd9\u8868\u660e____\nA. \u53d1\u5c55\u4e0e\u5408\u4f5c\u662f\u5f53\u4eca\u65f6\u4ee3\u7684\u4e3b\u9898\nB. \u7ecf\u6d4e\u5168\u7403\u5316\u7684\u80cc\u666f\u4e0b\uff0c\u6211\u56fd\u7ecf\u6d4e\u53d1\u5c55\u9762\u4e34\u7740\u8bb8\u591a\u98ce\u9669\u548c\u6311\u6218\nC. \u5bf9\u8bdd\u4ea4\u6d41\u6210\u4e3a\u5f53\u4eca\u56fd\u9645\u793e\u4f1a\u53d1\u5c55\u53cb\u597d\u5173\u7cfb\u3001\u89e3\u51b3\u56fd\u9645\u4e89\u7aef\u3001\u4fc3\u8fdb\u5408\u4f5c\u7684\u4e3b\u8981\u65b9\u5f0f\nD. \u4e2d\u7f8e\u4e4b\u95f4\u4e0d\u518d\u6709\u4efb\u4f55\u7684\u77db\u76fe\u4e0e\u5206\u6b67\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.920792445205502, "itpossible/Chinese-Mistral-7B-v0.1": 0.7747342544439499, "HuggingFaceH4/zephyr-7b-beta": 0.9992258059583586, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9545160888070011, "meta-llama/Meta-Llama-3-8B": 0.8337732628162479, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7674323825411157}}, {"question": "2022\u5e74\uff0c\u662f\u5168\u9762\u5efa\u8bbe\u793e\u4f1a\u4e3b\u4e49\u73b0\u4ee3\u5316\u56fd\u5bb6\uff0c\u5411\u7b2c\u4e8c\u4e2a\u767e\u5e74\u594b\u6597\u76ee\u6807\u8fdb\u519b\u7684\u91cd\u8981\u4e00\u5e74\u4e5f\u662f\u559c\u8fce\u4e2d\u56fd\u5171\u4ea7\u515a\u4e8c\u5341\u5927\u80dc\u5229\u53ec\u5f00\u7684\u91cd\u8981\u4e00\u5e74\u3002\u4e0b\u5217\u5173\u4e8e\u4e2d\u56fd\u5171\u4ea7\u515a\u7684\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u4e2d\u56fd\u5171\u4ea7\u515a\u5728\u6574\u4e2a\u56fd\u5bb6\u673a\u5173\u4f53\u7cfb\u4e2d\u5c45\u4e8e\u6700\u9ad8\u5730\u4f4d\nB. \u4e2d\u56fd\u5171\u4ea7\u515a\u662f\u4e2d\u56fd\u7279\u8272\u793e\u4f1a\u4e3b\u4e49\u4e8b\u4e1a\u7684\u9886\u5bfc\u6838\u5fc3\nC. \u515a\u7684\u9886\u5bfc\u662f\u4e2d\u56fd\u7279\u8272\u793e\u4f1a\u4e3b\u4e49\u5236\u5ea6\u7684\u6700\u5927\u4f18\u52bf\nD. \u515a\u7684\u521d\u5fc3\u548c\u4f7f\u547d\u662f\u4e3a\u4e2d\u56fd\u4eba\u6c11\u8c0b\u5e78\u798f\u3001\u4e3a\u4e2d\u534e\u6c11\u65cf\u8c0b\u590d\u5174\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47300853087008654, "meta-llama/Meta-Llama-3-8B": 0.48824495791204714, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7f8e\u56e2\u5916\u5356\u9a91\u624b\u5c0f\u6768\u4e3a\u4e86\u8d76\u65f6\u95f4\u591a\u9001\uff0c\u95ef\u7ea2\u706f\u88ab\u4ea4\u8b66\u7f5a\u6b3e100\u5143\uff1b\u649e\u4f24\u5c0f\u738b\u7684\u79c1\u5bb6\u8f66\uff0c\u5f04\u574f\u4fdd\u9669\u6760\uff0c\u8d54\u507f800\u5143\uff1b\u79c1\u5bb6\u8f66\u8f66\u4e3b\u628a\u5c0f\u6768\u6253\u6210\u91cd\u4f24\u88ab\u5224\u62d8\u5f793\u4e2a\u6708\uff0c\u7f5a\u91d110000\u5143\u3002\u4e0a\u8ff0\u8fdd\u6cd5\u884c\u4e3a\u5206\u522b\u662f____\nA. \u6c11\u4e8b\u8fdd\u6cd5\u884c\u4e3a\u3001\u884c\u653f\u8fdd\u6cd5\u884c\u4e3a\u3001\u5211\u4e8b\u8fdd\u6cd5\u884c\u4e3a\nB. \u884c\u653f\u8fdd\u6cd5\u884c\u4e3a\u3001\u5211\u4e8b\u8fdd\u6cd5\u884c\u4e3a\u3001\u6c11\u4e8b\u8fdd\u6cd5\u884c\u4e3a\nC. \u5211\u4e8b\u8fdd\u6cd5\u884c\u4e3a\u3001\u884c\u653f\u8fdd\u6cd5\u884c\u4e3a\u3001\u6c11\u4e8b\u8fdd\u6cd5\u884c\u4e3a\nD. \u884c\u653f\u8fdd\u6cd5\u884c\u4e3a\uff0c\u6c11\u4e8b\u8fdd\u6cd5\u884c\u4e3a\u3001\u5211\u4e8b\u8fdd\u6cd5\u884c\u4e3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4916495895788265, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u575a\u6301\u548c\u53d1\u5c55\u4e2d\u56fd\u7279\u8272\u793e\u4f1a\u4e3b\u4e49\u7684\u603b\u4efb\u52a1\u662f____\r\n\r\n\u2460\u5b9e\u73b0\u793e\u4f1a\u4e3b\u4e49\u73b0\u4ee3\u5316 \u2461\u575a\u6301\u4ee5\u7ecf\u6d4e\u5efa\u8bbe\u4e3a\u4e2d\u5fc3\r\n\u2462\u5b9e\u73b0\u4e2d\u534e\u6c11\u65cf\u4f1f\u5927\u590d\u5174 \u2463\u575a\u6301\u201c\u4e94\u4f4d\u4e00\u4f53\u201d\u603b\u5e03\u5c40\nA. \u2460\u2461\nB. \u2460\u2462\nC. \u2461\u2463\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3287145937103622, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2019\u5e745\u670810\u65e5\uff0c\u56fd\u5bb6\u5e02\u573a\u76d1\u7ba1\u603b\u5c40\u5c31\u201c\u897f\u5b89\u5954\u9a70\u6f0f\u6cb9\u4e8b\u4ef6\u201d\u53ca\u76f8\u5173\u95ee\u9898\u7ea6\u8c08\u5954\u9a70\uff0c\u660e\u786e\u8981\u6c42\uff0c\u7ecf\u9500\u5546\u4e0d\u5f97\u4ee5\u63d0\u4f9b\u91d1\u878d\u670d\u52a1\u4e3a\u7531\u6536\u53d6\u8d39\u7528\uff0c\u5fc5\u987b\u53d1\u5e03\u670d\u52a1\u516c\u7ea6\u548c\u6536\u8d39\u6e05\u5355\uff0c\u786e\u4fdd\u6536\u8d39\u516c\u5f00\u900f\u660e\u3002\u6b64\u9879\u89c4\u5b9a\u6709\u52a9\u4e8e\u4fdd\u62a4\u6d88\u8d39\u8005\u7684____\r\n\r\n\u2460\u5b89\u5168\u6743 \u2461\u81ea\u4e3b\u9009\u62e9\u6743 \r\n\u2462\u77e5\u60c5\u6743 \u2463\u516c\u5e73\u4ea4\u6613\u6743\nA. \u2460\u2461\u2462\nB. \u2460\u2461\u2463\nC. \u2461\u2462\u2463\nD. \u2460\u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4eba\u5458\u7684\u5de5\u4f5c\u5355\u4f4d\u5c5e\u4e8e\u4e2a\u4f53\u7ecf\u6d4e\u7684\u662f____\nA. \u5c0f\u5b81\u592b\u59bb\u7ecf\u8425\u7684\u5c0f\u9910\u9986\nB. \u5c0f\u7ea2\u5c31\u804c\u7684\u56fd\u6709\u4f01\u4e1a\nC. \u5c0f\u541b\u5de5\u4f5c\u7684\u9547\u529e\u4f01\u4e1a\nD. \u5c0f\u5b89\u5e94\u8058\u7684\u5916\u8d44\u4f01\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9690037992347702, "meta-math/MetaMath-Mistral-7B": 0.9989450871392902, "itpossible/Chinese-Mistral-7B-v0.1": 0.8702683368285848, "HuggingFaceH4/zephyr-7b-beta": 0.9999988431187573, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9909358889442677, "meta-llama/Meta-Llama-3-8B": 0.9738267612452332, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9992574530336102}}, {"question": "\u540c\u5b66\u4eec\u56f4\u7ed5\u201c\u4eba\u6cbb\u201d\u4e0e\u201c\u6cd5\u6cbb\u201d\u5c55\u5f00\u4e86\u7cfb\u5217\u8ba8\u8bba\uff0c\u4e0b\u5217\u89c2\u70b9\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u4eba\u6cbb\u5f3a\u8c03\u6cd5\u5f8b\u53ea\u662f\u4f5c\u4e3a\u529e\u4e8b\u7684\u53c2\u8003\nB. \u6cd5\u6cbb\u5f3a\u8c03\u6cd5\u5f8b\u5236\u5ea6\u7684\u7406\u6027\u53ca\u4e00\u822c\u6307\u5bfc\u4f5c\u7528\nC. \u6cd5\u6cbb\u5177\u6709\u53ef\u9884\u671f\u6027\u3001\u53ef\u64cd\u4f5c\u6027\u3001\u53ef\u6551\u6d4e\u6027\nD. \u6cd5\u6cbb\u662f\u516c\u5171\u900f\u660e\u7684\u89c4\u5219\u4e4b\u6cbb\uff0c\u4eba\u6cbb\u4f18\u4e8e\u6cd5\u6cbb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9353987597605373, "meta-math/MetaMath-Mistral-7B": 0.9972465131828999, "itpossible/Chinese-Mistral-7B-v0.1": 0.9019331615801357, "HuggingFaceH4/zephyr-7b-beta": 0.9999919740386498, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9856774551353565, "meta-llama/Meta-Llama-3-8B": 0.9097287689826017, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9712430288022736}}, {"question": "2018\u5e7411\u67081\u65e5\uff0c\u4e60\u8fd1\u5e73\u603b\u4e66\u8bb0\u4e3b\u6301\u53ec\u5f00\u6c11\u8425\u4f01\u4e1a\u5ea7\u8c08\u4f1a\u5e76\u53d1\u8868\u91cd\u8981\u8bb2\u8bdd\uff0c\u5f3a\u8c03\u6211\u56fd\u6c11\u8425\u7ecf\u6d4e\u53ea\u80fd\u58ee\u5927\u3001\u4e0d\u80fd\u5f31\u5316\u3002\u8fd9\u662f\u56e0\u4e3a____\nA. \u6c11\u8425\u7ecf\u6d4e\u662f\u56fd\u6c11\u7ecf\u6d4e\u7684\u4e3b\u5bfc\u529b\u91cf\nB. \u6c11\u8425\u7ecf\u6d4e\u662f\u793e\u4f1a\u4e3b\u4e49\u7ecf\u6d4e\u5236\u5ea6\u7684\u57fa\u7840\nC. \u53ea\u6709\u6c11\u8425\u7ecf\u6d4e\u624d\u80fd\u4fc3\u8fdb\u5927\u4f17\u521b\u4e1a\u3001\u4e07\u4f17\u521b\u65b0\nD. \u6211\u56fd\u575a\u6301\u4ee5\u516c\u6709\u5236\u4e3a\u4e3b\u4f53\u3001\u591a\u79cd\u6240\u6709\u5236\u7ecf\u6d4e\u5171\u540c\u53d1\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4213546502185918, "meta-math/MetaMath-Mistral-7B": 0.5104934369984532, "itpossible/Chinese-Mistral-7B-v0.1": 0.3306562312783846, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5171960113306794, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7708483894039974}}, {"question": "\u56fd\u5bb6\u4e3b\u5e2d\u4e60\u8fd1\u5e73\u5f3a\u8c03\uff1a\u201c\u8981\u4ece\u4fdd\u62a4\u4eba\u6c11\u5065\u5eb7\u3001\u4fdd\u969c\u56fd\u5bb6\u5b89\u5168\u3001\u7ef4\u62a4\u56fd\u5bb6\u957f\u6cbb\u4e45\u5b89\u7684\u9ad8\u5ea6\uff0c\u628a\u751f\u7269\u5b89\u5168\u7eb3\u5165\u56fd\u5bb6\u5b89\u5168\u4f53\u7cfb\u3002\u201d\u5bf9\u6b64\uff0c\u8ba4\u8bc6\u6b63\u786e\u7684\u6709____\r\n\r\n\u2460\u751f\u7269\u5b89\u5168\u6d89\u53ca\u56fd\u5bb6\u91cd\u8981\u5229\u76ca \u2461\u4fdd\u969c\u751f\u7269\u5b89\u5168\u5c31\u80fd\u5b9e\u73b0\u56fd\u5bb6\u5b89\u5168\r\n\u2462\u751f\u7269\u5b89\u5168\u5173\u7cfb\u4eba\u6c11\u5e78\u798f\u5b89\u5eb7 \u2463\u751f\u7269\u5b89\u5168\u95ee\u9898\u53ea\u5bf9\u7ecf\u6d4e\u9020\u6210\u5371\u5bb3\nA. \u2460\u2461\nB. \u2460\u2462\nC. \u2461\u2463\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8165143628613529, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.46601037218839503, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7228664682226776}}, {"question": "\u201c\u98ce\u58f0\u3001\u96e8\u58f0\u3001\u8bfb\u4e66\u58f0\uff0c\u58f0\u58f0\u4eba\u8033\uff1b\u5bb6\u4e8b\u3001\u56fd\u4e8b\u3001\u5929\u4e0b\u4e8b\uff0c\u4e8b\u4e8b\u5173\u5fc3\u3002\u201d\u8fd9\u526f\u5bf9\u8054\u7ed9\u6211\u4eec\u7684\u542f\u793a\u662f____\nA. \u8981\u53c2\u52a0\u793e\u4f1a\u5b9e\u8df5\u6d3b\u52a8\uff0c\u70ed\u5fc3\u5e2e\u52a9\u8d2b\u56f0\u513f\u7ae5\nB. \u8981\u5b66\u597d\u6587\u5316\u77e5\u8bc6\uff0c\u5176\u4ed6\u4e8b\u60c5\u4e0e\u81ea\u5df1\u65e0\u5173\nC. \u8981\u5173\u5fc3\u793e\u4f1a\u53d1\u5c55\uff0c\u5173\u6ce8\u56fd\u5bb6\u5927\u4e8b\nD. \u4e8b\u5fc5\u8eac\u4eb2\uff0c\u5927\u5c0f\u4e8b\u90fd\u8981\u4eb2\u529b\u4eb2\u4e3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9010480792052304, "meta-math/MetaMath-Mistral-7B": 0.9977320405677617, "itpossible/Chinese-Mistral-7B-v0.1": 0.8903080024377521, "HuggingFaceH4/zephyr-7b-beta": 0.9984067027863743, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9617576975621074, "meta-llama/Meta-Llama-3-8B": 0.9447509912165419, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8650586271419497}}, {"question": "2019\u5e743\u67085\u65e5\u5341\u4e09\u5c4a\u5168\u56fd\u4eba\u5927\u4e00\u6b21\u4f1a\u8bae\u4e0a\uff0c\u674e\u514b\u5f3a\u603b\u7406\u5728\u653f\u5e9c\u5de5\u4f5c\u62a5\u544a\u4e2d\u63d0\u51fa2019\u5e74\u56fd\u5185\u751f\u4ea7\u603b\u503c\u589e\u957f\u7684\u9884\u671f\u76ee\u6807\u662f____\nA. 5%-5.5%\nB. 5.5%-6%\nC. 6%-6.5%\nD. 6.5%-7%\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38938704644528593, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.35278092874909756, "HuggingFaceH4/zephyr-7b-beta": 0.594919077054373, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3967757715930558, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u73b0\u5728\u7684\u4e16\u754c\u662f____\r\n\r\n \u2460\u4e00\u4e2a\u5f00\u653e\u7684\u4e16\u754c \u2461\u4e00\u4e2a\u53d1\u5c55\u7684\u4e16\u754c\r\n \u2462\u4e00\u4e2a\u7d27\u5bc6\u8054\u7cfb\u7684\u4e16\u754c \u2463\u4e00\u4e2a\u6ca1\u6709\u8d2b\u56f0\u548c\u6218\u4e89\u7684\u4e16\u754c\nA. \u2460\u2461\u2462\nB. \u2460\u2461\u2463\nC. \u2461\u2462\u2463\nD. \u2460\u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4550475312585359, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47203052758493513, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4eca\u4e16\u754c\uff0c\u79d1\u5b66\u6280\u672f\u65e5\u65b0\u6708\u5f02\uff0c\u5168\u7403\u7ade\u4e89\u4e0d\u65ad\u5347\u7ea7\uff0c\u4e2d\u56fd\u8981\u628a\u63e1\u4e16\u754c\u7684\u53d1\u5c55\u8d8b\u52bf\uff0c\u79ef\u6781\u8c0b\u6c42\u81ea\u8eab\u53d1\u5c55\uff0c\u63d0\u9ad8\u56fd\u9645\u7ade\u4e89\u529b\uff0c\u4fc3\u8fdb\u53d1\u5c55\uff0c\u8981\u628a\u63d0\u5347____\u653e\u5728\u9996\u4f4d\u3002\nA. \u53d1\u5c55\u8d28\u91cf\nB. \u5236\u9020\u4e1a\nC. \u56fd\u9632\u5b9e\u529b\nD. \u4f20\u7edf\u4ea7\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8706130185263522, "meta-math/MetaMath-Mistral-7B": 0.9959436121238099, "itpossible/Chinese-Mistral-7B-v0.1": 0.8830938276729907, "HuggingFaceH4/zephyr-7b-beta": 0.9999968045198814, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9579365228819657, "meta-llama/Meta-Llama-3-8B": 0.8563908298241822, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9793780061697358}}, {"question": "\u6bcf\u5e74\u6625\u6696\u82b1\u5f00\u4e4b\u9645\u4e5f\u662f\u6211\u56fd\u201c\u4e24\u4f1a\u201d\u4e4b\u65f6\u3002\u5168\u56fd\u201c\u4e24\u4f1a\u201d\u6307\u7684\u662f____\nA. \u5168\u56fd\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u548c\u4e2d\u5171\u4e2d\u592e\u5168\u4f1a\nB. \u5168\u56fd\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u548c\u4e2d\u56fd\u4eba\u6c11\u653f\u6cbb\u534f\u5546\u4f1a\u8bae\nC. \u5168\u56fd\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u548c\u4e2d\u56fd\u5171\u4ea7\u515a\u5168\u56fd\u4ee3\u8868\u5927\u4f1a\nD. \u4e2d\u56fd\u5171\u4ea7\u515a\u5168\u56fd\u4ee3\u8868\u5927\u4f1a\u548c\u4e2d\u56fd\u4eba\u6c11\u653f\u6cbb\u534f\u5546\u4f1a\u8bae\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5520424925762917, "meta-math/MetaMath-Mistral-7B": 0.6920564793015188, "itpossible/Chinese-Mistral-7B-v0.1": 0.7497662676410569, "HuggingFaceH4/zephyr-7b-beta": 0.991116633258326, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8244814927813766, "meta-llama/Meta-Llama-3-8B": 0.9447220147101847, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8122185177080142}}, {"question": "\u201c\u6cd5\u5b9a\u804c\u8d23\u5fc5\u987b\u4e3a\uff0c\u6cd5\u65e0\u6388\u6743\u4e0d\u53ef\u4e3a\u3002\u201d\u5baa\u6cd5\u7684\u6838\u5fc3\u4ef7\u503c\u8ffd\u6c42\u662f____\nA. \u4f9d\u6cd5\u884c\u653f\nB. \u4fdd\u8bc1\u4eba\u6c11\u5f53\u5bb6\u4f5c\u4e3b\nC. \u516c\u6b63\u53f8\u6cd5\nD. \u89c4\u8303\u6743\u529b\u8fd0\u884c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.39396666046800444, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5732746720377035, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4914826691392187, "meta-llama/Meta-Llama-3-8B": 0.4907840909413319, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7122390476688679}}, {"question": "5\u4ebf\u4eba\uff0c\u7ec7\u5c31\u4e86\u4e16\u754c\u4e0a\u6700\u5927\u7684\u793e\u4f1a\u4fdd\u969c\u7f51\u3002\u4e0a\u8ff0\u4e3e\u63aa\u65e8\u5728\u5b9e\u73b0____\nA. \u56fd\u5bb6\u5bcc\u5f3a\nB. \u6c11\u65cf\u632f\u5174\nC. \u4eba\u6c11\u5e78\u798f\nD. \u56fd\u6709\u7ecf\u6d4e\u5c06\u53d6\u4ee3\u975e\u516c\u6709\u5236\u7ecf\u6d4e\u7684\u5730\u4f4d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9473350771163862, "meta-math/MetaMath-Mistral-7B": 0.9946784507536574, "itpossible/Chinese-Mistral-7B-v0.1": 0.9079682118873998, "HuggingFaceH4/zephyr-7b-beta": 0.9997910832931377, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9741054788692753, "meta-llama/Meta-Llama-3-8B": 0.8656007300381008, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9949521227207797}}, {"question": "\u6211\u56fd\u6700\u5927\u7684\u5c9b\u5c7f\u662f____\nA. \u53f0\u6e7e\u5c9b\nB. \u6d77\u5357\u5c9b\nC. \u9999\u6e2f\u5c9b\nD. \u5d07\u660e\u5c9b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5233466241856034, "meta-math/MetaMath-Mistral-7B": 0.9381802174052166, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.653061512972875, "meta-llama/Meta-Llama-3-8B": 0.9038756741697247, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6502527313482239}}, {"question": "\u5370\u5ea6\u7684\u201c\u7eff\u8272\u9769\u547d\u201d\u6307\u7684\u662f____\nA. \u690d\u6811\u9020\u6797\uff0c\u4fdd\u62a4\u73af\u5883\nB. \u5f15\u8fdb\u57f9\u80b2\u4f5c\u7269\u54c1\u79cd\uff0c\u6539\u8fdb\u7cae\u98df\u751f\u4ea7\u6280\u672f\nC. \u6539\u8fdb\u704c\u6e89\u6280\u672f\uff0c\u7528\u4f20\u7edf\u7caa\u80a5\u4ee3\u66ff\u5316\u80a5\nD. \u63a8\u5e7f\u5929\u7136\u65e0\u516c\u5bb3\u3001\u65e0\u6c61\u67d3\u7684\u7eff\u8272\u4ea7\u54c1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5462673942374467, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.9606997805618754, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.364489916204558, "meta-llama/Meta-Llama-3-8B": 0.9862814598559567, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9996820394529329}}, {"question": "\u5728\u5c0f\u521a\u7684\u4e00\u7bc7\u4f5c\u6587\u4e2d\u6709\u4ee5\u4e0b\u4e00\u4e9b\u63cf\u8ff0\u8bed\u8a00\uff0c\u4f60\u8ba4\u4e3a\u4e0d\u5408\u9002\u7684\u662f____  \u2460\u4eca\u5929\u7684\u6c14\u5019\u5f88\u597d\uff0c\u9002\u5408\u5916\u51fa\u6e38\u73a9     \u2461\u4eca\u5e74\u51ac\u5929\u6c14\u6e29\u8f83\u5e38\u5e74\u504f\u9ad8\uff0c\u5929\u6c14\u51fa\u73b0\u4e86\u5f02\u5e38     \u2462\u6606\u660e\u56db\u5b63\u5982\u6625\uff0c\u8fd9\u91cc\u7684\u6c14\u5019\u771f\u4e0d\u9519     \u2463\u65e9\u996d\u540e\u8fd8\u662f\u6674\u7a7a\u4e07\u91cc\uff0c\u5230\u4e86\u4e2d\u5348\u5374\u662f\u4e4c\u4e91\u6eda\u6eda\uff0c\u5927\u96e8\u503e\u76c6\uff0c\u4eca\u5929\u7684\u6c14\u5019\u53d8\u5316\u771f\u5927\nA. \u2460\u2461\u2462\nB. \u2461\u2462\u2463\nC. \u2460\u2461\u2463\nD. \u2460\u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33525737937180966, "meta-math/MetaMath-Mistral-7B": 0.37993597849898714, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.48890632753267693, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e16\u754c\u4e0a\u6930\u5b50\u7684\u6700\u5927\u751f\u4ea7\u56fd\u548c\u6700\u5927\u51fa\u53e3\u56fd\u5206\u522b\u662f____\nA. \u6cf0\u56fd\u3001\u83f2\u5f8b\u5bbe\nB. \u83f2\u5f8b\u5bbe\u3001\u5370\u5ea6\u5c3c\u897f\u4e9a\nC. \u5370\u5ea6\u5c3c\u897f\u4e9a\u3001\u83f2\u5f8b\u5bbe\nD. \u83f2\u5f8b\u5bbe\u3001\u6cf0\u56fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45800013650078736, "meta-math/MetaMath-Mistral-7B": 0.450722397102564, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9221475215511231, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.45092007969637743, "meta-llama/Meta-Llama-3-8B": 0.3060136256597631, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.41252316021326507}}, {"question": "\u5173\u4e8e\u6211\u56fd\u6cb3\u6d41\u7684\u53d9\u8ff0\uff0c\u9519\u8bef\u7684\u662f____\nA. \u5854\u91cc\u6728\u6cb3\u662f\u6211\u56fd\u6700\u957f\u7684\u5185\u6d41\u6cb3\nB. \u957f\u6c5f\u662f\u6211\u56fd\u957f\u5ea6\u3001\u6c34\u91cf\u6700\u5927\u3001\u6d41\u57df\u9762\u79ef\u6700\u5e7f\u7684\u6cb3\u6d41\nC. \u6211\u56fd\u5916\u6d41\u6cb3\u6700\u7ec8\u6ce8\u5165\u592a\u5e73\u6d0b\nD. \u957f\u6c5f\u88ab\u8a89\u4e3a\u201c\u6c34\u80fd\u5b9d\u5e93\u201d\u201c\u9ec4\u91d1\u6c34\u9053\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6185094674796129, "meta-math/MetaMath-Mistral-7B": 0.7070934092076735, "itpossible/Chinese-Mistral-7B-v0.1": 0.3534716292209113, "HuggingFaceH4/zephyr-7b-beta": 0.8440687511533155, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5683110330381251, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5730\u533a\u7684\u519c\u4e1a\u751f\u4ea7\u7b26\u5408\u56e0\u5730\u5236\u5b9c\u539f\u5219\u7684\u662f____\nA. \u5728\u9ec4\u571f\u9ad8\u539f\u5730\u533a\u5927\u529b\u53d1\u5c55\u7cae\u98df\u751f\u4ea7\nB. \u5728\u73e0\u6c5f\u4e09\u89d2\u6d32\u5927\u529b\u53d1\u5c55\u6797\u4e1a\nC. \u5728\u65b0\u7586\u5730\u533a\u5927\u529b\u53d1\u5c55\u6c34\u7a3b\u751f\u4ea7\nD. \u5728\u957f\u6c5f\u4e2d\u4e0b\u6e38\u5730\u533a\u5927\u529b\u53d1\u5c55\u6de1\u6c34\u517b\u6b96\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.40322669517609055, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.45518183272079943, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7027829328961288}}, {"question": "2016\u5e741\u6708\u8d77\uff0c\u6211\u56fd\u5168\u9762\u5f00\u653e\u4e8c\u5b69\u653f\u7b56\u7684\u4e3b\u8981\u76ee\u7684\u662f____\nA. \u2460\u2461\nB. \u2461\u2462\nC. \u2461\u2463\nD. \u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e16\u754c\u4e0a\u4f7f\u7528\u4eba\u6570\u6700\u591a\u3001\u4f7f\u7528\u6cdb\u56f4\u6700\u5e7f\u6cdb\u7684\u8bed\u8a00\u5206\u522b\u662f____\nA. \u82f1\u8bed\u3001\u6cd5\u8bed\nB. \u6c49\u8bed\u3001\u82f1\u8bed\nC. \u963f\u62c9\u4f2f\u8bed\u3001\u897f\u73ed\u7259\u8bed\nD. \u4fc4\u8bed\u3001\u82f1\u8bed\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7237503465384229, "meta-math/MetaMath-Mistral-7B": 0.8366882089198495, "itpossible/Chinese-Mistral-7B-v0.1": 0.7076607248500222, "HuggingFaceH4/zephyr-7b-beta": 0.7190130362314255, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8426456210693107, "meta-llama/Meta-Llama-3-8B": 0.5746624561183112, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5207461120788798}}, {"question": "2014\u5e743\u6708\uff0c\u5927\u8303\u56f4\u96fe\u973e\u5929\u6c14\u957f\u65f6\u95f4\u5f71\u54cd\u6211\u56fd\u4e1c\u90e8\u5730\u533a\uff0c\u4e25\u91cd\u5371\u5bb3\u4eba\u4f53\u5065\u5eb7\u3002\u9020\u6210\u96fe\u973e\u5929\u6c14\u7684\u4eba\u4e3a\u539f\u56e0\u6709____\r\n\u2460\u5de5\u4e1a\u751f\u4ea7\u4e2d\u4f7f\u7528\u77ff\u7269\u4f5c\u4e3a\u71c3\u6599\uff0c\u5927\u91cf\u6392\u653e\u6c61\u67d3\u7269     \u2461\u6c7d\u8f66\u5c3e\u6c14\u7684\u5927\u91cf\u6392\u653e     \r\n\u2462\u98ce\u529b\u5c0f\uff0c\u7a7a\u6c14\u6d41\u52a8\u4e0d\u7545     \u2463\u51ac\u5b63\u53d6\u6696\u6392\u653e\u7c89\u5c18\nA. \u2460\u2461\u2462\nB. \u2461\u2462\u2463\nC. \u2460\u2462\u2463\nD. \u2460\u2461\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5459081083891683, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2986334267609957, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bf9\u5370\u5ea6\u7684\u519c\u4e1a\u751f\u4ea7\u6709\u91cd\u8981\u610f\u4e49\u7684\u662f____\nA. \u897f\u5317\u5b63\u98ce\nB. \u4e1c\u5317\u5b63\u98ce\nC. \u4e1c\u5357\u5b63\u98ce\nD. \u897f\u5357\u5b63\u98ce\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4818704153867504, "meta-math/MetaMath-Mistral-7B": 0.8220799202941096, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9985890521024247, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7944062140556792, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ece\u6709\u5229\u4e8e\u4eba\u7c7b\u751f\u5b58\u7684\u89d2\u5ea6\u770b\uff0c\u4f60\u5e94\u8be5\u628a\u201c\u5bb6\u201d\u9009\u5728____\nA. \u5357\u6781\u5730\u533a\nB. \u6492\u54c8\u62c9\u6c99\u6f20\nC. \u559c\u9a6c\u62c9\u96c5\u5c71\nD. \u957f\u6c5f\u4e2d\u4e0b\u6e38\u5e73\u539f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.911035605661235, "meta-math/MetaMath-Mistral-7B": 0.9964513311286033, "itpossible/Chinese-Mistral-7B-v0.1": 0.9653216388729815, "HuggingFaceH4/zephyr-7b-beta": 0.9991475673854071, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9919809730251591, "meta-llama/Meta-Llama-3-8B": 0.9778169808914735, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9979949967480611}}, {"question": "\u6211\u56fd\u6c34\u8d44\u6e90\u7684\u65f6\u95f4\u5206\u5e03\u89c4\u5f8b\u662f____\nA. \u4e1c\u5357\u591a\uff0c\u897f\u5317\u5c11\nB. \u4e1c\u5357\u5c11\uff0c\u897f\u5317\u591a\nC. \u590f\u79cb\u591a\uff0c\u51ac\u6625\u5c11\nD. \u590f\u79cb\u5c11\uff0c\u51ac\u6625\u591a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3306562312783846, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.539027809803825}}, {"question": "1944\u5e744\u6708\u81f31945\u5e741\u6708\uff0c\u65e5\u672c\u53d1\u52a8\u6253\u901a\u4e2d\u56fd\u5927\u9646\u4ea4\u901a\u7ebf\u7684\u6218\u5f79\u662f____\nA. \u5ffb\u53e3\u6218\u5f79\nB. \u6dde\u6caa\u6218\u5f79\nC. \u8c6b\u6e58\u6842\u6218\u5f79\nD. \u67a3\u5b9c\u4f1a\u6218\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4847303831708126, "HuggingFaceH4/zephyr-7b-beta": 0.5370304363330354, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5228250354195327, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7371827059163534}}, {"question": "\u5927\u9769\u547d\u65f6\u671f\u7684\u7edf\u4e00\u6218\u7ebf\u548c\u6297\u65e5\u6c11\u65cf\u7edf\u4e00\u6218\u7ebf____\nA. \u90fd\u6709\u5171\u540c\u7684\u653f\u6cbb\u7eb2\u9886\nB. \u5747\u91c7\u53d6\u515a\u5185\u5408\u4f5c\u65b9\u5f0f\nC. \u5168\u5177\u6709\u53cd\u5e1d\u53cd\u5c01\u5efa\u6027\u8d28\nD. \u7686\u6709\u5404\u9636\u5c42\u5e7f\u6cdb\u53c2\u52a0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3436615088034303, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4479780449407606, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4e0d\u5e73\u7b49\u6761\u7ea6\u4e2d\uff0c\u8d54\u6b3e\u6570\u989d\u6700\u591a\u7684\u662f____\nA. \u300a\u5357\u4eac\u6761\u7ea6\u300b\nB. \u300a\u5317\u4eac\u6761\u7ea6\u300b\nC. \u300a\u9a6c\u5173\u6761\u7ea6\u300b\nD. \u300a\u8f9b\u4e11\u6761\u7ea6\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5115723993207937, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3460058095032025, "meta-llama/Meta-Llama-3-8B": 0.587987535128345, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7637258436313051}}, {"question": "\u4e2d\u56fd\u5171\u4ea7\u515a\u53d1\u51fa\u201c\u505c\u6b62\u5185\u6218\uff0c\u4e00\u81f4\u6297\u65e5\u201d\u7684\u53f7\u53ec\u662f\u5728____\nA. \u848b\u4ecb\u77f3\u5bf9\u4e2d\u592e\u82cf\u533a\u7b2c\u56db\u6b21\u201c\u56f4\u527f\u201d\u65f6\nB. \u201c\u4f55\u6885\u534f\u5b9a\u201d\u7b7e\u8ba2\u540e\nC. \u74e6\u7a91\u5821\u4f1a\u8bae\u671f\u95f4\nD. \u897f\u5b89\u4e8b\u53d8\u53d1\u751f\u540e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2986334267609957, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "1949\u5e749\u670821\u65e5\uff0c\u4e2d\u56fd\u4eba\u6c11\u653f\u6cbb\u534f\u5546\u4f1a\u8bae\u7b2c\u4e00\u5c4a\u5168\u4f53\u4f1a\u8bae\u901a\u8fc7\u4e86\u5177\u6709\u4e34\u65f6\u5baa\u6cd5\u4f5c\u7528\u7684\u662f____\nA. \u300a\u4e2d\u534e\u6c11\u56fd\u4e34\u65f6\u7ea6\u6cd5\u300b\nB. \u300a\u548c\u5e73\u5baa\u6cd5\u300b\nC. \u300a\u4e2d\u56fd\u4eba\u6c11\u653f\u6cbb\u534f\u5546\u4f1a\u8bae\u5171\u540c\u7eb2\u9886\u300b\nD. \u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5baa\u6cd5\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5337023114761172, "meta-math/MetaMath-Mistral-7B": 0.5908620161457196, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9552520755107148, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7283124637403325, "meta-llama/Meta-Llama-3-8B": 0.9603013604236664, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9681190895485966}}, {"question": "1946\u5e741\u670810\u65e5\uff0c\u653f\u6cbb\u534f\u5546\u4f1a\u8bae\u5728\u91cd\u5e86\u5f00\u5e55\uff0c\u5171\u4ea7\u515a\u4e0e\u6c11\u4e3b\u515a\u6d3e\u548c\u65e0\u515a\u6d3e\u4eba\u58eb\u7684\u4ee3\u8868\u5bc6\u5207\u5408\u4f5c\uff0c\u63a8\u52a8\u653f\u534f\u4f1a\u8bae\u8fbe\u6210\u4e86\u653f\u5e9c\u7ec4\u7ec7\u3001\u56fd\u6c11\u5927\u4f1a\u3001\u548c\u5e73\u5efa\u56fd\u7eb2\u9886\u3001\u5baa\u6cd5\u8349\u6848\u3001\u519b\u4e8b\u95ee\u9898\u7b49\u4e94\u9879\u51b3\u8bae\u3002\u8fd9\u4e9b\u51b3\u8bae\u53ca\u5176\u4ed6\u534f\u8bae____\nA. \u662f\u848b\u4ecb\u77f3\u53d1\u52a8\u5185\u6218\u7684\u4f9d\u636e\nB. \u662f\u793e\u4f1a\u4e3b\u4e49\u6027\u8d28\u7684\u51b3\u8bae\nC. \u6709\u5229\u4e8e\u51b2\u7834\u848b\u4ecb\u77f3\u7684\u72ec\u88c1\u7edf\u6cbb\u548c\u5b9e\u884c\u6c11\u4e3b\u653f\u6cbb\uff0c\u6709\u5229\u4e8e\u548c\u5e73\u5efa\u56fd\nD. \u662f\u65b0\u6c11\u4e3b\u4e3b\u4e49\u6027\u8d28\u7684\u51b3\u8bae\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8790246914554539, "meta-math/MetaMath-Mistral-7B": 0.9787633996157045, "itpossible/Chinese-Mistral-7B-v0.1": 0.8302913599269911, "HuggingFaceH4/zephyr-7b-beta": 0.9579774749645332, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9361297887141254, "meta-llama/Meta-Llama-3-8B": 0.6175625750668279, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9817419105218986}}, {"question": "\u4e2d\u56fd\u5171\u4ea7\u515a\u5728\u5b9e\u8df5\u4e2d\u63a2\u7d22\u4e2d\u56fd\u5efa\u8bbe\u793e\u4f1a\u4e3b\u4e49\u9053\u8def\u5f00\u59cb\u7684\u6807\u5fd7\u662f____\nA. \u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u7684\u5efa\u7acb\nB. \u8fc7\u6e21\u65f6\u671f\u603b\u8def\u7ebf\u7684\u63d0\u51fa\nC. \u300a\u8bba\u5341\u5927\u5173\u7cfb\u300b\u7684\u53d1\u8868\nD. \u4e2d\u5171\u516b\u5927\u7684\u53ec\u5f00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.57360729396177, "meta-math/MetaMath-Mistral-7B": 0.8504782716928969, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9402323224197636, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.830407219777826, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9161993091340469}}, {"question": "\u620a\u620c\u53d8\u6cd5\u7684\u9636\u7ea7\u57fa\u7840\u662f____\nA. \u519c\u6c11\u9636\u7ea7\nB. \u5f00\u660e\u5730\u4e3b\nC. \u7231\u56fd\u77e5\u8bc6\u5206\u5b50\nD. \u6c11\u65cf\u8d44\u4ea7\u9636\u7ea7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.36617639865290497, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.48005121704740095, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6d0b\u52a1\u8fd0\u52a8\u53d9\u8ff0\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u6d0b\u52a1\u8fd0\u52a8\u662f\u5c01\u5efa\u7edf\u6cbb\u9636\u7ea7\u4e3a\u4e86\u7ef4\u62a4\u81ea\u5df1\u7684\u7edf\u6cbb\u800c\u8fdb\u884c\u7684\u4e00\u573a\u81ea\u6551\u8fd0\u52a8\nB. \u5ba2\u89c2\u4e0a\u4fc3\u8fdb\u4e86\u8d44\u672c\u4e3b\u4e49\u7684\u53d1\u5c55\nC. \u53e3\u53f7\u662f\u201c\u81ea\u5f3a\u201d\u548c \u201c\u6c42\u5bcc\u201d\nD. \u89e6\u53ca\u5230\u4e86\u5c01\u5efa\u7edf\u6cbb\u7684\u6839\u57fa\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5165796946301179, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u7684\u6539\u9769\u4ece\u7ecf\u6d4e\u4f53\u5236\u6539\u9769\u7740\u624b\uff0c\u7ecf\u6d4e\u4f53\u5236\u7684\u6539\u9769\u9996\u5148\u5728____\nA. \u601d\u60f3\u89e3\u653e\u4e0a\u53d6\u5f97\u7a81\u7834\nB. \u5bf9\u5916\u5f00\u653e\u4e0a\u53d6\u5f97\u8fdb\u5c55\nC. \u57ce\u5e02\u7ecf\u6d4e\u4f53\u5236\u6539\u9769\u53d6\u5f97\u7a81\u7834\u6027\u8fdb\u5c55\nD. \u519c\u6751\u53d6\u5f97\u7a81\u7834\u6027\u8fdb\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.53210932360063, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9958805074817737, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5888722194809868, "meta-llama/Meta-Llama-3-8B": 0.6694011686587215, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u515a\u7684\u8fc7\u6e21\u65f6\u671f\u603b\u8def\u7ebf\u7684\u201c\u4e00\u4f53\u201d\u6307\u7684\u662f____\nA. \u56fd\u5bb6\u5de5\u4e1a\u5316\nB. \u5bf9\u519c\u4e1a\u7684\u793e\u4f1a\u4e3b\u4e49\u6539\u9020\nC. \u5bf9\u624b\u5de5\u4e1a\u7684\u793e\u4f1a\u4e3b\u4e49\u6539\u9020\nD. \u5bf9\u8d44\u672c\u4e3b\u4e49\u5de5\u5546\u4e1a\u7684\u793e\u4f1a\u4e3b\u4e49\u6539\u9020\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4187298044108945, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.718154904168315, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "1947\u5e74\u5218\u9093\u5927\u519b\u633a\u8fdb\u4e2d\u539f\u7684\u91cd\u5927\u610f\u4e49\u5728\u4e8e____\nA. \u5f71\u54cd\u6218\u7565\u51b3\u6218\u4e3b\u653b\u65b9\u5411\nB. \u7c89\u788e\u848b\u4ecb\u77f3\u7684\u91cd\u70b9\u8fdb\u653b\nC. \u6539\u53d8\u654c\u6211\u53cc\u65b9\u7684\u529b\u91cf\u5bf9\u6bd4\nD. \u6539\u53d8\u89e3\u653e\u6218\u4e89\u7684\u6218\u7565\u6001\u52bf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.638995317387452, "meta-math/MetaMath-Mistral-7B": 0.8962680482447752, "itpossible/Chinese-Mistral-7B-v0.1": 0.7228586603073918, "HuggingFaceH4/zephyr-7b-beta": 0.987258747668444, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7386320644954362, "meta-llama/Meta-Llama-3-8B": 0.6137569264764302, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5317\u4f10\u6218\u4e89\u5bf9\u51c6\u7684\u519b\u9600\u662f____\u2460\u5434\u4f69\u5b5a\u2461\u5b59\u4f20\u82b3\u2462\u5f20\u4f5c\u9716\u2463\u6bb5\u797a\u745e\nA. \u2460\u2461\u2462\nB. \u2461\u2462\u2463\nC. \u2460\u2462\u2463\nD. \u2460\u2461\u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2575662067712908, "meta-math/MetaMath-Mistral-7B": 0.31283638571410965, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41967679996925283, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u5bf9\u519c\u4e1a\u793e\u4f1a\u4e3b\u4e49\u6539\u9020\u91c7\u53d6\u7684\u65b9\u9488\u662f____\nA. \u5178\u578b\u793a\u8303\nB. \u81ea\u613f\u4e92\u5229\nC. \u56fd\u5bb6\u5e2e\u52a9\nD. \u79ef\u6781\u53d1\u5c55\u3001\u7a33\u6b65\u524d\u8fdb\u3001\u9010\u6b65\u8fc7\u6e21\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7808793449040011, "meta-math/MetaMath-Mistral-7B": 0.93997581187641, "itpossible/Chinese-Mistral-7B-v0.1": 0.8674518924972978, "HuggingFaceH4/zephyr-7b-beta": 0.9939958971333718, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8192785148030641, "meta-llama/Meta-Llama-3-8B": 0.8875886020396652, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9931209115498013}}, {"question": "\u300a\u53cc\u5341\u534f\u5b9a\u300b\u7684\u7b7e\u8ba2\uff0c\u4e2d\u5171\u53d6\u5f97\u7684\u6218\u7565\u4f18\u52bf\u662f____\nA. \u83b7\u5f97\u4e86\u81ea\u536b\u6218\u4e89\u7684\u51c6\u5907\u65f6\u95f4\nB. \u89e3\u653e\u533a\u83b7\u5f97\u4e86\u5408\u6cd5\u5730\u4f4d\nC. \u8d62\u5f97\u4e86\u6c11\u4e3b\u515a\u6d3e\u7684\u652f\u6301\nD. \u53d6\u5f97\u4e86\u653f\u6cbb\u4e0a\u7684\u4e3b\u52a8\u5730\u4f4d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40397669763096755, "meta-math/MetaMath-Mistral-7B": 0.6233865351903621, "itpossible/Chinese-Mistral-7B-v0.1": 0.5007587468402017, "HuggingFaceH4/zephyr-7b-beta": 0.675668097526284, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6773230468573681, "meta-llama/Meta-Llama-3-8B": 0.7419593624866244, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9036415081779731}}, {"question": "\u4e03\u5c4a\u4e8c\u4e2d\u5168\u4f1a\u53ec\u5f00\u7684\u5730\u70b9\u662f____\nA. \u5317\u5e73\nB. \u5ef6\u5b89\nC. \u897f\u67cf\u5761\nD. \u4e0a\u6d77\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5377748110289073, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3690058809048273, "meta-llama/Meta-Llama-3-8B": 0.5303556198049114, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7465229556560555}}, {"question": "\u7387\u9886\u5317\u5e73\u56fd\u6c11\u515a\u519b\u961f\u63a5\u53d7\u548c\u5e73\u6539\u7f16\u7684\u56fd\u6c11\u515a\u5c06\u9886\u662f____\nA. \u5f20\u6cbb\u4e2d\nB. \u8521\u5ef7\u9534\nC. \u675c\u807f\u660e\nD. \u5085\u4f5c\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.39845851868824184, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9696196489739084, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3402786740873538}}, {"question": "\u5b59\u4e2d\u5c71\u4e09\u6c11\u4e3b\u4e49\u601d\u60f3\u7684\u6838\u5fc3\u662f____\nA. \u9a71\u9664\u9791\u864f\nB. \u6062\u590d\u4e2d\u534e\nC. \u521b\u7acb\u6c11\u56fd\nD. \u5e73\u5747\u5730\u6743\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3696691653657074, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4045257140067991, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6297\u6218\u8fdb\u5165\u76f8\u6301\u9636\u6bb5\u540e\uff0c\u4e2d\u56fd\u4eba\u6c11\u5728\u534e\u5317\u7ed9\u65e5\u672c\u4fb5\u7565\u8005\u6c89\u91cd\u6253\u51fb\u7684\u4e00\u6b21\u519b\u4e8b\u884c\u52a8\u662f____\nA. \u767e\u56e2\u5927\u6218\nB. \u5e73\u578b\u5173\u6218\u5f79\nC. \u51c7\u6caa\u4f1a\u6218\nD. \u53f0\u513f\u5e84\u6218\u5f79\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3947268106050802, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3697864963766552, "HuggingFaceH4/zephyr-7b-beta": 0.9025085478869157, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6517105258405284, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u56fd\u5404\u6c11\u4e3b\u515a\u6d3e\u662f\u9636\u7ea7\u8054\u76df\u6027\u8d28\u7684\u653f\u515a\uff0c\u5176\u5f62\u6210\u65f6\u7684\u793e\u4f1a\u57fa\u7840\u4e3b\u8981\u662f____\nA. \u5f00\u660e\u7ec5\u58eb\u3001\u5730\u4ea7\u5b9e\u529b\u6d3e\nB. \u5de5\u4eba\u3001\u519c\u6c11\u3001\u5c0f\u8d44\u4ea7\u9636\u7ea7\nC. \u5de5\u4eba\u3001\u519c\u6c11\u3001\u5c0f\u8d44\u4ea7\u9636\u7ea7\u3001\u6c11\u65cf\u8d44\u4ea7\u9636\u7ea7\nD. \u6c11\u65cf\u8d44\u4ea7\u9636\u7ea7\u3001\u57ce\u5e02\u5c0f\u8d44\u4ea7\u9636\u7ea7\u4ee5\u53ca\u540c\u8fd9\u4e9b\u9636\u7ea7\u76f8\u8054\u7cfb\u7684\u77e5\u8bc6\u5206\u5b50\u548c\u5176\u4ed6\u7231\u56fd\u5206\u5b50\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6120846051710839, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7811189252211346, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4853526404042873}}, {"question": "\u7531\u4e8e\u5e1d\u56fd\u4e3b\u4e49\u3001\u5c01\u5efa\u4e3b\u4e49\u3001\u5b98\u50da\u8d44\u672c\u4e3b\u4e49\u7684\u6b8b\u9177\u538b\u8feb\uff0c\u4e2d\u56fd\u4eba\u6c11\u8d70\u4e0a\u4e86\u53cd\u5e1d\u53cd\u5c01\u5efa\u53cd\u5b98\u50da\u8d44\u672c\u4e3b\u4e49\u6597\u4e89\u7684\u4f1f\u5927\u65f6\u4ee3\u3002\u6c11\u4e3b\u9769\u547d\u7684\u4e3b\u8981\u529b\u91cf\u662f____\nA. \u5de5\u4eba\nB. \u6c11\u65cf\u8d44\u4ea7\u9636\u7ea7\nC. \u5de5\u4eba\u3001\u519c\u6c11\nD. \u5de5\u4eba\u3001\u519c\u6c11\u3001\u57ce\u5e02\u5c0f\u8d44\u4ea7\u9636\u7ea7\u7fa4\u4f17\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7432813307997745, "meta-math/MetaMath-Mistral-7B": 0.9374482445123773, "itpossible/Chinese-Mistral-7B-v0.1": 0.7237486533994145, "HuggingFaceH4/zephyr-7b-beta": 0.9849463427630963, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.765277662899668, "meta-llama/Meta-Llama-3-8B": 0.7118464762562882, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9739232230009883}}, {"question": "\u9769\u547d\u7edf\u4e00\u6218\u7ebf\u6b63\u5f0f\u5efa\u7acb\u7684\u6807\u5fd7\u662f____\nA. \u56fd\u6c11\u515a\u201c\u4e00\u5927\u201d\u7684\u53ec\u5f00\nB. \u56fd\u6c11\u515a\u6539\u7ec4\nC. \u4e09\u6c11\u4e3b\u4e49\u53d1\u5c55\u4e3a\u65b0\u4e09\u6c11\u4e3b\u4e49\nD. \u4e2d\u5171\u201c\u4e09\u5927\u201d\u7684\u53ec\u5f00\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6297\u65e5\u6218\u4e89\u80dc\u5229\u540e\uff0c\u67d0\u4e9b\u6c11\u4e3b\u515a\u6d3e\u7684\u9886\u5bfc\u4eba\u7269\u66fe\u7ecf\u9f13\u5439\u201c\u4e2d\u95f4\u8def\u7ebf\u201d\uff0c\u5373\u5728\u5171\u4ea7\u515a\u548c\u56fd\u6c11\u515a\u7684\u5efa\u56fd\u65b9\u6848\u4e2d\u95f4\uff0c\u5bfb\u627e\u51fa\u7b2c\u4e09\u6761\u9053\u8def\uff0c\u4f46\u6700\u7ec8\u5e7b\u706d\u4e86\u3002\u5176\u5e7b\u706d\u7684\u6839\u672c\u539f\u56e0\u5728\u4e8e____\nA. \u6ca1\u6709\u6b66\u88c5\u529b\u91cf\u3001\u6ca1\u6709\u7edf\u4e00\u7684\u653f\u7eb2\nB. \u56fd\u6c11\u515a\u5f53\u5c40\u5bf9\u6c11\u4e3b\u515a\u6d3e\u7684\u8feb\u5bb3\nC. \u8d44\u4ea7\u9636\u7ea7\u5171\u548c\u56fd\u65b9\u6848\u5728\u4e2d\u56fd\u884c\u4e0d\u901a\nD. \u6c11\u4e3b\u515a\u6d3e\u4e0d\u662f\u5355\u4e00\u9636\u7ea7\u7684\u653f\u515a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40979328935674253, "meta-math/MetaMath-Mistral-7B": 0.5829451401335002, "itpossible/Chinese-Mistral-7B-v0.1": 0.47677289979427817, "HuggingFaceH4/zephyr-7b-beta": 0.9513625664920541, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7295141758366909, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u822c\u6765\u8bf4\uff0c\u4e00\u4e2a\u4eba\u5bf9\u793e\u4f1a\u7684\u8d21\u732e\u8d8a\u5927\uff0c\u4ed6\u7684____\nA. \u793e\u4f1a\u5730\u4f4d\u5c31\u8d8a\u9ad8\nB. \u4e2a\u4eba\u4ef7\u503c\u5c31\u8d8a\u9ad8\nC. \u793e\u4f1a\u4ef7\u503c\u5c31\u8d8a\u9ad8\nD. \u81ea\u6211\u5b8c\u5584\u5c31\u8d8a\u9ad8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8093516906731287, "meta-math/MetaMath-Mistral-7B": 0.9061314780276412, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9483809816761634, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7519995451439443, "meta-llama/Meta-Llama-3-8B": 0.7347097623408834, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9505838813235682}}, {"question": "\u6211\u56fd\u68ee\u6797\u6cd5\u628a\u6bcf\u5e74____\u5b9a\u4e3a\u5168\u56fd\u7edf\u4e00\u7684\u201c\u690d\u6811\u8282\u201d\nA. 44990\nB. 44996\nC. 44997\nD. 45000\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3433107835296353, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.31911523504877376, "meta-llama/Meta-Llama-3-8B": 0.402526544736361, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4179949500520407}}, {"question": "\u7231\u56fd\u4e3b\u4e49\u5305\u542b\u7740\u60c5\u611f\u3001\u601d\u60f3\u3001\u884c\u4e3a\u4e09\u4e2a\u65b9\u9762\uff0c\u5176\u4e2d____\u662f\u7075\u9b42\nA. \u60c5\u611f\nB. \u601d\u60f3\nC. \u884c\u4e3a\nD. \u610f\u5fd7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7185994559442868, "meta-math/MetaMath-Mistral-7B": 0.9241169959054379, "itpossible/Chinese-Mistral-7B-v0.1": 0.898260654452293, "HuggingFaceH4/zephyr-7b-beta": 0.9890885930804104, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7132038025410424, "meta-llama/Meta-Llama-3-8B": 0.6307955432474669, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4740221660126821}}, {"question": "\u5b9e\u73b0\u4eba\u751f\u4ef7\u503c\u7684\u6839\u672c\u9014\u5f84\u662f____\nA. \u57f9\u517b\u6b63\u786e\u7684\u4eba\u751f\u6001\u5ea6\nB. \u81ea\u89c9\u63d0\u9ad8\u81ea\u6211\u7684\u4e3b\u4f53\u7d20\u8d28\u548c\u80fd\u529b\nC. \u8fdb\u884c\u6709\u610f\u8bc6\u3001\u6709\u76ee\u7684\u7684\u521b\u9020\u6027\u5b9e\u8df5\u6d3b\u52a8\nD. \u9009\u62e9\u4e0e\u793e\u4f1a\u4e3b\u5bfc\u4ef7\u503c\u89c2\u76f8\u4e00\u81f4\u7684\u4eba\u751f\u4ef7\u503c\u76ee\u6807\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4622654789417389, "meta-math/MetaMath-Mistral-7B": 0.7936986702394994, "itpossible/Chinese-Mistral-7B-v0.1": 0.9111050638002035, "HuggingFaceH4/zephyr-7b-beta": 0.6649269079147875, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.33482349867891054, "meta-llama/Meta-Llama-3-8B": 0.7108923421442717, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4eba\u751f\u4e0d\u4ec5\u4ec5\u662f\u4e00\u4e2a\u81ea\u7136\u8fc7\u7a0b\uff0c\u8fd8\u5305\u542b\u7740\u6781\u4e3a\u4e30\u5bcc\u7684____\nA. \u793e\u4f1a\u5b58\u5728\nB. \u793e\u4f1a\u5185\u5bb9\nC. \u793e\u4f1a\u8fc7\u7a0b\nD. \u793e\u4f1a\u5173\u7cfb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30742370490377713, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.46320867084863077}}, {"question": "\u4eba\u624d\u7d20\u8d28\u7684\u7075\u9b42\u662f____\nA. \u5fb7\nB. \u667a\nC. \u4f53\nD. \u7f8e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8549280139898279, "meta-math/MetaMath-Mistral-7B": 0.9361553359241562, "itpossible/Chinese-Mistral-7B-v0.1": 0.920549110265908, "HuggingFaceH4/zephyr-7b-beta": 0.9320171794796585, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8370777462046379, "meta-llama/Meta-Llama-3-8B": 0.9358894116138503, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8100451962263844}}, {"question": "\u4eba\u751f\u89c2\u7684\u6838\u5fc3____\nA. \u4eba\u751f\u4ef7\u503c\nB. \u4eba\u751f\u76ee\u7684\nC. \u4eba\u751f\u6001\u5ea6\nD. \u4eba\u751f\u4fe1\u4ef0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40202898548376254, "meta-math/MetaMath-Mistral-7B": 0.7759396200354118, "itpossible/Chinese-Mistral-7B-v0.1": 0.5586499695882373, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41829519824338984, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u793e\u4f1a\u4e3b\u4e49\u7ecf\u8fc7\u957f\u671f\u7684\u53d1\u5c55\uff0c\u5728\u9ad8\u5ea6\u53d1\u8fbe\u7684\u57fa\u7840\u4e0a\u6700\u7ec8\u4f1a\u8f6c\u53d8\u4e3a____\nA. \u8d44\u672c\u4e3b\u4e49\u793e\u4f1a\nB. \u5171\u4ea7\u4e3b\u4e49\u793e\u4f1a\nC. \u5e1d\u56fd\u4e3b\u4e49\nD. \u5784\u65ad\u4e3b\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8571089905402779, "meta-math/MetaMath-Mistral-7B": 0.9628912506591911, "itpossible/Chinese-Mistral-7B-v0.1": 0.9521452004996598, "HuggingFaceH4/zephyr-7b-beta": 0.9411600965811315, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8862550483646473, "meta-llama/Meta-Llama-3-8B": 0.8826908747886949, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9737249611933452}}, {"question": "\u79d1\u5b66\u53d1\u5c55\u89c2\u7684\u672c\u8d28\u548c\u6838\u5fc3\u662f____\nA. \u5168\u9762\u53d1\u5c55\nB. \u534f\u8c03\u53d1\u5c55\nC. \u7edf\u7b79\u53d1\u5c55\nD. \u4ee5\u4eba\u4e3a\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6654164251329266, "meta-math/MetaMath-Mistral-7B": 0.7517488964151272, "itpossible/Chinese-Mistral-7B-v0.1": 0.7138333903380782, "HuggingFaceH4/zephyr-7b-beta": 0.8932637100981163, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.587266640693722, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u73b0\u4ee3\u4eba\u624d\u7efc\u5408\u7d20\u8d28\u7684\u7075\u9b42\u662f____\nA. \u4eba\u624d\u7684\u601d\u60f3\u9053\u5fb7\u7d20\u8d28\nB. \u4eba\u624d\u7684\u6587\u5316\u7d20\u8d28\nC. \u4eba\u624d\u7684\u5fc3\u7406\u7d20\u8d28\nD. \u4eba\u624d\u7684\u8eab\u4f53\u7d20\u8d28\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9335883048404828, "meta-math/MetaMath-Mistral-7B": 0.9896721046749586, "itpossible/Chinese-Mistral-7B-v0.1": 0.9649773680497951, "HuggingFaceH4/zephyr-7b-beta": 0.8627730985843988, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9243160847588257, "meta-llama/Meta-Llama-3-8B": 0.9499622345840288, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9716757162591131}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u4eba\u7684\u793e\u4f1a\u5173\u7cfb\u4e0e\u81ea\u7136\u5173\u7cfb\u7684\u8868\u8ff0\u9519\u8bef\u7684\u662f____\nA. \u4eba\u5728\u4e0e\u81ea\u7136\u53d1\u751f\u5173\u7cfb\u7684\u8fc7\u7a0b\u4e2d\u7ed3\u6210\u4e86\u793e\u4f1a\u5173\u7cfb\nB. \u4eba\u4e0e\u4eba\u7684\u793e\u4f1a\u5173\u7cfb\u6781\u5927\u5730\u5f71\u54cd\u7740\u4eba\u4e0e\u81ea\u7136\u7684\u5173\u7cfb\nC. \u81ea\u7136\u5173\u7cfb\u662f\u793e\u4f1a\u5173\u7cfb\u7684\u57fa\u7840\uff0c\u793e\u4f1a\u5173\u7cfb\u662f\u81ea\u7136\u5173\u7cfb\u7684\u5ef6\u4f38\nD. \u534f\u8c03\u597d\u4eba\u4e0e\u81ea\u7136\u7684\u5173\u7cfb\uff0c\u5c31\u9700\u8981\u534f\u8c03\u597d\u4eba\u4e0e\u4eba\u4e4b\u95f4\u7684\u793e\u4f1a\u5173\u7cfb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.308176776288574, "meta-llama/Meta-Llama-3-8B": 0.5673840870472119, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u793e\u4f1a\u4e3b\u4e49\u8363\u8a89\u89c2\u662f____\u7684\u91cd\u8981\u7ec4\u6210\u90e8\u5206\nA. \u79d1\u5b66\u53d1\u5c55\u89c2\nB. \u9a6c\u514b\u601d\u6ce8\u610f\u5386\u53f2\u89c2\nC. \u9a6c\u514b\u601d\u4e3b\u4e49\u4e16\u754c\u89c2\nD. \u793e\u4f1a\u4e3b\u4e49\u9053\u5fb7\u89c2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.47215760852448246, "itpossible/Chinese-Mistral-7B-v0.1": 0.7220298634921849, "HuggingFaceH4/zephyr-7b-beta": 0.48207415932235265, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.48866528990686947, "meta-llama/Meta-Llama-3-8B": 0.5327251153278126, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5482601385401136}}, {"question": "\u4eba\u751f\u7684\u81ea\u6211\u4ef7\u503c,\u662f\u6307____\nA. \u4eba\u5bf9\u81ea\u7136\u754c\u7684\u5229\u7528\u548c\u6539\u9020\nB. \u4eba\u5bf9\u793e\u4f1a\u548c\u4ed6\u4eba\u6240\u4f5c\u7684\u8d21\u732e\nC. \u4e2a\u4f53\u7684\u4eba\u751f\u6d3b\u52a8\u5bf9\u793e\u4f1a\u3001\u4ed6\u4eba\u6240\u5177\u6709\u4ef7\u503c\nD. \u4e2a\u4f53\u7684\u4eba\u751f\u6d3b\u52a8\u5bf9\u81ea\u5df1\u751f\u5b58\u548c\u53d1\u5c55\u6240\u5177\u6709\u7684\u4ef7\u503c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6124291495880739, "meta-math/MetaMath-Mistral-7B": 0.8915403247055668, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9565452195715972, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.878750662242115, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9015059957597714}}, {"question": "\u4eba\u751f\u76ee\u7684\u4e3b\u8981\u56de\u7b54____\nA. \u4eba\u4e3a\u4ec0\u4e48\u6d3b\u7740\nB. \u4e16\u754c\u672c\u6e90\u662f\u4ec0\u4e48\nC. \u4eba\u5e94\u600e\u6837\u5bf9\u5f85\u751f\u6d3b\nD. \u600e\u6837\u7684\u4eba\u751f\u624d\u6709\u610f\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3802392343806497, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9a6c\u514b\u601d\u4e3b\u4e49\u7406\u60f3\u4fe1\u5ff5\u7684\u57fa\u7840\u662f____\nA. \u4fe1\u4ef0\nB. \u79d1\u5b66\nC. \u575a\u5b9a\nD. \u9769\u547d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7278552352424574, "meta-math/MetaMath-Mistral-7B": 0.9608253009681473, "itpossible/Chinese-Mistral-7B-v0.1": 0.5987341535209013, "HuggingFaceH4/zephyr-7b-beta": 0.9691208869060168, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8889098274421336, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7406\u60f3\uff0c\u662f\u4eba\u4eec\u5728\u5b9e\u8df5\u4e2d\u5f62\u6210\u7684\uff0c\u5177\u6709____\u7684\u5bf9\u7f8e\u597d\u672a\u6765\u7684\u8ffd\u6c42\u548c\u5411\u5f80\uff0c\u662f\u4eba\u4eec\u7684\u653f\u6cbb\u7acb\u573a\u548c\u4e16\u754c\u89c2\u5728\u4eba\u751f\u594b\u6597\u76ee\u6807\u4e0a\u7684\u4f53\u73b0\u3002\nA. \u5b9e\u73b0\u5fc5\u7136\u6027\nB. \u4e0d\u53ef\u5b9e\u73b0\u6027\nC. \u8d85\u8d8a\u5ba2\u89c2\u6027\nD. \u5b9e\u73b0\u53ef\u80fd\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5392501244346278, "meta-math/MetaMath-Mistral-7B": 0.7321163402772144, "itpossible/Chinese-Mistral-7B-v0.1": 0.7287633197034649, "HuggingFaceH4/zephyr-7b-beta": 0.7479949972443939, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4644320585233337, "meta-llama/Meta-Llama-3-8B": 0.6621691371112924, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9478327117130937}}, {"question": "\u5728\u5f53\u4eca\u65f6\u4ee3\u4efb\u4f55\u4e00\u4e2a\u5177\u6709\u7231\u56fd\u60c5\u6000\u7684\u4eba\uff0c\u90fd\u5e94\u5927\u529b\u5f18\u626c\u4ee5____\u4e3a\u6838\u5fc3\u7684\u65f6\u4ee3\u7cbe\u795e\u3002\nA. \u89e3\u653e\u601d\u60f3\nB. \u6539\u9769\u521b\u65b0\nC. \u81ea\u5f3a\u4e0d\u606f\nD. \u51fa\u56fd\u6df1\u9020\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.668093535234846, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7085322572410471}}, {"question": "\u6211\u56fd\u793e\u4f1a\u4e3b\u4e49\u6cd5\u5f8b\u7684\u672c\u8d28\u7279\u5f81\u8868\u73b0\u4e3a____\u7684\u7edf\u4e00\u3002\nA. \u9636\u7ea7\u6027\u548c\u4eba\u6c11\u6027\nB. \u5f3a\u5236\u6027\u548c\u60e9\u7f5a\u6027\nC. \u6559\u80b2\u6027\u548c\u9636\u7ea7\u6027\nD. \u6559\u80b2\u6027\u548c\u5f3a\u5236\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4245814271659906, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.39825184798242386, "HuggingFaceH4/zephyr-7b-beta": 0.9775853882470048, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.701625669755037, "meta-llama/Meta-Llama-3-8B": 0.7890154838865427, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7707195371157511}}, {"question": "\u4e00\u4e2a\u4eba\u793e\u4f1a\u4ef7\u503c\u7684\u5b9e\u8d28\u662f____\nA. \u8d21\u732e\nB. \u6210\u529f\nC. \u52b3\u52a8\nD. \u521b\u9020\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4740698200688341, "meta-math/MetaMath-Mistral-7B": 0.686605356456866, "itpossible/Chinese-Mistral-7B-v0.1": 0.8235530424352051, "HuggingFaceH4/zephyr-7b-beta": 0.7966700444882634, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7071163176528791, "meta-llama/Meta-Llama-3-8B": 0.7296553978571815, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9336103068281922}}, {"question": "\u8bb8\u591a\u516c\u53f8\u76ee\u524d\u90fd\u4e3a\u96c7\u5458\u514d\u8d39\u63d0\u4f9b\u5065\u8eab\u3001\u7f13\u89e3\u538b\u529b\u6216\u6212\u70df\u7684\u670d\u52a1\u9879\u76ee\u3002\u8fd9\u4e9b\u9879\u76ee\u589e\u52a0\u4e86\u5458\u5de5\u7684\u751f\u4ea7\u529b\uff0c\u51cf\u5c11\u4e86\u7f3a\u52e4\u7387\uff0c\u5e76\u964d\u4f4e\u4e86\u5458\u5de5\u7684\u5065\u5eb7\u4fdd\u9669\u8d39\u3002\u56e0\u6b64\uff0c\u8fd9\u4e9b\u670d\u52a1\u9879\u76ee\u4e0d\u4f46\u6709\u76ca\u4e8e\u516c\u53f8\uff0c\u800c\u4e14\u6709\u5229\u4e8e\u5458\u5de5\u4e2a\u4eba\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f\uff0c\u6700\u80fd\u6784\u6210\u5bf9\u4e0a\u8ff0\u8bba\u8bc1\u7684\u652f\u6301?____\nA. \u5065\u8eab\u662f\u516c\u53f8\u4e3a\u5458\u5de5\u6240\u63d0\u4f9b\u7684\u6700\u5e38\u89c1\u7684\u670d\u52a1\u9879\u76ee\u3002\nB. \u6709\u7814\u7a76\u8868\u660e\uff0c\u5728\u6709\u538b\u529b\u7684\u7ba1\u7406\u73af\u5883\u4e2d\uff0c\u8bad\u7ec3\u5bf9\u8bb8\u591a\u4eba\u90fd\u662f\u65e0\u6548\u7684\u3002\nC. \u6709\u89c4\u5f8b\u7684\u953b\u70bc\u53ef\u4ee5\u51cf\u5c11\u5fc3\u810f\u75c5\u53d1\u75c5\u7387\u5e76\u4f7f\u4eba\u7684\u7cbe\u529b\u66f4\u52a0\u5145\u6c9b\u3002\nD. \u8fc7\u5feb\u5730\u53c2\u52a0\u5927\u8fd0\u52a8\u91cf\u7684\u5065\u8eab\u6d3b\u52a8\u6709\u65f6\u4f1a\u9020\u6210\u8fd0\u52a8\u4f24\u5bb3\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7229068320435992, "meta-math/MetaMath-Mistral-7B": 0.9043544245810144, "itpossible/Chinese-Mistral-7B-v0.1": 0.7721306561570299, "HuggingFaceH4/zephyr-7b-beta": 0.9951537786377758, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9592734345062781, "meta-llama/Meta-Llama-3-8B": 0.878465723241318, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9941151391803679}}, {"question": "\u67d0\u7ec4\u7ec7\u6539\u9009\u9886\u5bfc\u73ed\u5b50\u5b9e\u884c\u8fd9\u6837\u4e00\u6761\u89c4\u5219\uff1a\u5982\u679c\u5019\u9009\u4eba\u591a\u4e8e\u4e00\u4e2a\uff0c\u90a3\u4e48\u5019\u9009\u4eba\u5fc5\u987b\u540c\u610f\u88ab\u63d0\u540d\uff0c\u5e76\u4e14\u5728\u8868\u6001\u4e4b\u524d\uff0c\u5fc5\u987b\u88ab\u544a\u4e4b\u5176\u4ed6\u7684\u5019\u9009\u4eba\u662f\u8c01\u3002\u5982\u679c\u4e8b\u5b9e\u4e0a\u53ea\u6709\u5f53\u5019\u9009\u4eba\u540c\u610f\u88ab\u63d0\u540d\u540e\u624d\u80fd\u77e5\u9053\u5b9e\u9645\u7684\u5019\u9009\u4eba\u662f\u8c01\uff0c\u90a3\u4e48\u4ee5\u4e0b\u54ea\u9879\u662f\u5bf9\u4e0a\u8ff0\u89c4\u5219\u6700\u51c6\u786e\u7684\u8bc4\u4ef7?____\nA. \u5b9e\u884c\u8be5\u89c4\u5219\uff0c\u4f7f\u5f97\u88ab\u63d0\u540d\u7684\u5019\u9009\u4eba\u7684\u4eba\u6570\u6bd4\u4e0d\u5b9e\u884c\u8be5\u89c4\u5219\u8981\u591a\u3002\nB. \u5b9e\u884c\u8be5\u89c4\u5219\uff0c\u4f7f\u5f97\u88ab\u63d0\u540d\u7684\u5019\u9009\u4eba\u7684\u4eba\u6570\u6bd4\u4e0d\u5b9e\u884c\u8be5\u89c4\u5219\u8981\u5c11\u3002\nC. \u5b9e\u884c\u8be5\u89c4\u5219\uff0c\u6ca1\u6709\u5019\u9009\u4eba\u53ef\u80fd\u88ab\u63d0\u540d\u3002\nD. \u5b9e\u884c\u8be5\u89c4\u5219\uff0c\u88ab\u63d0\u540d\u7684\u5019\u9009\u4eba\u6700\u591a\u53ea\u53ef\u80fd\u662f\u4e00\u4e2a\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.37887215961900156, "HuggingFaceH4/zephyr-7b-beta": 0.6198795870370845, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.39525411812066613, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u793e\u4f1a\u6210\u5458\u7684\u5e78\u798f\u611f\u662f\u53ef\u4ee5\u8fd0\u7528\u73b0\u4ee3\u624b\u6bb5\u7cbe\u786e\u91cf\u5316\u7684\u3002\u8861\u91cf\u4e00\u9879\u793e\u4f1a\u6539\u9769\u63aa\u65bd\u662f\u5426\u6210\u529f\uff0c\u8981\u770b\u793e\u4f1a\u6210\u5458\u7684\u5e78\u798f\u611f\u603b\u91cf\u662f\u5426\u589e\u52a0\u3002S\u5e02\u6700\u8fd1\u63a8\u51fa\u7684\u798f\u5229\u6539\u9769\u660e\u663e\u589e\u52a0\u4e86\u516c\u52a1\u5458\u7684\u5e78\u798f\u611f\u603b\u91cf\uff0c\u56e0\u6b64\uff0c\u8fd9\u9879\u6539\u9769\u63aa\u65bd\u662f\u6210\u529f\u7684\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f\uff0c\u6700\u80fd\u524a\u5f31\u4e0a\u8ff0\u8bba\u8bc1?____\nA. \u4e0a\u8ff0\u6539\u9769\u63aa\u65bd\u5e76\u6ca1\u6709\u589e\u52a0s\u5e02\u6240\u6709\u516c\u52a1\u5458\u7684\u5e78\u798f\u611f\u3002\nB. S\u5e02\u516c\u52a1\u5458\u53ea\u5360\u5168\u5e02\u793e\u4f1a\u6210\u5458\u5f88\u5c0f\u7684\u6bd4\u4f8b\u3002\nC. \u4e0a\u8ff0\u6539\u9769\u63aa\u65bd\u5728\u589e\u52a0\u516c\u52a1\u5458\u5e78\u798f\u611f\u603b\u91cf\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u4e86S\u5e02\u6c11\u8425\u4f01\u4e1a\u4eba\u5458\u7684\u5e78\u798f\u611f\u603b\u91cf\u3002\nD. \u4e0a\u8ff0\u6539\u9769\u63aa\u65bd\u5728\u589e\u52a0\u516c\u52a1\u5458\u5e78\u798f\u611f\u603b\u91cf\u7684\u540c\u65f6\uff0c\u51cf\u5c11\u4e86S\u5e02\u5168\u4f53\u793e\u4f1a\u6210\u5458\u7684\u5e78\u798f\u611f\u603b\u91cf\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4184552292163296, "HuggingFaceH4/zephyr-7b-beta": 0.9661739203957328, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5407197643500086, "meta-llama/Meta-Llama-3-8B": 0.6986244087826965, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7224488588142322}}, {"question": "\u67d0\u5e022018\u5e74\u7684\u4eba\u53e3\u53d1\u5c55\u62a5\u544a\u663e\u793a\uff0c\u8be5\u5e02\u5e38\u4f4f\u4eba\u53e31170\u4e07\uff0c\u5176\u4e2d\u5e38\u4f4f\u5916\u6765\u4eba\u53e3440\u4e07\uff0c\u6237\u7c4d\u4eba\u53e3730\u4e07\u3002\u4ece\u533a\u7ea7\u4eba\u53e3\u5206\u5e03\u60c5\u51b5\u6765\u770b\uff0c\u8be5\u5e02G\u533a\u5e38\u4f4f\u4eba\u53e3240\u4e07\uff0c\u5c45\u5404\u533a\u4e4b\u9996\uff1bH\u533a\u5e38\u4f4f\u4eba\u53e3200\u4e07\uff0c\u4f4d\u5c45\u7b2c\u4e8c\uff1b\u540c\u65f6\uff0c\u8fd9\u4e24\u4e2a\u533a\u4e5f\u662f\u5438\u7eb3\u5916\u6765\u4eba\u53e3\u8f83\u591a\u7684\u533a\u57df\uff0c\u4e24\u4e2a\u533a\u5e38\u4f4f\u5916\u6765\u4eba\u53e3200\u4e07\uff0c\u5360\u5168\u5e02\u5e38\u4f4f\u5916\u6765\u4eba\u53e3\u768445\uff05\u4ee5\u4e0a\u3002\u6839\u636e\u4ee5\u4e0a\u9648\u8ff0\uff0c\u53ef\u4ee5\u5f97\u51fa\u4ee5\u4e0b\u54ea\u9879\uff1f____\nA. \u8be5\u5e02G\u533a\u7684\u6237\u7c4d\u4eba\u53e3\u6bd4H\u533a\u7684\u5e38\u4f4f\u5916\u6765\u4eba\u53e3\u591a\u3002\nB. \u8be5\u5e02H\u533a\u7684\u6237\u7c4d\u4eba\u53e3\u6bd4G\u533a\u7684\u5e38\u4f4f\u5916\u6765\u4eba\u53e3\u591a\u3002\nC. \u8be5\u5e02H\u533a\u7684\u6237\u7c4d\u4eba\u53e3\u6bd4H\u533a\u7684\u5e38\u4f4f\u5916\u6765\u4eba\u53e3\u591a\u3002\nD. \u8be5\u5e02G\u533a\u7684\u6237\u7c4d\u4eba\u53e3\u6bd4G\u533a\u7684\u5e38\u4f4f\u5916\u6765\u4eba\u53e3\u591a\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3527809287490976, "meta-llama/Meta-Llama-3-8B": 0.2810882504428991, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.39181904780548615}}, {"question": "\u9648\u5148\u751f\u5728\u9f13\u52b1\u4ed6\u7684\u5b69\u5b50\u65f6\u8bf4\u9053\uff1a\u201c\u4e0d\u8981\u5bb3\u6015\u6682\u65f6\u7684\u56f0\u96be\u548c\u632b\u6298\u3002\u4e0d\u7ecf\u5386\u98ce\u96e8\u600e\u4e48\u89c1\u5f69\u8679?\u201d\u4ed6\u5b69\u5b50\u4e0d\u670d\u6c14\u5730\u8bf4\uff1a\u201c\u60a8\u8bf4\u5f97\u4e0d\u5bf9\u3002\u6211\u7ecf\u5386\u4e86\u90a3\u4e48\u591a\u98ce\u96e8\uff0c\u600e\u4e48\u5c31\u6ca1\u89c1\u5230\u5f69\u8679\u5462?\u201d\u9648\u5148\u751f\u5b69\u5b50\u7684\u56de\u7b54\u6700\u9002\u5b9c\u7528\u6765\u53cd\u9a73\u4ee5\u4e0b\u54ea\u9879____\nA. \u5373\u4f7f\u7ecf\u5386\u4e86\u98ce\u96e8\uff0c\u4e5f\u53ef\u80fd\u89c1\u4e0d\u5230\u5f69\u8679\u3002\nB. \u53ea\u8981\u7ecf\u5386\u4e86\u98ce\u96e8\uff0c\u5c31\u53ef\u4ee5\u89c1\u5230\u5f69\u8679\u3002\nC. \u53ea\u6709\u7ecf\u5386\u98ce\u96e8\uff0c\u624d\u80fd\u89c1\u5230\u5f69\u8679\u3002\nD. \u5982\u679c\u60f3\u89c1\u5230\u5f69\u8679\uff0c\u5c31\u5fc5\u987b\u7ecf\u5386\u98ce\u96e8\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2689463386046895, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8981\u9009\u4fee\u6570\u7406\u903b\u8f91\u8bfe\uff0c\u5fc5\u987b\u5df2\u4fee\u666e\u901a\u903b\u8f91\u8bfe\uff0c\u5e76\u5bf9\u6570\u5b66\u611f\u5174\u8da3\u3002\u6709\u4e9b\u5b66\u751f\u867d\u7136\u5bf9\u6570\u5b66\u611f\u5174\u8da3\uff0c\u4f46\u5e76\u6ca1\u6709\u4fee\u8fc7\u666e\u901a\u903b\u8f91\u8bfe\uff0c\u56e0\u6b64\uff0c\u6709\u4e9b\u5bf9\u6570\u5b66\u611f\u5174\u8da3\u7684\u5b66\u751f\u4e0d\u80fd\u9009\u4fee\u6570\u7406\u903b\u8f91\u8bfe\u3002\u4ee5\u4e0b\u54ea\u9879\u4e2d\u7684\u903b\u8f91\u7ed3\u6784\u4e0e\u9898\u5e72\u6700\u4e3a\u7c7b\u4f3c?____\nA. \u636e\u5b66\u6821\u7684\u89c4\u5b9a\uff0c\u8981\u83b7\u5f97\u672c\u5e74\u5ea6\u7684\u7279\u8bbe\u5956\u5b66\u91d1\uff0c\u5fc5\u987b\u6765\u81ea\u8d2b\u56f0\u5730\u533a\uff0c\u5e76\u4e14\u6210\u7ee9\u4f18\u79c0\u3002\u6709\u4e9b\u672c\u5e74\u5ea6\u7279\u8bbe\u5956\u5b66\u91d1\u7684\u83b7\u5f97\u8005\u6210\u7ee9\u4f18\u79c0\uff0c\u4f46\u5e76\u975e\u6765\u81ea\u8d2b\u56f0\u5730\u533a\uff0c\u56e0\u6b64\uff0c\u5b66\u6821\u8bc4\u9009\u672c\u5e74\u5ea6\u5956\u5b66\u91d1\u7684\u89c4\u5b9a\u5e76\u6ca1\u6709\u5f97\u5230\u5f88\u597d\u7684\u6267\u884c\u3002\nB. \u4e00\u672c\u4e66\u8981\u7545\u9500\uff0c\u5fc5\u987b\u65e2\u6709\u53ef\u8bfb\u6027\uff0c\u53c8\u7ecf\u8fc7\u7cbe\u5fc3\u7684\u5305\u88c5\u3002\u6709\u4e9b\u7545\u9500\u4e66\u53ef\u8bfb\u6027\u4e0d\u5927\uff0c\u56e0\u6b64\uff0c\u6709\u4e9b\u7545\u9500\u4e66\u4e3b\u8981\u662f\u9760\u5305\u88c5\u3002\nC. \u4e3a\u521d\u5b66\u9a91\u58eb\u8bad\u7ec3\u7684\u9a6c\u5fc5\u987b\u5f3a\u5065\u800c\u4e14\u6e29\u987a\uff0c\u6709\u4e9b\u9a6c\u5f3a\u5065\u4f46\u5e76\u4e0d\u6e29\u987a\uff0c\u56e0\u6b64\uff0c\u6709\u4e9b\u5f3a\u5065\u7684\u9a6c\u5e76\u4e0d\u9002\u5408\u4e8e\u521d\u5b66\u9a91\u58eb\u8bad\u7ec3\u7684\u9a6c\u3002\nD. \u9ad8\u7ea7\u5199\u5b57\u697c\u8981\u503c\u5f97\u6295\u8d44\uff0c\u5fc5\u987b\u8bbe\u8ba1\u65b0\u9896\uff0c\u6216\u8005\u63d0\u4f9b\u5927\u91cf\u529e\u516c\u7528\u5730\u3002\u6709\u4e9b\u65b0\u5199\u5b57\u697c\u867d\u7136\u8bbe\u8ba1\u65b0\u9896\uff0c\u4f46\u4e0d\u80fd\u63d0\u4f9b\u5927\u91cf\u7684\u529e\u516c\u7528\u5730\uff0c\u56e0\u6b64\uff0c\u6709\u4e9b\u65b0\u5199\u5b57\u697c\u4e0d\u503c\u5f97\u6295\u8d44\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5935373389359672}}, {"question": "\u674e\u8001\u5e08\u8bf4\u201c\u5e76\u975e\u4e3d\u4e3d\u8003\u4e0a\u4e86\u6e05\u534e\u5927\u5b66\u5e76\u4e14\u660e\u660e\u6ca1\u6709\u8003\u4e0a\u5357\u4eac\u5927\u5b66\u3002\u201d\u5982\u679c\u674e\u8001\u5e08\u8bf4\u7684\u662f\u4e3a\u771f\uff0c\u5219\u4ee5\u4e0b\u54ea\u9879\u53ef\u80fd\u4e3a\u771f?____\u2160\uff0e\u4e3d\u4e3d\u8003\u4e0a\u4e86\u6e05\u534e\u5927\u5b66\uff0c\u660e\u660e\u8003\u4e0a\u4e86\u5357\u4eac\u5927\u5b66\u3002\u2161\uff0e\u4e3d\u4e3d\u6ca1\u8003\u4e0a\u6e05\u534e\u5927\u5b66\uff0c\u660e\u660e\u6ca1\u8003\u4e0a\u5357\u4eac\u5927\u5b66\u3002\u2162\uff0e\u4e3d\u4e3d\u6ca1\u8003\u4e0a\u6e05\u534e\u5927\u5b66\uff0c\u660e\u660e\u8003\u4e0a\u4e86\u5357\u4eac\u5927\u5b66\u3002\u2163\uff0e\u4e3d\u4e3d\u8003\u4e0a\u4e86\u6e05\u534e\u5927\u5b66\uff0c\u660e\u660e\u6ca1\u6709\u8003\u4e0a\u5357\u4eac\u5927\u5b66\u3002\nA. \u4ec5\u2160\u548c\u2161\u3002\nB. \u4ec5\u2161\u548c\u2162\u3002\nC. \u4ec5\u2161\u3001\u2162\u548c\u2163\u3002\nD. \u4ec5\u2160\u3001\u2161\u548c\u2162\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3559524557971754, "HuggingFaceH4/zephyr-7b-beta": 0.9680888920419961, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u8d85\u5e02\u8d2d\u7269\u540e\uff0c\u5f20\u6797\u628a\u4e03\u4ef6\u5546\u54c1\u653e\u5728\u8d85\u5e02\u7684\u4f20\u9001\u5e26\u4e0a\uff0c\u8089\u677e\u540e\u9762\u7d27\u8ddf\u7740\u86cb\u7cd5\uff0c\u9178\u5976\u540e\u9762\u63a5\u7740\u653e\u7684\u662f\u997c\u5e72\uff0c\u53ef\u53e3\u53ef\u4e50\u6c7d\u6c34\u7d27\u8ddf\u5728\u6c34\u679c\u6c41\u540e\u9762\uff0c\u65b9\u4fbf\u9762\u540e\u9762\u7d27\u8ddf\u7740\u9178\u5976\uff0c\u8089\u677e\u548c\u997c\u5e72\u4e4b\u95f4\u6709\u4e24\u4ef6\u5546\u54c1\uff0c\u65b9\u4fbf\u9762\u548c\u6c34\u679c\u6c41\u4e4b\u95f4\u6709\u4e24\u4ef6\u5546\u54c1\uff0c\u6700\u540e\u653e\u4e0a\u53bb\u7684\u662f\u4e00\u53ea\u86cb\u7cd5\u3002\u5982\u679c\u4e0a\u8ff0\u65ad\u5b9a\u4e3a\u771f\uff0c\u90a3\u4e48\u4ee5\u4e0b\u54ea\u9879\u4e00\u5b9a\u4e3a\u771f?____\u2160\uff0e\u6c34\u679c\u6c41\u5728\u5012\u6570\u7b2c\u4e09\u4f4d\u7f6e\u4e0a\u3002\u2161\uff0e\u9178\u5976\u653e\u5728\u7b2c\u4e8c\u3002\u2162\uff0e\u53ef\u53e3\u53ef\u4e50\u6c7d\u6c34\u653e\u5728\u4e2d\u95f4\u3002\nA. \u53ea\u6709\u2160\u3002\nB. \u53ea\u6709\u2161\u3002\nC. \u53ea\u6709\u2162\u3002\nD. \u53ea\u6709\u2160\u548c\u2161\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65b0\u7586\u7684\u54c8\u8428\u514b\u4eba\u7528\u7ecf\u8fc7\u8bad\u7ec3\u7684\u91d1\u96d5\u5728\u8349\u539f\u4e0a\u957f\u9014\u8ffd\u51fb\u91ce\u72fc\u3002\u67d0\u7814\u7a76\u5c0f\u7ec4\u4e3a\u7814\u7a76\u91d1\u96d5\u7684\u98de\u884c\u65b9\u5411\u548c\u5224\u65ad\u91ce\u72fc\u7fa4\u7684\u6d3b\u52a8\u8303\u56f4\uff0c\u5c06\u65e0\u7ebf\u7535\u4f20\u5bfc\u5668\u653e\u7f6e\u5728\u4e00\u53ea\u91d1\u96d5\u8eab\u4e0a\u8fdb\u884c\u8ffd\u8e2a\u3002\u91ce\u72fc\u4e3a\u4e86\u89c5\u98df\uff0c\u5176\u6d3b\u52a8\u8303\u56f4\u901a\u5e38\u5f88\u5e7f\u3002\u56e0\u6b64\uff0c\u91d1\u96d5\u8ffd\u51fb\u91ce\u72fc\u7684\u98de\u884c\u8303\u56f4\u901a\u5e38\u4e5f\u5f88\u5927\u3002\u7136\u800c\u4e24\u5468\u4ee5\u6765\uff0c\u65e0\u7ebf\u7535\u4f20\u5bfc\u5668\u4e0d\u65ad\u4f20\u56de\u7684\u4fe1\u53f7\u663e\u793a\uff0c\u91d1\u96d5\u4ec5\u5728\u653e\u98de\u57303\u516c\u91cc\u7684\u8303\u56f4\u5185\u98de\u884c\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f\uff0c\u6700\u6709\u52a9\u4e8e\u89e3\u91ca\u4e0a\u8ff0\u91d1\u96d5\u7684\u884c\u4e3a?____\nA. \u91d1\u96d5\u653e\u98de\u5730\u5468\u8fb9\u91cd\u5ce6\u53e0\u5d82\uff0c\u9669\u5cfb\u5f02\u5e38\u3002\nB. \u91d1\u96d5\u7684\u653e\u98de\u57302\u516c\u91cc\u8303\u56f4\u5185\u6709\u4e00\u7267\u7f8a\u8349\u573a\uff0c\u6210\u4e3a\u72fc\u7fa4\u88ad\u51fb\u7684\u76ee\u6807\u3002\nC. \u7531\u4e8e\u53d7\u8bad\u91d1\u96d5\u7684\u6355\u6740\uff0c\u653e\u98de\u5730\u5e7f\u9614\u8349\u539f\u7684\u91ce\u72fc\u51e0\u4e4e\u706d\u7edd\u4e86\u3002\nD. \u65e0\u7ebf\u7535\u4f20\u5bfc\u4fe1\u53f7\u4ec5\u80fd\u5728\u6709\u9650\u7684\u8303\u56f4\u5185\u4f20\u5bfc\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5600526580969469, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u77e5\u67d0\u73ed\u5171\u670925\u4f4d\u540c\u5b66\uff0c\u5973\u751f\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u77ee\u8005\u76f8\u5dee10\u5398\u7c73\uff1b\u7537\u751f\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u77ee\u8005\u5219\u76f8\u5dee15\u5398\u7c73\u3002\u5c0f\u660e\u8ba4\u4e3a\uff0c\u6839\u636e\u5df2\u77e5\u4fe1\u606f\uff0c\u53ea\u8981\u518d\u77e5\u9053\u7537\u751f\u3001\u5973\u751f\u6700\u9ad8\u8005\u7684\u5177\u4f53\u8eab\u9ad8\uff0c\u6216\u8005\u518d\u77e5\u9053\u7537\u751f\u3001\u5973\u751f\u7684\u5e73\u5747\u8eab\u9ad8\uff0c\u5747\u53ef\u786e\u5b9a\u5168\u73ed\u540c\u5b66\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u4f4e\u8005\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f\uff0c\u6700\u80fd\u6784\u6210\u5bf9\u5c0f\u660e\u89c2\u70b9\u7684\u53cd\u9a73\uff1f____\nA. \u6839\u636e\u5df2\u77e5\u4fe1\u606f\uff0c\u5982\u679c\u4e0d\u80fd\u786e\u5b9a\u5168\u73ed\u540c\u5b66\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u4f4e\u8005\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5219\u65e2\u4e0d\u80fd\u786e\u5b9a\u7537\u751f\u3001\u5973\u751f\u6700\u9ad8\u8005\u7684\u5177\u4f53\u8eab\u9ad8\uff0c\u4e5f\u4e0d\u80fd\u786e\u5b9a\u7537\u751f\u3001\u5973\u751f\u7684\u5e73\u5747\u8eab\u9ad8\u3002\nB. \u6839\u636e\u5df2\u77e5\u4fe1\u606f\uff0c\u5c3d\u7ba1\u518d\u77e5\u9053\u7537\u751f\u3001\u5973\u751f\u7684\u5e73\u5747\u8eab\u9ad8\uff0c\u4e5f\u4e0d\u80fd\u786e\u5b9a\u5168\u73ed\u540c\u5b66\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u4f4e\u8005\u4e4b\u95f4\u7684\u5dee\u8ddd\u3002\nC. \u6839\u636e\u5df2\u77e5\u4fe1\u606f\uff0c\u5373\u4f7f\u786e\u5b9a\u4e86\u5168\u73ed\u540c\u5b66\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u4f4e\u8005\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u4e5f\u4e0d\u80fd\u786e\u5b9a\u7537\u751f\u3001\u5973\u751f\u7684\u5e73\u5747\u8eab\u9ad8\u3002\nD. \u6839\u636e\u5df2\u77e5\u4fe1\u606f\uff0c\u5982\u679c\u4e0d\u80fd\u786e\u5b9a\u5168\u73ed\u540c\u5b66\u4e2d\u8eab\u9ad8\u6700\u9ad8\u8005\u4e0e\u6700\u4f4e\u8005\u4e4b\u95f4\u7684\u5dee\u8ddd\uff0c\u5219\u4e5f\u4e0d\u80fd\u786e\u5b9a\u7537\u751f\u3001\u5973\u751f\u6700\u9ad8\u8005\u7684\u5177\u4f53\u8eab\u9ad8\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34508607798276414, "meta-math/MetaMath-Mistral-7B": 0.500391651135273, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.3942759947368272, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7017514694751176, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6838\u7535\u7ad9\u6240\u53d1\u751f\u7684\u6838\u6cc4\u6f0f\u4e25\u91cd\u4e8b\u6545\u7684\u6700\u521d\u8d77\u56e0\uff0c\u6ca1\u6709\u4e00\u6b21\u662f\u8bbe\u5907\u6545\u969c\uff0c\u90fd\u662f\u4eba\u4e3a\u5931\u8bef\u6240\u81f4\u3002\u8fd9\u79cd\u5931\u8bef\uff0c\u548c\u5c0f\u5230\u5bfc\u81f4\u4ea4\u901a\u5835\u585e\uff0c\u5927\u5230\u5bfc\u81f4\u4ed3\u5e93\u5931\u706b\u7684\u4eba\u4e3a\u5931\u8bef\uff0c\u6ca1\u6709\u5b9e\u8d28\u6027\u7684\u533a\u522b\u3002\u4ece\u957f\u8fdc\u7684\u89c2\u70b9\u770b\uff0c\u4ea4\u901a\u5835\u585e\u548c\u4ed3\u5e93\u5931\u706b\u51e0\u4e4e\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002\u4e0a\u8ff0\u65ad\u5b9a\u6700\u80fd\u652f\u6301\u4ee5\u4e0b\u54ea\u9879\u7ed3\u8bba?____\nA. \u6838\u7535\u7ad9\u4e0d\u53ef\u80fd\u56e0\u8bbe\u5907\u6545\u969c\u800c\u5bfc\u81f4\u4e8b\u6545\u3002\nB. \u6838\u7535\u7ad9\u7684\u7ba1\u7406\u5e76\u4e0d\u6bd4\u6307\u6325\u4ea4\u901a\u3001\u7ba1\u7406\u4ed3\u5e93\u590d\u6742\u3002\nC. \u6838\u7535\u7ad9\u5982\u679c\u6301\u7eed\u8fd0\u4f5c\uff0c\u90a3\u4e48\u53d1\u751f\u6838\u6cc4\u6f0f\u4e25\u91cd\u4e8b\u6545\u51e0\u4e4e\u662f\u4e0d\u53ef\u907f\u514d\u7684\u3002\nD. \u4eba\u4eec\u8bd5\u56fe\u901a\u8fc7\u4e25\u683c\u7684\u89c4\u7ae0\u5236\u5ea6\u4ee5\u675c\u7edd\u5b89\u5168\u4e8b\u6545\u7684\u52aa\u529b\u662f\u6ca1\u6709\u610f\u4e49\u7684\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6645456645287602, "meta-math/MetaMath-Mistral-7B": 0.8060817912565297, "itpossible/Chinese-Mistral-7B-v0.1": 0.4542763838190806, "HuggingFaceH4/zephyr-7b-beta": 0.9974232015657998, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8603611340200726, "meta-llama/Meta-Llama-3-8B": 0.8363185853610424, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9078984291030753}}, {"question": "\u8db3\u7403\u662f\u4e00\u9879\u96c6\u4f53\u8fd0\u52a8\uff0c\u82e5\u60f3\u4e0d\u65ad\u53d6\u5f97\u80dc\u5229\uff0c\u6bcf\u4e2a\u5f3a\u961f\u90fd\u5fc5\u987b\u6709\u4e00\u4f4d\u6838\u5fc3\u961f\u5458\uff0c\u4ed6\u603b\u662f\u80fd\u5728\u5173\u952e\u573a\u6b21\u5e26\u9886\u5168\u961f\u8d62\u5f97\u6bd4\u8d5b\u3002\u53cb\u5357\u662f\u67d0\u56fd\u7532\u7ea7\u8054\u8d5b\u5f3a\u961f\u897f\u6d77\u961f\u961f\u5458\u3002\u636e\u67d0\u8bb0\u8005\u7edf\u8ba1\uff0c\u5728\u4e0a\u8d5b\u5b63\u53c2\u52a0\u7684\u6240\u6709\u6bd4\u8d5b\u4e2d\uff0c\u6709\u53cb\u5357\u53c2\u8d5b\u7684\u573a\u6b21\uff0c\u897f\u6d77\u961f\u80dc\u7387\u9ad8\u8fbe75\uff0e5\uff05\uff0c\u53e6\u670916\uff0e3\uff05\u7684\u5e73\u5c40\uff0c8\uff0e2\uff05\u7684\u573a\u6b21\u8f93\u7403\uff0c\u800c\u5728\u53cb\u5357\u7f3a\u6218\u7684\u60c5\u51b5\u4e0b\uff0c\u897f\u6d77\u961f\u80dc\u7387\u53ea\u670958\uff0e9\uff05\uff0c\u8f93\u7403\u7684\u6bd4\u7387\u9ad8\u8fbe23\uff0e5\uff05\u3002\u8be5\u8bb0\u8005\u7531\u6b64\u5f97\u51fa\u7ed3\u8bba\uff0c\u53cb\u5357\u662f\u4e0a\u8d5b\u5b63\u897f\u6d77\u961f\u7684\u6838\u5fc3\u961f\u5458\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f,\u6700\u80fd\u8d28\u7591\u8be5\u8bb0\u8005\u7684\u7ed3\u8bba____\nA. \u4e0a\u8d5b\u5b63\u53cb\u5357\u4e0a\u573a\u4e14\u897f\u6d77\u961f\u8f93\u7403\u7684\u6bd4\u8d5b\uff0c\u90fd\u662f\u897f\u6d77\u961f\u4e0e\u4f20\u7edf\u5f3a\u961f\u5bf9\u9635\u7684\u5173\u952e\u573a\u6b21\u3002\nB. \u897f\u6d77\u961f\u961f\u957f\u8868\u793a\uff1a\u201c\u6ca1\u6709\u53cb\u5357\u6211\u4eec\u5c06\u5931\u53bb\u5f88\u591a\u4e1c\u897f\uff0c\u4f46\u6211\u4eec\u4f1a\u627e\u5230\u89e3\u51b3\u529e\u6cd5\u3002\u201d\nC. \u672c\u8d5b\u5b63\u5f00\u59cb\u4ee5\u6765\uff0c\u5728\u53cb\u5357\u4e0a\u573a\u7684\u60c5\u51b5\u4e0b\uff0c\u897f\u6d77\u961f\u80dc\u7387\u66b4\u8dcc20\uff05\u3002\nD. \u4e0a\u8d5b\u5b63\u53cb\u5357\u7f3a\u5e2d\u4e14\u897f\u6d77\u961f\u8f93\u7403\u7684\u6bd4\u8d5b\uff0c\u90fd\u662f\u5c0f\u7ec4\u8d5b\u4e2d\u897f\u6d77\u961f\u5df2\u7ecf\u786e\u5b9a\u51fa\u7ebf\u540e\u7684\u6bd4\u8d5b\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.38109590680712047, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6509212910019883}}, {"question": "\u5173\u4e8e\u7532\u73ed\u4f53\u80b2\u8fbe\u6807\u6d4b\u8bd5\uff0c\u4e09\u4f4d\u8001\u5e08\u6709\u5982\u4e0b\u9884\u6d4b\uff1a\u5f20\u8001\u5e08\u8bf4\uff1a\u201c\u4e0d\u4f1a\u6240\u6709\u4eba\u90fd\u4e0d\u53ca\u683c\u3002\u201d\u674e\u8001\u5e08\u8bf4\uff1a\u201c\u6709\u4eba\u4f1a\u4e0d\u53ca\u683c\u3002\u201d\u738b\u8001\u5e08\u8bf4\uff1a\u201c\u73ed\u957f\u548c\u5b66\u4e60\u59d4\u5458\u90fd\u80fd\u53ca\u683c\u3002\u201d\u5982\u679c\u4e09\u4f4d\u8001\u5e08\u4e2d\u53ea\u6709\u4e00\u4eba\u7684\u9884\u6d4b\u6b63\u786e\uff0c\u5219\u4ee5\u4e0b\u54ea\u9879\u4e00\u5b9a\u4e3a\u771f?____\nA. \u73ed\u957f\u548c\u5b66\u4e60\u59d4\u5458\u90fd\u6ca1\u53ca\u683c\u3002\nB. \u73ed\u957f\u548c\u5b66\u4e60\u59d4\u5458\u90fd\u53ca\u683c\u4e86\u3002\nC. \u73ed\u957f\u53ca\u683c\uff0c\u4f46\u5b66\u4e60\u59d4\u5458\u6ca1\u53ca\u683c\nD. \u73ed\u957f\u6ca1\u53ca\u683c\uff0c\u4f46\u5b66\u4e60\u59d4\u5458\u53ca\u683c\u4e86\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5927\u6295\u8d44\u7684\u6240\u8c13\u5de8\u7247\u7684\u7968\u623f\u6536\u5165\uff0c\u4e00\u822c\u662f\u5f71\u7247\u5236\u4f5c\u4e0e\u5546\u4e1a\u5ba3\u4f20\u603b\u6210\u672c\u7684\u4e8c\u81f3\u4e09\u500d\u3002\u4f46\u662f\u7535\u5f71\u4e1a\u7684\u5e74\u6536\u5165\u5927\u90e8\u5206\u6765\u81ea\u4e2d\u5c0f\u6295\u8d44\u7684\u5f71\u7247\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f\uff0c\u6700\u80fd\u89e3\u91ca\u9898\u5e72\u7684\u73b0\u8c61?____\nA. \u7968\u623f\u6536\u5165\u4e0d\u662f\u8bc4\u4ef7\u5f71\u7247\u8d28\u91cf\u7684\u4e3b\u8981\u6807\u51c6\u3002\nB. \u5927\u6295\u8d44\u7684\u5de8\u7247\u4e2d\u786e\u5b9e\u4e0d\u4e4f\u7cbe\u54c1\u3002\nC. \u5927\u6295\u8d44\u5de8\u7247\u7684\u7968\u4ef7\u660e\u663e\u9ad8\u4e8e\u4e2d\u5c0f\u6295\u8d44\u5f71\u7247\u3002\nD. \u6295\u5165\u5e02\u573a\u7684\u5f71\u7247\u4e2d\uff0c\u5927\u90e8\u5206\u662f\u4e2d\u5c0f\u6295\u8d44\u7684\u5f71\u7247\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.43521513670539946, "meta-math/MetaMath-Mistral-7B": 0.6413163853821207, "itpossible/Chinese-Mistral-7B-v0.1": 0.6481867205308844, "HuggingFaceH4/zephyr-7b-beta": 0.9997039009959803, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9050353974555531, "meta-llama/Meta-Llama-3-8B": 0.578432765796758, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9524189829876244}}, {"question": "\u529e\u516c\u5ba4\u4e3b\u4efb\uff1a\u672c\u529e\u516c\u5ba4\u4e0d\u6253\u7b97\u4f7f\u7528\u5faa\u73af\u518d\u5229\u7528\u7eb8\u5f20\u3002\u7ed9\u7528\u6237\u7684\u4fe1\u4ef6\u5fc5\u987b\u80fd\u7559\u4e0b\u597d\u7684\u5370\u8c61\u3002\u4e0d\u80fd\u6253\u5370\u5728\u52a3\u8d28\u7eb8\u5f20\u4e0a\u3002\u6587\u5177\u4f9b\u5e94\u5546\uff1a\u5faa\u73af\u518d\u5229\u7528\u7eb8\u5f20\u4e0d\u4e00\u5b9a\u662f\u52a3\u8d28\u7684\u3002\u4e8b\u5b9e\u4e0a\uff0c\u6700\u521d\u7684\u7eb8\u5f20\u5c31\u662f\u7528\u53ef\u56de\u6536\u6750\u6599\u5236\u9020\u7684\u3002\u4e00\u76f4\u523019\u4e16\u7eaa50\u5e74\u4ee3\uff0c\u7531\u4e8e\u788e\u5c51\u539f\u6599\u4f9b\u4e0d\u5e94\u6c42\uff0c\u624d\u4f7f\u7528\u6728\u7ea4\u7ef4\u4f5c\u4e3a\u9020\u7eb8\u539f\u6599\u3002\u4ee5\u4e0b\u54ea\u9879\u6700\u4e3a\u6070\u5f53\u5730\u6982\u62ec\u4e86\u6587\u5177\u4f9b\u5e94\u5546\u7684\u53cd\u9a73\u4e2d\u5b58\u5728\u7684\u6f0f\u6d1e?____\nA. \u6ca1\u6709\u610f\u8bc6\u5230\u529e\u516c\u5ba4\u4e3b\u4efb\u5bf9\u4e8e\u5faa\u73af\u518d\u5229\u7528\u7eb8\u5f20\u7684\u504f\u89c1\u662f\u7531\u4e8e\u67d0\u79cd\u65e0\u77e5\u3002\nB. \u4f7f\u7528\u4e86\u4e0d\u76f8\u5173\u7684\u4e8b\u5b9e\u6765\u8bc1\u660e\u4e00\u4e2a\u5173\u4e8e\u4ea7\u54c1\u8d28\u91cf\u7684\u65ad\u5b9a\u3002\nC. \u4e0d\u6070\u5f53\u5730\u5047\u8bbe\u529e\u516c\u5ba4\u4e3b\u4efb\u5ffd\u89c6\u4e86\u73af\u5883\u4fdd\u62a4\u3002\nD. \u4e0d\u6070\u5f53\u5730\u5047\u8bbe\u529e\u516c\u5ba4\u4e3b\u4efb\u4e86\u89e3\u7eb8\u5f20\u7684\u5236\u9020\u5de5\u827a\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4831580640719806, "meta-math/MetaMath-Mistral-7B": 0.4045257140067991, "itpossible/Chinese-Mistral-7B-v0.1": 0.7521737283827566, "HuggingFaceH4/zephyr-7b-beta": 0.7877764510123911, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8575124978265464, "meta-llama/Meta-Llama-3-8B": 0.4566948812278862, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7243941344807331}}, {"question": "\u672a\u6765\u6df1\u6d77\u7535\u7f06\u7684\u5916\u76ae\u662f\u7531\u73bb\u7483\u5236\u6210\u7684\uff0c\u800c\u4e0d\u662f\u7279\u6b8a\u7684\u94a2\u6750\u6216\u94dd\u5408\u91d1\u3002\u539f\u56e0\u662f\u91d1\u5c5e\u5177\u6709\u9897\u7c92\u72b6\u7684\u5fae\u89c2\u7ed3\u6784\uff0c\u5728\u6df1\u6d77\u538b\u529b\u4e4b\u4e0b\uff0c\u7c92\u5b50\u4ea4\u7ed3\u5904\u7684\u91d1\u5c5e\u5916\u76ae\u6613\u4e8e\u65ad\u88c2\u3002\u73bb\u7483\u5916\u76ae\u5c31\u4e0d\u4f1a\u6709\u8fd9\u79cd\u60c5\u51b5\uff0c\u56e0\u4e3a\u73bb\u7483\u770b\u8d77\u6765\u662f\u56fa\u4f53\uff0c\u7531\u4e8e\u5b83\u5728\u538b\u529b\u4e4b\u4e0b\u53ef\u4ee5\u6d41\u52a8\uff0c\u6240\u4ee5\u53ef\u5c06\u4e4b\u89c6\u4e3a\u6db2\u4f53\u3002\u4ee5\u4e0b\u54ea\u9879\u6700\u6709\u53ef\u80fd\u4ece\u4e0a\u8ff0\u8bae\u8bba\u4e2d\u63a8\u51fa?____\nA. \u6db2\u4f53\u6ca1\u6709\u9897\u7c92\u72b6\u7684\u5fae\u89c2\u7ed3\u6784\u3002\nB. \u6240\u6709\u79f0\u4e4b\u4e3a\u56fa\u4f53\u7684\u4e1c\u897f\u53ea\u4e0d\u8fc7\u662f\u79fb\u52a8\u6781\u5176\u7f13\u6162\u7684\u6db2\u4f53\u3002\nC. \u53ea\u6709\u65ad\u88c2\u7684\u73bb\u7483\u662f\u5fae\u89c2\u7c92\u72b6\u7684\u3002\nD. \u4f5c\u4e3a\u4e00\u79cd\u5efa\u7b51\u6750\u6599\uff0c\u73bb\u7483\u4f18\u4e8e\u94a2\u6750\u548c\u94dd\u6750\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.543195929468281, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9354620097456733}}, {"question": "\u751f\u6001\u6587\u660e\u5efa\u8bbe\u4e8b\u5173\u793e\u4f1a\u53d1\u5c55\u65b9\u5f0f\u548c\u4eba\u6c11\u798f\u7949\u3002\u53ea\u6709\u5b9e\u884c\u6700\u4e25\u683c\u7684\u5236\u5ea6\uff0c\u6700\u4e25\u5bc6\u7684\u6cd5\u6cbb\uff0c\u624d\u80fd\u4e3a\u751f\u6001\u6587\u660e\u5efa\u8bbe\u63d0\u4f9b\u53ef\u9760\u4fdd\u969c\uff1b\u5982\u679c\u8981\u5b9e\u884c\u6700\u4e25\u683c\u7684\u5236\u5ea6\u3001\u6700\u4e25\u5bc6\u7684\u6cd5\u6cbb\uff0c\u5c31\u8981\u5efa\u7acb\u8d23\u4efb\u8ffd\u7a76\u5236\u5ea6\uff0c\u5bf9\u90a3\u4e9b\u4e0d\u987e\u751f\u6001\u73af\u5883\u76f2\u76ee\u51b3\u7b56\u5e76\u9020\u6210\u4e25\u91cd\u540e\u679c\u8005\uff0c\u8ffd\u7a76\u5176\u76f8\u5e94\u7684\u8d23\u4efb\u3002\u6839\u636e\u4e0a\u8ff0\u4fe1\u606f,\u53ef\u4ee5\u5f97\u51fa\u4ee5\u4e0b\u54ea\u9879\uff1f____\nA. \u5982\u679c\u5bf9\u90a3\u4e9b\u4e0d\u987e\u751f\u6001\u73af\u5883\u76f2\u76ee\u51b3\u7b56\u5e76\u9020\u6210\u4e25\u91cd\u540e\u679c\u8005\u8ffd\u7a76\u76f8\u5e94\u8d23\u4efb\uff0c\u5c31\u80fd\u4e3a\u751f\u6001\u6587\u660e\u5efa\u8bbe\u63d0\u4f9b\u53ef\u9760\u4fdd\u969c\u3002\nB. \u5b9e\u884c\u6700\u4e25\u683c\u7684\u5236\u5ea6\u548c\u6700\u4e25\u5bc6\u7684\u6cd5\u6cbb\u662f\u751f\u6001\u6587\u660e\u5efa\u8bbe\u7684\u91cd\u8981\u76ee\u6807\u3002\nC. \u5982\u679c\u4e0d\u5efa\u7acb\u8d23\u4efb\u8ffd\u7a76\u5236\u5ea6\uff0c\u5c31\u4e0d\u80fd\u4e3a\u751f\u6001\u6587\u660e\u5efa\u8bbe\u63d0\u4f9b\u53ef\u9760\u4fdd\u969c\u3002\nD. \u53ea\u6709\u7b51\u7262\u751f\u6001\u73af\u5883\u7684\u5236\u5ea6\u9632\u62a4\u5899\uff0c\u624d\u80fd\u9020\u798f\u4e8e\u6c11\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5225775674920512, "meta-math/MetaMath-Mistral-7B": 0.47756793392932306, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9956563675671123, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6700\u8fd1\u7531\u4e8e\u5728\u871c\u6a58\u6210\u719f\u5b63\u8282\u51fa\u73b0\u6301\u7eed\u5e72\u65f1\uff0c\u56db\u5ddd\u871c\u6a58\u7684\u4ef7\u683c\u6bd4\u5e73\u65f6\u540c\u671f\u4e0a\u6da8\u4e86\u4e09\u500d\uff0c\u8fd9\u5c31\u5927\u5927\u63d0\u9ad8\u4e86\u6a58\u6c41\u917f\u9020\u4e1a\u7684\u6210\u672c\uff0c\u4f30\u8ba1\u6a58\u6c41\u7684\u4ef7\u683c\u5c06\u6709\u5927\u5e45\u5ea6\u7684\u63d0\u9ad8\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u662f\u771f\u7684\uff0c\u6700\u80fd\u524a\u5f31\u4e0a\u8ff0\u7ed3\u8bba?____\nA. \u53bb\u5e74\u6a58\u6c41\u7684\u4ef7\u683c\u662f\u5386\u5e74\u6700\u4f4e\u7684\u3002\nB. \u5176\u4ed6\u66ff\u4ee3\u539f\u6599\u53ef\u4ee5\u7528\u6765\u751f\u4ea7\u4eff\u6a58\u6c41\u3002\nC. \u6700\u8fd1\u7684\u5e72\u65f1\u5e76\u4e0d\u5982\u4e13\u5bb6\u4eec\u4f30\u8ba1\u7684\u90a3\u4e48\u4e25\u91cd\u3002\nD. \u9664\u4e86\u56db\u5ddd\u5916\uff0c\u5176\u4ed6\u7701\u4efd\u4e5f\u53ef\u4ee5\u63d0\u4f9b\u871c\u6a58\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3689108554330874, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6559\u80b2\u4e13\u5bb6\u674e\u6559\u6388\u63d0\u51fa\uff0c\u6bcf\u4e2a\u4eba\u5728\u81ea\u5df1\u7684\u4e00\u751f\u4e2d\uff0c\u90fd\u8981\u4e0d\u65ad\u5730\u52aa\u529b\uff0c\u5426\u5219\u5c31\u4f1a\u50cf\u9f9f\u5154\u8d5b\u8dd1\u7684\u6545\u4e8b\u4e00\u6837\uff0c\u4e00\u65f6\u8dd1\u5f97\u5feb\u5e76\u4e0d\u80fd\u4fdd\u8bc1\u4e00\u76f4\u9886\u5148\u3002\u5982\u679c\u4f60\u672c\u6765\u57fa\u7840\u597d\u53c8\u80fd\u4e0d\u65ad\u52aa\u529b\uff0c\u90a3\u4f60\u80af\u5b9a\u80fd\u6bd4\u522b\u4eba\u66f4\u65e9\u53d6\u5f97\u6210\u529f\u3002\u5982\u679c\u674e\u6559\u6388\u7684\u9648\u8ff0\u4e3a\u771f,\u4ee5\u4e0b\u54ea\u9879\u4e00\u5b9a\u4e3a\u5047____\nA. \u53ea\u8981\u4e0d\u65ad\u52aa\u529b\uff0c\u4efb\u4f55\u4eba\u90fd\u53ef\u80fd\u53d6\u5f97\u6210\u529f\u3002\nB. \u4e00\u65f6\u4e0d\u6210\u529f\u5e76\u4e0d\u610f\u5473\u7740\u4e00\u76f4\u4e0d\u6210\u529f\u3002\nC. \u5c0f\u738b\u672c\u6765\u57fa\u7840\u597d\u5e76\u4e14\u80fd\u4e0d\u65ad\u52aa\u529b\uff0c\u4f46\u4e5f\u53ef\u80fd\u6bd4\u522b\u4eba\u66f4\u665a\u53d6\u5f97\u6210\u529f\u3002\nD. \u4eba\u7684\u6210\u529f\u662f\u6709\u8861\u91cf\u6807\u51c6\u7684\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.47684762164047934, "meta-math/MetaMath-Mistral-7B": 0.6603662587463921, "itpossible/Chinese-Mistral-7B-v0.1": 0.42204124505650253, "HuggingFaceH4/zephyr-7b-beta": 0.7096678084639951, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9406142184234628, "meta-llama/Meta-Llama-3-8B": 0.5469986248786403, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5c0f\u7ea2\u88c5\u75c5\u9003\u5b66\u4e86\u4e00\u5929\uff0c\u5927\u660e\u7b54\u5e94\u4e3a\u5979\u4fdd\u5bc6\u3002\u4e8b\u540e\uff0c\u77e5\u9053\u4e8b\u60c5\u5e95\u7ec6\u7684\u8001\u5e08\u5bf9\u5927\u660e\u8bf4\uff0c\u6211\u548c\u4f60\u4e00\u6837\uff0c\u90fd\u8ba4\u4e3a\u8fdd\u80cc\u627f\u8bfa\u662f\u4e00\u4ef6\u4e0d\u597d\u7684\u4e8b\u60c5\u3002\u4f46\u662f\uff0c\u4eba\u548c\u4eba\u7684\u4ea4\u5f80\uff0c\u4e8b\u5b9e\u4e0a\u9ed8\u8ba4\u4e00\u4e2a\u627f\u8bfa\uff0c\u8fd9\u5c31\u662f\u8bf4\u771f\u8bdd\uff0c\u4efb\u4f55\u8c0e\u8a00\u90fd\u8fdd\u80cc\u8fd9\u4e00\u627f\u8bfa\u3002\u56e0\u6b64\uff0c\u5982\u679c\u5c0f\u7ea2\u786e\u5b9e\u88c5\u75c5\u9003\u5b66\uff0c\u90a3\u4e48\uff0c\u4f60\u5373\u4f7f\u5df2\u7ecf\u627f\u8bfa\u4e3a\u5979\u4fdd\u5bc6\uff0c\u4e5f\u5e94\u8be5\u5bf9\u6211\u8bf4\u5b9e\u8bdd\u3002\u8981\u4f7f\u8001\u5e08\u7684\u8bdd\u6210\u7acb\uff0c\u4ee5\u4e0b\u54ea\u9879\u662f\u5fc5\u987b\u5047\u8bbe\u7684?____\nA. \u8bf4\u8c0e\u6bd4\u8fdd\u80cc\u5176\u4ed6\u627f\u8bfa\u66f4\u6709\u5bb3\u3002\nB. \u6709\u65f6\uff0c\u8fdd\u80cc\u627f\u8bfa\u5e76\u4e0d\u662f\u4e00\u4ef6\u574f\u4e8b\u3002\nC. \u4efb\u4f55\u9ed8\u8ba4\u7684\u627f\u8bfa\u90fd\u6bd4\u8868\u8fbe\u7684\u627f\u8bfa\u66f4\u91cd\u8981\u3002\nD. \u8fdd\u80cc\u9ed8\u8ba4\u7684\u627f\u8bfa\u6709\u65f6\u8981\u6bd4\u8fdd\u80cc\u8868\u8fbe\u7684\u627f\u8bfa\u66f4\u4e0d\u597d\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7724796455773245, "meta-math/MetaMath-Mistral-7B": 0.7949542014738044, "itpossible/Chinese-Mistral-7B-v0.1": 0.5097675912446954, "HuggingFaceH4/zephyr-7b-beta": 0.9996927637006993, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9763353564920609, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6294574742448561}}, {"question": "\u7532\u88ab\u6307\u63a7\u72af\u7f6a\uff0c\u4e59\u662f\u6b64\u9879\u8d77\u8bc9\u7684\u4e3b\u8981\u8bc1\u4eba\u3002\u5173\u4e8e\u8fd9\u4e2a\u6848\u4ef6\uff0c\u6709\u5982\u4e0b\u65ad\u5b9a\uff1a(1)\u57fa\u4e8e\u4e59\u63d0\u4f9b\u7684\u6709\u5173\u8bc1\u8bcd\uff0c\u5c31\u53ef\u4ee5\u5ba3\u5224\u7532\u6709\u7f6a\u3002(2)\u4e59\u7684\u8bc1\u8bcd\u8bf4\u660e\u4ed6\u81ea\u5df1\u5b9e\u9645\u4e0a\u4e5f\u53c2\u52a0\u4e86\u7532\u7684\u72af\u7f6a\u6d3b\u52a8\u3002(3)\u7532\u88ab\u6307\u63a7\u7684\u72af\u7f6a\u6d3b\u52a8\u53ea\u53ef\u80fd\u7531\u4e00\u4e2a\u4eba\u72ec\u7acb\u5b8c\u6210\u3002\u5982\u679c\u4ee5\u4e0a\u65ad\u5b9a\u90fd\u662f\u771f\u7684\uff0c\u5219\u4ee5\u4e0b\u54ea\u9879\u6700\u53ef\u80fd\u662f\u5ba1\u5224\u7684\u7ed3\u679c?____\nA. \u7532\u548c\u4e59\u90fd\u88ab\u5ba3\u5224\u5728\u4e59\u8d77\u8bc9\u7684\u6848\u4ef6\u4e2d\u6709\u7f6a\u3002\nB. \u9664\u4e86\u5728\u4e59\u5df2\u88ab\u6307\u63a7\u7684\u6848\u4ef6\u4e2d\uff0c\u7532\u548c\u4e59\u8fd8\u88ab\u5ba3\u5224\u4e3a\u5728\u5176\u4ed6\u6848\u4ef6\u4e2d\u6709\u7f6a\u3002\nC. \u7532\u88ab\u5ba3\u5224\u4e3a\u6709\u7f6a\uff0c\u800c\u4e59\u88ab\u5ba3\u5224\u4e3a\u65e0\u7f6a\u3002\nD. \u7532\u88ab\u5ba3\u5224\u4e3a\u65e0\u7f6a\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3704758892804015, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9851941479481975, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u56fd\u4ea7\u7247\u300a\u82f1\u96c4\u300b\u663e\u7136\u662f\u524d\u4e24\u5e74\u6700\u597d\u7684\u53e4\u88c5\u6b66\u6253\u7247\u3002\u8fd9\u90e8\u7535\u5f71\u662f\u7531\u8457\u540d\u5bfc\u6f14\u3001\u6f14\u5458\u3001\u6444\u5f71\u5e08\u3001\u6b66\u6253\u8bbe\u8ba1\u5e08\u548c\u670d\u88c5\u8bbe\u8ba1\u5e08\u53c2\u4e0e\u7684\u4e00\u90e8\u56fd\u9645\u5316\u5927\u5236\u4f5c\u7684\u7535\u5f71\u3002\u7968\u623f\u6536\u5165\u7684\u660e\u663e\u9886\u5148\u8bf4\u660e\u89c2\u770b\u8be5\u90e8\u5f71\u7247\u7684\u4eba\u6570\u8fdc\u591a\u4e8e\u8fdb\u53e3\u7684\u7f8e\u56fd\u5927\u7247\u300a\u5367\u864e\u85cf\u9f99\u300b\u7684\u4eba\u6570\uff0c\u5c3d\u7ba1\u300a\u5367\u864e\u85cf\u9f99\u300b\u4e5f\u662f\u7cbe\u5fc3\u5236\u4f5c\u7684\u4e2d\u56fd\u53e4\u88c5\u6b66\u6253\u7247\u3002\u4e3a\u4f7f\u4e0a\u8ff0\u8bba\u8bc1\u6210\u7acb\uff0c\u4ee5\u4e0b\u54ea\u9879\u662f\u5fc5\u987b\u5047\u8bbe\u7684?____\u2160\uff0e\u56fd\u4ea7\u5f71\u7247\u300a\u82f1\u96c4\u300b\u548c\u7f8e\u56fd\u5f71\u7247\u300a\u5367\u864e\u85cf\u9f99\u300b\u7684\u7968\u4ef7\u57fa\u672c\u76f8\u540c\u3002\u2161\uff0e\u89c2\u4f17\u6570\u91cf\u662f\u8bc4\u4ef7\u7535\u5f71\u8d28\u91cf\u7684\u6807\u51c6\u3002\u2162\uff0e\u5bfc\u6f14\u3001\u6f14\u5458\u3001\u6444\u5f71\u5e08\u3001\u6b66\u6253\u8bbe\u8ba1\u5e08\u548c\u670d\u88c5\u8bbe\u8ba1\u5e08\u7684\u9635\u5bb9\u662f\u8bc4\u4ef7\u7535\u5f71\u8d28\u91cf\u7684\u6807\u51c6\u3002\nA. \u4ec5\u4ec5\u3002\nB. \u4ec5\u4ec5\u2161\u3002\nC. \u4ec5\u4ec5\u2162\u3002\nD. \u4ec5\u4ec5\u2160\u548c\u2161\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38981153985049755, "meta-math/MetaMath-Mistral-7B": 0.5349682363620976, "itpossible/Chinese-Mistral-7B-v0.1": 0.41340327407643723, "HuggingFaceH4/zephyr-7b-beta": 0.8021299833755827, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7615135366706483, "meta-llama/Meta-Llama-3-8B": 0.3220562534414596, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.44972446948515077}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6cd5\u5f8b\u63a8\u7406\u7684\u8868\u8ff0\uff0c\u80fd\u591f\u6210\u7acb\u7684\u662f____\u3002\nA. \u6f14\u7ece\u63a8\u7406\u662f\u4e00\u79cd\u6216\u7136\u6027\u63a8\u7406\nB. \u5f52\u7eb3\u63a8\u7406\u662f\u4ece\u4e00\u822c\u77e5\u8bc6\u63a8\u51fa\u4e2a\u522b\u77e5\u8bc6\u7684\u63a8\u7406\nC. \u7c7b\u6bd4\u63a8\u7406\u662f\u5224\u4f8b\u6cd5\u56fd\u5bb6\u8fd0\u7528\u7684\u4e00\u79cd\u57fa\u672c\u7684\u6cd5\u5f8b\u63a8\u7406\u65b9\u6cd5\nD. \u8fa9\u8bc1\u63a8\u7406\u5b9e\u9645\u4e0a\u662f\u4e00\u79cd\u7acb\u6cd5\u6d3b\u52a8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6129908097974537, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7000143059908333, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9920340026835504}}, {"question": "\u67d0\u4f4f\u5b85\u5c0f\u533a\u4e1a\u4e3b\u4ece\u4e8b\u7684\u4e0b\u5217\u884c\u4e3a\u4e2d\uff0c\u4e0d\u5fc5\u5c06\u76f8\u5173\u60c5\u51b5\u544a\u77e5\u7269\u4e1a\u670d\u52a1\u4eba\u7684\u60c5\u5f62\u662f____\u3002\nA. \u4e1a\u4e3b\u7532\u5c06\u5176\u623f\u5c4b\u51fa\u79df\u7ed9\u8d75\u67d0\nB. \u4e1a\u4e3b\u4e59\u5728\u5176\u4f4f\u5b85\u4e0a\u8bbe\u7acb\u5c45\u4f4f\u6743\u4f9b\u5176\u5f1f\u5c45\u4f4f\nC. \u4e1a\u4e3b\u4e19\u4f9d\u6cd5\u5c06\u5efa\u7b51\u533a\u5212\u5185\u7684\u7eff\u5730\u6539\u9020\u6210\u82b1\u56ed\nD. \u4e1a\u4e3b\u4e01\u5728\u5176\u4f4f\u5b85\u4e0a\u8bbe\u7acb\u5730\u5f79\u6743\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9435824260073372, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3602912416786143, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f20\u67d0\u5728\u7532\u671f\u520a\u793e\u53d1\u8868\u4e86\u4e00\u7bc7\u9887\u5177\u4ef7\u503c\u7684\u5b66\u672f\u8bba\u6587\uff0c\u4f46\u672a\u4f5c\u7248\u6743\u8bf4\u660e\u3002\u4e59\u671f\u520a\u793e\u5c06\u8be5\u5b66\u672f\u8bba\u6587\u4f5c\u4e3a\u8d44\u6599\u520a\u767b\u3002\u5219\u4e59\u671f\u520a\u793e\u7684\u884c\u4e3a____\u3002\nA. \u5c5e\u4e8e\u5408\u7406\u4f7f\u7528\uff0c\u4e0d\u5fc5\u5411\u8457\u4f5c\u6743\u4eba\u652f\u4ed8\u62a5\u916c\nB. \u5c5e\u4e8e\u4fb5\u72af\u8457\u4f5c\u6743\u7684\u884c\u4e3a\nC. \u4e0d\u5fc5\u7ecf\u7532\u671f\u520a\u793e\u540c\u610f\uff0c\u4f46\u5e94\u5411\u5176\u652f\u4ed8\u62a5\u916c\nD. \u4e0d\u5fc5\u7ecf\u5f20\u67d0\u540c\u610f\uff0c\u4f46\u5e94\u5411\u5176\u652f\u4ed8\u62a5\u916c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u6211\u56fd\u5baa\u6cd5\u4fee\u6539\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684____\u3002\nA. \u6211\u56fd\u4fee\u5baa\u5b9e\u8df5\u4e2d\u65e2\u6709\u5bf9\u5baa\u6cd5\u7684\u90e8\u5206\u4fee\u6539\uff0c\u4e5f\u6709\u5bf9\u5baa\u6cd5\u7684\u5168\u9762\u4fee\u6539\nB. \u7ecf1/10\u4ee5\u4e0a\u7684\u5168\u56fd\u4eba\u5927\u4ee3\u8868\u63d0\u8bae\uff0c\u53ef\u4ee5\u542f\u52a8\u5baa\u6cd5\u4fee\u6539\u7a0b\u5e8f\nC. \u5168\u56fd\u4eba\u5927\u5e38\u59d4\u4f1a\u662f\u6cd5\u5b9a\u7684\u4fee\u5baa\u4e3b\u4f53\nD. \u5baa\u6cd5\u4fee\u6b63\u6848\u662f\u6211\u56fd\u5baa\u6cd5\u89c4\u5b9a\u7684\u5baa\u6cd5\u4fee\u6539\u65b9\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38181830457859045, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4800666736249149, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44223815353089696, "meta-llama/Meta-Llama-3-8B": 0.3527809287490976, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u53ef\u4ee5\u9002\u7528\u4e0d\u5f53\u5f97\u5229\u4e3b\u5f20\u8bf7\u6c42\u6743\u7684\u60c5\u5f62\u662f____\u3002\nA. \u7532\u4e3a\u81ea\u5df1\u6b63\u5728\u8bfb\u5927\u5b66\u7684\u5f1f\u5f1f\u4e59\u652f\u4ed8\u5b66\u8d39\uff0c\u540e\u7532\u8981\u6c42\u4e59\u8fd4\u8fd8\nB. \u4e19\u660e\u77e5\u4e0d\u6b20\u4e01\u7684\u94b1\u800c\u6267\u610f\u5411\u4e01\u8fd8\u94b1\uff0c\u540e\u4e19\u8981\u6c42\u4e01\u8fd4\u8fd8\u8be5\u91d1\u94b1\nC. \u5f20\u67d0\u507f\u8fd8\u4e86\u6b20\u674e\u67d0\u7684\u8d4c\u503a\uff0c\u540e\u5f20\u67d0\u8981\u6c42\u674e\u67d0\u8fd4\u8fd8\u8d4c\u8d44\nD. \u9648\u67d0\u548c\u5434\u67d0\u540c\u5728\u6cb3\u8fb9\u653e\u725b\uff0c\u540e\u9648\u67d0\u7684\u4e00\u5934\u725b\u8d70\u5165\u5434\u67d0\u7684\u725b\u7fa4\u4e2d\uff0c\u800c\u5434\u67d0\u5bf9\u6b64\u5e76\u4e0d\u77e5\u60c5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.27416108226793107, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5218\u5a46\u5a46\u56de\u5bb6\u9014\u4e2d\uff0c\u770b\u89c1\u90bb\u5c45\u8096\u5a46\u5a46\u5e26\u7740\u5916\u5b59\u5c0f\u52c7\u548c\u53e6\u4e00\u5bb6\u90bb\u5c45\u7684\u5b69\u5b50\u5c0f\u56e1(\u5747\u4e3a4\u5c81\u591a)\u5728\u5c0f\u533a\u82b1\u56ed\u4e2d\u73a9\u800d\uff0c\u4fbf\u4e0a\u524d\u62ff\u51fa\u51e0\u6839\u9999\u8549\u9012\u7ed9\u5c0f\u52c7\uff0c\u968f\u540e\u79bb\u53bb\u3002\u5c0f\u52c7\u63a5\u8fc7\u9999\u8549\u540e\uff0c\u9012\u7ed9\u5c0f\u56e1\u4e00\u6839\uff0c\u5c0f\u56e1\u541e\u98df\u65f6\u8bef\u5165\u6c14\u7ba1\u5bfc\u81f4\u4f11\u514b\uff0c\u7ecf\u62a2\u6551\u65e0\u6548\u6b7b\u4ea1\u3002\u5bf9\u6b64\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684?____\nA. \u5218\u5a46\u5a46\u5e94\u5bf9\u5c0f\u56e1\u7684\u6b7b\u4ea1\u627f\u62c5\u6c11\u4e8b\u8d23\u4efb\nB. \u8096\u5a46\u5a46\u5e94\u5bf9\u5c0f\u56e1\u7684\u6b7b\u4ea1\u627f\u62c5\u6c11\u4e8b\u8d23\u4efb\nC. \u5c0f\u52c7\u7684\u7236\u6bcd\u5e94\u5bf9\u5c0f\u56e1\u7684\u6b7b\u4ea1\u627f\u62c5\u6c11\u4e8b\u8d23\u4efb\nD. \u5c5e\u610f\u5916\u4e8b\u4ef6\uff0c\u4e0d\u4ea7\u751f\u76f8\u5173\u4eba\u5458\u7684\u8fc7\u9519\u8d23\u4efb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4658923272442273, "itpossible/Chinese-Mistral-7B-v0.1": 0.4702008436521869, "HuggingFaceH4/zephyr-7b-beta": 0.9557303633483388, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8175216935874132, "meta-llama/Meta-Llama-3-8B": 0.7909437131384758, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9219991210830121}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u80fd\u591f\u5f15\u8d77\u4e0d\u5f53\u5f97\u5229\u4e4b\u503a\u53d1\u751f\u7684\u662f____\u3002\nA. \u4e3a\u56de\u8d4e\u7ed1\u7968\u5411\u7ed1\u532a\u4ea4\u4ed8\u8d4e\u91d1\nB. \u4e3a\u90bb\u5c45\u57ab\u652f\u8bdd\u8d39\nC. \u5192\u540d\u5c06\u4ed6\u4eba\u7a3f\u916c\u53d6\u8d70\nD. \u5c65\u884c\u671f\u9650\u5230\u6765\u4e4b\u524d\u5411\u503a\u6743\u4eba\u53d1\u8d27\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u3001\u4e59\u56e0\u751f\u6d3b\u7410\u4e8b\u4e92\u76f8\u6597\u6bb4\uff0c\u4e59\u611f\u5230\u4e0d\u662f\u7532\u7684\u5bf9\u624b\u800c\u9003\u8dd1\u3002\u7532\u7d27\u8ffd\u4e0d\u820d\uff0c\u4e59\u9003\u51fa500\u7c73\u540e\u88ab\u7532\u8d76\u4e0a\u3002\u7532\u7528\u6728\u68cd\u5411\u4e59\u5934\u90e8\u731b\u51fb\u3002\u60c5\u6025\u4e4b\u4e0b\uff0c\u4e59\u62bd\u51fa\u968f\u8eab\u643a\u5e26\u7684\u6c34\u679c\u5200\u671d\u7532\u523a\u53bb\uff0c\u81f4\u7532\u91cd\u4f24\u3002\u4e59\u7684\u884c\u4e3a____\u3002\nA. \u6784\u6210\u6545\u610f\u6740\u4eba\u7f6a\u672a\u9042\nB. \u6784\u6210\u6545\u610f\u4f24\u5bb3\u7f6a\nC. \u6784\u6210\u5bfb\u8845\u6ecb\u4e8b\u7f6a\nD. \u4e0d\u6784\u6210\u72af\u7f6a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u3001\u4e59\u662f\u67d0\u9ad8\u6821\u4f4f\u540c\u4e00\u5bdd\u5ba4\u7684\u7814\u7a76\u751f\uff0c\u4e8c\u4eba\u5408\u7528\u4e00\u53f0\u7535\u8111\u3002\u7532\u5411\u7f8e\u56fd\u67d0\u5927\u5b66\u7533\u8bf7\u7559\u7f8e\u5956\u5b66\u91d1\uff0c\u5e76\u5c06\u6b64\u4e8b\u544a\u77e5\u4e59\u3002\u7f8e\u65b9\u53d1\u51fa\u7535\u5b50\u90ae\u4ef6\uff0c\u9080\u8bf7\u7532\u8d74\u7f8e\u7559\u5b66\u3002\u6070\u5de7\u7532\u4e0d\u5728\uff0c\u4e59\u51fa\u4e8e\u5ac9\u5992\uff0c\u64c5\u81ea\u53d1\u90ae\u4ef6\u62d2\u7edd\u7f8e\u65b9\u9080\u8bf7\u3002\u6570\u65e5\u540e\u7532\u53d1\u7535\u5b50\u90ae\u4ef6\u5411\u7f8e\u65b9\u8be2\u95ee\uff0c\u7f8e\u65b9\u544a\u77e5\u7532\u56e0\u5176\u62d2\u7edd\u9080\u8bf7\u800c\u4e0d\u518d\u8003\u8651\u3002\u4e59\u4fb5\u72af\u4e86\u7532\u7684____\u3002\nA. \u59d3\u540d\u6743\nB. \u540d\u8a89\u6743\nC. \u540d\u79f0\u6743\nD. \u9690\u79c1\u6743\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8981\u7d20\u4e2d\uff0c\u4e0d\u80fd\u4f5c\u4e3a\u5546\u6807\u7533\u8bf7\u6ce8\u518c\u7684\u662f____\u3002\nA. \u5546\u52a1\u6807\u8bed\nB. \u58f0\u97f3\nC. \u5b57\u6bcd\nD. \u989c\u8272\u7ec4\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ee5\u725f\u5229\u4e3a\u76ee\u7684\uff0c\u76d7\u63a5\u4ed6\u4eba\u901a\u4fe1\u7ebf\u8def\u3001\u590d\u5236\u4ed6\u4eba\u7535\u4fe1\u7801\u53f7\u6216\u8005\u660e\u77e5\u662f\u76d7\u63a5\u3001\u590d\u5236\u7684\u7535\u4fe1\u8bbe\u5907\u3001\u8bbe\u65bd\u800c\u4f7f\u7528\u7684\uff0c\u5e94\u6784\u6210____\u3002\nA. \u975e\u6cd5\u7ecf\u8425\u7f6a\nB. \u4fb5\u5360\u7f6a\nC. \u76d7\u7a83\u7f6a\nD. \u7834\u574f\u516c\u7528\u7535\u4fe1\u8bbe\u65bd\u7f6a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4294839928845748, "meta-math/MetaMath-Mistral-7B": 0.5408762698280217, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7035944261661088, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5541354870738728, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4e0d\u5c5e\u4e8e\u544a\u8bc9\u624d\u5904\u7406\u7684\u60c5\u5f62\u662f____\u3002\nA. \u4fb5\u5360\u7f6a\nB. \u4fae\u8fb1\u7f6a\u672a\u4e25\u91cd\u5371\u5bb3\u793e\u4f1a\u79e9\u5e8f\u548c\u56fd\u5bb6\u5229\u76ca\u7684\nC. \u8650\u5f85\u7f6a\u81f4\u4f7f\u88ab\u5bb3\u4eba\u91cd\u4f24\u3001\u6b7b\u4ea1\u7684\nD. \u66b4\u529b\u5e72\u6d89\u5a5a\u59fb\u81ea\u7531\u7f6a\uff0c\u672a\u81f4\u4f7f\u88ab\u5bb3\u4eba\u6b7b\u4ea1\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8818507257546687, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u56e0\u76d7\u7a83\u7f6a\u6848\u53d1\u88ab\u6355\uff0c\u5728\u4fa6\u67e5\u4eba\u5458\u5bf9\u5176\u5ba1\u8baf\u671f\u95f4\uff0c\u7532\u4ea4\u4ee3\u4e86\u81ea\u5df1\u4e0e\u4e59\u5728\u4ea4\u901a\u5de5\u5177\u4e0a\u62a2\u52ab3\u4e07\u5143\u7684\u72af\u7f6a\u4e8b\u5b9e\uff0c\u5e76\u534f\u52a9\u4fa6\u67e5\u673a\u5173\u5c06\u4e59\u6293\u83b7\u3002\u5bf9\u7532\u7684\u62a2\u52ab\u7f6a____\u3002\nA. \u53ef\u4ee5\u4ece\u8f7b\u6216\u8005\u51cf\u8f7b\u5904\u7f5a\nB. \u53ef\u4ee5\u51cf\u8f7b\u6216\u8005\u514d\u9664\u5904\u7f5a\nC. \u53ef\u4ee5\u514d\u9664\u5904\u7f5a\nD. \u5e94\u5f53\u51cf\u8f7b\u6216\u8005\u514d\u9664\u5904\u7f5a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3655991109681543, "meta-math/MetaMath-Mistral-7B": 0.3632935652811919, "itpossible/Chinese-Mistral-7B-v0.1": 0.35347162922091135, "HuggingFaceH4/zephyr-7b-beta": 0.989654868079166, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5501667453606542, "meta-llama/Meta-Llama-3-8B": 0.36150852560561064, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4e0b\u5217\u72af\u7f6a\u5f62\u6001\u4e2d\uff0c\u9002\u7528\u201c\u4ece\u4e00\u91cd\u5904\u65ad\u201d\u539f\u5219\u4e88\u4ee5\u8bba\u5904\u7684\u662f____\u3002\nA. \u7ed3\u679c\u52a0\u91cd\u72af\nB. \u7ee7\u7eed\u72af\nC. \u60f3\u8c61\u7ade\u5408\u72af\nD. \u5438\u6536\u72af\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.28966338381871215, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u5c5e\u4e8e\u65e0\u56e0\u884c\u4e3a\u7684\u662f____\u3002\nA. \u51fa\u552e\u623f\u5c4b\nB. \u6c47\u7968\u7684\u51fa\u7968\nC. \u8d60\u4e0e\u7535\u8111\nD. \u7ee7\u627f\u9057\u4ea7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3354456100429363, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7327867445245662}}, {"question": "\u4e0e\u300a\u5927\u6e05\u5f8b\u4f8b\u300b\u76f8\u6bd4\uff0c\u300a\u5927\u6e05\u73b0\u884c\u5211\u5f8b\u300b\u7684\u53d8\u5316\u4e0d\u5305\u62ec____\u3002\nA. \u53d6\u6d88\u4e86\u516d\u90e8\u5206\u7bc7\u7684\u6cd5\u5178\u7f16\u7e82\u4f53\u4f8b\nB. \u5220\u9664\u4e86\u201c\u5341\u6076\u201d\u91cd\u7f6a\u7b49\u5185\u5bb9\nC. \u5bf9\u4e8e\u5a5a\u59fb\u3001\u7ee7\u627f\u3001\u7530\u5b85\u3001\u94b1\u503a\u7b49\u7eaf\u5c5e\u6c11\u4e8b\u6027\u8d28\u7684\u884c\u4e3a\u4e0d\u518d\u79d1\u5211\nD. \u589e\u52a0\u4e86\u4e00\u4e9b\u65b0\u7f6a\u540d\uff0c\u8bf8\u5982\u59a8\u5bb3\u56fd\u4ea4\u7f6a\u3001\u59a8\u5bb3\u9009\u4e3e\u7f6a\u3001\u79c1\u94f8\u94f6\u5143\u7f6a\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u5211\u6cd5\u300b\u7b2c115\u6761\u7b2c2\u6b3e\u89c4\u5b9a\u201c\u8fc7\u5931\u72af\u524d\u6b3e\u7f6a\u7684\u2026\u2026\u201d\uff0c\u5c5e\u4e8e____\u3002\nA. \u7b80\u5355\u7f6a\u72b6\nB. \u53d9\u660e\u7f6a\u72b6\nC. \u7a7a\u767d\u7f6a\u72b6\nD. \u5f15\u8bc1\u7f6a\u72b6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34239623393788804, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u5c5e\u4e8e\u4ee3\u7406\u60c5\u5f62\u7684\u662f____\u3002\nA. \u7532\u59d4\u6258\u4e59\u628a\u81ea\u5df1\u7684\u5b69\u5b50\u4ece\u5e7c\u513f\u56ed\u63a5\u56de\u6765\nB. \u4e19\u63a5\u53d7\u4e01\u7684\u59d4\u6258\uff0c\u4ee5\u4e01\u7684\u540d\u4e49\u4e0e\u620a\u7b7e\u8ba2\u4e70\u5356\u5408\u540c\nC. \u8d75\u67d0\u63a5\u53d7\u94b1\u67d0\u7684\u59d4\u6258\uff0c\u5c06\u94b1\u67d0\u4e0d\u63a5\u53d7\u7f14\u7ea6\u8981\u6c42\u7684\u610f\u601d\u8868\u793a\u5411\u5b59\u67d0\u4f5c\u4e86\u56de\u590d\nD. \u8fdc\u5927\u516c\u53f8\u7531\u6cd5\u5b9a\u4ee3\u8868\u4eba\u674e\u67d0\u4e0e\u5b8f\u8fdc\u516c\u53f8\u6cd5\u5b9a\u4ee3\u8868\u4eba\u5468\u67d0\u7b7e\u8ba2\u52a0\u5de5\u627f\u63fd\u5408\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4150345784019574, "meta-math/MetaMath-Mistral-7B": 0.6493938225869548, "itpossible/Chinese-Mistral-7B-v0.1": 0.7176399883429826, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.711383299390238, "meta-llama/Meta-Llama-3-8B": 0.48280112859829744, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.39008525750841133}}, {"question": "\u7532\u3001\u4e59\u3001\u4e19\u4e09\u4eba\u5206\u522b\u51fa\u8d4430\u4e07\u5143\u300130\u4e07\u5143\u300140\u4e07\u5143\u8d2d\u4e70\u91cd\u578b\u8d27\u8f66\u4e00\u8f86\uff0c\u4ece\u4e8b\u957f\u9014\u8fd0\u8f93\u3002\u4e09\u4eba\u7ea6\u5b9a\uff1a\u7532\u8d1f\u8d23\u9a7e\u9a76\uff0c\u4e59\u8d1f\u8d23\u5bf9\u8f66\u7ba1\u7406\u7ef4\u62a4\uff0c\u800c\u4e19\u8d1f\u8d23\u62db\u63fd\u4e1a\u52a1\uff0c\u4e143\u5e74\u5185\u4e0d\u5f97\u5206\u5272\u5171\u6709\u7269\u3002\u4e09\u4eba\u5bf9\u5176\u4ed6\u4e8b\u9879\u672a\u4f5c\u7ea6\u5b9a\u3002\u7532\u3001\u4e19\u4e8c\u4eba\u672a\u7ecf\u4e59\u7684\u540c\u610f\uff0c\u64c5\u81ea\u7b7e\u8ba2\u62b5\u62bc\u5408\u540c\u5c06\u8be5\u8f66\u62b5\u62bc\u7ed9\u4e0d\u77e5\u60c5\u7684\u4e01\uff0c\u5e76\u529e\u7406\u4e86\u62b5\u62bc\u767b\u8bb0\u3002\u540e\u6765\uff0c\u7532\u56e0\u75b2\u52b3\u9a7e\u9a76\u53d1\u751f\u4e8b\u6545\uff0c\u9020\u6210\u884c\u4eba\u620a\u53d7\u4f24\u3002\u5bf9\u6b64\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u7532\u3001\u4e59\u3001\u4e19\u5bf9\u4e8e\u8d27\u8f66\u4eab\u6709\u7684\u6743\u5229\u4efd\u989d\uff0c\u5e94\u5f53\u6309\u7167\u51fa\u8d44\u989d\u786e\u5b9a\nB. \u620a\u53ea\u80fd\u8981\u6c42\u7532\u8d54\u507f\u635f\u5931\nC. \u4e01\u5584\u610f\u53d6\u5f97\u8d27\u8f66\u7684\u62b5\u62bc\u6743\nD. \u7532\u3001\u4e59\u3001\u4e19\u53ef\u4ee5\u968f\u65f6\u8bf7\u6c42\u5206\u5272\u5171\u6709\u7269\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.47321646225871894, "meta-math/MetaMath-Mistral-7B": 0.5817114796349813, "itpossible/Chinese-Mistral-7B-v0.1": 0.29539205153207015, "HuggingFaceH4/zephyr-7b-beta": 0.9608189162395219, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.57718281063504, "meta-llama/Meta-Llama-3-8B": 0.39418479166418224, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.878995986559357}}, {"question": "\u5e7c\u513f\u56ed\u6559\u5e08\u7532\u5728\u5e7c\u513f\u56ed\u536b\u751f\u95f4\u591a\u6b21\u7528\u9488\u523a\u6233\u8096\u67d0\u7b4910\u4f59\u540d\u5e7c\u513f\u7684\u81c0\u90e8\uff0c\u867d\u672a\u9020\u6210\u4f24\u5bb3\u540e\u679c\uff0c\u4f46\u60c5\u8282\u5341\u5206\u6076\u52a3\u3002\u7532\u7684\u884c\u4e3a\u5e94\u8ba4\u5b9a\u4e3a____\u3002\nA. \u4fae\u8fb1\u7f6a\nB. \u7325\u4eb5\u513f\u7ae5\u7f6a\nC. \u8650\u5f85\u88ab\u76d1\u62a4\u3001\u770b\u62a4\u4eba\u7f6a\nD. \u6545\u610f\u4f24\u5bb3\u7f6a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6211\u56fd\u5211\u6cd5\u4e2d\u7f6a\u5211\u6cd5\u5b9a\u539f\u5219\u7684\u7406\u89e3\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u7b80\u5355\u7f6a\u72b6\u56e0\u7f3a\u4e4f\u660e\u786e\u6027\u4e0d\u7b26\u5408\u7f6a\u5211\u6cd5\u5b9a\u539f\u5219\nB. \u5c06\u4e60\u60ef\u6cd5\u89c6\u4e3a\u5211\u6cd5\u7684\u6e0a\u6e90\u4e0d\u8fdd\u53cd\u7f6a\u5211\u6cd5\u5b9a\u539f\u5219\nC. \u7f6a\u5211\u6cd5\u5b9a\u539f\u5219\u4e0d\u5141\u8bb8\u6709\u5229\u4e8e\u88ab\u544a\u4eba\u7684\u65b0\u6cd5\u6eaf\u53ca\u65e2\u5f80\nD. \u7f6a\u5211\u6cd5\u5b9a\u539f\u5219\u4e2d\u7684\u201c\u6cd5\u201d\u4e0d\u5305\u62ec\u884c\u653f\u6cd5\u89c4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3358514617492744, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.44818171645488536, "HuggingFaceH4/zephyr-7b-beta": 0.5302497869301047, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u3001\u4e59\u540c\u4e3a\u513f\u7ae5\u73a9\u5177\u751f\u4ea7\u5546\u3002\u516d\u4e00\u8282\u524d\u5915\uff0c\u4e19\u4e0e\u7532\u5546\u8c08\u8fdb\u8d27\u4e8b\u5b9c\u3002\u4e59\u77e5\u9053\u540e\u5411\u4e19\u63d0\u51fa\u66f4\u4f18\u60e0\u6761\u4ef6\uff0c\u5e76\u6307\u4f7f\u4e01\u5047\u501f\u8ba2\u8d27\u4e0e\u7532\u63a5\u6d3d\uff0c\u62a5\u4ef7\u9ad8\u4e8e\u4e19\u4ee5\u963b\u6b62\u7532\u4e0e\u4e19\u7b7e\u7ea6\u3002\u4e19\u7ecf\u6bd4\u8f83\u4e0e\u4e59\u7b7e\u7ea6\uff0c\u4e01\u968f\u5373\u7ec8\u6b62\u4e0e\u7532\u7684\u8c08\u5224\uff0c\u7532\u56e0\u6b64\u906d\u53d7\u635f\u5931\u3002\u5bf9\u6b64\uff0c\u4e0b\u5217\u54ea\u4e00\u8bf4\u6cd5\u662f\u6b63\u786e\u7684?____\nA. \u4e59\u5e94\u5bf9\u7532\u627f\u62c5\u7f14\u7ea6\u8fc7\u5931\u8d23\u4efb\nB. \u4e19\u5e94\u5bf9\u7532\u627f\u62c5\u7f14\u7ea6\u8fc7\u5931\u8d23\u4efb\nC. \u4e01\u5e94\u5bf9\u7532\u627f\u62c5\u7f14\u7ea6\u8fc7\u5931\u8d23\u4efb\nD. \u4e59\u3001\u4e19\u3001\u4e01\u65e0\u987b\u5bf9\u7532\u627f\u62c5\u7f14\u7ea6\u8fc7\u5931\u8d23\u4efb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.41714136208229385, "meta-math/MetaMath-Mistral-7B": 0.7078945050856347, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4216209395983889, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3818183045785905, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u5c06\u5176\u5bf9\u4e59\u4eab\u6709\u768410\u4e07\u5143\u8d27\u6b3e\u503a\u6743\u8f6c\u8ba9\u7ed9\u4e19\uff0c\u4e19\u518d\u8f6c\u8ba9\u7ed9\u4e01\uff0c\u4e59\u5747\u4e0d\u77e5\u60c5\u3002\u4e59\u5c06\u503a\u52a1\u8f6c\u8ba9\u7ed9\u620a\uff0c\u5f97\u5230\u4e86\u7532\u7684\u540c\u610f\u3002\u4e01\u8981\u6c42\u4e59\u5c65\u884c\u503a\u52a1\uff0c\u4e59\u4ee5\u5176\u4e0d\u77e5\u60c5\u4e3a\u7531\u6297\u8fa9\u3002\u4e0b\u5217\u54ea\u4e00\u8868\u8ff0\u662f\u6b63\u786e\u7684?____\nA. \u7532\u5c06\u503a\u6743\u8f6c\u8ba9\u7ed9\u4e19\u7684\u884c\u4e3a\u65e0\u6548\nB. \u4e19\u5c06\u503a\u6743\u8f6c\u8ba9\u7ed9\u4e01\u7684\u884c\u4e3a\u65e0\u6548\nC. \u4e59\u5c06\u503a\u52a1\u8f6c\u8ba9\u7ed9\u620a\u7684\u884c\u4e3a\u65e0\u6548\nD. \u5982\u4e59\u6e05\u507f10\u4e07\u5143\u503a\u52a1\uff0c\u5219\u4eab\u6709\u5bf9\u620a\u7684\u6c42\u507f\u6743\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4032266808331313, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7525967005985389}}, {"question": "\u4f2a\u8bc1\u7f6a\u53ea\u80fd\u53d1\u751f\u5728____\u3002\nA. \u7acb\u6848\u4fa6\u67e5\u4ee5\u524d\nB. \u8d77\u8bc9\u4e4b\u540e\nC. \u7acb\u6848\u3001\u4fa6\u67e5\u3001\u8d77\u8bc9\u548c\u5ba1\u5224\u8fc7\u7a0b\u4e2d\nD. \u5224\u51b3\u5ba3\u544a\u4ee5\u540e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5664883049278057, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5859786962643325, "HuggingFaceH4/zephyr-7b-beta": 0.9875261935407025, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6487062281175797, "meta-llama/Meta-Llama-3-8B": 0.8604546041538427, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.79605508328734}}, {"question": "\u82f1\u8bed\u540d\u8bcd\u201clab\u201d(\u5b9e\u9a8c\u5ba4)\u539f\u6765\u7684\u5f62\u5f0f\u662f\u201claboratory\u201d\uff0c\u8fd9\u5728\u8bcd\u7684\u5f62\u6210\u65b9\u5f0f\u4e0a\u5c5e\u4e8e____\u3002\nA. \u76f4\u63a5\u6210\u8bcd\nB. \u53d8\u5f62\u6210\u8bcd\nC. \u53d8\u6027\u6210\u8bcd\nD. \u9006\u5e8f\u6210\u8bcd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u97f3\u4f4d\u662f____\u3002\nA. \u6700\u5c0f\u7684\u8bed\u97f3\u8bed\u4e49\u7ed3\u5408\u4f53\nB. \u4e00\u4e2a\u8bed\u97f3\u7cfb\u7edf\u4e2d\u80fd\u533a\u522b\u610f\u4e49\u7684\u6700\u5c0f\u8bed\u97f3\u5355\u4f4d\nC. \u8bed\u8a00\u4e2d\u6700\u5c0f\u7684\u80fd\u533a\u522b\u610f\u4e49\u7684\u8bed\u97f3\u7279\u5f81\u5355\u4f4d\nD. \u8bed\u8a00\u4e2d\u6709\u533a\u522b\u6027\u7279\u5f81\u7684\u6700\u5c0f\u8bed\u97f3\u5355\u4f4d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2885095257630687, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bed\u8a00\u4e2d\uff0c\u5c5e\u4e8e\u5370\u6b27\u8bed\u7cfb\u62c9\u4e01\u8bed\u65cf\u7684\u8bed\u8a00\u662f____\u3002\nA. \u82f1\u8bed\nB. \u4fc4\u8bed\nC. \u5fb7\u8bed\nD. \u6cd5\u8bed\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7060035892778568, "meta-math/MetaMath-Mistral-7B": 0.7392230041418599, "itpossible/Chinese-Mistral-7B-v0.1": 0.3626062801770276, "HuggingFaceH4/zephyr-7b-beta": 0.9894869373681853, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40101791712441026, "meta-llama/Meta-Llama-3-8B": 0.6147667719948102, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.747651356996926}}, {"question": "\u300a\u53f2\u8bb0\u00b7\u9ad8\u7956\u672c\u7eaa\u300b\uff1a\u201c\u4eca\u5219\u6765\uff0c\u6c9b\u516c\u6050\u4e0d\u5f97\u6709\u6b64\u3002\u201d\u53e5\u4e2d\u201c\u5219\u201d\u7684\u7528\u6cd5\u662f____\u3002\nA. \u8868\u793a\u627f\u63a5\nB. \u8868\u793a\u8f6c\u6298\nC. \u8868\u793a\u5047\u8bbe\nD. \u8868\u793a\u56e0\u679c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3468666740605408, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6920176270096857}}, {"question": "\u300a\u56db\u4e16\u540c\u5802\u300b\u4e2d\u7684\u51a0\u6653\u8377\u662f____\u3002\nA. \u8001\u6d3e\u5e02\u6c11\u7684\u5f62\u8c61\nB. \u9769\u547d\u8005\u7684\u5f62\u8c61\nC. \u6b63\u76f4\u7684\u77e5\u8bc6\u5206\u5b50\u5f62\u8c61\nD. \u6c11\u65cf\u8d25\u7c7b\u7684\u5f62\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9273723441197411, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u5851\u201d\u8fd9\u4e2a\u5b57\u7684\u97f3\u8282\u7684\u58f0\u6bcd\u662f____\u3002\nA. sh\nB. x\nC. s\nD. \u96f6\u58f0\u6bcd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38357722138264766, "meta-math/MetaMath-Mistral-7B": 0.5294346632427401, "itpossible/Chinese-Mistral-7B-v0.1": 0.2986334267609957, "HuggingFaceH4/zephyr-7b-beta": 0.7203842762417153, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40195574520453115, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u8bba\u8bed\u00b7\u8ff0\u800c\u300b\uff1a\u201c\u82e5\u5723\u4e0e\u4ec1\uff0c\u5219\u543e\u5c82\u6562?\u6291\u4e3a\u4e4b\u4e0d\u538c\uff0c\u8bf2\u4eba\u4e0d\u5026\uff0c\u5219\u53ef\u8c13\u4e91\u5c14\u5df2\u77e3\u3002\u201d\u53e5\u4e2d\u201c\u6291\u201d\u7684\u7528\u6cd5\u662f____\u3002\nA. \u8868\u793a\u5047\u8bbe\nB. \u8868\u793a\u8f6c\u6298\nC. \u8868\u793a\u539f\u56e0\nD. \u8868\u793a\u76ee\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35540643906208824, "meta-math/MetaMath-Mistral-7B": 0.7141736143866645, "itpossible/Chinese-Mistral-7B-v0.1": 0.547690360045609, "HuggingFaceH4/zephyr-7b-beta": 0.9691282627307404, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47139485408072623, "meta-llama/Meta-Llama-3-8B": 0.6235091617850893, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9176095795004438}}, {"question": "\u4e0b\u5217\u6709\u6b67\u4e49\u7684\u4e00\u9879\u662f____\u3002\nA. \u8fdb\u53e3\u6c7d\u8f66\nB. \u8def\u8fb9\u79cd\u7740\u6811\nC. \u6d17\u5f97\u5e72\u51c0\nD. \u54ac\u6b7b\u4e86\u730e\u4eba\u7684\u9e21\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3396322224598924, "meta-math/MetaMath-Mistral-7B": 0.4097933037728859, "itpossible/Chinese-Mistral-7B-v0.1": 0.40573899958451787, "HuggingFaceH4/zephyr-7b-beta": 0.9997858452748444, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7392318622405337, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8997728540904817}}, {"question": "[p][p\u2018][b][m]\u56db\u4e2a\u97f3\u7d20\u7684\u533a\u522b\u4e3b\u8981\u662f____\u3002\nA. \u6e05\u6d4a\nB. \u53d1\u97f3\u65b9\u6cd5\nC. \u53d1\u97f3\u90e8\u4f4d\nD. \u9001\u6c14\u4e0e\u5426\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3142819961202565, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u662f\u4e2d\u56fd\u53e4\u4ee3\u8499\u5b66\u6559\u80b2\u6240\u91c7\u7528\u7684\u4e00\u79cd\u8bc6\u5b57\u8bfe\u672c\uff0c\u7531\u5468\u5174\u55e3\u7f16\u64b0\u800c\u6210\u3002\nA. \u300a\u4e09\u5b57\u7ecf\u300b\nB. \u300a\u5f1f\u5b50\u89c4\u300b\nC. \u300a\u767e\u5bb6\u59d3\u300b\nD. \u300a\u5343\u5b57\u6587\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7660683976269084, "meta-math/MetaMath-Mistral-7B": 0.8966917942063948, "itpossible/Chinese-Mistral-7B-v0.1": 0.865808465972603, "HuggingFaceH4/zephyr-7b-beta": 0.9999160577024228, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.95815426384232, "meta-llama/Meta-Llama-3-8B": 0.4638260884196924, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5362\u820d\u90a3\u5927\u4f5b\u662f\u77f3\u7a9f\u96d5\u5851\u4e2d____\u7684\u4ee3\u8868\u4f5c\u3002\nA. \u4e91\u5188\u77f3\u7a9f\nB. \u9f99\u95e8\u77f3\u7a9f\nC. \u83ab\u9ad8\u7a9f\nD. \u9ea6\u79ef\u5c71\u77f3\u7a9f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32160936023490916, "meta-math/MetaMath-Mistral-7B": 0.46601034252379464, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5599722259862949, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u76ee\u524d\u6700\u901a\u7528\u7684\u6977\u4e66\u5370\u5237\u4f53\u662f____\u3002\nA. \u5b8b\u4f53\nB. \u4eff\u5b8b\u4f53\nC. \u6977\u4f53\nD. \u9ed1\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u53e5\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u5bbe\u8bed\u524d\u7f6e\u7684\u662f____\u3002\nA. \u59dc\u6c0f\u4f55\u538c\u4e4b\u6709?\nB. \u65a5\u9dc3\u7b11\u4e4b\u66f0\uff1a\u201c\u5f7c\u4e14\u595a\u9002\u4e5f?\u201d\nC. \u5c45\u5219\u66f0\uff1a\u201c\u4e0d\u543e\u77e5\u4e5f!\u201d\nD. \u80e1\u4e0d\u89c1\u6211\u4e8e\u738b?\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4577664813587173, "meta-math/MetaMath-Mistral-7B": 0.5940327223058192, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8522207085257771, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5451708460875703, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.2986334100721063}}, {"question": "\u201c\u5458\u3001\u53ef\u3001\u4e61\u3001\u5206\u3001\u5c55\u3001\u4ece\u201d\u4e2d\u5305\u542b\u7684\u81ea\u7531\u8bed\u7d20\u662f____\u3002\nA. \u4e61\u3001\u5206\u3001\u4ece\nB. \u53ef\u3001\u5206\u3001\u5c55\nC. \u5458\u3001\u4e61\u3001\u5206\nD. \u5458\u3001\u53ef\u3001\u4e61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.45985432891590383}}, {"question": "\u300a\u675c\u5341\u5a18\u6012\u6c89\u767e\u5b9d\u7bb1\u300b\u51fa\u81ea____\u3002\nA. \u300a\u4f20\u5947\u300b\nB. \u300a\u804a\u658b\u5fd7\u5f02\u300b\nC. \u201c\u4e09\u8a00\u201d\nD. \u201c\u4e8c\u62cd\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.33482349867891054, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.575187002447216, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5267\u4f5c\u5bb6____\u88ab\u8a89\u4e3a\u201c\u4e2d\u56fd\u5341\u516d\u4e16\u7eaa\u7684\u838e\u58eb\u6bd4\u4e9a\u201d\u3002\nA. \u5173\u6c49\u537f\nB. \u767d\u6734\nC. \u6c64\u663e\u7956\nD. \u9a6c\u81f4\u8fdc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.30601362565976303, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6921793255245757, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5246735333761017, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u4e09\u56fd\u5fd7\u00b7\u8700\u4e66\u00b7\u8bf8\u845b\u4eae\u4f20\u300b\uff1a\u201c\u6bcf\u81ea\u6bd4\u4e8e\u7ba1\u4ef2\u3001\u4e50\u6bc5\uff0c\u65f6\u4eba\u83ab\u4e4b\u8bb8\u4e5f\u3002\u201d\u53e5\u4e2d\u201c\u4e8e\u201d\u7684\u7528\u6cd5\u662f____\u3002\nA. \u8868\u5bf9\u8c61\nB. \u8868\u6bd4\u8f83\nC. \u8868\u539f\u56e0\nD. \u8868\u65bd\u4e8b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u672c\u8349\u7eb2\u76ee\u300b\u7684\u4f5c\u8005\u662f____\u674e\u65f6\u73cd\u3002\nA. \u5357\u5b8b\u4eba\nB. \u660e\u671d\u4eba\nC. \u5143\u671d\u4eba\nD. \u6e05\u671d\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8772201321946094, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9478559999091687, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9309087745704389}}, {"question": "\u201c\u6211\u3001\u4f60\u3001\u4ed6\u201d\u662f____\u3002\nA. \u6307\u793a\u4ee3\u8bcd\nB. \u7591\u95ee\u4ee3\u8bcd\nC. \u4eba\u79f0\u4ee3\u8bcd\nD. \u540d\u8bcd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9500743930745127, "meta-math/MetaMath-Mistral-7B": 0.9981116455889872, "itpossible/Chinese-Mistral-7B-v0.1": 0.875635459990228, "HuggingFaceH4/zephyr-7b-beta": 0.9997933610631347, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9739558242798508, "meta-llama/Meta-Llama-3-8B": 0.983614319051332, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9996257123901443}}, {"question": "\u5173\u4e8e\u8bcd\u7684\u672c\u4e49\u548c\u57fa\u672c\u4e49\u7684\u5173\u7cfb\uff0c\u4e0b\u5217\u8868\u8ff0\u6b63\u786e\u7684\u662f____\u3002\nA. \u5b8c\u5168\u4e0d\u4e00\u81f4\nB. \u5b8c\u5168\u4e00\u81f4\nC. \u672c\u4e49\u6bd4\u57fa\u672c\u4e49\u66f4\u5e38\u7528\nD. \u57fa\u672c\u4e49\u6bd4\u672c\u4e49\u66f4\u5e38\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7003099987390724, "meta-math/MetaMath-Mistral-7B": 0.8914513248595953, "itpossible/Chinese-Mistral-7B-v0.1": 0.5847717490451392, "HuggingFaceH4/zephyr-7b-beta": 0.9985847220124083, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7390730908594955, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u73b0\u5728\u8f6e\u5230\u4f60\u8bf4\u4e86\u201d\u662f____\u3002\nA. \u8fde\u8c13\u53e5\nB. \u517c\u8bed\u53e5\nC. \u88ab\u52a8\u53e5\nD. \u53cc\u5bbe\u8bed\u53e5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3060136256597631, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.37491960840523747, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u961f\u201d\u4e0e\u201c\u5760\u201d\u662f____\u3002\nA. \u53e4\u4eca\u5b57\nB. \u5f02\u4f53\u5b57\nC. \u901a\u5047\u5b57\nD. \u7e41\u7b80\u5b57\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.41605133135086875}}, {"question": "d\u3001t\u3001n\u3001l\u56db\u4e2a\u8f85\u58f0\u7684\u53d1\u97f3\u90e8\u4f4d\u662f____\u3002\nA. \u820c\u5c16\u524d\nB. \u820c\u9762\nC. \u820c\u5c16\u4e2d\nD. \u820c\u5c16\u540e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u84dd\u5370\u82b1\u5e03\u662f\u4e00\u79cd\u4f20\u7edf\u7684\u6c11\u95f4\u7eba\u7ec7\u5370\u67d3\u5de5\u827a\u54c1\u3002\u84dd\u5370\u82b1\u5e03\u5370\u5236\u65b9\u6cd5\u59cb\u4e8e____\u3002\nA. \u6c49\u4ee3\nB. \u9b4f\u664b\u65f6\u671f\nC. \u5510\u4ee3\nD. \u5b8b\u4ee3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7a0b\u5a74\u3001\u516c\u5b59\u6775\u81fc\u662f____\u4e2d\u7684\u4eba\u7269\u3002\nA. \u300a\u8d75\u6c0f\u5b64\u513f\u300b\nB. \u300a\u6740\u72d7\u8bb0\u300b\nC. \u300a\u5899\u5934\u9a6c\u4e0a\u300b\nD. \u300a\u5cb3\u9633\u697c\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2777229469001534, "meta-math/MetaMath-Mistral-7B": 0.31283638571410965, "itpossible/Chinese-Mistral-7B-v0.1": 0.5754010051247702, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4861861135360488, "meta-llama/Meta-Llama-3-8B": 0.5893012300888714, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u4e0d\u662f\u53e4\u5178\u4e3b\u4e49\u620f\u5267\u7684\u4ee3\u8868\u4eba\u7269\u3002\nA. \u9ad8\u4e43\u4f9d\nB. \u62c9\u8f9b\nC. \u838e\u58eb\u6bd4\nD. \u83ab\u91cc\u54c0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u521b\u4f5c\u7684\u300a\u5927\u536b\u300b\u662f\u7b2c\u4e00\u4ef6\u590d\u5174\u4e86\u53e4\u4ee3\u88f8\u4f53\u96d5\u50cf\u4f20\u7edf\u7684\u4f5c\u54c1\u3002\nA. \u5409\u8d1d\u5c14\u8482\nB. \u5e03\u9c81\u5185\u83b1\u65af\u57fa\nC. \u591a\u7eb3\u6cf0\u7f57\nD. \u9a6c\u8428\u4e54\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3418241299464301, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u838e\u58eb\u6bd4\u4e9a\u7684\u300a\u674e\u5c14\u738b\u300b\u662f____\u3002\nA. \u60b2\u5267\nB. \u559c\u5267\nC. \u6b63\u5267\nD. \u519c\u6751\u5267\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4105053194100906, "meta-math/MetaMath-Mistral-7B": 0.7793405690942126, "itpossible/Chinese-Mistral-7B-v0.1": 0.8981554658225221, "HuggingFaceH4/zephyr-7b-beta": 0.6446823795495809, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5421114721996542, "meta-llama/Meta-Llama-3-8B": 0.9808351718676082, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9423899377415987}}, {"question": "\u5728\u897f\u65b9\u97f3\u4e50\u5386\u53f2\u4e0a\u88ab\u8a89\u4e3a\u201c\u4ea4\u54cd\u4e50\u4e4b\u7236\u201d\u7684\u662f____\u3002\nA. \u8d1d\u591a\u82ac\nB. \u83ab\u624e\u7279\nC. \u6d77\u987f\nD. \u8212\u4f2f\u7279\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5444768322747208, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "1912\u5e74\u6210\u7acb\u4e8e\u897f\u5b89\u7684\u79e6\u8154\u6539\u826f\u56e2\u4f53\u662f____\u3002\nA. \u6613\u4fd7\u793e\nB. \u6606\u5267\u4f20\u4e60\u6240\nC. \u5bcc\u8fde\u6210\u793e\nD. \u4f36\u5de5\u5b66\u793e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3075818303735862, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u6789\u51dd\u7709\u300b\u662f\u7535\u89c6\u5267____\u7684\u4e3b\u9898\u66f2\u3002\nA. \u300a\u7ea2\u697c\u68a6\u300b\nB. \u300a\u6c34\u6d52\u4f20\u300b\nC. \u300a\u56db\u4e16\u540c\u5802\u300b\nD. \u300a\u5c0f\u8857\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.37354501646787847, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4124578775795746, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4666435603894331}}, {"question": "\u300a\u7f8a\u6cc9\u6751\u300b\u3001\u300a\u72d7\u5360\u9a6c\u69fd\u300b\u662f\u6587\u827a\u590d\u5174\u65f6\u671f____\u7684\u4ee3\u8868\u4f5c\u3002\nA. \u6b4c\u5fb7\nB. \u6613\u535c\u751f\nC. \u6d1b\u535c.\u5fb7.\u7ef4\u8fe6\nD. \u5a01\u5ec9.\u838e\u58eb\u6bd4\u4e9a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4696892114365, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5fb7\u56fd\u8868\u73b0\u4e3b\u4e49\u5267\u4f5c\u5bb6\u607a\u6492\u7684\u4ee3\u8868\u4f5c\u662f____\u3002\nA. \u300a\u9b3c\u9b42\u594f\u9e23\u66f2\u300b\nB. \u300a\u4ece\u6e05\u6668\u5230\u5348\u591c\u300b\nC. \u300a\u53bb\u5927\u9a6c\u58eb\u9769\u300b\nD. \u300a\u4e07\u80fd\u673a\u5668\u4eba\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.33424000363035195, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u521b\u4f5c\u98ce\u683c\u88ab\u8a89\u4e3a\u201c\u97f3\u4e50\u82ad\u857e\u201d\u7684\u82ad\u857e\u821e\u7f16\u5bfc\u5927\u5e08\u662f____\u3002\nA. \u9a6c\u91cc\u4e4c\u65af.\u5f7c\u5b63\u5e15\nB. \u7c73\u6b47\u5c14.\u798f\u91d1\nC. \u4e54\u6cbb.\u5df4\u5170\u94a6\nD. \u5217\u592b.\u4f0a\u4e07\u8bfa\u592b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u94a6\u5dee\u5927\u81e3\u300b\u662f____\u521b\u4f5c\u7684\u3002\nA. \u8427\u4f2f\u7eb3\nB. \u5951\u8bc3\u592b\nC. \u6613\u535c\u751f\nD. \u679c\u6208\u7406\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.3833677325643038, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "____\u4e0d\u662f\u6c34\u534e\u7684\u4f5c\u54c1\u3002\nA. \u300a\u65e9\u6625\u4e8c\u6708\u300b\nB. \u300a\u6797\u5bb6\u94fa\u5b50\u300b\nC. \u300a\u571f\u5730\u300b\nD. \u300a\u767d\u6bdb\u5973\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u56e0\u5728\u300a\u7267\u7f8a\u5973\u300b\u3001\u300a\u5929\u5c71\u4e4b\u6625\u300b\u3001\u300a\u592a\u5b5c\u95f4\u594f\u66f2\u300b\u7b49\u821e\u8e48\u4e2d\u4ee5\u7cbe\u6e5b\u7684\u8868\u6f14\u6280\u827a\u4eab\u8a89\u4e2d\u5916\u7684\u4e2d\u56fd\u821e\u8e48\u5bb6\u662f____\u3002\nA. \u963f\u4f9d\u5410\u62c9\nB. \u767d\u6dd1\u6e58\nC. \u9648\u7231\u83b2\nD. \u5d14\u7f8e\u5584\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u5341\u4e94\u8d2f\u300b\u53c8\u53eb____\u3002\nA. \u300a\u6e05\u5fe0\u8c31\u300b\nB. \u300a\u53cc\u718a\u68a6\u300b\nC. \u300a\u5341\u4e94\u8d2f\u620f\u8a00\u6210\u5de7\u7978\u300b\nD. \u300a\u5948\u4f55\u5929\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u5434\u95e8\u56db\u5bb6\u201d\u4e0d\u5305\u62ec____\u3002\nA. \u6c88\u5468\nB. \u6587\u5f81\u660e\nC. \u5510\u5bc5\nD. \u5f90\u6e2d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3841126193695843, "meta-math/MetaMath-Mistral-7B": 0.44391743844858456, "itpossible/Chinese-Mistral-7B-v0.1": 0.3148300531811561, "HuggingFaceH4/zephyr-7b-beta": 0.43495988922323, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40415511509115004, "meta-llama/Meta-Llama-3-8B": 0.5547358243634991, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.46664358654600785}}, {"question": "\u62c9\u65af\u91d1\u7684\u8457\u4f5c\u5305\u62ec\u4ee5\u4e0b\u7684\uff1a____\nA. \u88c5\u9970\u7684\u57fa\u672c\u539f\u7406\nB. \u5efa\u7b51\u7684\u4e03\u76cf\u660e\u706f\nC. \u8bba\u8861\nD. \u5efa\u7b51\u5341\u4e66\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.34012114524656833, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6b4c\u5267\u300a\u5965\u83f2\u6b27\u300b\u7684\u4f5c\u8005\u8499\u7279\u5a01\u5c14\u7b2c\u662f____\u3002\nA. \u610f\u5927\u5229\u4eba\nB. \u5fb7\u56fd\u4eba\nC. \u5e0c\u814a\u4eba\nD. \u82f1\u56fd\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9709760441464304, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.998458621215341}}, {"question": "\u674e\u65af\u7279\u662f____\u7684\u4f5c\u66f2\u5bb6\u3001\u94a2\u7434\u5bb6\u3002\nA. \u5965\u5730\u5229\nB. \u5308\u7259\u5229\nC. \u5fb7\u56fd\nD. \u6cd5\u56fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44123398989748713, "meta-math/MetaMath-Mistral-7B": 0.6079974954917886, "itpossible/Chinese-Mistral-7B-v0.1": 0.9672381433644316, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6609139372425625, "meta-llama/Meta-Llama-3-8B": 0.9811950924541497, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9949630051038298}}, {"question": "\u300a\u6f58\u70c8\u58eb\u6295\u6d77\u300b\u3001\u300a\u9ed1\u7c4d\u51a4\u9b42\u300b\u5c5e\u4e8e____\u3002\nA. \u65f6\u88c5\u65b0\u620f\nB. \u8fde\u53f0\u672c\u620f\nC. \u53e4\u88c5\u65b0\u620f\nD. \u4eac\u5267\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5546\u4ee3\u9752\u94dc\u5668\u7684\u4ee3\u8868\u7eb9\u6837\u662f____\u3002\nA. \u9955\u992e\u7eb9\u3001\u5914\u7eb9\nB. \u7a83\u66f2\u7eb9\u3001\u73af\u5e26\u7eb9\nC. \u87e0\u87ad\u7eb9\nD. \u94ed\u6587\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.41098419480502263, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8416057408990706, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9144567004571983}}, {"question": "\u5f20\u62e9\u7aef\u7684\u300a\u6e05\u660e\u4e0a\u6cb3\u56fe\u300b\u63cf\u7ed8\u7684\u662f____\u90fd\u57ce\u7684\u98ce\u5149\u3002\nA. \u5317\u5b8b\nB. \u5357\u5b8b\nC. \u5357\u5510\nD. \u540e\u5468\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5540337094437799, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5245395275154601}}, {"question": "\u66f9\u79ba\u7684\u300a\u5317\u4eac\u4eba\u300b\u88ab\u7814\u7a76\u8005\u79f0\u4e3a\u4e2d\u56fd\u6700\u4f1f\u5927\u7684____\u3002\nA. \u559c\u5267\nB. \u60b2\u5267\nC. \u793e\u4f1a\u95ee\u9898\u5267\nD. \u6b63\u5267\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5143\u4ee3\u7684\u6f06\u5668\u54c1\u79cd\u8f83\u591a\uff0c\u4ee5____\u4e3a\u4e3b\uff0c\u6709\u5254\u7ea2\u3001\u5254\u9ec4\u3001\u5254\u9ed1\u3001\u5254\u5f69\u7b49\u4e0d\u540c\u7684\u8272\u5f69\u8fd0\u7528\u3002\nA. \u96d5\u6f06\nB. \u6217\u91d1\nC. \u87ba\u94bf\nD. \u5e73\u8131\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7220298874178153, "meta-math/MetaMath-Mistral-7B": 0.9065482315242005, "itpossible/Chinese-Mistral-7B-v0.1": 0.47925690555858935, "HuggingFaceH4/zephyr-7b-beta": 0.9985865797490542, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8585193248628898, "meta-llama/Meta-Llama-3-8B": 0.5470856940144372, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9854155586361377}}, {"question": "\u300a\u65b9\u73cd\u73e0\u300b\u3001\u300a\u897f\u671b\u957f\u5b89\u300b\u548c\u300a\u5b9d\u8239\u300b\u662f____\u7684\u4f5c\u54c1\u3002\nA. \u7530\u6c49\nB. \u90ed\u6cab\u82e5\nC. \u6b27\u9633\u4e88\u5029\nD. \u8001\u820d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5684773595794433, "meta-math/MetaMath-Mistral-7B": 0.8759054548584221, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9778169867902393, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6965837282252489, "meta-llama/Meta-Llama-3-8B": 0.9737466367662949, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9762020691170686}}, {"question": "\u300a\u5b89\u63d0\u6208\u6d85\u300b\u662f____\u7684\u4f5c\u54c1\u3002\nA. \u57c3\u65af\u5e93\u7f57\u65af\nB. \u7d22\u798f\u514b\u52d2\u65af\nC. \u963f\u91cc\u65af\u6258\u82ac\nD. \u6b27\u91cc\u5e87\u5f97\u65af\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4310339459413379, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.530200341456634, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7246861750237036}}, {"question": "\u6700\u65e9\u53d1\u5c55\u5de5\u4e1a\u8bbe\u8ba1\u7684\u5317\u6b27\u56fd\u5bb6\uff0c\u5f00\u521b\u5317\u6b27\u5de5\u4e1a\u8bbe\u8ba1\u4e4b\u5148\u6cb3\u7684\u662f____\u3002\nA. \u745e\u5178\nB. \u82ac\u5170\nC. \u632a\u5a01\nD. \u6ce2\u5170\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4822941332762553, "meta-math/MetaMath-Mistral-7B": 0.6633513455216706, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5818756488811256, "meta-llama/Meta-Llama-3-8B": 0.7705321744170311, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6219954008780314}}, {"question": "\u660e\u4f20\u5947\u300a\u76ee\u8fde\u6551\u6bcd\u529d\u5584\u8bb0\u300b\u662f____\u5199\u7684\u3002\nA. \u5468\u671d\u4fca\nB. \u9ad8\u6fc2\nC. \u8bb8\u81ea\u660c\nD. \u90d1\u81ea\u73cd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8718448410719633, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u7f00\u767d\u88d8\u300b\u662f____\u7684\u96c6\u9526\u9009\u672c\u3002\nA. \u6298\u5b50\u620f\nB. \u6caa\u5267\nC. \u4e8c\u4eba\u8f6c\nD. \u4e50\u5267\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.2801288226217134, "itpossible/Chinese-Mistral-7B-v0.1": 0.32871459371036227, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.39855634310426846, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u5c3c\u4f2f\u9f99\u6839\u7684\u6307\u73af\u300b\u662f____\u7684\u4f5c\u54c1\u3002\nA. \u5e03\u62c9\u59c6\u65af\nB. \u8096\u90a6\nC. \u5a01\u5c14\u7b2c\nD. \u74e6\u683c\u7eb3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.30817677628857404, "itpossible/Chinese-Mistral-7B-v0.1": 0.9741717191022814, "HuggingFaceH4/zephyr-7b-beta": 0.7255908731372779, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9944528177718934, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9485278748478227}}, {"question": "\u300a\u7f8e\u72c4\u4e9a\u300b\u548c\u300a\u5e0c\u6ce2\u5415\u6258\u65af\u300b\u662f____\u7684\u4ee3\u8868\u4f5c\u3002\nA. \u6b27\u91cc\u5e87\u5f97\u65af\nB. \u963f\u91cc\u65af\u6258\u82ac\nC. \u57c3\u65af\u5e93\u7f57\u65af\nD. \u7d22\u798f\u514b\u52d2\u65af\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.325455072595945, "meta-math/MetaMath-Mistral-7B": 0.40870095898383446, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4862640527805441, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8d1d\u591a\u82ac\u5171\u6709____\u90e8\u4ea4\u54cd\u66f2\u3002\nA. 5\nB. 7\nC. 9\nD. 11\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.45510571014075074, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47030692393245893, "meta-llama/Meta-Llama-3-8B": 0.8901616291671498, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6402258570778049}}, {"question": "____\u7684\u6b4c\u8bcd\u4e2d\u91c7\u7528\u4e86\u4e2d\u56fd\u5510\u4ee3\u8bd7\u4eba\u7684\u8bd7\u7bc7(\u674e\u767d\u7684\u300a\u60b2\u6b4c\u884c\u300b\u3001\u300a\u91c7\u83b2\u8c23\u300b\uff1b\u5b5f\u6d69\u7136\u7684\u300a\u5bbf\u4e1a\u5e08\u5c71\u623f\u5f85\u4e01\u5927\u4e0d\u81f3\u300b\u548c\u738b\u7ef4\u7684\u300a\u9001\u522b\u300b\u7b49\u4e03\u9996)\u3002\nA. \u300a\u73ab\u7470\u9a91\u58eb\u300b\nB. \u300a\u5927\u5730\u4e4b\u6b4c\u300b\nC. \u300a\u8352\u5c71\u4e4b\u591c\u300b\nD. \u300a\u4ea1\u513f\u4e4b\u6b4c\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34993237149116996, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.34478590299221606, "HuggingFaceH4/zephyr-7b-beta": 0.35961757839159497, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4201996519262058, "meta-llama/Meta-Llama-3-8B": 0.47432231883442416, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9505501706205202}}, {"question": "\u300a\u4e34\u5ddd\u5148\u751f\u6587\u96c6\u300b\u4e2d\u7684\u201c\u738b\u4e34\u5ddd\u201d\u7528\u7684\u662f____\u79f0\u8c13\u3002\nA. \u522b\u53f7\nB. \u5b98\u7235\nC. \u5730\u671b\nD. \u6392\u884c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5e7f\u4e1c\u98ce\u5473\u5c0f\u5403\u6709____\u3002\nA. \u732b\u8033\u6735\nB. \u4e94\u82b3\u658b\u7cbd\u5b50\nC. \u53cc\u76ae\u5976\nD. \u867e\u7206\u9cdd\u9762\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35070304913481487, "meta-math/MetaMath-Mistral-7B": 0.4219746937605935, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u56fd\u5185\u536b\u661f\u901a\u4fe1\u7f51\u6b63\u5f0f\u5efa\u6210\u4e8e____\u3002\nA. 1980\u5e74\nB. 1983\u5e74\nC. 1986\u5e74\nD. 1988\u5e74\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34624119845705303, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5423437170663881, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e1c\u6c49\u7531\u897f\u6c49\u738b\u5ba4\u5218\u79c0\u521b\u5efa\uff0c\u5efa\u90fd____\u3002\nA. \u957f\u5b89\nB. \u6d1b\u9633\nC. \u6210\u90fd\nD. \u5efa\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34675927014289815, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.7333071604239528, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5721776856047139, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6135205880912515}}, {"question": "\u5bf9\u6211\u56fd\u540d\u5c71\u7684\u63cf\u8ff0\u6b63\u786e\u7684\u662f____\u3002\nA. \u6cf0\u5c71\u6709\u201c\u5929\u4e0b\u7b2c\u4e00\u5c71\u201d\u4e4b\u79f0\uff0c\u88ab\u5217\u5165\u4e16\u754c\u81ea\u7136\u4e0e\u6587\u5316\u53cc\u91cd\u9057\u4ea7\nB. \u9ec4\u5c71\u6709\u201c\u4e94\u5cb3\u72ec\u79c0\u201d\u4e4b\u79f0\uff0c\u88ab\u5217\u5165\u4e16\u754c\u81ea\u7136\u4e0e\u6587\u5316\u53cc\u91cd\u9057\u4ea7\nC. \u534e\u5c71\u6700\u9ad8\u5cf0\u5357\u5cf0\u6d77\u62d41800\u7c73\uff0c\u81ea\u53e4\u4ee5\u9669\u95fb\u540d\u9050\u8fe9\nD. \u8861\u5c71\u6709\u4e03\u5341\u4e8c\u5cf0\uff0c\u4e09\u5927\u4e3b\u5cf0\u83b2\u82b1\u5cf0\u3001\u5929\u90fd\u5cf0\u3001\u795d\u878d\u5cf0\u90fd\u8d85\u8fc71800\u7c73\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.47020114546155056, "meta-math/MetaMath-Mistral-7B": 0.48824495791204714, "itpossible/Chinese-Mistral-7B-v0.1": 0.4165348555064769, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4976938153588114, "meta-llama/Meta-Llama-3-8B": 0.46601034339345865, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u56fd\u5386\u53f2\u4e0a\u7b2c\u4e00\u4e2a\u5974\u96b6\u5236\u56fd\u5bb6\u653f\u6743\u590f\u671d\u5efa\u7acb\u5728____\u3002\nA. \u664b\u5357\nB. \u6d1b\u9633\nC. \u5b89\u9633\nD. \u4e8c\u91cc\u5c97\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0a\u6d77\u8c6b\u56ed\u9c7c\u4e50\u69ad\u6709\u4e00\u4e0a\u5b9e\u4e0b\u7a7a\u7684\u5899\uff0c\u906e\u6321\u4e86\u539f\u6765\u6d41\u6c34\u8f83\u8fd1\u7684\u77ed\u5904\uff0c\u4ea7\u751f\u4e86\u6e90\u8fdc\u6d41\u957f\u7684\u6548\u679c\uff0c\u8fd9\u662f____\u7684\u795e\u6765\u4e4b\u7b14\u3002\nA. \u6291\u666f\nB. \u6846\u666f\nC. \u501f\u666f\nD. \u969c\u666f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u9738\u738b\u522b\u59ec\u201d\u662f____\u7684\u4ee3\u8868\u83dc\u3002\nA. \u82cf\u83dc\nB. \u9c81\u83dc\nC. \u6d59\u83dc\nD. \u6e58\u83dc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2821833983601387, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u7684\u201c\u56db\u5927\u540d\u781a\u201d\u4e2d\uff0c\u552f\u4e00\u4e0d\u7528\u5ca9\u77f3\u4e3a\u781a\u6750\u5236\u4f5c\u539f\u6599\u7684\u662f____\u3002\nA. \u7aef\u781a\nB. \u6b59\u781a\nC. \u6f84\u6ce5\u781a\nD. \u6d2e\u6cb3\u781a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40573901395608375, "meta-math/MetaMath-Mistral-7B": 0.6606419869893934, "itpossible/Chinese-Mistral-7B-v0.1": 0.31649016643535544, "HuggingFaceH4/zephyr-7b-beta": 0.9468986559269731, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7398568129089458, "meta-llama/Meta-Llama-3-8B": 0.3423962339378881, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9ed1\u9f99\u6c5f\u5728\u6211\u56fd\u5883\u5185\u7684\u6700\u957f\u652f\u6d41\u662f____\u3002\nA. \u677e\u82b1\u6c5f\nB. \u6d77\u6cb3\nC. \u9e2d\u7eff\u6c5f\nD. \u8fbd\u6cb3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7321703097227188, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u897f\u5468\u65f6\u7684\u5546\u9ad8\u662f\u89c1\u4e8e\u8457\u8ff0\u7684\u4e2d\u56fd\u53e4\u4ee3\u7b2c\u4e00\u4f4d____\u3002\nA. \u519c\u5b66\u5bb6\nB. \u533b\u5b66\u5bb6\nC. \u6570\u5b66\u5bb6\nD. \u5929\u6587\u5b66\u5bb6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40615263225222603, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.603657053793514, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3230435121167668, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u88ab\u8a89\u4e3a\u201c\u56db\u5927\u56fd\u5b9d\u201d\u7684\u6211\u56fd\u4e00\u7ea7\u4fdd\u62a4\u52a8\u7269\u662f____\u3002\nA. \u85cf\u7f9a\u7f8a\u3001\u767d\u5507\u9e7f\u3001\u767d\u9ccd\u8c5a\u3001\u91d1\u4e1d\u7334\nB. \u534e\u5357\u864e\u3001\u767d\u9ccd\u8c5a\u3001\u4e9a\u6d32\u8c61\u3001\u5927\u718a\u732b\nC. \u5927\u718a\u732b\u3001\u91d1\u4e1d\u7334\u3001\u767d\u9ccd\u8c5a\u3001\u767d\u5507\u9e7f\nD. \u91d1\u4e1d\u7334\u3001\u4e1c\u5317\u864e\u3001\u767d\u5507\u9e7f\u3001\u4e9a\u6d32\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4501929635718453, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3148300531811561, "HuggingFaceH4/zephyr-7b-beta": 0.7636824335410036, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6355675981681508, "meta-llama/Meta-Llama-3-8B": 0.4175059711973427, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.48870269849240183}}, {"question": "\u82f1\u56fd\u4e3a\u4e86\u6253\u5f00\u4e2d\u56fd\u5e02\u573a\uff0c\u5728____\u53d1\u52a8\u4e86\u9e26\u7247\u6218\u4e89\uff0c\u6e05\u671d\u6218\u8d25\u3002\nA. 1780\u5e74\nB. 1820\u5e74\nC. 1840\u5e74\nD. 1860\u5e74\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7322009930768202, "meta-math/MetaMath-Mistral-7B": 0.9734016325249605, "itpossible/Chinese-Mistral-7B-v0.1": 0.8890444129399822, "HuggingFaceH4/zephyr-7b-beta": 0.6707183537427645, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7461098620191071, "meta-llama/Meta-Llama-3-8B": 0.9140273602224056, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9372130301187679}}, {"question": "\u6211\u56fd\u73b0\u5b58\u6700\u53e4\u8001\u7684\u6728\u7ed3\u6784\u5efa\u7b51\u4f4d\u4e8e____\u3002\nA. \u5c71\u897f\u4e94\u53f0\u53bf\u5357\u7985\u5bfa\nB. \u5c71\u897f\u4e94\u53f0\u53bf\u4f5b\u5149\u5bfa\nC. \u5c71\u897f\u4e94\u53f0\u53bf\u5854\u9662\u5bfa\nD. \u5c71\u897f\u82ae\u57ce\u53bf\u5e7f\u4ec1\u738b\u5e99\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28012882262171335, "meta-math/MetaMath-Mistral-7B": 0.4536094404415808, "itpossible/Chinese-Mistral-7B-v0.1": 0.2575662067712908, "HuggingFaceH4/zephyr-7b-beta": 0.9637275489153081, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.37905047623827515, "meta-llama/Meta-Llama-3-8B": 0.29258944112561125, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6197193642715897}}, {"question": "____\u662f\u4f26\u6566\u7684\u6807\u5fd7\u6027\u5efa\u7b51\u4e4b\u4e00\uff0c\u6709\u82f1\u56fd\u6700\u5927\u7684\u949f\u3002\nA. \u4f26\u6566\u5854\u6865\nB. \u4f0a\u4e3d\u838e\u767d\u5854\nC. \u5723\u4fdd\u7f57\u6559\u5802\nD. \u6d77\u5fb7\u516c\u56ed\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6751005282516497, "meta-math/MetaMath-Mistral-7B": 0.9137797677384738, "itpossible/Chinese-Mistral-7B-v0.1": 0.6137511835335298, "HuggingFaceH4/zephyr-7b-beta": 0.9969392054328613, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8445059943505427, "meta-llama/Meta-Llama-3-8B": 0.6331435119400478, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9918872887757653}}, {"question": "\u65e0\u9521\u5bc4\u7545\u56ed\u56e0\u56ed\u5916\u60e0\u5c71\u7684\u666f\u8272\u800c\u663e\u5f97\u66f4\u52a0\u79c0\u4e3d\u3002\u4ea7\u751f\u8fd9\u4e00\u6548\u679c\u7684\u6784\u666f\u624b\u6cd5\u662f____\u3002\nA. \u501f\u666f\nB. \u6dfb\u666f\nC. \u6291\u666f\nD. \u969c\u666f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.487427125725444, "meta-math/MetaMath-Mistral-7B": 0.7581014504397221, "itpossible/Chinese-Mistral-7B-v0.1": 0.9013836143379836, "HuggingFaceH4/zephyr-7b-beta": 0.8174420556175105, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9074816516214514, "meta-llama/Meta-Llama-3-8B": 0.46054897151740054, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e16\u754c\u65c5\u6e38\u7ec4\u7ec7\u603b\u90e8\u8bbe\u5728____\u3002\nA. \u65e7\u91d1\u5c71\nB. \u66fc\u8c37\nC. \u6d77\u7259\nD. \u9a6c\u5fb7\u91cc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4628142780126266, "meta-math/MetaMath-Mistral-7B": 0.5854784027759558, "itpossible/Chinese-Mistral-7B-v0.1": 0.7466987499161033, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36448991345244786, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u68a6\u6eaa\u7b14\u8c08\u300b\u88ab\u79f0\u4e3a\u201c\u4e2d\u56fd\u79d1\u5b66\u53f2\u4e0a\u7684\u5750\u6807\u201d\uff0c\u5176\u4f5c\u8005\u662f____\u3002\nA. \u6c88\u62ec\nB. \u7956\u51b2\u4e4b\nC. \u5f90\u971e\u5ba2\nD. \u5434\u656c\u6893\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8021397535238411, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8449126784668206, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.47402215384600604}}, {"question": "\u5317\u65b9\u56ed\u6797\u5c24\u4ee5____\u4e3a\u4ee3\u8868\u3002\nA. \u5f00\u5c01\nB. \u897f\u5b89\nC. \u6d1b\u9633\nD. \u5317\u4eac\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.423442608492013, "meta-math/MetaMath-Mistral-7B": 0.5262386711124636, "itpossible/Chinese-Mistral-7B-v0.1": 0.6061547623194425, "HuggingFaceH4/zephyr-7b-beta": 0.9025366556514682, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5469058221455735, "meta-llama/Meta-Llama-3-8B": 0.7589989175163727, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9409893341017641}}, {"question": "\u6211\u56fd\u6210\u529f\u53d1\u5c04\u7684\u4e16\u754c\u9996\u9897\u91cf\u5b50\u79d1\u5b66\u5b9e\u9a8c\u536b\u661f\u53eb____\u3002\nA. \u201c\u58a8\u5b50\u53f7\u201d\nB. \u201c\u7389\u5154\u53f7\u201d\nC. \u201c\u5ae6\u5a25\u53f7\u201d\nD. \u201c\u5929\u5bab\u53f7\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.9359244486227537, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u56fd\u6700\u5927\u7684\u4e1b\u4e66\u662f____\u3002\nA. \u300a\u5415\u6c0f\u6625\u79cb\u300b\nB. \u300a\u6c38\u4e50\u5927\u5178\u300b\nC. \u300a\u53e4\u4eca\u56fe\u4e66\u96c6\u6210\u300b\nD. \u300a\u56db\u5e93\u5168\u4e66\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6867278899636218, "meta-math/MetaMath-Mistral-7B": 0.9069025105636769, "itpossible/Chinese-Mistral-7B-v0.1": 0.8842353347744819, "HuggingFaceH4/zephyr-7b-beta": 0.9963561990783766, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6612446649559208, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7976018339793424}}, {"question": "\u90c1\u91d1\u9999\u771f\u6b63\u7684\u539f\u4ea7\u5730\u662f____\u3002\nA. \u8377\u5170\nB. \u571f\u8033\u5176\nC. \u6cd5\u56fd\nD. \u610f\u5927\u5229\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2801288226217134, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.535472814630819, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3689108554330874, "meta-llama/Meta-Llama-3-8B": 0.5175034360544655, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6e05\u4e7e\u9686\u5e74\u95f4\u201c\u56db\u5927\u5fbd\u73ed\u8fdb\u4eac\u201d\u5bf9\u4eac\u5267\u827a\u672f\u7684\u5f62\u6210\u5f71\u54cd\u6df1\u8fdc\uff0c\u56db\u5927\u5fbd\u73ed\u4e2d\u6700\u65e9\u8fdb\u4eac\u6f14\u51fa\u5e76\u5927\u83b7\u6210\u529f\u7684\u662f____\u3002\nA. \u548c\u6625\u73ed\nB. \u56db\u559c\u73ed\nC. \u4e09\u5e86\u73ed\nD. \u6625\u53f0\u73ed\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u674e\u6c42\u771f\u5728\u201c\u4e07\u91cc\u6674\u7a7a\uff0c\u51e0\u7247\u95f2\u4e91\u6d6e\u6d77\u89d2\uff1b\u4e00\u6e7e\u78a7\u6c34\uff0c\u516b\u65b9\u6e38\u5b50\u604b\u5929\u6daf\u201d\u8054\u8bed\u4e2d\u5de7\u5999\u5730\u5d4c\u5165\u4e86\u201c\u6d77\u89d2\u5929\u6daf\u201d\u56db\u4e2a\u5b57\uff0c\u5b83\u662f____\u7701\u7684\u65c5\u6e38\u540d\u80dc\u3002\nA. \u5e7f\u4e1c\nB. \u5e7f\u897f\nC. \u8d35\u5dde\nD. \u6d77\u5357\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3275570440337724, "meta-math/MetaMath-Mistral-7B": 0.43914977225272506, "itpossible/Chinese-Mistral-7B-v0.1": 0.5357296199014007, "HuggingFaceH4/zephyr-7b-beta": 0.9715184941969758, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3788721596190015, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u56ed\u6797\u5efa\u7b51\u4e2d\uff0c____\u5f62\u5f0f\u4f18\u7f8e\u4e14\u4e0d\u8bb2\u7a76\u5bf9\u79f0\u5e03\u5c40\u3002\nA. \u69ad\nB. \u8f69\nC. \u4ead\nD. \u5eca\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5625620434340824, "itpossible/Chinese-Mistral-7B-v0.1": 0.2801288226217134, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.47323493771076264, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5143\u5927\u90fd\u662f\u6309\u7167____\u4f20\u7edf\u90fd\u57ce\u7684\u5e03\u5c40\u5efa\u9020\u7684\u3002\nA. \u6c49\u65cf\nB. \u85cf\u65cf\nC. \u8499\u53e4\u65cf\nD. \u6ee1\u65cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3742744353722653, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.45513163274954094, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u88ab\u79f0\u4e3a\u201c\u571f\u65cf\u6881\u795d\u201d\u7684\u53d9\u4e8b\u957f\u8bd7\u662f____\u3002\nA. \u300a\u725b\u8fbe\u7684\u4f20\u8bf4\u300b\nB. \u300a\u6c57\u5e86\u683c\u5c14\u300b\nC. \u300a\u7941\u5bb6\u5ef6\u897f\u300b\nD. \u300a\u62c9\u4ec1\u5e03\u4e0e\u5409\u95e8\u7d22\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29863342676099575, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5202594843756851, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u98ce\u7269\u7279\u4ea7\u4e2d\uff0c\u5c5e\u4e8e\u97e9\u56fd\u98ce\u7269\u7279\u4ea7\u7684\u662f____\u3002\nA. \u73cd\u73e0\nB. \u71d5\u7a9d\nC. \u9ad8\u4e3d\u53c2\nD. \u9999\u6599\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.7910196186392213, "HuggingFaceH4/zephyr-7b-beta": 0.8960518317951637, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.87956921316271, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9484996648352264}}, {"question": "\u897f\u6c49\u7684____\uff0c\u5305\u62ec\u300a\u7d20\u95ee\u300b\u548c\u300a\u7075\u67a2\u300b\u4e24\u90e8\u5206\uff0c\u5960\u5b9a\u4e86\u4f20\u7edf\u4e2d\u533b\u5b66\u7406\u8bba\u57fa\u7840\uff0c\u662f\u6211\u56fd\u73b0\u5b58\u6700\u65e9\u7684\u4e00\u90e8\u533b\u4e66\u3002\nA. \u300a\u9ec4\u5e1d\u5185\u7ecf\u300b\nB. \u300a\u4f24\u5bd2\u6742\u75c5\u8bba\u300b\nC. \u300a\u8109\u7ecf\u300b\nD. \u300a\u5343\u91d1\u65b9\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9159729029098498, "meta-math/MetaMath-Mistral-7B": 0.9979373748706445, "itpossible/Chinese-Mistral-7B-v0.1": 0.9736152138454683, "HuggingFaceH4/zephyr-7b-beta": 0.9998596977905017, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9869437690709507, "meta-llama/Meta-Llama-3-8B": 0.9793884599164482, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7890270767950837}}, {"question": "\u4f73\u666e\u516c\u53f8\u5728\u5176\u5236\u9020\u548c\u51fa\u552e\u7684\u6253\u5370\u673a\u548c\u6253\u5370\u673a\u58a8\u76d2\u4ea7\u54c1\u4e0a\u6ce8\u518c\u4e86\u201c\u4f73\u666e\u201d\u5546\u6807\u3002\u4e0b\u5217\u672a\u7ecf\u8be5\u516c\u53f8\u8bb8\u53ef\u7684\u54ea\u4e00\u884c\u4e3a\u4fb5\u72af\u4e86\u201c\u4f73\u666e\u201d\u6ce8\u518c\u5546\u6807\u4e13\u7528\u6743?____\nA. \u7532\u5728\u5e97\u94fa\u62db\u724c\u4e2d\u6807\u6709\u201c\u4f73\u666e\u6253\u5370\u673a\u4e13\u8425\u201d\u5b57\u6837\uff0c\u53ea\u9500\u552e\u4f73\u666e\u516c\u53f8\u5236\u9020\u7684\u6253\u5370\u673a\nB. \u4e59\u5236\u9020\u5e76\u9500\u552e\u4e0e\u4f73\u666e\u6253\u5370\u673a\u517c\u5bb9\u7684\u58a8\u76d2\uff0c\u8be5\u58a8\u76d2\u4e0a\u5370\u6709\u4e59\u7684\u540d\u79f0\u548c\u5176\u6ce8\u518c\u5546\u6807\u201c\u91d1\u5174\u201d\uff0c\u4f46\u6807\u6709\u201c\u672c\u4ea7\u54c1\u9002\u7528\u4e8e\u4f73\u666e\u6253\u5370\u673a\u201d\nC. \u4e19\u628a\u8d2d\u4e70\u7684\u201c\u4f73\u666e\u201d\u58a8\u76d2\u88c5\u5165\u81ea\u5df1\u5236\u9020\u7684\u6253\u5370\u673a\u540e\u9500\u552e\uff0c\u8be5\u6253\u5370\u673a\u4e0a\u5370\u6709\u4e19\u7684\u540d\u79f0\u548c\u5176\u6ce8\u518c\u5546\u6807\u201c\u4e1c\u5347\u201d\uff0c\u4f46\u6807\u6709\u201c\u672c\u4ea7\u54c1\u4f7f\u7528\u4f73\u666e\u58a8\u76d2\u201d\nD. \u4e01\u56de\u6536\u58a8\u6c34\u7528\u5c3d\u7684\u201c\u4f73\u666e\u201d\u724c\u58a8\u76d2\uff0c\u704c\u6ce8\u5ec9\u4ef7\u58a8\u6c34\u540e\u9500\u552e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u738b\u67d0\u7cfb\u804b\u54d1\u4eba\uff0c\u56e0\u6d89\u5acc\u76d7\u7a83\u7f6a\u88ab\u63d0\u8d77\u516c\u8bc9\u3002\u5173\u4e8e\u672c\u6848\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684?____\nA. \u8baf\u95ee\u738b\u67d0\u65f6\uff0c\u5982\u6709\u5fc5\u8981\u53ef\u901a\u77e5\u901a\u6653\u804b\u54d1\u624b\u52bf\u7684\u4eba\u53c2\u52a0\nB. \u738b\u67d0\u6ca1\u6709\u59d4\u6258\u8fa9\u62a4\u4eba\uff0c\u5e94\u901a\u77e5\u6cd5\u5f8b\u63f4\u52a9\u673a\u6784\u6307\u6d3e\u5f8b\u5e08\u4e3a\u5176\u63d0\u4f9b\u8fa9\u62a4\nC. \u8fa9\u62a4\u4eba\u7ecf\u901a\u77e5\u672a\u5230\u5ead\uff0c\u7ecf\u738b\u67d0\u540c\u610f\uff0c\u6cd5\u9662\u51b3\u5b9a\u5f00\u5ead\u5ba1\u7406\nD. \u56e0\u4e8b\u5b9e\u6e05\u695a\u4e14\u738b\u67d0\u8ba4\u7f6a\uff0c\u5b9e\u884c\u72ec\u4efb\u5ba1\u5224\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4703900541798305, "meta-math/MetaMath-Mistral-7B": 0.7378927772215991, "itpossible/Chinese-Mistral-7B-v0.1": 0.5863769635410938, "HuggingFaceH4/zephyr-7b-beta": 0.9946965292951561, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7019277062465532, "meta-llama/Meta-Llama-3-8B": 0.41605131293904374, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7775709250080574}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u516c\u8bc9\u7684\u8868\u8ff0\uff0c\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684?____\nA. \u6211\u56fd\u516c\u8bc9\u5236\u5ea6\u5949\u884c\u516c\u8bc9\u72ec\u5360\u4e3b\u4e49\nB. \u6211\u56fd\u516c\u8bc9\u5236\u5ea6\u5949\u884c\u8d77\u8bc9\u6cd5\u5b9a\u4e3b\u4e49\nC. \u68c0\u5bdf\u9662\u5bf9\u4e8e\u516c\u5b89\u673a\u5173\u79fb\u9001\u5ba1\u67e5\u8d77\u8bc9\u7684\u6848\u4ef6\uff0c\u5e94\u5f53\u5728\u4e00\u4e2a\u6708\u5185\u4f5c\u51fa\u51b3\u5b9a\uff0c\u5bf9\u4e8e\u91cd\u5927\u3001\u590d\u6742\u7684\u6848\u4ef6\uff0c\u7ecf\u8fc7\u68c0\u5bdf\u957f\u6279\u51c6\uff0c\u53ef\u4ee5\u5ef6\u957f\u534a\u4e2a\u6708\nD. \u7532\u53bf\u68c0\u5bdf\u673a\u5173\u5ba1\u67e5\u8d77\u8bc9\u738b\u67d0\u8d2a\u6c61\u4e00\u6848\uff0c\u5982\u679c\u7532\u53bf\u68c0\u5bdf\u673a\u5173\u8ba4\u4e3a\u738b\u67d0\u53ef\u80fd\u88ab\u5224\u5904\u6b7b\u5211\uff0c\u5c06\u6848\u4ef6\u79fb\u4ea4\u67d0\u5e02\u68c0\u5bdf\u673a\u5173\u5ba1\u67e5\u8d77\u8bc9\u7684\uff0c\u67d0\u5e02\u68c0\u5bdf\u673a\u5173\u5e94\u5f53\u7d2f\u8ba1\u8ba1\u7b97\u5ba1\u67e5\u8d77\u8bc9\u671f\u9650\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37742802246227186, "meta-math/MetaMath-Mistral-7B": 0.6237243846671462, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8503628389664959, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.42000513123430305, "meta-llama/Meta-Llama-3-8B": 0.42876490286251856, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7531\u4e8e\u5404\u56fd\u6cd5\u5f8b\u5173\u4e8e\u4f4f\u6240\u7684\u89c4\u5b9a\u4e0d\u540c\uff0c\u81ea\u7136\u4eba\u7684\u4f4f\u6240\u4e5f\u4f1a\u53d1\u751f\u51b2\u7a81\uff0c\u4f9d\u636e\u6211\u56fd\u6cd5\u5f8b\u89c4\u5b9a\uff1a____\nA. \u5f53\u4e8b\u4eba\u6709\u51e0\u4e2a\u4f4f\u6240\u7684\uff0c\u4ee5\u540e\u53d6\u5f97\u7684\u4f4f\u6240\u5730\u4e3a\u51c6\nB. \u5f53\u4e8b\u4eba\u6709\u51e0\u4e2a\u4f4f\u6240\u7684\uff0c\u4ee5\u5f53\u4e8b\u4eba\u73b0\u5728\u5c45\u4f4f\u5730\u4e3a\u51c6\nC. \u5f53\u4e8b\u4eba\u6709\u51e0\u4e2a\u4f4f\u6240\u7684\uff0c\u4ee5\u4e0e\u5f53\u4e8b\u4eba\u6700\u5bc6\u5207\u8054\u7cfb\u7684\u4f4f\u6240\u4e3a\u51c6\nD. \u5f53\u4e8b\u4eba\u6ca1\u6709\u4f4f\u6240\u7684\uff0c\u4ee5\u5f53\u4e8b\u4eba\u7684\u7ecf\u5e38\u5c45\u4f4f\u5730\u4e3a\u51c6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f20\u4e09\u548c\u674e\u56db\u7684\u623f\u5c4b\u7ea0\u7eb7\u4e00\u6848\uff0c\u7ecf\u6b66\u6c49\u5e02\u6d2a\u5c71\u533a\u57fa\u5c42\u6cd5\u9662\u5224\u51b3\u623f\u5c4b\u5f52\u5f20\u4e09\u6240\u6709\u3002\u751f\u6548\u6cd5\u5f8b\u6587\u4e66\u4f5c\u51fa\u540e\uff0c\u738b\u4e94\u8ba4\u4e3a\u623f\u5c4b\u5f52\u81ea\u5df1\u6240\u6709\uff0c\u5411\u6cd5\u9662\u63d0\u8d77\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\uff0c\u68c0\u5bdf\u9662\u8ba4\u4e3a\u539f\u5224\u51b3\u9519\u8bef\uff0c\u63d0\u8d77\u6297\u8bc9\uff0c\u6cd5\u9662\u88c1\u5b9a\u518d\u5ba1\u3002\u4e0b\u5217\u5173\u4e8e\u8fd9\u4e24\u79cd\u7a0b\u5e8f\u8bf4\u6cd5\u54ea\u4e00\u9879\u662f\u6b63\u786e\u7684?____\nA. \u738b\u4e94\u7684\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\u548c\u68c0\u5bdf\u9662\u7684\u6297\u8bc9\u5747\u5e94\u5411\u6b66\u6c49\u5e02\u4e2d\u7ea7\u4eba\u6c11\u6cd5\u9662\u63d0\u51fa\nB. \u56e0\u738b\u4e94\u5148\u63d0\u8d77\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\uff0c\u6cd5\u9662\u5e94\u5148\u5ba1\u7406\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\uff0c\u4e2d\u6b62\u518d\u5ba1\u7a0b\u5e8f\nC. \u6cd5\u9662\u5e94\u8be5\u4f18\u5148\u5ba1\u7406\u518d\u5ba1\uff0c\u5c06\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\u5e76\u4eba\u518d\u5ba1\nD. \u6cd5\u9662\u5e94\u8be5\u4f18\u5148\u5ba1\u7406\u518d\u5ba1\uff0c\u5c06\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\u5e76\u4eba\u518d\u5ba1\uff0c\u4f46\u5f20\u4e09\u3001\u674e\u56db\u6076\u610f\u4e32\u901a\u635f\u5bb3\u738b\u4e94\u5408\u6cd5\u6743\u76ca\u7684\uff0c\u5219\u7b2c\u4e09\u4eba\u64a4\u9500\u4e4b\u8bc9\u4f18\u5148\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40701510171211347, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4802307824689959, "HuggingFaceH4/zephyr-7b-beta": 0.6769474561543302, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8425\u4e1a\u5730\u5728\u7532\u56fd\u7684A\u516c\u53f8\u4f5c\u4e3a\u4e70\u65b9\uff0c\u548c\u8425\u4e1a\u5730\u5728\u4e59\u56fd\u7684B\u516c\u53f8\u4f5c\u4e3a\u5356\u65b9\uff0c\u7b7e\u8ba2\u4e86\u4e00\u4efd\u6210\u5957\u8bbe\u5907\u4e70\u5356\u5408\u540c\u3002\u5173\u4e8e\u672c\u5408\u540c\uff0c\u4ee5\u4e0b\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\nA. \u53cc\u65b9\u53ef\u4ee5\u7ea6\u5b9a\u9002\u7528\u300a\u8054\u5408\u56fd\u56fd\u9645\u8d27\u7269\u4e70\u5356\u5408\u540c\u516c\u7ea6\u300b(\u4ee5\u4e0b\u7b80\u79f0\u300a\u516c\u7ea6\u300b)\uff0c\u4f46\u662f\u4e0d\u80fd\u4fee\u6539\u300a\u516c\u7ea6\u300b\u4e2d\u7684\u89c4\u5b9a\nB. \u82e5\u53cc\u65b9\u7ea6\u5b9aB\u516c\u53f8\u8d1f\u8d23\u8fd0\u8f93\uff0c\u4e14\u4ef7\u683c\u672f\u8bed\u4e3aCIF\uff0c\u5219\u53cc\u65b9\u5173\u4e8e\u6295\u4fdd\u9669\u79cd\u7684\u95ee\u9898\u9002\u7528\u516c\u7ea6\u300b\u7684\u6709\u5173\u89c4\u5b9a\nC. \u82e5\u7532\u56fd\u4e3a\u4e2d\u56fd\uff0c\u5219\u56fd\u9645\u8d27\u7269\u9500\u552e\u5408\u540c\u4e0d\u662f\u5fc5\u987b\u4ee5\u4e66\u9762\u5f62\u5f0f\u8ba2\u7acb\u6216\u8005\u8bc1\u660e\nD. \u82e5B\u516c\u53f8\u51fa\u552e\u7684\u6210\u5957\u8bbe\u5907\uff0c\u662f\u901a\u8fc7\u62cd\u5356\u65b9\u5f0f\u9500\u552e\u7ed9A\u516c\u53f8\u7684\uff0c\u5219\u5173\u4e8e\u4e70\u5356\u53cc\u65b9\u7684\u6743\u5229\u3001\u4e49\u52a1\u4e0d\u9002\u7528\u300a\u516c\u7ea6\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u6cd5\u5f8b\u9002\u7528\u6cd5\u300b\u7b2c25\u6761\u89c4\u5b9a\uff1a\u7236\u6bcd\u5b50\u5973\u4eba\u8eab\u3001\u8d22\u4ea7\u5173\u7cfb\uff0c\u9002\u7528\u5171\u540c\u7ecf\u5e38\u5c45\u6240\u5730\u6cd5\u5f8b\uff1b\u6ca1\u6709\u5171\u540c\u7ecf\u5e38\u5c45\u6240\u5730\u7684\uff0c\u9002\u7528\u4e00\u65b9\u5f53\u4e8b\u4eba\u7ecf\u5e38\u5c45\u6240\u5730\u6cd5\u5f8b\u6216\u8005\u56fd\u7c4d\u56fd\u6cd5\u5f8b\u4e2d\u6709\u5229\u4e8e\u4fdd\u62a4\u5f31\u8005\u6743\u76ca\u7684\u6cd5\u5f8b\u3002\u8be5\u89c4\u5b9a\u5c5e\u4e8e\u4e0b\u5217\u54ea\u4e00\u79cd\u51b2\u7a81\u89c4\u8303?____\nA. \u5355\u8fb9\u51b2\u7a81\u89c4\u8303\nB. \u91cd\u53e0\u9002\u7528\u7684\u51b2\u7a81\u89c4\u8303\nC. \u65e0\u6761\u4ef6\u9009\u62e9\u9002\u7528\u7684\u51b2\u7a81\u89c4\u8303\nD. \u6709\u6761\u4ef6\u9009\u62e9\u9002\u7528\u7684\u51b2\u7a81\u89c4\u8303\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5042631004239816, "meta-math/MetaMath-Mistral-7B": 0.8875886109602519, "itpossible/Chinese-Mistral-7B-v0.1": 0.36617639865290497, "HuggingFaceH4/zephyr-7b-beta": 0.9983933202985817, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6195429335471625, "meta-llama/Meta-Llama-3-8B": 0.5243222918601541, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.91718063669456}}, {"question": "\u738b\u67d0\u8d85\u901f\u9a7e\u9a76\u5c06\u6b63\u5728\u7b49\u7ea2\u7eff\u706f\u7684\u8def\u4eba\u674e\u67d0\u649e\u98de14\u7c73\u8fdc\uff0c\u674e\u67d0\u5f53\u573a\u660f\u8ff7\uff0c\u738b\u67d0\u4e0b\u8f66\u5bdf\u770b\uff0c\u6709\u8def\u4eba\u7532\u6307\u8d23\u738b\u67d0\u6784\u6210\u6545\u610f\u6740\u4eba\u7f6a\uff0c\u4e5f\u6709\u8def\u4eba\u4e59\u6307\u8d23\u738b\u67d0\u5e94\u5f53\u9a6c\u4e0a\u9001\u5f80\u533b\u9662\u3002\u738b\u67d0\u5bb3\u6015\u6cd5\u5f8b\u5236\u88c1\uff0c\u5c06\u674e\u67d0\u9001\u5230\u533b\u9662\u3002\u7ed3\u5408\u6cd5\u7684\u89c4\u8303\u4f5c\u7528\u7684\u5bf9\u8c61\u8bc4\u4ef7\uff0c\u738b\u67d0\u7684\u884c\u4e3a\u4f53\u73b0\u4e86\u54ea\u4e00\u4f5c\u7528?____\nA. \u6559\u80b2\u4f5c\u7528\nB. \u6307\u5f15\u4f5c\u7528\nC. \u8bc4\u4ef7\u4f5c\u7528\nD. \u5f3a\u5236\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.27416108226793107, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5174255166618215, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u76ee\u524d\uff0c\u6211\u56fd\u5404\u5730\u53f8\u6cd5\u884c\u653f\u90e8\u95e8\u666e\u904d\u6210\u7acb\u4e86\u793e\u533a\u77eb\u6b63\u673a\u6784\uff0c\u901a\u8fc7\u4e25\u8c28\u7684\u76d1\u7763\u7ba1\u7406\u673a\u5236\u548c\u793e\u4f1a\u9002\u5e94\u6027\u5e2e\u6276\u63aa\u65bd\uff0c\u5524\u9192\u670d\u5211\u4eba\u5458\u5fc3\u5e95\u826f\u77e5\uff0c\u4f7f\u5176\u91cd\u83b7\u65b0\u751f\u3002\u5728\u5168\u56fd\u8303\u56f4\u5185\uff0c\u793e\u533a\u670d\u5211\u4eba\u5458\u5728\u77eb\u6b63\u671f\u95f4\u91cd\u65b0\u8fdd\u6cd5\u72af\u7f6a\u7387\u4fdd\u6301\u57280.2%\u5de6\u53f3\u7684\u8f83\u4f4e\u6c34\u5e73\uff0c\u53d6\u5f97\u4e86\u826f\u597d\u7684\u6cd5\u5f8b\u6548\u679c\u548c\u793e\u4f1a\u6548\u679c\u3002\u5bf9\u6b64\uff0c\u4e0b\u5217\u54ea\u4e00\u7406\u89e3\u662f\u6b63\u786e\u7684?____\nA. \u793e\u533a\u77eb\u6b63\u6ce8\u91cd\u5bf9\u72af\u7f6a\u4eba\u7684\u6539\u9020\u3001\u5b8c\u5584\u800c\u4e0d\u662f\u62a5\u590d\uff0c\u53ea\u5f3a\u8c03\u9053\u5fb7\u7684\u6559\u5316\u4f5c\u7528\nB. \u793e\u533a\u77eb\u6b63\u4f5c\u4e3a\u884c\u5211\u793e\u4f1a\u5316\u7684\u4e00\u79cd\u65b9\u5f0f\uff0c\u4e0d\u5b9e\u884c\u6743\u529b\u6e05\u5355\u548c\u8d23\u4efb\u6e05\u5355\u5236\u5ea6\nC. \u53d1\u5c55\u793e\u533a\u77eb\u6b63\uff0c\u4e0d\u4ec5\u9700\u8981\u4e13\u95e8\u7acb\u6cd5\uff0c\u8fd8\u9700\u8981\u4fee\u6539\u5211\u6cd5\nD. \u793e\u533a\u77eb\u6b63\u672c\u8d28\u662f\u5211\u7f5a\u7684\u6062\u590d\u6027\uff0c\u201c\u793e\u533a\u5211\u7f5a\u6267\u884c\u201d\u6709\u8fdd\u6cd5\u6cbb\u7cbe\u795e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4181874685359793, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5758813396135002, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u6559\u5506\u72af\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684?____\nA. \u7532\u6b32\u6740\u6b7b\u4e59\uff0c\u5c06\u6295\u4e86\u6bd2\u7684\u5496\u5561\u8ba9\u516c\u53f8\u540c\u4e8b\u4e19\u62ff\u7ed9\u4e59\uff0c\u4e19\u5b9e\u9645\u4e0a\u5df2\u7ecf\u5077\u5077\u770b\u5230\u4e86\u7532\u7684\u6295\u6bd2\u8fc7\u7a0b\uff0c\u77e5\u9053\u5496\u5561\u6709\u6bd2\uff0c\u4f46\u4ecd\u7136\u5c06\u5496\u5561\u62ff\u7ed9\u4e86\u4e59\uff0c\u5e76\u9020\u6210\u4e86\u4e59\u7684\u6b7b\u4ea1\u3002\u7532\u6784\u6210\u4e86\u6545\u610f\u6740\u4eba\u7f6a\u7684\u95f4\u63a5\u6b63\u72af\uff0c\u800c\u975e\u6559\u5506\u72af\nB. \u7532\u6559\u5506\u4e59\u62a2\u593a\u8def\u4eba\u8d22\u7269\uff0c\u4e59\u5728\u5b9e\u65bd\u62a2\u593a\u8fc7\u7a0b\u4e2d\u906d\u5230\u88ab\u5bb3\u4eba\u7684\u963b\u6321\uff0c\u4fbf\u4f7f\u7528\u66b4\u529b\u62a2\u52ab\u4e86\u8d22\u7269\u3002\u867d\u7136\u4e59\u5b9e\u65bd\u4e86\u62a2\u52ab\u72af\u7f6a\uff0c\u4f46\u7532\u5e94\u5728\u62a2\u593a\u7f6a\u7684\u9650\u5ea6\u5185\u627f\u62c5\u5211\u4e8b\u8d23\u4efb\uff0c\u800c\u4e0d\u5c5e\u4e8e\u6559\u5506\u672a\u9042\nC. \u7532\u4e3a\u5211\u6ee1\u91ca\u653e\u4eba\u5458\uff0c\u597d\u9038\u6076\u52b3\uff0c\u6559\u5506\u4e59\u53bb\u5b9e\u65bd\u76d7\u7a83\uff0c\u5e76\u5c06\u5982\u4f55\u64ac\u95e8\u538b\u9501\u7b49\u201c\u6280\u672f\u201d\u4f20\u6388\u7ed9\u4e59\uff0c\u4e59\u5e76\u672a\u5b9e\u65bd\u76d7\u7a83\u884c\u4e3a\u3002\u5219\u7532\u4e3a\u6559\u5506\u72af\uff0c\u53ef\u4ee5\u4ece\u8f7b\u6216\u51cf\u8f7b\u5904\u7f5a\nD. \u7532\u6559\u5506\u672a\u6210\u5e74\u4eba\u4e59\u5438\u98df\u6bd2\u54c1\uff0c\u4f46\u4e59\u5e76\u672a\u5438\u98df\uff0c\u5219\u7532\u4e0d\u6784\u6210\u72af\u7f6a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2016\u5e744\u6708\uff0c\u4e2d\u56fd\u7532\u516c\u53f8\u4e0e\u6cd5\u56fd\u4e59\u516c\u53f8\u7b7e\u8ba2DAP(\u5df4\u9ece)\u7684\u5408\u540c\u51fa\u53e3\u4e00\u6279\u8336\u53f6\uff0c\u6839\u636e\u300a2010\u5e74\u56fd\u9645\u8d38\u6613\u672f\u8bed\u89e3\u91ca\u901a\u5219\u300b\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u5c5e\u4e8e\u53cc\u65b9\u5728\u5408\u540c\u4e2d\u7ea6\u5b9a\u7684\u5185\u5bb9?____\nA. \u5356\u65b9\u53ea\u9700\u5c06\u8d27\u7269\u8fd0\u5230\u5df4\u9ece\u4ea4\u7531\u4e70\u65b9\u5904\u7f6e\u5373\u53ef\uff0c\u65e0\u987b\u627f\u62c5\u5c06\u8d27\u7269\u4ece\u4ea4\u901a\u5de5\u5177\u4e0a\u5378\u4e0b\u7684\u4e49\u52a1\nB. \u5356\u65b9\u9700\u8981\u5c06\u8d27\u7269\u8fd0\u5230\u5df4\u9ece\uff0c\u5c06\u8d27\u7269\u4ece\u8fd0\u8f93\u5de5\u5177\u4e0a\u5378\u4e0b\u5e76\u4ea4\u7531\u4e70\u65b9\u5904\u7f6e\nC. \u5356\u65b9\u9700\u8981\u5c06\u8d27\u7269\u8fd0\u5230\u5df4\u9ece\uff0c\u5c06\u8d27\u7269\u4ece\u4ea4\u901a\u5de5\u5177\u4e0a\u5378\u4e0b\u5e76\u5b8c\u6210\u8fdb\u53e3\u6e05\u5173\u540e\u5c06\u8d27\u7269\u4ea4\u7ed9\u4e70\u65b9\nD. \u5356\u65b9\u9700\u8981\u627f\u62c5\u8d27\u7269\u5728\u5df4\u9ece\u8d27\u4ea4\u7b2c\u4e00\u627f\u8fd0\u4eba\u4e4b\u524d\u7684\u6240\u6709\u98ce\u9669\u548c\u8d39\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u5e02\u4eba\u6c11\u6cd5\u9662\u9662\u957f\u56e0\u4e3a\u9152\u540e\u9a7e\u9a76\u673a\u52a8\u8f66\u8f86\uff0c\u81f4\u4f7f\u4e00\u4eba\u6b7b\u4ea1\uff0c\u516d\u4eba\u91cd\u4f24\u3002\u5bf9\u4e8e\u6b64\u6848\uff0c\u5e94\u5f53\u7531\u54ea\u4e2a\u90e8\u95e8\u7acb\u6848\u4fa6\u67e5?____\nA. \u4eba\u6c11\u68c0\u5bdf\u9662\nB. \u76d1\u5bdf\u90e8\u95e8\u548c\u515a\u7684\u7eaa\u5f8b\u68c0\u67e5\u59d4\u5458\u4f1a\nC. \u516c\u5b89\u673a\u5173\nD. \u4eba\u6c11\u6cd5\u9662\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6307264308648849, "meta-math/MetaMath-Mistral-7B": 0.9180198227277332, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7300768636728961, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7638422819799937, "meta-llama/Meta-Llama-3-8B": 0.7706960301749791, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9620023527173526}}, {"question": "\u7531\u6267\u884c\u673a\u5173\u5411(1)\u4ee5\u4e0a\u6cd5\u9662\u63d0\u51fa(2)\u5efa\u8bae\u4e66\uff0c\u6cd5\u9662\u5e94\u5f53\u7ec4\u6210\u5408\u8bae\u5ead\u8fdb\u884c\u5ba1\u7406\uff0c\u5bf9\u7b26\u5408(3)\u6761\u4ef6\u7684\uff0c\u88c1\u5b9a\u4e88\u4ee5(4)\u3002\u5c06\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u5185\u5bb9\u586b\u5145\u5230\u4ee5\u4e0a\u76f8\u5e94\u4f4d\u7f6e\u662f\u6b63\u786e\u7684?____\nA. (1)\u4e2d\u7ea7(2)\u51cf\u5211(3)\u51cf\u5211(4)\u51cf\u5211\nB. (1)\u4e2d\u7ea7(2)\u53ef\u586b\u201c\u51cf\u5211\u201d\u6216\u8005\u201c\u5047\u91ca\u201d(3)\u53ef\u586b\u201c\u51cf\u5211\u201d\u6216\u8005\u201c\u5047\u91ca\u201d(4)\u53ef\u586b\u201c\u51cf\u5211\u201d\u6216\u8005\u201c\u5047\u91ca\u201d\nC. (1)\u9ad8\u7ea7(2)\u5047\u91ca(3)\u5047\u91ca(4)\u5047\u91ca\nD. (1)\u9ad8\u7ea7(2)\u53ef\u586b\u201c\u51cf\u5211\u201d\u6216\u8005\u201c\u5047\u91ca\u201d(3)\u53ef\u586b\u201c\u51cf\u5211\u201d\u6216\u8005\u201c\u5047\u91ca\u201d(4)\u53ef\u586b\u201c\u51cf\u5211\u201d\u6216\u8005\u201c\u5047\u91ca\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.43265709150726833, "meta-math/MetaMath-Mistral-7B": 0.6731278495296191, "itpossible/Chinese-Mistral-7B-v0.1": 0.5243222918601541, "HuggingFaceH4/zephyr-7b-beta": 0.9638392719905576, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44033071620591985, "meta-llama/Meta-Llama-3-8B": 0.4279733272551463, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8794899066725393}}, {"question": "\u949f\u67d0\u6027\u60c5\u66b4\u8e81\uff0c\u5e38\u6bb4\u6253\u59bb\u5b50\u67f3\u67d0\uff0c\u67f3\u67d0\u7ecf\u5e38\u627e\u540c\u6751\u672a\u5a5a\u7537\u9752\u5e74\u675c\u67d0\u8bc9\u82e6\u6392\u9063\uff0c\u65e5\u4e45\u751f\u60c5\u3002\u73b0\u67f3\u67d0\u8d77\u8bc9\u79bb\u5a5a\uff0c\u5173\u4e8e\u949f\u3001\u67f3\u4e8c\u4eba\u7684\u79bb\u5a5a\u8d22\u4ea7\u5904\u7406\u4e8b\u5b9c\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684?____\nA. \u9488\u5bf9\u949f\u67d0\u5bb6\u5ead\u66b4\u529b\uff0c\u67f3\u67d0\u4e0d\u80fd\u5411\u5176\u4e3b\u5f20\u635f\u5bb3\u8d54\u507f\nB. \u9488\u5bf9\u949f\u67d0\u5bb6\u5ead\u66b4\u529b\uff0c\u67f3\u67d0\u4e0d\u80fd\u5411\u5176\u4e3b\u5f20\u7cbe\u795e\u635f\u5bb3\u8d54\u507f\nC. \u5982\u67f3\u67d0\u5a5a\u5185\u4e0e\u675c\u67d0\u540c\u5c45\uff0c\u5219\u67f3\u67d0\u4e0d\u80fd\u5411\u949f\u67d0\u4e3b\u5f20\u635f\u5bb3\u8d54\u507f\nD. \u5982\u67f3\u67d0\u5a5a\u5185\u4e0e\u675c\u67d0\u540c\u5c45\uff0c\u5219\u949f\u67d0\u53ef\u4ee5\u5411\u67f3\u67d0\u4e3b\u5f20\u635f\u5bb3\u8d54\u507f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.31828968051251794, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f8b\u5e08\u5e94\u4ee5\u8c01\u7684\u540d\u4e49\u4e0e\u59d4\u6258\u4eba\u7b7e\u8ba2\u59d4\u6258\u4ee3\u7406\u5408\u540c?____\nA. \u56fd\u5bb6\nB. \u5f8b\u5e08\u672c\u4eba\nC. \u5f8b\u5e08\u4e8b\u52a1\u6240\u4e3b\u4efb\nD. \u5f8b\u5e08\u4e8b\u52a1\u6240\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.45077244158804625, "HuggingFaceH4/zephyr-7b-beta": 0.9824782693899119, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6934595374665067, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.691293202765461}}, {"question": "\u4e0b\u9762\u5173\u4e8e\u6cd5\u7684\u89c4\u8303\u4f5c\u7528\uff0c\u8bf4\u6cd5\u4e0d\u6b63\u786e\u7684\u662f\uff1a____\nA. \u300a\u6c11\u6cd5\u901a\u5219\u300b\u89c4\u5b9a\uff0c\u5f53\u4e8b\u4eba\u4e00\u65b9\u4e0d\u5c65\u884c\u5408\u540c\u4e49\u52a1\u6216\u8005\u5c65\u884c\u5408\u540c\u4e49\u52a1\u4e0d\u7b26\u5408\u7ea6\u5b9a\u6761\u4ef6\u7684\uff0c\u53e6\u4e00\u65b9\u6709\u6743\u8981\u6c42\u5c65\u884c\u6216\u8005\u91c7\u53d6\u8865\u6551\u63aa\u65bd\uff0c\u5e76\u6709\u6743\u8981\u6c42\u8d54\u507f\u635f\u5931\u3002\u8fd9\u4e00\u6cd5\u6761\u4f53\u73b0\u4e86\u6cd5\u7684\u6307\u5f15\u4f5c\u7528\nB. \u4e00\u5bcc\u5bb6\u5b50\u5f1f\u5728\u95f9\u5e02\u98d9\u8f66\u5c06\u4e00\u884c\u4eba\u649e\u6b7b\uff0c\u5728\u56f4\u89c2\u7684\u4eba\u7fa4\u4e2d\u6709\u4eba\u8bf4\uff0c\u8087\u4e8b\u8005\u5e94\u5f53\u4ee5\u5371\u5bb3\u516c\u5171\u5b89\u5168\u7f6a\u8bba\u5904\u3002\u56f4\u89c2\u8005\u7684\u8a00\u8bba\u4f53\u73b0\u6cd5\u7684\u8bc4\u4ef7\u4f5c\u7528\nC. \u4e00\u5efa\u7b51\u5546\u4e3a\u627f\u5305\u67d0\u5de5\u7a0b\uff0c\u4fbf\u5411\u4e3b\u7ba1\u8be5\u9879\u76ee\u7684\u5e02\u9886\u5bfc\u5f20\u67d0\u9001\u53bb5\u4e07\u5143\u7684\u89c1\u9762\u94b1\uff0c\u5f20\u67d0\u4e49\u6b63\u8bcd\u4e25\u5730\u5bf9\u5efa\u7b51\u5546\u8bf4\uff0c\u4f60\u8fd9\u79cd\u884c\u4e3a\u6211\u5982\u679c\u6536\u4e0b\uff0c\u56fd\u5bb6\u5c06\u4f1a\u5236\u88c1\u6211\uff0c\u6240\u4ee5\u6211\u4e0d\u80fd\u63a5\u53d7\u3002\u8fd9\u4f53\u73b0\u4e86\u6cd5\u7684\u9884\u6d4b\u4f5c\u7528\nD. \u67d0\u79c1\u8425\u7164\u77ff\u7684\u77ff\u4e3b\u56e0\u8fdd\u89c4\u5f00\u77ff\u53d1\u751f\u91cd\u5927\u77ff\u96be\uff0c\u88ab\u6cd5\u9662\u4ee5\u91cd\u5927\u5b89\u5168\u4e8b\u6545\u7f6a\u5224\u5904\u6709\u671f\u5f92\u52116\u5e74\uff0c\u8fd9\u4f53\u73b0\u4e86\u6cd5\u7684\u6559\u80b2\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4115736768130199, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.47530701330645597, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f20\u67d0\u5728\u672a\u53d6\u5f97\u8425\u4e1a\u6267\u7167\u7684\u60c5\u51b5\u4e0b\uff0c\u5728\u8857\u9053\u4e0a\u9500\u552e\u6d3b\u9e21\u9e2d\uff0c\u5e02\u57ce\u7ba1\u5c40\u67e5\u83b7\u5f20\u67d0\u7684\u65e0\u7167\u7ecf\u8425\u884c\u4e3a\uff0c\u6263\u62bc\u4e86\u5f20\u67d0\u7684\u7535\u5b50\u79e4\u4e00\u4e2a\uff0c\u9e21\u9e2d\u6570\u53ea\uff0c\u5f20\u67d0\u5728\u57ce\u7ba1\u5c40\u5b9e\u65bd\u6263\u62bc\u7684\u8fc7\u7a0b\u4e2d\u4e0e\u57ce\u7ba1\u5c40\u53d1\u751f\u51b2\u7a81\u963b\u788d\u6263\u62bc\uff0c\u57ce\u7ba1\u4eba\u5458\u62a5\u8b66\uff0c\u533a\u516c\u5b89\u5c40\u5bf9\u5f20\u67d0\u4f5c\u51fa5\u65e5\u7684\u884c\u653f\u62d8\u7559\u5904\u7f5a\u51b3\u5b9a\uff0c\u5f20\u67d0\u4e0d\u670d\uff0c\u7533\u8bf7\u884c\u653f\u590d\u8bae\uff0c\u4e0b\u5217\u54ea\u4e00\u8bf4\u6cd5\u662f\u6b63\u786e\u7684?____\nA. \u5f20\u67d0\u7533\u8bf7\u884c\u653f\u590d\u8bae\uff0c\u5e94\u5f53\u5411\u5e02\u516c\u5b89\u5c40\u63d0\u51fa\nB. \u5f20\u67d0\u53ef\u4ee5\u53e3\u5934\u59d4\u62582\u540d\u4ee3\u7406\u4eba\u53c2\u52a0\u884c\u653f\u590d\u8bae\nC. \u590d\u8bae\u673a\u5173\u5e94\u5f53\u572860\u5929\u5185\u4f5c\u51fa\u590d\u8bae\u51b3\u5b9a\nD. \u590d\u8bae\u673a\u5173\u53ef\u4ee5\u5411\u5f20\u67d0\u6536\u53d6\u529e\u7406\u884c\u653f\u590d\u8bae\u6848\u4ef6\u6240\u9700\u7684\u8d39\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.43871329944202475, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7877026958934376}}, {"question": "\u7532\u3001\u4e59\u3001\u4e19\u4e09\u56fd\u90fd\u662f\u300a\u7ef4\u4e5f\u7eb3\u9886\u4e8b\u5173\u7cfb\u516c\u7ea6\u300b\u7f14\u7ea6\u56fd\uff0c\u7532\u3001\u4e59\u4e24\u56fd\u56e0\u8fb9\u5883\u77f3\u6cb9\u5f00\u53d1\u95ee\u9898\u4e0d\u65ad\u53d1\u751f\u51b2\u7a81\u3002\u4e59\u56fd\u67d0\u516c\u6c11\u4e3a\u4e86\u6cc4\u6124\uff0c\u5077\u5077\u5728\u7532\u56fd\u9886\u9986\u91cc\u653e\u706b\uff0c\u706b\u52bf\u8513\u5ef6\u6781\u5feb\u3002\u6b64\u65f6\uff0c\u4e19\u56fd\u9a7b\u4e59\u56fd\u7684\u9886\u4e8b\u5b98\u5458\u738b\u67d0\u521a\u597d\u7ecf\u8fc7\uff0c\u76ee\u7779\u4e86\u5168\u8fc7\u7a0b\u3002\u6839\u636e\u76f8\u5173\u56fd\u9645\u6cd5\u89c4\u5219\uff0c\u4e0b\u5217\u54ea\u4e00\u9009\u9879\u662f\u6b63\u786e\u7684?____\nA. \u5982\u679c\u7532\u56fd\u5355\u65b9\u9762\u5173\u95ed\u9886\u9986\uff0c\u90a3\u4e48\u9886\u9986\u9986\u820d\u4ee5\u53ca\u6863\u6848\u4e0d\u518d\u53d7\u4fdd\u62a4\nB. \u4e59\u56fd\u7684\u6d88\u9632\u4eba\u5458\u8981\u5728\u7532\u56fd\u9886\u9986\u9986\u957f\u7684\u540c\u610f\u4e0b\u624d\u80fd\u8fdb\u5165\u6551\u706b\nC. \u5bf9\u4e8e\u653e\u706b\u4e8b\u4ef6\uff0c\u738b\u67d0\u5982\u62d2\u7edd\u4f5c\u8bc1\uff0c\u4e0d\u5f97\u5bf9\u5176\u65bd\u4ee5\u5f3a\u5236\u6216\u5904\u7f5a\nD. \u4e19\u56fd\u5728\u7532\u56fd\u7684\u9886\u9986\u8bbe\u5907\u4e0d\u5f97\u88ab\u5f81\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36415328794517626, "meta-math/MetaMath-Mistral-7B": 0.4853399933081958, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.623888902113888, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5406921808822187}}, {"question": "\u300a\u5168\u56fd\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u5e38\u52a1\u59d4\u5458\u4f1a\u5173\u4e8e\u3008\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u5211\u6cd5\u3009\u7b2c\u4e00\u767e\u4e94\u5341\u516b\u6761\u3001\u7b2c\u4e00\u767e\u4e94\u5341\u4e5d\u6761\u7684\u89e3\u91ca\u300b\u4e2d\u89c4\u5b9a\uff1a\u201c\u5211\u6cd5\u7b2c\u4e00\u767e\u4e94\u5341\u516b\u6761\u3001\u7b2c\u4e00\u767e\u4e94\u5341\u4e5d\u6761\u7684\u89c4\u5b9a\uff0c\u53ea\u9002\u7528\u4e8e\u4f9d\u6cd5\u5b9e\u884c\u6ce8\u518c\u8d44\u672c\u5b9e\u7f34\u767b\u8bb0\u5236\u7684\u516c\u53f8\u3002\u201d\u5173\u4e8e\u8be5\u89e3\u91ca\uff0c\u4e0b\u5217\u54ea\u4e00\u8bf4\u6cd5\u662f\u6b63\u786e\u7684?____\nA. \u6548\u529b\u4f4e\u4e8e\u300a\u5211\u6cd5\u300b\nB. \u5168\u56fd\u4eba\u5927\u5e38\u59d4\u4f1a\u53ea\u80fd\u5c31\u300a\u5211\u6cd5\u300b\u4f5c\u6cd5\u5f8b\u89e3\u91ca\nC. \u5bf9\u6cd5\u5f8b\u6761\u6587\u8fdb\u884c\u4e86\u9650\u5236\u89e3\u91ca\nD. \u662f\u5b66\u7406\u89e3\u91ca\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5051993569295654, "meta-math/MetaMath-Mistral-7B": 0.7961327798352901, "itpossible/Chinese-Mistral-7B-v0.1": 0.3728641892601242, "HuggingFaceH4/zephyr-7b-beta": 0.9997562376316154, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7807333523925353, "meta-llama/Meta-Llama-3-8B": 0.6444712716223122, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9531915698012604}}, {"question": "\u7532\u81f4\u4e59\u91cd\u4f24\uff0c\u6536\u96c6\u5230\u4e0b\u5217\u8bc1\u636e\uff0c\u5176\u4e2d\u65e2\u5c5e\u4e8e\u76f4\u63a5\u8bc1\u636e\uff0c\u53c8\u5c5e\u4e8e\u4f20\u95fb\u8bc1\u636e\u7684\u6709?____\nA. \u6709\u88ab\u5bb3\u4eba\u8840\u8ff9\u7684\u5315\u9996\u7167\u7247\nB. \u8bc1\u4eba\u770b\u5230\u7532\u8eab\u4e0a\u6709\u8840\u8ff9\uff0c\u4ece\u73b0\u573a\u8d70\u51fa\u7684\u8bc1\u8a00\nC. \u5315\u9996\u4e0a\u7559\u4e0b\u7684\u6307\u5370\u4e0e\u7532\u7684\u6307\u7eb9\u540c\u4e00\u7684\u9274\u5b9a\u610f\u89c1\nD. \u4e19\u542c\u8bf4\u7532\u4f24\u5bb3\u4e59\u8fc7\u7a0b\u7684\u9648\u8ff0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6709\u5173\u56fd\u5bb6\u8d54\u507f\u7684\u5f52\u8d23\u539f\u5219\u7684\u8bf4\u6cd5\u54ea\u4e00\u9879\u662f\u6b63\u786e\u7684?____\nA. \u5b9e\u884c\u8fdd\u6cd5\u5f52\u8d23\u539f\u5219\nB. \u5b9e\u884c\u7ed3\u679c\u5f52\u8d23\u539f\u5219\nC. \u5b9e\u884c\u591a\u5143\u5f52\u8d23\u539f\u5219\nD. \u5b9e\u884c\u5355\u4e00\u5f52\u8d23\u539f\u5219\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "DES\u672f\u8bed\u9002\u7528\u4e8e____\u3002\nA. \u94c1\u8def\u8fd0\u8f93\nB. \u516c\u8def\u8fd0\u8f93\nC. \u6d77\u4e0a\u8fd0\u8f93\u53ca\u5185\u6cb3\u8fd0\u8f93\nD. \u591a\u5f0f\u8054\u8fd0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5361111612790901, "meta-math/MetaMath-Mistral-7B": 0.8923000557556284, "itpossible/Chinese-Mistral-7B-v0.1": 0.31712010892822357, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7564038300905578, "meta-llama/Meta-Llama-3-8B": 0.418037156266984, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8633476152405242}}, {"question": "\u4e0a\u6d77\u957f\u5b81\u533a\u4eba\u674e\u5e0c\u5c06\u4e0e\u82cf\u5dde\u5e73\u6c5f\u533a\u4eba\u6c6a\u4eac\u7b7e\u8ba2\u4e70\u5356\u5927\u7c73\u7684\u5408\u540c\u3002\u7ea6\u5b9a\u5c65\u884c\u5730\u5728\u626c\u5dde\u5e7f\u9675\u533a\uff0c\u5b9e\u9645\u5927\u7c73\u5728\u5357\u4eac\u96e8\u82b1\u533a\u4ea4\u4ed8\uff0c\u4e24\u4eba\u7ea6\u5b9a\u53d1\u751f\u7ea0\u7eb7\u540e\uff0c\u7531\u5357\u4eac\u96e8\u82b1\u533a\u6cd5\u9662\u7ba1\u8f96\u3002\u540e\u56e0\u6c6a\u4eac\u4e0d\u652f\u4ed8\u5408\u540c\u8d27\u6b3e\uff0c\u674e\u5e0c\u4e3a\u8981\u56de\u6b3e\u9879\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f?____\nA. \u672c\u6848\u5e94\u7531\u626c\u5dde\u5e7f\u9675\u533a\u6cd5\u9662\u7ba1\u8f96\nB. \u672c\u6848\u5e94\u7531\u4e0a\u6d77\u5e02\u957f\u5b81\u533a\u6cd5\u9662\u7ba1\u8f96\nC. \u672c\u6848\u5e94\u7531\u5357\u4eac\u96e8\u82b1\u533a\u6cd5\u9662\u7ba1\u8f96\nD. \u672c\u6848\u7531\u82cf\u5dde\u5e73\u6c5f\u533a\u6cd5\u9662\u7ba1\u8f96\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8681058313635214, "meta-math/MetaMath-Mistral-7B": 0.9905436824069892, "itpossible/Chinese-Mistral-7B-v0.1": 0.6537734350836034, "HuggingFaceH4/zephyr-7b-beta": 0.9943598930777936, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9560595115791903, "meta-llama/Meta-Llama-3-8B": 0.7660123915756377, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9944100405430591}}, {"question": "\u4e0b\u6587\u5212\u7ebf\u5904\u9009\u586b\u54ea\u9879\u6700\u6070\u5207____\r\n\u4f5c\u7269\u540c\u75c5\u83cc\u8fdb\u884c\u6597\u4e89\uff0c\u60c5\u5f62\u662f\u590d\u6742\u7684\uff1a____\uff0c\u5c31\u662f\u540c\u4e00\u4e2a\u6297\u75c5\u54c1\u79cd\uff0c\u5bf9\u4e0d\u540c\u7684\u75c5\u83cc\u7684\u62b5\u6297\u65b9\u5f0f\u4e5f\u4e0d\u4e00\u6837\u3002\nA. \u4e0d\u540c\u7684\u6297\u75c5\u54c1\u79cd\u62b5\u6297\u75c5\u83cc\u7684\u65b9\u5f0f\u4e0d\u4ec5\u6709\u6240\u4e0d\u540c\nB. \u4e0d\u540c\u7684\u6297\u75c5\u54c1\u79cd\u4e0d\u4ec5\u62b5\u6297\u75c5\u83cc\u7684\u65b9\u5f0f\u6709\u6240\u4e0d\u540c\nC. \u4e0d\u4ec5\u4e0d\u540c\u7684\u6297\u75c5\u54c1\u79cd\u62b5\u6297\u75c5\u83cc\u7684\u65b9\u5f0f\u6709\u6240\u4e0d\u540c\nD. \u56fa\u7136\u4e0d\u540c\u7684\u6297\u75c5\u54c1\u79cd\u62b5\u6297\u75c5\u83cc\u7684\u65b9\u5f0f\u6709\u6240\u4e0d\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6400597094819421, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6605489565573717}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u7684\u4e00\u53e5\u662f____\nA. \u67d0\u4e9b\u5403\u60ef\u201c\u5927\u9505\u996d\u201d\u7684\u804c\u5de5\u5bf9\u52b3\u52a8\u4eba\u4e3a\u5236\u5ea6\u7684\u9769\u65b0\uff0c\u5207\u5b9e\u5176\u5b9e\u4f1a\u611f\u5230\u4e0d\u9002\u5e94\u3002\nB. \u201c\u5168\u9762\u5efa\u8bbe\u5c0f\u5eb7\u793e\u4f1a\u201d\u7684\u76ee\u6807\uff0c\u5bf9\u4e8e\u6211\u4eec\u611f\u5230\u5341\u5206\u4eb2\u70ed\uff1b\u5b83\u5df2\u7ecf\u6210\u4e3a\u5168\u515a\u5929\u4e0b\u4eba\u6c11\u5728\u65b0\u4e16\u7eaa\u4e2d\u594b\u6597\u7684\u884c\u52a8\u7eb2\u9886\u3002\nC. \u65e5\u672c\u8f85\u5f3c\u524d\u53bb\u201c\u9756\u56fd\u795e\u793e\u201d\u4e3a\u4e1c\u6761\u82f1\u673a\u7b49\u6218\u4e89\u7f6a\u72af\u62db\u9b42\u7684\u53cd\u52a8\u884c\u5f84\uff0c\u5bf9\u4e8e\u66fe\u9971\u53d7\u4fb5\u7565\u6218\u4e89\u7978\u5bb3\u7684\u4e2d\u56fd\u4eba\u6c11\u548c\u5176\u4ed6\u4e9a\u6d32\u56fd\u5bb6\u7684\u4eba\u6c11\u662f\u4e0d\u514b\u4e0d\u53ca\u5bb9\u5fcd\u7684\u3002\nD. \u4e16\u754c\u91cd\u91cf\u7ea7\u62f3\u51fb\u51a0\u519b\u6613\u65af\u63a5\u53d7\u4e86\u5973\u7687\u9881\u53d1\u7684\u7687\u5bb6\u52cb\u7ae0\uff0c\u4ee5\u8868\u5f70\u4ed6\u4e3a\u82f1\u56fd\u62f3\u51fb\u4e8b\u4e1a\u505a\u51fa\u7684\u8d21\u732e\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u7684\u4e00\u53e5\u662f____\nA. \u5728\u5bf9WTO\u95ee\u9898\u7684\u5173\u6ce8\u4e0a\uff0c\u8fc7\u53bb\u4e3b\u8981\u96c6\u4e2d\u5728\u884c\u4e1a\u3001\u4f01\u4e1a\u7b49\u65b9\u9762\u6240\u9762\u4e34\u7684\u538b\u529b\u4e0a\uff0c\u591a\u662f\u4ece\u5fae\u89c2\u5c42\u9762\u8003\u8651\u95ee\u9898\uff0c\u800c\u5bf9\u4e8e\u7ecf\u6d4e\u4f53\u5236\u7b49\u5b8f\u89c2\u95ee\u9898\u5374\u601d\u8003\u751a\u5c11\u3002\nB. \u5bf9\u5728\u5982\u4f55\u4f7f\u5b66\u751f\u638c\u63e1\u73b0\u4ee3\u5316\u751f\u6d3b\u6240\u5fc5\u987b\u7684\u77e5\u8bc6\u6280\u80fd\u7684\u95ee\u9898\u4e0a\uff0c\u8be5\u6821\u7684\u8001\u5e08\u4f5c\u8fc7\u6df1\u5165\u8be6\u5c3d\u7684\u7814\u7a76\u3002\nC. \u8457\u540d\u8bcd\u66f2\u4f5c\u5bb6\u4ed8\u6797\u521b\u4f5c\u300a\u5988\u5988\u7684\u543b\u300b\u300a\u5c0f\u87ba\u53f7\u300b\u300a\u6545\u56ed\u4e4b\u604b\u300b\u7b49\u810d\u7099\u751f\u9f7f\u7684\u6b4c\u66f2\u800c\u871a\u58f0\u4e50\u575b\u3002\nD. \u8f7d\u4eba\u822a\u5929\u6280\u672f\uff0c\u662f\u6211\u56fd\u9ad8\u65b0\u79d1\u6280\u6c34\u5e73\u663e\u8457\u63d0\u9ad8\u7684\u91cd\u8981\u6807\u5fd7\uff0c\u4e5f\u662f\u6211\u56fd\u7efc\u5408\u56fd\u529b\u663e\u8457\u63d0\u9ad8\u7684\u91cd\u8981\u4f53\u73b0\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3467592701428982, "meta-math/MetaMath-Mistral-7B": 0.7902353188841053, "itpossible/Chinese-Mistral-7B-v0.1": 0.3588823130168717, "HuggingFaceH4/zephyr-7b-beta": 0.9806061638509435, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5114296304240291, "meta-llama/Meta-Llama-3-8B": 0.4124578775795746, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u7684\u4e00\u53e5\u662f____\nA. \u8bb0\u8005\u4ece\u65b0\u95fb\u53d1\u5e03\u4f1a\u4e0a\u83b7\u6089\uff0c10\u670826\u65e5\uff0c\u8fbd\u5b81\u7701\u9526\u5dde\u5e02\u9ed1\u5c71\u53bf\u51fa\u73b0\u79bd\u6d41\u611f\u75ab\u60c5\u5df2\u5f97\u5230\u6709\u6548\u63a7\u5236\u3002\nB. \u738b\u8d8a\u6d32\u548c\u59da\u4f73\u742a\u8d76\u8d74\u822a\u5929\u57ce\uff0c\u4ed6\u4eec\u5c06\u4ece\u822a\u5929\u5458\u7684\u624b\u4e2d\u63a5\u8fc7\u642d\u4e58\u201c\u795e\u821f\u516d\u53f7\u201d\u8fdb\u884c\u592a\u7a7a\u4e4b\u65c5\u7684\u81ea\u5df1\u7684\u753b\u4f5c\uff0c\u5e76\u5f97\u5230\u7eaa\u5ff5\u8bc1\u4e66\u3002\nC. \u4e0d\u7ba1\u300a\u6cf0\u6664\u58eb\u62a5\u300b\u8fd9\u4e2a\u6392\u884c\u699c\u7684\u6743\u5a01\u7a0b\u5ea6\u9887\u53d7\u56fd\u4eba\u8d28\u7591\uff0c\u4f46\u636e\u4e13\u5bb6\u79f0\uff0c\u6392\u884c\u699c\u662f\u80fd\u591f\u8bf4\u660e\u4e00\u4e9b\u95ee\u9898\u7684\u3002\nD. \u8fdb\u5165\u4e4c\u9547\uff0c\u4fe1\u6b65\u4e8e\u5e7d\u6df1\u7684\u8857\u5df7\u4e2d\uff0c\u4f60\u5c31\u4f1a\u89c9\u5f97\u81ea\u5df1\u597d\u50cf\u6d4f\u89c8\u7740\u4e00\u90e8\u5173\u4e8e\u6c5f\u5357\u6c34\u4e61\u6587\u5316\u7684\u7ebf\u88c5\u4e66\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.34239623393788804, "itpossible/Chinese-Mistral-7B-v0.1": 0.4087009733881603, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.32871459371036227, "meta-llama/Meta-Llama-3-8B": 0.30817677628857404, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5217\u5b57\u6ce8\u97f3\u5168\u5bf9\u7684\u4e00\u9879\u662f\t____\nA. \u590d\u6742\uff08f\u00f9\uff09\t\u6309\u637a\uff08n\u00e0i\uff09\t\u6df7\u6dc6\uff08xi\u00e1o\uff09\t\u7b14\u753b\u7ea4\u7ec6(qi\u0101n)\nB. \u5f25\u8865\uff08m\u00ed\uff09\t\u84d3\u857e\uff08b\u00e8i\uff09\t\u53d1\u9175\uff08ji\u00e0o\uff09\t\u4e0d\u7740\u8fb9\u9645\uff08zhu\u00f3\uff09\nC. \u62c2\u6653\uff08f\u00f3\uff09\t\u8d28\u91cf\uff08zh\u01d0\uff09\t\u9ad8\u6863\uff08d\u00e0ng\uff09\t\u5927\u8179\u4fbf\u4fbf\uff08pi\u00e1n\uff09\nD. \u52d2\u7d22\uff08l\u0113\uff09\t\u7ed3\u675f\uff08s\u00f9\uff09\t\u55a7\u56a3\uff08xi\u0101o\uff09\t\u9157\u9152\u6ecb\u4e8b\uff08x\u00f9\uff09\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2779730307312053, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.40888409166778283, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u7684\u4e00\u53e5\u662f____\nA. \u534a\u671f\u8003\u8bd5\u4e4b\u540e\uff0c\u56e0\u4e3a\u5979\u8fd9\u6837\u597d\u7684\u6210\u7ee9\uff0c\u83b7\u5f97\u4e86\u8001\u5e08\u548c\u540c\u5b66\u4eec\u7684\u9882\u626c\u3002\nB. \u5168\u6821\u5e08\u751f\u5728\u96f7\u950b\u7cbe\u795e\u7684\u9f13\u821e\u4e0b\uff0c\u597d\u4eba\u597d\u4e8b\uff0c\u5982\u96e8\u540e\u6625\u7b0b\u4f3c\u7684\u6d8c\u73b0\u51fa\u6765\u3002\nC. \u4ed6\u4eec\u895f\u6000\u80f8\u895f\u7956\u56fd\uff0c\u653e\u773c\u5929\u4e0b\uff0c\u5728\u9ad8\u624b\u5982\u6797\u7684\u96c5\u5178\u5965\u8fd0\u4f1a\u4e0a\uff0c\u5927\u529b\u53d1\u626c\u4e86\u6562\u62fc\u6562\u640f\uff0c\u7ec8\u4e8e\u593a\u5f97\u4e86\u51a0\u519b\u3002\nD. \u8fd9\u4e2a\u8282\u76ee\u8868\u8fbe\u4e86\u540c\u5b66\u4eec\u8981\u4ee5\u5b9e\u9645\u884c\u52a8\u5411\u96f7\u950b\u540c\u5fd7\u5b66\u4e60\uff0c\u4ee5\u4f18\u5f02\u7684\u6210\u7ee9\u5411\u515a\u62a5\u544a\u7684\u51b3\u5fc3\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38345383933860794, "meta-math/MetaMath-Mistral-7B": 0.7631855446814866, "itpossible/Chinese-Mistral-7B-v0.1": 0.43589454625904106, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u6807\u70b9\u7b26\u53f7\u4f7f\u7528\u5408\u4e4e\u89c4\u8303\u7684\u4e00\u9879\u662f____\nA. \u5bf9\u674e\u6e05\u7167\u7684\u8bd7\uff0c\u6bd4\u4e4b\u90a3\u201c\u5bfb\u5bfb\u89c5\u89c5\uff0c\u51b7\u51b7\u6e05\u6e05\uff0c\u51c4\u51c4\u60e8\u60e8\u621a\u621a\u201d\u7684\u54c0\u6028\uff0c\u6211\u5012\u66f4\u559c\u6b22\u5979\u7684\u201c\u751f\u5f53\u4f5c\u4eba\u6770\uff0c\u6b7b\u4ea6\u4e3a\u9b3c\u96c4\u201d\u7684\u521a\u70c8\u3002\nB. \u6628\u65e5\uff0c\u6b66\u6c49\u5de5\u4e1a\u5b66\u9662\u4e09\u540d\u5b66\u751f\u5ba3\u5e03\uff1a\u4ed6\u4eec\u7ecf\u8fc7\u8fde\u7eed\u594b\u6218\uff0c\u5df2\u7ecf\u627e\u5230\u4e86\u4e09\u79cd\u7b80\u4fbf\u5feb\u901f\u68c0\u6d4b\u5976\u7c89\u4e2d\u662f\u5426\u542b\u6709\u4e09\u805a\u6c30\u80fa\u7684\u529e\u6cd5\uff0c\u53ef\u89c1\u666e\u901a\u5e02\u6c11\u4e5f\u53ef\u4ee5\u81ea\u5df1\u52a8\u624b\u68c0\u6d4b\u5976\u7c89\u4e2d\u6709\u65e0\u4e09\u805a\u6c30\u80fa\u3002\nC. \u4e3a\u7ed9\u5730\u94c12\u53f7\u7ebf\u548c4\u53f7\u7ebf\u8ba9\u8def\uff0c\u6b66\u6c49\u5e02\u6700\u5927\u7684\u5e7f\u573a\u2014\u2014\u6d2a\u5c71\u5e7f\u573a\u5c06\u88ab\u62c6\u9664\u91cd\u5efa\u7684\u6d88\u606f\u4f20\u51fa\u540e\uff0c\u8bb8\u591a\u4eba\u90fd\u975e\u5e38\u5173\u5fc3\u672a\u6765\u7684\u5e7f\u573a\u5c06\u600e\u4e48\u5efa\uff1f\u90a3\u91cc\u7684\u51e0\u767e\u682a\u6811\u6728\u5c06\u600e\u4e48\u529e\uff1f\nD. \u201c\u7eff\u52a8\u672a\u67652008\u201d\u73af\u4fdd\u65b9\u6848\u8bc4\u9009\u6d3b\u52a8\u5f00\u5c55\u4ee5\u6765\uff0c\u5927\u8d5b\u7ec4\u59d4\u4f1a\u5f81\u96c6\u5230\u9ad8\u8d28\u91cf\u53c2\u8d5b\u65b9\u6848367\u4efd\uff0c\u5185\u5bb9\u6d89\u53ca\u65b0\u80fd\u6e90\u3001\u65b0\u6750\u6599\u7684\u5f00\u53d1\u4e0e\u5229\u7528\u3001\u53d1\u5c55\u7eff\u8272\u7ecf\u6d4e\u3001\u73af\u5883\u4fdd\u62a4\u548c\u751f\u6001\u6cbb\u7406\u65b0\u6280\u672f\u7b49\u8bf8\u591a\u65b9\u9762\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.27312720402870727, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5511358856657306}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u3001\u53e5\u610f\u660e\u786e\u7684\u4e00\u9879\u662f____\nA. \u8fd1\u5e74\u6765\u9a91\u9a6c\u7231\u597d\u8005\u5267\u589e\uff0c\u4f7f\u5f97\u8d5b\u9a6c\u8fd0\u52a8\u53d1\u5c55\u8fc5\u901f\uff0c\u76f8\u5e94\u7684\uff0c\u4e00\u4e9b\u9a91\u9a6c\u4ff1\u4e50\u90e8\u4e5f\u5e94\u8fd0\u800c\u751f\u3002\nB. \u4ed6\u9970\u6f14\u4e86\u4e00\u4e2a\u82f1\u96c4\u4eba\u7269\uff0c\u89c2\u4f17\u88ab\u6df1\u6df1\u6253\u52a8\u4e86\uff0c\u8bf4\u8fd9\u662f\u6211\u4eec\u7684\u5076\u50cf\u3002\nC. \u5728\u5f15\u8fdb\u7ade\u4e89\u673a\u5236\u7684\u60c5\u51b5\u4e0b\uff0c\u5982\u679c\u8fd8\u60f3\u6367\u7740\u201c\u94c1\u996d\u7897\u201d\u4e0d\u653e\uff0c\u90a3\u5c31\u662f\u4e00\u53a2\u60c5\u613f\u3002\nD. \u827a\u672f\u6559\u80b2\u65e0\u8bba\u5728\u5fb7\u80b2\u3001\u667a\u80b2\uff0c\u5728\u4eba\u683c\u7684\u5b8c\u5584\u3001\u6027\u60c5\u7684\u9676\u51b6\u7b49\u65b9\u9762\u90fd\u662f\u6559\u80b2\u884c\u4e3a\u4e2d\u7684\u4e00\u4e2a\u91cd\u8981\u7ec4\u6210\u90e8\u5206\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u6587\u6a2a\u7ebf\u5904\u9009\u586b\u54ea\u9879\u6700\u6070\u5f53____\r\n\u5362\u6885\u5761\u7684\u8bd7\u53e5\u201c\u6885\u987b\u900a\u96ea\u4e09\u5206\u767d\uff0c\u96ea\u5374\u8f93\u6885-\u6bb5\u9999\u201d\uff0c\u5e38\u88ab\u4eba\u5f15\u7528\uff0c\u501f\u6b64\u8bf4\u660e____\u3002\nA. \u4efb\u4f55\u4eba\u548c\u4e8b\u7269\u90fd\u5404\u6709\u7f3a\u61be\nB. \u4efb\u4f55\u4eba\u548c\u4e8b\u7269\u90fd\u5404\u6709\u5343\u79cb\nC. \u4efb\u4f55\u4eba\u548c\u4e8b\u7269\u90fd\u5404\u6709\u77ed\u957f\nD. \u4efb\u4f55\u4eba\u548c\u4e8b\u7269\u8005\u54af\u6709\u4f18\u52bf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5464113665922726, "meta-math/MetaMath-Mistral-7B": 0.6216533761803383, "itpossible/Chinese-Mistral-7B-v0.1": 0.3017444864199176, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6640013884957311, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bcd\u8bed\u7684\u6ce8\u97f3\u6709\u9519\u8bef\u7684\u4e00\u9879\u662f____\nA. \u601d\u91cf\uff08li\u00e1ng\uff09\t\u5ea6\u91cf\uff08li\u00e0ng\uff09\t\u80f8\u812f\uff08p\u00fa\uff09\t\u679c\u812f\uff08f\u01d4\uff09\nB. \u98a4\uff08zh\u00e0n\uff09\u6296\t\u98a4\uff08ch\u00e0n\uff09\u6817\t\u9753\uff08j\u00ecng\uff09\u5986\t\u9753\uff08li\u00e0ng\uff09\u5973\nC. \u963d\uff08di\u00e0n\uff09\u5371\t\u73b7\uff08di\u00e0n\uff09\u8fb1\t\u80e1\u8bcc\uff08zh\u014du\uff09\t\u8c04\uff08ch\u01cen\uff09\u8c00\nD. \u778b\u76ee\uff08ch\u0113n\uff09\t\u77a0\uff08ch\u0113ng\uff09\u76ee\u7ed3\u820c  \u89ca\u89ce\uff08y\u00fa\uff09\t\u9762\u9762\u76f8\u89d1\uff08q\u00f9\uff09\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u7684\u4e00\u53e5\u662f____\nA. \u8fd9\u5c4a\u4f53\u80b2\u8282\u4f1a\u5fbd\u548c\u5409\u7965\u7269\u8bbe\u8ba1\u7684\u5e94\u5f81\u8005\u5927\u591a\u4ee5\u9752\u5e74\u4f53\u80b2\u7231\u597d\u8005\u4e3a\u4e3b\u3002\nB. \u8fd9\u5c4a\u201c\u6311\u6218\u676f\u201d\u7ade\u8d5b\u7684\u53c2\u8d5b\u9ad8\u6821\u6570\u91cf\u548c\u4f5c\u54c1\u8d28\u91cf\uff0c\u90fd\u6709\u4e86\u660e\u663e\u63d0\u9ad8\u3002\nC. \u5e08\u5085\u8ba9\u4f4d\u4e8e\u5f92\u5f1f\uff0c\u4ece\u4e00\u4e2a\u4fa7\u9762\u53cd\u6620\u4e86\u4eba\u4eec\u5df2\u4e0d\u518d\u60df\u5e08\u662f\u5c0a\uff0c\u800c\u662f\u5f00\u59cb\u5f3a\u8c03\u591a\u65b9\u9762\u7684\u80fd\u529b\u4e0e\u7d20\u517b\u3002\nD. \u4ee5\u751f\u4ea7\u5185\u8863\u4e3a\u4e3b\u7684\u4e09\u67aa\u96c6\u56e2\uff0c\u662f\u4eca\u5e74\u5728\u5168\u56fd\u540c\u884c\u4e1a\u4e2d\u4ea7\u503c\u7387\u5148\u7a81\u7834\u5341\u4ebf\u5927\u5173\u7684\u4e00\u4e2a\u8457\u540d\u54c1\u724c\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.45421439820760373}}, {"question": "\u4e0b\u6587\u5212\u7ebf\u5904\u9009\u586b\u54ea\u9879\u624d\u6070\u5f53____\r\n\u7fcc\u65e5\uff0c\u8d3e\u6bcd\u5e26\u7740\u8d3e\u84c9\u5ab3\u5987\u4e58\u5750\u4e00\u4e58\u9a6e\u8f7f\uff0c\u738b\u592b\u4eba\u5728\u540e\uff0c\u4ea6\u4e58\u5750\u4e00\u4e58\u9a6e\u8f7f\uff1b\u8d3e\u73cd\u9a91\u9a6c\uff0c\u7387\u9886\u4f17\u5bb6\u4e01\u56f4\u62a4\uff1b____\uff0c\u5e76\u653e\u4e9b\u968f\u6362\u7684\u8863\u5305\u7b49\u4ef6\u3002\nA. \u5a46\u5b50\u4e2b\u73af\u7b49\u4e58\u5750\u51e0\u8f86\u5927\u8f66\nB. \u53c8\u6709\u51e0\u8f86\u5927\u8f66\uff0c\u5a46\u5b50\u4e2b\u73af\u7b49\u5750\nC. \u53c8\u6709\u51e0\u8f86\u5927\u8f66\uff0c\u4e0e\u5a46\u5b50\u4e2b\u73af\u7b49\u5750\nD. \u51e0\u8f86\u5927\u8f66\uff0c\u5a46\u5b50\u4e2b\u73af\u7b49\u5750\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3423962339378881, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bcd\u8bed\u4e2d\u6ce8\u97f3\u5168\u90fd\u6b63\u786e\u7684\u4e00\u9879\u662f____\nA. \u5de8\u64d8(b\u00f2)        \u84d3\u857e(l\u011bi)          \u524d\u5028\u540e\u606d(j\u016b)\nB. \u4e2d\u4f24(zh\u014dn\u0261)     \u8385\u4e34(l\u00ec)           \u97ad\u8f9f\u5165\u91cc(b\u00ec)\nC. \u66f2\u89e3(q\u016b)        \u9a81\u52c7(xi\u0101o)         \u4f59\u52c7\u53ef\u8d3e(\u0261\u01d4)\nD. \u871a\u58f0(f\u0113i)       \u961c\u76db(\uff46\u00f9)          \u91cf\u4f53\u88c1\u8863(li\u00e1n\u0261)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\u52a0\u4e0b\u5212\u7ebf\u7684\u6210\u8bed\u4f7f\u7528\u6070\u5f53\u7684\u4e00\u53e5\u662f\uff1a____\nA. \u4f60\u7684\u8fd9\u4e2a$\\underline{\u4e0d\u60c5\u4e4b\u8bf7}$\u8ba9\u6211\u5f88\u4e3a\u96be\uff0c\u8fc7\u4e24\u5929\u6211\u518d\u7b54\u590d\u4f60\u5427\u3002\nB. \u5bf9\u4e8e\u5b66\u5230\u7684\u539f\u7406\uff0c\u4ed6\u90fd\u8981\u62ff\u5b9e\u7269\u6765\u505a\u5b9e\u9a8c\uff0c\u6c42\u5f97\u5f7b\u5e95\u4e86\u89e3\uff0c\u51b3\u4e0d$\\underline{\u56eb\u56f5\u541e\u67a3}$\uff0c\u9a6c\u864e\u4e86\u4e8b\u3002\nC. \u5ce8\u7709\u5c71\u662f\u95fb\u540d\u4e2d\u5916\u7684\u65c5\u6e38\u80dc\u5730\uff0c\u7d20\u6709\u201c\u5ce8\u7709\u5929\u4e0b\u79c0\u201d\u4e4b\u8a89\u5176\u5dcd\u5ce8\u78c5\u7934\uff0c\u91cd\u5ce6\u53e0\u5d82\uff0c\u5c71\u5c71\u6709\u5947\u666f\uff0c\u5341\u91cc\u4e0d\u540c\u5929\uff0c\u771f\u662f$\\underline{\u5de7\u593a\u5929\u5de5}$\u3002\nD. \u5728\u5b66\u4e60\u4e0a\u4e5f\u662f\u8fd9\u6837\uff0c\u5403\u522b\u4eba\u56bc\u8fc7\u7684\u998d\u4e0d\u9999\uff0c\u8981\u5584\u4e8e\u52a8\u8111\u7b4b\uff0c$\\underline{\u5e08\u5fc3\u81ea\u7528}$\uff0c\u624d\u80fd\u5b66\u6df1\u5b66\u900f\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u53e5\u4e2d\uff0c\u6ca1\u6709\u8bed\u75c5\u7684\u4e00\u9879\u662f____\nA. \u4ee5\u201c\u4f1f\u5927\u5386\u7a0b\u8f89\u714c\u6210\u5c31\u201d\u4e3a\u4e3b\u9898\u7684\u7eaa\u5ff5\u65b0\u4e2d\u56fd\u6210\u7acb70\u5468\u5e74\u5c55\u89c8\u5728\u5317\u4eac\u62c9\u5f00\u5e37\u5e55\uff0c\u8be5\u5c55\u89c8\u91c7\u7528\u7f16\u5e74\u4f53\u7684\u5f62\u5f0f\u4e3a\u4e3b\u5168\u65b9\u4f4d\u56de\u987e\u4e86\u4e2d\u56fd\u4eba\u6c11\u8d70\u8fc7\u7684\u8f89\u714c\u5386\u7a0b\u3002\nB. \u7ecf\u8fc7\u4e3b\u521b\u56e2\u961f\u5bf9\u7ecf\u5178\u6545\u4e8b\u7684\u5927\u80c6\u6539\u7f16\uff0c\u300a\u54ea\u5412\u300b\u4e0d\u4ec5\u4fdd\u7559\u4e86\u539f\u4f5c\u7cbe\u534e\uff0c\u8fd8\u878d\u5165\u4e86\u5177\u6709\u65f6\u4ee3\u5143\u7d20\u7684\u5185\u5bb9\uff0c\u56e0\u6b64\u6210\u529f\u65a9\u83b7\u6691\u671f\u7535\u5f71\u6700\u4f73\u53e3\u7891\u3002\nC. \u7f51\u7edc\u8c23\u8a00\u5bf9\u793e\u4f1a\u7684\u7834\u574f\u529b\u662f\u5de8\u5927\u7684\uff0c\u5982\u4e0d\u53ca\u65f6\u6251\u706d\uff0c\u5bf9\u516c\u4f17\u9020\u6210\u7684\u521b\u4f24\uff0c\u4e43\u81f3\u5f15\u8d77\u793e\u4f1a\u52a8\u8361\uff0c\u4e5f\u4e0d\u662f\u5b8c\u5168\u4e0d\u53ef\u80fd\u7684\u3002\nD. \u5783\u573e\u5206\u7c7b\u5de5\u4f5c\u80fd\u5426\u6267\u884c\u5230\u4f4d\uff0c\u4e00\u65b9\u9762\u53d6\u51b3\u4e8e\u653f\u5e9c\u76f8\u5173\u6cd5\u5f8b\u6cd5\u89c4\u7684\u7ea6\u675f\u529b\uff0c\u53e6\u4e00\u65b9\u9762\u4e5f\u53d6\u51b3\u4e8e\u5e02\u6c11\u7684\u73af\u4fdd\u610f\u8bc6\uff0c\u5c24\u5176\u662f\u5bf9\u5783\u573e\u5206\u7c7b\u610f\u4e49\u7684\u8ba4\u8bc6\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2994509091275925, "meta-math/MetaMath-Mistral-7B": 0.5977709964227158, "itpossible/Chinese-Mistral-7B-v0.1": 0.45287283807467454, "HuggingFaceH4/zephyr-7b-beta": 0.5855464145984783, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u586b\u5165\u4e0b\u6587\u5212\u7ebf\u5904\u6070\u5f53\u7684\u4e00\u53e5\u662f____\r\n\u81ea\u4ece\u201c\u4e94\u56db\u201d\u4ee5\u6765\uff0c\u7ffb\u8bd1\u4ecb\u7ecd\u5148\u8fdb\u56fd\u5bb6\u7684\u6587\u5316\u6210\u679c\uff0c\u5c31\u6210\u4e86\u4e2d\u56fd\u4eba\u6c11\u7684\u8feb\u5207\u8981\u6c42\u3002____\u3002\nA. \u8fd9\u4e9b\u7ffb\u8bd1\u4f5c\u54c1\u4fc3\u8fdb\u4e86\u4e2d\u56fd\u5b66\u672f\u6587\u5316\u7684\u53d1\u5c55\uff0c\u540c\u65f6\u4e5f\u5f71\u54cd\u4e86\u4e2d\u56fd\u7684\u4e66\u9762\u8bed\u8a00\nB. \u7ffb\u8bd1\u4f5c\u54c1\u65e5\u6e10\u5176\u591a\uff0c\u4e00\u65b9\u9762\u8fd9\u4e9b\u4f5c\u54c1\u63d0\u9ad8\u4e86\u4e2d\u56fd\u5b66\u672f\u6587\u5316\u7684\u7d20\u517b\uff0c\u53e6\u4e00\u65b9\u9762\u4e5f\u4fc3\u8fdb\u4e86\u4e2d\u56fd\u4e66\u9762\u8bed\u8a00\u7684\u53d1\u5c55\nC. \u7ffb\u8bd1\u4f5c\u54c1\u65e5\u89c1\u5176\u591a\uff0c\u8fd9\u4e9b\u4f5c\u54c1\u4fc3\u8fdb\u4e86\u4e2d\u56fd\u5b66\u672f\u6587\u5316\u7684\u53d1\u5c55\uff0c\u540c\u65f6\u4e5f\u5f71\u54cd\u4e86\u4e2d\u56fd\u7684\u4e66\u9762\u8bed\u8a00\nD. \u8fd9\u4e9b\u7ffb\u8bd1\u4f5c\u54c1\u63d0\u9ad8\u4e86\u4e2d\u56fd\u5b66\u672f\u6587\u5316\u7684\u7d20\u517b\uff0c\u540c\u65f6\u4e5f\u4fc3\u8fdb\u4e86\u4e2d\u56fd\u4e66\u9762\u8bed\u8a00\u7684\u53d1\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36617639865290497, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4853399784198446, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.40880388358603037, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7525679105645829}}, {"question": "\u586b\u5165\u4e0b\u9762\u6a2a\u7ebf\u5904\u7684\u53e5\u5b50\uff0c\u4e0e\u4e0a\u4e0b\u6587\u8854\u63a5\u6700\u6070\u5f53\u7684\u4e00\u53e5\u662f____\r\n\u300a\u6bdb\u8bd7\u5e8f\u300b\u662f\u5148\u79e6\u5112\u5bb6\u8bd7\u8bba\u7684\u603b\u7ed3\uff0c\u5176\u4e2d\u5fc3\u5185\u5bb9\u662f\u9610\u8ff0\u8bd7\u6b4c\u4e0e\u5c01\u5efa\u653f\u6559\u7684\u5173\u7cfb\u3002____\u3002\u201c\u6b63\u5f97\u5931\uff0c\u52a8\u5929\u5730\uff0c\u611f\u9b3c\u795e\uff0c\u83ab\u8fd1\u4e8e\u8bd7\u3002\u5148\u738b\u4ee5\u662f\u7ecf\u592b\u5987\uff0c\u6210\u5b5d\u656c\uff0c\u539a\u4eba\u4f26\uff0c\u7f8e\u6559\u5316\uff0c\u79fb\u98ce\u4fd7\u3002\u201d\u56e0\u4e3a\u8bd7\u6b4c\u5177\u6709\u611f\u67d3\u7684\u529b\u91cf\uff0c\u6240\u4ee5\u662f\u5c01\u5efa\u7edf\u6cbb\u8005\u7528\u4ee5\u7ef4\u62a4\u653f\u6559\u7684\u6709\u529b\u5de5\u5177\u3002\nA. \u4e45\u5b83\u8ba4\u4e3a\u8bd7\u6b4c\u4e0d\u4ec5\u662f\u793e\u4f1a\u6cbb\u4e71\u3001\u653f\u6559\u5f97\u5931\u7684\u53cd\u6620\uff0c\u800c\u4e14\u53cd\u8fc7\u6765\u53ef\u4ee5\u7ef4\u62a4\u5c01\u5efa\u7edf\u6cbb\u548c\u5c01\u5efa\u79e9\u5e8f\nB. \u5b83\u8ba4\u4e3a\u4e0d\u4ec5\u8bd7\u6b4c\u662f\u653f\u6559\u5f97\u5931\u3001\u793e\u4f1a\u6cbb\u4e71\u7684\u53cd\u6620\uff0c\u800c\u4e14\u53cd\u8fc7\u6765\u53ef\u4ee5\u7ef4\u62a4\u5c01\u5efa\u7edf\u6cbb\u548c\u5c01\u5efa\u79e9\u5e8f\nC. \u5b83\u8ba4\u4e3a\u8bd7\u6b4c\u4e0d\u4f46\u80fd\u7ef4\u62a4\u5c01\u5efa\u7edf\u6cbb\u548c\u5c01\u5efa\u79e9\u5e8f\uff0c\u800c\u4e14\u80fd\u53cd\u6620\u793e\u4f1a\u6cbb\u4e71\u3001\u6c11\u751f\u82e6\u4e50\nD. \u5b83\u8ba4\u4e3a\u7531\u4e8e\u8bd7\u6b4c\u5177\u6709\u5f3a\u5927\u7684\u827a\u672f\u611f\u67d3\u529b\uff0c\u6545\u800c\u5c01\u5efa\u7edf\u6cbb\u8005\u90fd\u8981\u7528\u5b83\u6765\u7ef4\u62a4\u5c01\u5efa\u7edf\u6cbb\u548c\u79e9\u5e8f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u586b\u5165\u4e0b\u9762\u6a2a\u7ebf\u5904\u7684\u53e5\u5b50\uff0c\u4e0e\u4e0a\u53e5\u8854\u63a5\u6700\u6070\u5f53\u7684\u4e00\u7ec4\u662f____\r\n\u516c\u5b89\u5e72\u8b66\u53ca\u65f6\u8d76\u8d74\u73b0\u573a\u4fa6\u5bdf\uff0c\u4e2d\u534812\u65f6\uff0c____\u3002\nA. \u5728\u5bb6\u91cc\u72af\u7f6a\u5acc\u7591\u4eba\u88ab\u6293\u83b7\uff0c\u5168\u90e8\u8d43\u7269\u548c\u8d43\u6b3e\u4e5f\u540c\u65f6\u8d77\u83b7\nB. \u5728\u72af\u7f6a\u5acc\u7591\u4eba\u5bb6\u91cc\u5c06\u5176\u6293\u83b7\uff0c\u5168\u90e8\u8d43\u7269\u548c\u8d43\u6b3e\u4e5f\u540c\u65f6\u8d77\u83b7\nC. \u72af\u7f6a\u5acc\u7591\u4eba\u5728\u5bb6\u91cc\u88ab\u6293\u83b7\uff0c\u5e76\u8d77\u83b7\u4e86\u5168\u90e8\u8d43\u7269\u548c\u8d43\u6b3e\nD. \u5728\u72af\u7f6a\u5acc\u7591\u4eba\u5bb6\u91cc\u5c06\u5176\u6293\u83b7\uff0c\u5e76\u8d77\u83b7\u4e86\u5168\u90e8\u8d43\u7269\u548c\u8d43\u6b3e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7128185801925866, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7649701917706111, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8bcd\u8bed\u4e2d\u6ce8\u97f3\u5168\u90fd\u6b63\u786e\u7684\u4e00\u9879\u662f____\nA. \u63a5\u6d3d(\uff51\uff49\u00e0)     \u63ae\u5ba2(\uff51\uff49\u00e1\uff4e)     \u60ad\u541d(\uff4a\uff49\u00e0\uff4e)     \u5730\u58f3(\uff51\uff49\u00e0\uff4f)\nB. \u521a\u52b2(\uff4a\u00ec\uff4e)     \u8210\u728a(\uff53\uff48\u00ec)       \u9f8b\u9f7f(\uff51\u01d4)         \u79df\u8d41(\uff4c\u00ec\uff4e)\nC. \u754f\u8478(\uff53\u012b)       \u6006\u7136(\uff43\uff48\uff55\u00e0\uff4e\u0261)  \u7688\u4f9d(\u0261\uff55\u012b)        \u5e72\u6db8(\uff48\u00e9)\nD. \u590d\u8f9f(\uff42\u00ec)       \u5df7\u9053(\uff48\u00e0\uff4e\u0261)      \u70bd\u70ed(\uff43\uff48\u00ec)       \u773c\u7751(\uff4a\uff49\u01ce\uff4e)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.30601362565976303, "HuggingFaceH4/zephyr-7b-beta": 0.6319395193620101, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.32871459371036227, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u636e\u7f8e\u56fd\u94a2\u94c1\u4e1a\u7edf\u8ba1\uff0c1870\u5e74\uff0c\u7f8e\u56fd\u6709\u94a2\u94c1\u4f01\u4e1a808\u4e2a\uff0c\u5de5\u4eba7.8\u4e07\u4eba\uff0c\u94a2\u4ea7\u91cf320\u4e07\u5428\uff0c\u6295\u8d44\u989d1210\u4e07\u7f8e\u5143\uff1b\u52301900\u5e74\uff0c\u7f8e\u56fd\u6709\u94a2\u94c1\u4f01\u4e1a669\u4e2a\uff0c\u5de5\u4eba27.2\u4e07\u4eba\uff0c\u94a2\u4ea7\u91cf2950\u4e07\u5428\uff0c\u6295\u8d44\u989d5.9\u4ebf\u7f8e\u5143\u3002\u8fd9\u4e00\u6570\u636e\u53cd\u6620\u768419\u4e16\u7eaa\u540e\u671f\u7f8e\u56fd\u94a2\u94c1\u4e1a\u53d1\u5c55\u53d8\u5316\u7684\u4e3b\u8981\u7279\u5f81\u662f____\nA. \u884c\u4e1a\u7ade\u4e89\u6fc0\u70c8\nB. \u751f\u4ea7\u548c\u8d44\u672c\u8d70\u5411\u96c6\u4e2d\nC. \u4f01\u4e1a\u89c4\u6a21\u4fdd\u6301\u7a33\u5b9a\nD. \u52b3\u52a8\u751f\u4ea7\u7387\u5feb\u901f\u63d0\u9ad8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7758246186750832, "meta-math/MetaMath-Mistral-7B": 0.9075633074974799, "itpossible/Chinese-Mistral-7B-v0.1": 0.8933754228876561, "HuggingFaceH4/zephyr-7b-beta": 0.9981946238047832, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8482041107682283, "meta-llama/Meta-Llama-3-8B": 0.9536045699716076, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9723913147762988}}, {"question": "\u662d\u793a\u7740\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u7684\u6700\u9ad8\u6743\u529b\u5c5e\u4e8e\u4eba\u6c11\u7684\u6807\u5fd7\u662f\uff1a____\nA. \u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u5236\u5ea6\u7684\u786e\u7acb\nB. \u65b0\u4e2d\u56fd\u7684\u6210\u7acb\nC. \u793e\u4f1a\u4e3b\u4e49\u5236\u5ea6\u7684\u521d\u6b65\u786e\u7acb\nD. \u653f\u6cbb\u534f\u5546\u5236\u5ea6\u7684\u5f62\u6210\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5801904697155346, "meta-math/MetaMath-Mistral-7B": 0.9577127460852976, "itpossible/Chinese-Mistral-7B-v0.1": 0.7373082052122731, "HuggingFaceH4/zephyr-7b-beta": 0.9401273600571887, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9191740392219963, "meta-llama/Meta-Llama-3-8B": 0.6355675912652943, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8854641805791446}}, {"question": "\u968b\u5510\u65f6\u671f\uff0c\u9646\u8def\u4e0e\u6d77\u4e0a\u201c\u4e1d\u7ef8\u4e4b\u8def\u201d\u57fa\u672c\u7545\u901a\uff0c\u5510\u671d\u8bbe\u5e02\u8236\u53f8\u4e3b\u7ba1\u5bf9\u5916\u6e2f\u53e3\u8d38\u6613\uff0c\u5b8b\u4ee3\u5bf9\u62db\u5546\u6709\u6210\u6548\u7684\u5b98\u540f\u5b9e\u884c\u63d0\u9ad8\u7ea7\u522b\u5f85\u9047\u7684\u653f\u7b56\uff0c\u6cc9\u5dde\u3001\u5e7f\u5dde\u63a5\u6b64\u6267\u884c\u3002\u53ef\u89c1\uff0c\u5510\u5b8b\u65f6\u671f\u6d77\u5916\u8d38\u6613\u7684\u6d3b\u8dc3\u662f____\nA. \u653f\u5e9c\u653f\u7b56\u63a8\u52a8\u7684\u7ed3\u679c\nB. \u9020\u8239\u4e1a\u53d1\u8fbe\u7684\u4ea7\u7269\nC. \u91cd\u519c\u653f\u7b56\u677e\u52a8\u7684\u8868\u73b0\nD. \u4e1d\u7ec7\u4e1a\u5174\u76db\u7684\u4f53\u73b0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8584225518340431, "meta-math/MetaMath-Mistral-7B": 0.9908433052343656, "itpossible/Chinese-Mistral-7B-v0.1": 0.6607154636362402, "HuggingFaceH4/zephyr-7b-beta": 0.9997025552532949, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.981866338365058, "meta-llama/Meta-Llama-3-8B": 0.7990973025014861, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9679881220539591}}, {"question": "2020\u5e74\uff0c\u6df1\u5733\u7ecf\u6d4e\u7279\u533a\u5efa\u7acb40\u5468\u5e74\u3002\u56db\u5341\u5e74\u6765\uff0c\u6df1\u5733\u5730\u533a\u751f\u4ea7\u603b\u503c\u51fa1979\u5e74\u76841.96\u4ebf\u5143\u589e\u957f\u52302019\u5e74\u76842.6927\u4e07\u4ebf\u5143\uff0c\u6309\u53ef\u6bd4\u4ef7\u683c\u8ba1\u7b97\uff0c\u589e\u957f2491\u500d\uff0c\u5e74\u5747\u589e\u957f21.6%\uff0c\u5b9e\u73b0\u4e86\u7531\u4e00\u5ea7\u843d\u540e\u7684\u8fb9\u9672\u5c0f\u9547\u5230\u5177\u6709\u5168\u7403\u5f71\u54cd\u529b\u7684\u56fd\u9645\u5316\u5927\u90fd\u5e02\u7684\u5386\u53f2\u6027\u8de8\u8d8a\u3002\u6df1\u5733\u5feb\u901f\u5d1b\u8d77\u7684\u91cd\u8981\u539f\u56e0\u662f____\nA. \u7387\u5148\u5c55\u5f00\u4e86\u7ecf\u6d4e\u4f53\u5236\u6539\u9769\nB. \u8f83\u65e9\u5efa\u7acb\u4e86\u5e02\u573a\u7ecf\u6d4e\u4f53\u5236\nC. \u6539\u9769\u5f00\u653e\u653f\u7b56\u7684\u6301\u7eed\u63a8\u52a8\nD. \u6bd7\u90bb\u9999\u6e2f\u5730\u7406\u6761\u4ef6\u8f83\u4f18\u8d8a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4799686361735565, "meta-math/MetaMath-Mistral-7B": 0.762449559970651, "itpossible/Chinese-Mistral-7B-v0.1": 0.6685718654922559, "HuggingFaceH4/zephyr-7b-beta": 0.9597716666148824, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7574068989695008, "meta-llama/Meta-Llama-3-8B": 0.7154515170456891, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9710686098296841}}, {"question": "\u674e\u56db\u5149\u662f\u6211\u56fd20\u4e16\u7eaa\u6770\u51fa\u7684\u79d1\u5b66\u5bb6\uff0c\u4ed6\u5bf9\u7956\u56fd\u7684\u8d21\u732e\u662f____\nA. \u7814\u7a76\u201c\u4e24\u5f39\u4e00\u661f\u201d\nB. \u4e3a\u6211\u56fd\u52d8\u63a2\u77f3\u6cb9\u63d0\u4f9b\u4e86\u7406\u8bba\u4f9d\u636e\nC. \u57f9\u80b2\u51fa\u9ad8\u4ea7\u6c34\u7a3b\nD. \u7814\u5236\u51fa\u5de8\u578b\u8ba1\u7b97\u673a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.45263711683221447, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4219746842879504, "meta-llama/Meta-Llama-3-8B": 0.4627525219094322, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8130025619371734}}, {"question": "\u516c\u51431175\u5e746\u6708\uff0c\u9646\u4e5d\u9f84\u3001\u9646\u4e5d\u6e0a\u5144\u5f1f\u5728\u9e45\u6e56\u5bfa\u4e0e\u6731\u71b9\u5c31\u5404\u81ea\u7684\u54f2\u5b66\u89c2\u70b9\u5c55\u5f00\u6fc0\u70c8\u7684\u8fa9\u8bba\u3002\u5bf9\u4ed6\u4eec\u8fa9\u8bba\u89c2\u70b9\u53d9\u8ff0\u6b63\u786e\u7684\u662f____\nA. \u6731\u71b9\u4e3b\u5f20\u201c\u6cdb\u89c2\u535a\u89c8\uff0c\u800c\u540e\u4e3a\u4e4b\u7ea6\u201d\nB. \u6731\u71b9\u63d0\u51fa\u201c\u5fc3\u5373\u7406\u4e5f\u201d\uff0c\u672c\u5fc3\u5373\u5929\u7406\nC. \u9646\u4e5d\u6e0a\u4e3b\u5f20\u201c\u81f4\u826f\u77e5\u201d\u201c\u77e5\u884c\u5408\u4e00\u201d\nD. \u9646\u4e5d\u6e0a\u533a\u5206\u4e86\u6559\u80b2\u7684\u201c\u5c0f\u5b66\u201d\u201c\u5927\u5b66\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u9f50\u6c11\u8981\u672f\u300b\u7684\u5e8f\u8a00\u4e2d\u5199\u9053\uff1a\u201c\u820d\u672c\u9010\u672b\uff0c\u8d24\u8005\u6240\u975e\u3002\u65e5\u5bcc\u5c81\u8d2b\uff0c\u9965\u5bd2\u4e4b\u6e10\uff0c\u6545\u5546\u8d3e\u4e4b\u4e8b\uff0c\u9619\uff08\u540c\u201c\u7f3a\u201d\uff09\u800c\u4e0d\u5f55\u3002\u201d\u8fd9\u8bf4\u660e\u8be5\u4e66____\nA. \u91cd\u89c6\u5546\u4e1a\u53d1\u5c55\nB. \u63a8\u52a8\u4e86\u5357\u65b9\u519c\u4e1a\u751f\u4ea7\nC. \u4f53\u73b0\u4e86\u4ee5\u519c\u4e3a\u672c\u7684\u601d\u60f3\nD. \u53cd\u6620\u4e86\u6c11\u65cf\u878d\u5408\u7684\u8d8b\u52bf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8067743006983462, "meta-math/MetaMath-Mistral-7B": 0.9766554002272322, "itpossible/Chinese-Mistral-7B-v0.1": 0.7182771005337986, "HuggingFaceH4/zephyr-7b-beta": 0.9958736496301795, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7177912667589025, "meta-llama/Meta-Llama-3-8B": 0.703152447081818, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7928832141576366}}, {"question": "19\u4e16\u7eaa60-70\u5e74\u4ee3\u51fa\u73b0\u4e86\u8d44\u4ea7\u9636\u7ea7\u9769\u547d\u548c\u6539\u9769\u7684\u6d6a\u6f6e\uff0c\u8d44\u672c\u4e3b\u4e49\u5236\u5ea6\u5728\u5168\u4e16\u754c\u8303\u56f4\u5185\u786e\u7acb\u3002\u8fd9\u4e00\u65f6\u671f\u7684\u9769\u547d\u548c\u6539\u9769\u7684\u7279\u70b9\u662f____\nA. \u90fd\u91c7\u7528\u81ea\u4e0a\u800c\u4e0b\u7684\u65b9\u5f0f\nB. \u6392\u9664\u5916\u90e8\u52bf\u529b\u7684\u5e72\u6270\nC. \u4ecd\u6709\u65e7\u5236\u5ea6\u7684\u75d5\u8ff9\nD. \u65e0\u4ea7\u9636\u7ea7\u7b49\u4e0a\u653f\u6cbb\u5386\u53f2\u821e\u53f0\u5e76\u5f00\u59cb\u53d1\u6325\u91cd\u8981\u4f5c\u7528\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9964793353908845, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6692187064747218, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e8c\u6218\u524d\uff0c\u7ea630\u5e74\u7684\u793e\u4f1a\u4e3b\u4e49\u6539\u9769\u548c\u9ad8\u901f\u53d1\u5c55\uff0c\u82cf\u8054\u5de5\u4e1a\u4ea7\u503c\u589e\u957f\u4e8638\u500d\uff0c\u5b9e\u73b0\u4e86\u5de5\u4e1a\u5316\u3002\u4e8c\u6218\u540e\uff0c\u82cf\u8054\u7ecf\u6d4e\u7ee7\u7eed\u4fdd\u6301\u4e86\u8f83\u9ad8\u589e\u957f\u7387\u30021946-1950\u5e74\uff0c\u793e\u4f1a\u603b\u4ea7\u503c\u5e74\u5747\u589e\u957f\u7387\u4e3a14.4%\uff0c1951\u5e74\u20141960\u5e74\u4e3a10%\uff0c\u8fdc\u9ad8\u4e8e\u540c\u671f\u7684\u7f8e\u6b27\u56fd\u5bb6\u3002\u82cf\u8054\u7ecf\u6d4e\u7684\u9ad8\u901f\u589e\u957f\u5f97\u76ca\u4e8e____\nA. \u5de5\u519c\u4e1a\u751f\u4ea7\u7684\u5747\u8861\u53d1\u5c55\nB. \u8ba1\u5212\u7ecf\u6d4e\u4f53\u5236\u7684\u5f71\u54cd\nC. \u6b27\u7f8e\u56fd\u5bb6\u906d\u9047\u7ecf\u6d4e\u5371\u673a\nD. \u79d1\u5b66\u6280\u672f\u7684\u5feb\u901f\u53d1\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.783473797768736, "meta-math/MetaMath-Mistral-7B": 0.9606549761602249, "itpossible/Chinese-Mistral-7B-v0.1": 0.8699603161619214, "HuggingFaceH4/zephyr-7b-beta": 0.9742160283286853, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9808271520058925, "meta-llama/Meta-Llama-3-8B": 0.4706646783063024, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9846182433874016}}, {"question": "\u5efa\u56fd\u521d\u56fd\u6c11\u7ecf\u6d4e\u6062\u590d\u65f6\u671f\uff0c\u5f53\u65f6\u56fd\u5bb6\u7ecf\u6d4e\u5de5\u4f5c\u4e2d\u6700\u8feb\u5207\u7684\u4efb\u52a1\u662f____\nA. \u7a33\u5b9a\u7269\u4ef7\nB. \u6ca1\u6536\u5b98\u50da\u8d44\u672c\uff0c\u5efa\u7acb\u56fd\u8425\u7ecf\u6d4e\nC. \u7edf\u4e00\u8d22\u7ecf\nD. \u5408\u7406\u8c03\u6574\u5de5\u5546\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4947459530213668, "meta-math/MetaMath-Mistral-7B": 0.8879234282657167, "itpossible/Chinese-Mistral-7B-v0.1": 0.4638260800808638, "HuggingFaceH4/zephyr-7b-beta": 0.9702067213945121, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u56fd\u8d44\u672c\u4e3b\u4e49\u840c\u82bd\u51fa\u73b0\u7684\u4e3b\u8981\u6807\u5fd7\u662f____\nA. \u624b\u5de5\u4e1a\u4f5c\u574a\u5927\u91cf\u589e\u591a\nB. \u624b\u5de5\u4e1a\u6280\u672f\u6c34\u5e73\u7a7a\u524d\u63d0\u9ad8\nC. \u201c\u673a\u6237\u51fa\u8d44\uff0c\u673a\u5de5\u51fa\u529b\u201d\u7684\u201c\u673a\u623f\u201d\u4ea7\u751f\nD. \u5546\u54c1\u7ecf\u6d4e\u53d1\u5c55.\u5bf9\u5916\u8d38\u6613\u6269\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37992540642600275, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9959947848030996, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4451936161658243, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5968243158330544}}, {"question": "15\u4e16\u7eaa\u4e2d\u53f6\uff0c\u5728\u4e0e\u4e1c\u65b9\u7684\u8d38\u6613\u4e2d\uff0c\u6b27\u6d32\u7684\u91d1\u94f6\u6e90\u6e90\u4e0d\u65ad\u5411\u5916\u6d41\u51fa\uff0c\u201c\u9ec4\u91d1\u95ee\u9898\u201d\u53d8\u4e3a\u6b27\u6d32\u7ecf\u6d4e\u4e0a\u7684\u4e25\u91cd\u5371\u673a\u3002\u7531\u6b64\u5e26\u6765\u7684\u76f4\u63a5\u5f71\u54cd\u662f____\nA. \u6b27\u6d32\u4e2d\u5fc3\u5730\u4f4d\u9010\u6b65\u786e\u7acb\nB. \u82f1\u56fd\u6210\u7acb\u4e1c\u5370\u5ea6\u516c\u53f8\nC. \u523a\u6fc0\u4e86\u6b27\u6d32\u5f00\u8f9f\u65b0\u822a\u8def\nD. \u5f15\u53d1\u4e86\u6b27\u6d32\u7684\u4ef7\u683c\u9769\u547d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4045257140067991, "meta-math/MetaMath-Mistral-7B": 0.4097933037728859, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8472420829637127, "meta-llama/Meta-Llama-3-8B": 0.6066621007123628, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6407600180050231}}, {"question": "\u8f9b\u4ea5\u9769\u547d\u540e\uff0c\u5728\u8bb8\u591a\u901a\u5546\u5927\u57e0\uff0c\u4eba\u4eec\"\u8d8b\u6539\u6d0b\u670d\u6d0b\u5e3d\uff0c\u5176\u4e3a\u6570\u4e0d\u77e5\u51e1\u51e0\"\uff1b\u5f53\u65f6\uff0c\u5bb6\u5883\u7a0d\u4f18\u88d5\u8005\"\u5fc5\u5907\u6d0b\u670d\u6570\u5957\uff0c\u4ee5\u793a\u7ef4\u65b0\"\uff0c\u5373\u4f7f\u662f\"\u8863\u98df\u8270\u96be\u4e4b\u8f88\uff0c\u4ea6\u591a\u820d\u81ea\u5236\u4e4b\u8349\u5e3d\uff0c\u800c\u8d2d\u5916\u6765\u4e4b\u8349\u5e3d\"\u3002\u8fd9\u79cd\u73b0\u8c61\u51fa\u73b0\u7684\u4e3b\u8981\u539f\u56e0\u662f____\nA. \u5d07\u6d0b\u98ce\u6c14\u7684\u76db\u884c\nB. \u793e\u4f1a\u6027\u8d28\u7684\u53d8\u5316\nC. \u653f\u5e9c\u653f\u7b56\u7684\u5f15\u5bfc\nD. \u8d2b\u5bcc\u5dee\u8ddd\u7684\u589e\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "1883\u5e74\uff0c\u4e3a\u89e3\u51b3\u77e5\u8bc6\u4ea7\u6743\u7684\u56fd\u9645\u4fdd\u62a4\u95ee\u9898\uff0c\u6b27\u7f8e\u56fd\u5bb6\u76f8\u4e92\u5408\u4f5c\uff0c\u534f\u5546\u8fbe\u6210\u4e86\u300a\u4fdd\u62a4\u5de5\u4e1a\u4ea7\u6743\u5df4\u9ece\u516c\u7ea6\u300b\uff0c\u6210\u7acb\u4fdd\u62a4\u5de5\u4e1a\u4ea7\u6743\uff08\u5305\u62ec\u4e13\u5229\u6743\uff09\u7684\u56fd\u9645\u4e13\u5229\u5c40\uff0c\u7531\u6b64\u5f00\u521b\u4e86\u56fd\u9645\u4fdd\u62a4\u77e5\u8bc6\u4ea7\u6743\u7684\u5148\u6cb3\u3002\u8be5\u4e3e\u63aa____\nA. \u63a8\u52a8\u7b2c\u4e00\u6b21\u5de5\u4e1a\u9769\u547d\u7684\u53d1\u751f\u4e0e\u53d1\u5c55\nB. \u63d0\u9ad8\u6b27\u7f8e\u56fd\u5bb6\u5728\u4e16\u754c\u5e02\u573a\u7684\u7ade\u4e89\u529b\nC. \u6709\u529b\u6291\u5236\u4e86\u56fd\u9645\u7ecf\u8d38\u4e2d\u7684\u5f3a\u6743\u653f\u6cbb\nD. \u6210\u4e3a\u4e16\u754c\u5e02\u573a\u8fc5\u901f\u62d3\u5c55\u4e3b\u8981\u9014\u5f84\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6366200944252312, "meta-math/MetaMath-Mistral-7B": 0.9165360112490872, "itpossible/Chinese-Mistral-7B-v0.1": 0.41181126583177446, "HuggingFaceH4/zephyr-7b-beta": 0.999850097441776, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9353370298537392, "meta-llama/Meta-Llama-3-8B": 0.5906120580878216, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9020156659750294}}, {"question": "\u897f\u5468\u65f6\u671f\uff0c\u7528\u4e8e\u89e3\u51b3\u8840\u4eb2\u8d35\u65cf\u4e4b\u95f4\u5728\u6743\u529b\u3001\u8d22\u4ea7\u548c\u571f\u5730\u7ee7\u627f\u4e0a\u77db\u76fe\u7684\u5236\u5ea6\u662f____\nA. \u5206\u5c01\u5236\nB. \u5b97\u6cd5\u5236\nC. \u4e95\u7530\u5236\nD. \u7985\u8ba9\u5236\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5944043876915932, "meta-math/MetaMath-Mistral-7B": 0.7822975316960868, "itpossible/Chinese-Mistral-7B-v0.1": 0.511193498646212, "HuggingFaceH4/zephyr-7b-beta": 0.8792798489955579, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6757492976079577, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e2d\u56fd\u8bfb\u4e66\u4eba\u5386\u6765\u201c\u803b\u4e8e\u8a00\u5546\uff0c\u803b\u4e8e\u8a00\u5229\u201d\uff0c\u800c\u6e05\u672b\u72b6\u5143\u5f20\u8b07\u5374\u653e\u5f03\u4ed5\u9014\uff0c\u6295\u8eab\u4e8e\u8fd1\u4ee3\u5de5\u5546\u4e1a\u3002\u8fd9\u91cc\u53cd\u6620\u51fa\u7684\u65f6\u4ee3\u89c2\u5ff5\u662f____\nA. \u5b9e\u4e1a\u6551\u56fd\nB. \u5de5\u5546\u7686\u672c\nC. \u91cd\u5229\u8f7b\u4e49\nD. \u91cd\u5546\u8f7b\u519c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37887254889294053, "meta-math/MetaMath-Mistral-7B": 0.763508020693905, "itpossible/Chinese-Mistral-7B-v0.1": 0.7246135113727112, "HuggingFaceH4/zephyr-7b-beta": 0.4916237397704288, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7344132123697928, "meta-llama/Meta-Llama-3-8B": 0.5940327556981279, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7346970679416004}}, {"question": "\u6bdb\u6cfd\u4e1c\u7684\u4e3b\u8981\u5386\u53f2\u8d21\u732e\u6709____\r\n\u2460\u5e26\u9886\u4e2d\u56fd\u4eba\u6c11\u5b9e\u73b0\u6c11\u65cf\u72ec\u7acb    \r\n\u2461\u63d0\u51fa\u201c\u767e\u82b1\u9f50\u653e\u3001\u767e\u5bb6\u4e89\u9e23\u201d\u7684\u65b9\u9488\r\n  \u2462\u5f00\u542f\u4e2d\u7f8e\u5173\u7cfb\u6b63\u5e38\u5316\u5386\u7a0b    \r\n\u2463\u91cd\u65b0\u786e\u7acb\u89e3\u653e\u601d\u60f3\u3001\u5b9e\u4e8b\u6c42\u662f\u7684\u601d\u60f3\u8def\u7ebf\nA. \u2460\u2461\u2462\nB. \u2460\u2461\u2463\nC. \u2460\u2462\u2463\nD. \u2461\u2462\u2463\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6e05\u672b\u6c11\u521d\uff0c\u5728\u5e7f\u5927\u4e61\u6751\uff0c\u4ee5\u4f20\u7edf\u755c\u529b\u8f66\u53ca\u6728\u8239\u4e3a\u4e3b\uff0c\u867d\u6709\u81ea\u884c\u8f66\u548c\u516c\u5171\u6c7d\u8f66\uff0c\u4f46\u53d1\u5c55\u7f13\u6162\u3002\u8fd9\u8bf4\u660e\u5f53\u65f6\u6211\u56fd____\nA. \u519c\u6751\u5c01\u95ed\u72b6\u6001\u4e25\u91cd\nB. \u57ce\u4e61\u4ea4\u901a\u5dee\u8ddd\u8f83\u5927\nC. \u65b0\u65e7\u4ea4\u901a\u5de5\u5177\u5e76\u5b58\nD. \u8fd1\u4ee3\u4ea4\u901a\u5f00\u59cb\u6539\u9769\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3529667315455447, "meta-math/MetaMath-Mistral-7B": 0.7724796508152271, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5556087045828851, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44966513927888074, "meta-llama/Meta-Llama-3-8B": 0.42941358538895313, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7f8e\u56fd\u5baa\u6cd5\u5c06\u653f\u5e9c\u5206\u4e3a\u76f8\u4e92\u72ec\u7acb\u7684\u4e09\u4e2a\u90e8\u5206\uff0c\u5e76\u4f34\u4e4b\u4ee5\u5236\u8861\u5236\u5ea6\uff0c\u4ee5\u9632\u6b62\u5176\u4e2d\u4efb\u4f55\u4e00\u90e8\u5206\u660e\u663e\u5730\u9ad8\u4e8e\u5176\u5b83\u90e8\u5206\u3002\u8fd9\u5b9e\u73b0\u4e86\u54ea\u4f4d\u601d\u60f3\u5bb6\u7684\u4e3b\u5f20____\nA. \u4f0f\u5c14\u6cf0\nB. \u5362\u68ad\nC. \u5b5f\u5fb7\u65af\u9e20\nD. \u5eb7\u5fb7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32225510020639786, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3436615088034303, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9794344306659754, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.983491693889603}}, {"question": "1880\u5e74\uff0c\u65e5\u672c\u653f\u5e9c\u7684\u4e00\u9879\u6559\u80b2\u6307\u4ee4\u79f0\uff1a\u5e94\u5229\u7528\u201c\u53e4\u4eca\u4e4b\u753b\u50cf\u7167\u7247\u201d\u5ba3\u4f20\u5fe0\u5b5d\u7cbe\u795e\uff1b\u4e0e\u5176\u8fc7\u5206\u5173\u6ce8\u9ad8\u6df1\u7684\u7406\u8bba\u548c\u5916\u8bed\uff0c\u4e0d\u5982\u5bf9\u519c\u5546\u5eb6\u6c11\u65bd\u4ee5\u751f\u5b58\u7684\u5b9e\u9645\u6559\u80b2\u3002\u7ed3\u5408\u6240\u5b66\u5224\u65ad\uff0c\u8be5\u6307\u4ee4____\nA. \u8bd5\u56fe\u963b\u6b62\u897f\u65b9\u79d1\u6280\u7684\u4f20\u64ad\nB. \u8868\u660e\u5fe0\u5b5d\u7cbe\u795e\u5df2\u5728\u65e5\u672c\u74e6\u89e3\nC. \u65e8\u5728\u5f3a\u5316\u65e5\u672c\u793e\u4f1a\u7684\u7b49\u7ea7\u5236\u5ea6\nD. \u65e8\u5728\u57f9\u517b\u638c\u63e1\u73b0\u4ee3\u6280\u80fd\u7684\u5fe0\u987a\u81e3\u6c11\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8890055496925382, "meta-math/MetaMath-Mistral-7B": 0.9667019462145254, "itpossible/Chinese-Mistral-7B-v0.1": 0.7274484282762209, "HuggingFaceH4/zephyr-7b-beta": 0.9993288020842759, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9468221786200764, "meta-llama/Meta-Llama-3-8B": 0.8337380971797651, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9526448533281245}}, {"question": "\u6b4c\u66f2\u300a\u6625\u5929\u7684\u6545\u4e8b\u300b\u4e2d\u6709\u201c\u90a3\u662f\u4e00\u4e2a\u6625\u5929\uff0c\u6709\u4e00\u4f4d\u8001\u4eba\u5728\u4e2d\u56fd\u7684\u5357\u6d77\u8fb9\u753b\u4e86\u4e00\u4e2a\u5708\u201d\uff0c\u8fd9\u53e5\u6b4c\u8bcd\u6307\u7684\u662f____\nA. \u5b9e\u884c\u6c11\u65cf\u533a\u57df\u81ea\u6cbb\nB. \u5236\u5b9a\u793e\u4f1a\u4e3b\u4e49\u521d\u7ea7\u9636\u6bb5\u7684\u57fa\u672c\u8def\u7ebf\nC. \u63a8\u884c\u5bb6\u5ead\u8054\u4ea7\u627f\u5305\u8d23\u4efb\u5236\nD. \u5efa\u7acb\u7ecf\u6d4e\u7279\u533a\u5b9e\u884c\u5bf9\u5916\u5f00\u653e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5097675912446954, "meta-math/MetaMath-Mistral-7B": 0.49184901406379156, "itpossible/Chinese-Mistral-7B-v0.1": 0.5428422083910406, "HuggingFaceH4/zephyr-7b-beta": 0.963003999172829, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5749918976319641, "meta-llama/Meta-Llama-3-8B": 0.6109588665935083, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6589201182097436}}, {"question": "\u88ab\u79f0\u4e3a\u4e2d\u56fd\u8fd1\u4ee3\u53f2\u4e0a\u7b2c\u4e00\u6b21\u5de8\u53d8\u7684\u662f____\nA. \u8f9b\u4ea5\u9769\u547d\u7684\u80dc\u5229\u548c\u4e2d\u534e\u6c11\u56fd\u7684\u6210\u7acb\nB. \u6d0b\u52a1\u8fd0\u52a8\u5f00\u59cb\u4e86\u4e2d\u56fd\u7684\u8fd1\u4ee3\u5316\nC. 1840\u5e74\u9e26\u7247\u6218\u4e89\nD. \u620a\u620c\u53d8\u6cd5\u6cd5\u4ee4\u7684\u9881\u5e03\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4487345922690983, "meta-math/MetaMath-Mistral-7B": 0.8617204501455792, "itpossible/Chinese-Mistral-7B-v0.1": 0.5262386627528426, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41172531682861635, "meta-llama/Meta-Llama-3-8B": 0.6526395479035315, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4697679424145983}}, {"question": "\u968b\u671d\u672b\u5e74\uff0c\u6709\u4f4d\u5546\u4eba\u6b32\u901a\u8fc7\u5927\u8fd0\u6cb3\u4ece\u4f59\u676d\u8fd0\u9001\u4e00\u6279\u7cae\u98df\u5230\u6d1b\u9633\uff0c\u5176\u5148\u540e\u8981\u7ecf\u8fc7____\nA. \u6c5f\u5357\u6cb3\u2192\u9097\u6c9f\nB. \u9097\u6c9f\u2192\u6c5f\u5357\u6cb3\u2192\u901a\u6d4e\u6e20\nC. \u6c5f\u5357\u6cb3\u2192\u9097\u6c9f\u2192\u6c38\u6d4e\u6e20\nD. \u6c5f\u5357\u6cb3\u2192\u9097\u6c9f\u2192\u901a\u6d4e\u6e20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45686299232658883, "meta-math/MetaMath-Mistral-7B": 0.8011531426409427, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8036195045083576, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4699766828466004, "meta-llama/Meta-Llama-3-8B": 0.34040633907578005, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2005\u5e74\u662f\u4e2d\u56fd\u7535\u5f71\u8bde\u751f100\u5468\u5e74\u3002\u767e\u5e74\u524d\uff0c\u6211\u56fd\u62cd\u6444\u7684\u7b2c\u4e00\u90e8\u7535\u5f71\u662f____\u3002\nA. \u300a\u9a6c\u8def\u5929\u4f7f\u300b\nB. \u300a\u6e14\u5149\u66f2\u300b\nC. \u300a\u5b9a\u519b\u5c71\u300b\nD. \u300a\u5341\u5b57\u8857\u5934\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.31938304507653403, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5023813135788648, "meta-llama/Meta-Llama-3-8B": 0.31911523504877376, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e03\u5e74\u7ea7\uff08\u4e00\uff09\u73ed\u672c\u6708\u8d1f\u8d23\u5b66\u6821\u6587\u5316\u957f\u5eca\u7684\u9ed1\u677f\u62a5\u8bbe\u8ba1\uff0c\u4ed6\u4eec\u9009\u5b9a\u7684\u4e3b\u9898\u662f\u201c\u5510\u4ee3\u7684\u4e2d\u5916\u4ea4\u5f80\u201d\uff0c\u5e76\u62df\u5b9a\u4e86\u5982\u4e0b\u56db\u4e2a\u6807\u9898\uff0c\u8bf7\u4f60\u5e2e\u4ed6\u4eec\u6307\u51fa\u54ea\u4e00\u9879\u662f\u4e0d\u6070\u5f53\u7684____\nA. \u6587\u6210\u516c\u4e3b\u4e0e\u677e\u8d5e\u5e72\u5e03\u6210\u4eb2\nB. \u9274\u771f\u4e1c\u6e21\u5ba3\u626c\u4e2d\u56fd\u6587\u5316\nC. \u7384\u5958\u897f\u6e38\u5929\u7afa\u53d6\u7ecf\nD. \u65e5\u672c\u6d3e\u9063\u5510\u4f7f\u6765\u534e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4527235670473921, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6563869106249582, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u82f1\u56fd\u8d44\u4ea7\u9636\u7ea7\u9769\u547d\u524d\uff0c\u65b0\u8d35\u65cf\u548c\u65e7\u8d35\u65cf\u7684\u4e3b\u8981\u533a\u522b\u5728\u4e8e\u4ed6\u4eec____\nA. \u5bf9\u541b\u4e3b\u4e13\u5236\u7684\u6001\u5ea6\nB. \u8eab\u4efd\u548c\u5730\u4f4d\nC. \u5bf9\u4eba\u6c11\u7684\u6001\u5ea6\nD. \u91c7\u7528\u7684\u751f\u4ea7\u65b9\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5386\u53f2\u4e0a\u7b2c\u4e00\u4e2a\u5706\u4e86\u4eba\u7c7b\u98de\u4e0a\u84dd\u5929\u7684\u68a6\u60f3\u800c\u88ab\u79f0\u4e3a\u201c\u822a\u5929\u98de\u884c\u5668\u7684\u5148\u9a71\u201d\u7684\u662f____\u3002\nA. \u5965\u6258\nB. \u83b1\u7279\u5144\u5f1f\nC. \u5bcc\u5170\u514b\u6797\nD. \u8499\u7279\u54e5\u83f2\u5c14\u5144\u5f1f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3324879294350306, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.848067592475605, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7724796612910317, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9996747212968673}}, {"question": "\u201c\u5f53\u9769\u547d\u7684\u98ce\u66b4\u6a2a\u626b\u6574\u4e2a\u6cd5\u56fd\u7684\u65f6\u5019\uff0c\u82f1\u56fd\u6b63\u5728\u8fdb\u884c\u4e00\u573a\u6bd4\u8f83\u5e73\u9759\u3001\u4f46\u662f\u5e76\u4e0d\u56e0\u6b64\u5c31\u663e\u5f97\u7f3a\u4e4f\u529b\u91cf\u7684\u53d8\u9769\u3002\u201d\u8fd9\u53e5\u8bdd\u4e2d\u7684\u201c\u53d8\u9769\u201d\u662f\u6307____\u3002\nA. \u82f1\u56fd\u8d44\u4ea7\u9636\u7ea7\u9769\u547d\nB. \u5149\u8363\u9769\u547d\nC. \u82f1\u56fd\u7ec4\u7ec7\u7684\u201c\u53cd\u6cd5\u540c\u76df\u201d\nD. \u5de5\u4e1a\u9769\u547d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9497881690492112, "meta-math/MetaMath-Mistral-7B": 0.9990326559311622, "itpossible/Chinese-Mistral-7B-v0.1": 0.5103689082028736, "HuggingFaceH4/zephyr-7b-beta": 0.999921760900324, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9866163910008391, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fd1\u4ee3\u4e2d\u56fd\u9762\u4e34\u7740\u4e25\u91cd\u7684\u6c11\u65cf\u5371\u673a\uff0c\u65e0\u6570\u4ec1\u4eba\u5fd7\u58eb\u90fd\u5728\u63a2\u6c42\u6551\u56fd\u6551\u6c11\u7684\u51fa\u8def\u3002\u4e0b\u5217\u9009\u9879\u642d\u914d\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u674e\u9e3f\u7ae0\u2192\u6d0b\u52a1\u8fd0\u52a8\nB. \u9b4f\u6e90\u2192\u620a\u620c\u53d8\u6cd5\nC. \u5b59\u4e2d\u5c71\u2192\u8f9b\u4ea5\u9769\u547d\nD. \u9648\u72ec\u79c0\u2192\u65b0\u6587\u5316\u8fd0\u52a8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4052824778727207, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.63740001155407, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6426946419804292, "meta-llama/Meta-Llama-3-8B": 0.5567495501650369, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6e05\u4ee3\u7687\u5e1d\u5728\u5317\u4eac\u897f\u90ca\u5efa\u9020\u7684\u4e2d\u897f\u5408\u74a7\u7684\u7687\u5bb6\u56ed\u6797\u2500\u2500\u5706\u660e\u56ed\u662f\u5728\u4e2d____\u88ab____\u6bc1\u6389\u7684\u3002\nA. \u9e26\u7247\u6218\u4e89\u3001\u82f1\u56fd\nB. \u7b2c\u4e8c\u6b21\u9e26\u7247\u6218\u4e89\u3001\u82f1\u56fd\u548c\u6cd5\u56fd\nC. \u7532\u5348\u4e2d\u65e5\u6218\u4e89\u3001\u65e5\u672c\nD. \u516b\u56fd\u8054\u519b\u4fb5\u534e\u6218\u4e89\u3001\u516b\u56fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3211269784560798, "meta-math/MetaMath-Mistral-7B": 0.457570726354355, "itpossible/Chinese-Mistral-7B-v0.1": 0.48128636358058524, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5678408657456304, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9520670144897225}}, {"question": "\u4e0b\u5217\u4e0e\u6b66\u5219\u5929\u6709\u5173\u7684\u8868\u8ff0\u4e0d\u51c6\u786e\u7684\u4e00\u9879\u662f____\u3002\nA. \u4ee3\u5510\u9ad8\u5b97\u89c6\u653f\uff0c\u521d\u663e\u7ba1\u7406\u624d\u80fd\nB. \u81ea\u7acb\u4e3a\u5e1d\uff0c\u6539\u56fd\u53f7\u4e3a\u201c\u5468\u201d\nC. \u201c\u6b66\u5468\u653f\u6cbb\u201d\u65f6\u671f\uff0c\u793e\u4f1a\u7ecf\u6d4e\u8fbe\u5230\u524d\u6240\u672a\u6709\u7684\u6781\u76db\u65f6\u671f\nD. \u4ee5\u6b8b\u9177\u8bdb\u6740\u7684\u624b\u6bb5\u5bf9\u4ed8\u674e\u5510\u5b97\u5ba4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6248486762152041, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9436563738223329}}, {"question": "1943\u5e742\u6708\uff0c\u7f57\u65af\u798f\u5728\u81f4\u65af\u5927\u6797\u7684\u4e00\u5c01\u8d3a\u4fe1\u4e2d\u5199\u5230\uff1a\u201c\u662f\u4f60\u4eec\u5236\u6b62\u4e86\u4fb5\u7565\u6d6a\u6f6e\uff0c\u6210\u4e3a\u76df\u519b\u53cd\u4fb5\u7565\u6218\u4e89\u7684\u8f6c\u6298\u70b9\u3002\u201d\u8fd9\u4e00\u201c\u8f6c\u6298\u70b9\u201d\u662f\u6307____\nA. \u65e5\u672c\u5077\u88ad\u73cd\u73e0\u6e2f\nB. \u83ab\u65af\u79d1\u4fdd\u536b\u6218\nC. \u65af\u5927\u6797\u683c\u52d2\u4f1a\u6218\nD. \u8bfa\u66fc\u5e95\u767b\u9646\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7513178109885719, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4043216625437318}}, {"question": "\u7532\u5348\u4e2d\u65e5\u6218\u4e89\u5931\u8d25\u4ee5\u540e\uff0c\u674e\u9e3f\u7ae0\u4f24\u611f\u5730\u53cd\u7701\u8bf4\uff1a\u201c\u6211\u529e\u4e86\u4e00\u8f88\u5b50\u4e8b\uff0c\u7ec3\u5175\u4e5f\uff0c\u6d77\u519b\u4e5f\uff0c\u90fd\u662f\u7eb8\u7cca\u7684\u8001\u864e\u2026\u2026\u4e0d\u8fc7\u52c9\u5f3a\u6d82\u9970\uff0c\u865a\u6709\u5176\u8868\u3002\u201d\u5bf9\u8fd9\u53e5\u8bdd\u7684\u7406\u89e3\uff0c\u6700\u4e3a\u6b63\u786e\u7684\u5e94\u5f53\u662f____\nA. \u6d0b\u52a1\u8fd0\u52a8\u4e00\u65e0\u662f\u5904\nB. \u6d0b\u52a1\u8fd0\u52a8\u52b3\u800c\u65e0\u529f\nC. \u6d0b\u52a1\u8fd0\u52a8\u7684\u76ee\u7684\u5728\u4e8e\u8868\u9762\u505a\u505a\u6837\u5b50\nD. \u6d0b\u52a1\u8fd0\u52a8\u6ca1\u6709\u8fbe\u5230\u201c\u81ea\u5f3a\u201d\u3001\u201c\u6c42\u5bcc\u201d\u7684\u76ee\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6629267611161193}}, {"question": "1997\u5e747\u67081\u65e5\u9999\u6e2f\u7ef4\u591a\u5229\u4e9a\u6e2f\u6e7e\u7684\u4f1a\u5c55\u4e2d\u5fc3\u706f\u706b\u8f89\u714c\uff0c0\u65f6\u6574\uff0c\u4f34\u968f\u7740\u5639\u4eae\u7684\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u56fd\u6b4c\uff0c\u9c9c\u8273\u7684\u4e94\u661f\u7ea2\u65d7\u5189\u5189\u5347\u8d77\u3002\u4ece\u8fd9\u4e00\u523b\u8d77____\nA. \u9999\u6e2f\u793e\u4f1a\u5236\u5ea6\u6539\u53d8\u4e86\nB. \u4e2d\u56fd\u5bf9\u9999\u6e2f\u6062\u590d\u884c\u4f7f\u4e3b\u6743\nC. \u9999\u6e2f\u7ecf\u6d4e\u7279\u533a\u6210\u7acb\u4e86\nD. \u9999\u6e2f\u5f00\u59cb\u5b9e\u884c\u6c11\u65cf\u533a\u57df\u81ea\u6cbb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7729329539023008, "meta-math/MetaMath-Mistral-7B": 0.9950344369391457, "itpossible/Chinese-Mistral-7B-v0.1": 0.6251917493002416, "HuggingFaceH4/zephyr-7b-beta": 0.9395510014552998, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9350498609842182, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9811640315917254}}, {"question": "\u6709\u4e9b\u4eba\u7684\u540d\u5b57\u5f80\u5f80\u4e0e\u65f6\u4ee3\u7279\u5f81\u6709\u4e00\u5b9a\u7684\u8054\u7cfb\uff0c\u4e0b\u5217\u540d\u5b57\u4e2d\u4e0e\u4ed6\u51fa\u751f\u7684\u65f6\u4ee3\u7279\u5f81\u4e0d\u76f8\u7b26\u5408\u7684\u662f____\nA. \u51fa\u751f\u4e8e1949\u5e74\uff0c\u53d6\u540d\u5efa\u56fd\nB. \u51fa\u751f\u4e8e1951\u5e74\uff0c\u53d6\u540d\u63f4\u671d\nC. \u51fa\u751f\u4e8e1958\u5e74\uff0c\u53d6\u540d\u8dc3\u8fdb\nD. \u51fa\u751f\u4e8e1978\u5e74\uff0c\u53d6\u540d\u6587\u9769\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.48438633060354563, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6791841616277358, "HuggingFaceH4/zephyr-7b-beta": 0.6664841507591008, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5052963379994225, "meta-llama/Meta-Llama-3-8B": 0.5243222984399222, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u4eca\u5929\u83f2\u5f8b\u5bbe\u7684\u9a6c\u514b\u5766\u5c9b\u4e0a\u77d7\u7acb\u7740\u4e00\u5757\u53cc\u9762\u7891\uff0c\u4e00\u9762\u7684\u7891\u6587\u662f\u7eaa\u5ff5\u9ea6\u54f2\u4f26\uff0c\u56e0\u4e3a\u4ed6\u5b8c\u6210\u4e86\u4eba\u7c7b\u5386\u53f2\u4e0a\u7b2c\u4e00\u6b21\u73af\u7403\u822a\u884c\uff1b\u53e6\u4e00\u9762\u662f\u7eaa\u5ff5\u83f2\u5f8b\u5bbe\u7684\u4e00\u4f4d\u52c7\u58eb\uff0c\u56e0\u4e3a\u6b63\u662f\u4ed6\u6740\u6b7b\u4e86\u6b96\u6c11\u5934\u5b50\u9ea6\u54f2\u4f26\u3002\u5bf9\u4e8e\u65b0\u822a\u8def\u7684\u5f00\u8f9f\uff0c\u4ee5\u4e0b\u8bf4\u6cd5\u4e0d\u786e\u5207\u7684\u662f____\nA. \u63a8\u52a8\u4e86\u6d77\u5916\u6269\u5f20\u548c\u4e16\u754c\u5e02\u573a\u7684\u521d\u6b65\u5f62\u6210\nB. \u52a0\u901f\u4e86\u6b27\u6d32\u7684\u8d44\u672c\u539f\u59cb\u79ef\u7d2f\nC. \u6253\u7834\u4e86\u4e16\u754c\u5404\u5730\u533a\u7684\u5c01\u95ed\u548c\u5b64\u7acb\u72b6\u6001\nD. \u5bfc\u81f4\u4e86\u7b2c\u4e00\u6b21\u9e26\u7247\u6218\u4e89\u7684\u53d1\u751f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5485226185086203, "meta-math/MetaMath-Mistral-7B": 0.9335883105090221, "itpossible/Chinese-Mistral-7B-v0.1": 0.7633044104321756, "HuggingFaceH4/zephyr-7b-beta": 0.9784068878444142, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9191740392219964, "meta-llama/Meta-Llama-3-8B": 0.8253532584992705, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.45092007275187534}}, {"question": "\u628a\u9e26\u7247\u6218\u4e89\u4f5c\u4e3a\u4e2d\u56fd\u8fd1\u4ee3\u53f2\u7684\u5f00\u7aef\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a____\nA. \u4e2d\u56fd\u793e\u4f1a\u6027\u8d28\u53d1\u751f\u4e86\u53d8\u5316\nB. \u4e2d\u56fd\u793e\u4f1a\u4e3b\u8981\u77db\u76fe\u53d1\u751f\u4e86\u53d8\u5316\nC. \u4e2d\u56fd\u9769\u547d\u6027\u8d28\u53d1\u751f\u4e86\u53d8\u5316\nD. \u4e2d\u56fd\u4eba\u6c11\u9769\u547d\u4efb\u52a1\u53d1\u751f\u4e86\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6cb3\u59c6\u6e21\u539f\u59cb\u5c45\u6c11\u751f\u6d3b\u72b6\u51b5\u7684\u63cf\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u4e00\u9879\u662f____\nA. \u4f1a\u9972\u517b\u5bb6\u755c\nB. \u4f1a\u5236\u9020\u9752\u94dc\u5668\nC. \u79cd\u690d\u6c34\u7a3b\nD. \u4f1a\u5236\u9020\u5e72\u680f\u5f0f\u623f\u5c4b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5873401727207056, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7824311043034099}}, {"question": "\u6539\u9769\u5f00\u653e\u4ee5\u6765\uff0c\u6211\u56fd\u7684\u5916\u4ea4\u4e8b\u4e1a\u53d6\u5f97\u91cd\u5927\u6210\u5c31\u7684\u6839\u672c\u539f\u56e0\u662f____\nA. \u7efc\u5408\u56fd\u529b\u7684\u589e\u5f3a\nB. \u72ec\u7acb\u81ea\u4e3b\u7684\u548c\u5e73\u5916\u4ea4\u653f\u7b56\nC. \u4e2d\u56fd\u662f\u8054\u5408\u56fd\u5b89\u7406\u4f1a\u5e38\u4efb\u7406\u4e8b\u56fd\nD. \u6210\u529f\u4e3e\u529e\u4e9a\u592a\u7ecf\u5408\u7ec4\u7ec7\u4f1a\u8bae\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9767428035881052}}, {"question": "\u5f62\u6210\u65e5\u540e\u534e\u590f\u65cf\u7684\u4e3b\u8981\u90e8\u843d\u662f____\nA. \u9ec4\u5e1d\u3001\u86a9\u5c24\u90e8\u843d\nB. \u708e\u5e1d\u3001\u86a9\u5c24\u90e8\u843d\nC. \u9ec4\u5e1d\u3001\u708e\u5e1d\u3001\u86a9\u5c24\u90e8\u843d\nD. \u9ec4\u5e1d\u3001\u708e\u5e1d\u90e8\u843d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5337677715354708, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u515a\u5728\u793e\u4f1a\u4e3b\u4e49\u521d\u7ea7\u9636\u6bb5\u57fa\u672c\u8def\u7ebf\u7684\u6838\u5fc3\u5185\u5bb9\u662f\u201c\u4e00\u4e2a\u4e2d\u5fc3\uff0c\u4e24\u4e2a\u57fa\u672c\u70b9\u201d\uff0c\u8fd9\u91cc\u201c\u4e00\u4e2a\u4e2d\u5fc3\u201d\u662f\u6307____\nA. \u4ee5\u6539\u9769\u5f00\u653e\u4e3a\u4e2d\u5fc3\nB. \u4ee5\u7ecf\u6d4e\u5efa\u8bbe\u4e3a\u4e2d\u5fc3\nC. \u4ee5\u56db\u9879\u57fa\u672c\u539f\u5219\u4e3a\u4e2d\u5fc3\nD. \u4ee5\u8270\u82e6\u521b\u4e1a\u4e3a\u4e2d\u5fc3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8054766401956605, "meta-math/MetaMath-Mistral-7B": 0.9873390926962561, "itpossible/Chinese-Mistral-7B-v0.1": 0.6852212152091665, "HuggingFaceH4/zephyr-7b-beta": 0.9991465376827922, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9377971096369425, "meta-llama/Meta-Llama-3-8B": 0.9420714551905137, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7317385045137726}}, {"question": "\u6539\u9769\u5f00\u653e\u4ee5\u6765\uff0c\u515a\u548c\u653f\u5e9c\u4e3a\u53d1\u5c55\u793e\u4f1a\u4e3b\u4e49\u7ecf\u6d4e\u91c7\u53d6\u7684\u4e3e\u63aa\u4e0d\u5305\u62ec____\nA. \u5efa\u7acb\u7ecf\u6d4e\u7279\u533a\nB. \u519c\u6751\u5b9e\u884c\u5bb6\u5ead\u8054\u4ea7\u627f\u5305\u8d23\u4efb\u5236\nC. \u57ce\u5e02\u5b9e\u884c\u7ecf\u6d4e\u4f53\u5236\u6539\u9769\nD. \u519c\u6751\u5efa\u7acb\u4eba\u6c11\u516c\u793e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8991236531141108, "meta-math/MetaMath-Mistral-7B": 0.9922823224346458, "itpossible/Chinese-Mistral-7B-v0.1": 0.768916485062119, "HuggingFaceH4/zephyr-7b-beta": 0.9892370893162247, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9851149946419755, "meta-llama/Meta-Llama-3-8B": 0.9765230808776969, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.990215848202056}}, {"question": "\u7532\u4e0e\u4e59\u51c6\u5907\u8fdb\u884c\u4e00\u4e2a\u6e38\u620f\uff1a\u5411\u7a7a\u4e2d\u6254\u4e09\u679a\u786c\u5e01\uff0c\u5982\u679c\u5b83\u4eec\u843d\u5730\u540e\u5168\u662f\u6b63\u9762\u5411\u4e0a\u6216\u5168\u662f\u53cd\u9762\u5411\u4e0a\uff0c\u4e59\u5c31\u7ed9\u7532\u94b1\uff1b\u4f46\u82e5\u51fa\u73b0\u4e24\u6b63\u9762\u4e00\u53cd\u9762\u6216\u4e24\u53cd\u9762\u4e00\u6b63\u9762\u7684\u60c5\u51b5\uff0c\u5219\u7531\u7532\u7ed9\u4e59\u94b1\u3002\u4e59\u8981\u6c42\u7532\u6bcf\u6b21\u7ed910\u5143\uff0c\u90a3\u4e48\uff0c\u4ece\u957f\u8fdc\u6765\u770b\uff0c\u7532\u5e94\u8be5\u8981\u6c42\u4e59\u6bcf\u6b21\u81f3\u5c11\u7ed9____\u5143\u624d\u53ef\u8003\u8651\u53c2\u52a0\u8fd9\u4e2a\u6e38\u620f\u3002\nA. 10\nB. 15\nC. 20\nD. 30\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7133696477505281, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36727669046039974, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8457\u540d\u8bd7\u4eba\u4e0e\u5176\u4ee3\u8868\u4f5c\u5bf9\u5e94\u6709\u8bef\u7684\u662f____\u3002\nA. \u674e\u767d\u2014\u2014\u300a\u5c06\u8fdb\u9152\u300b\nB. \u767d\u5c45\u6613\u2014\u2014\u300a\u7435\u7436\u884c\u300b\nC. \u738b\u4e4b\u7115\u2014\u2014\u300a\u767b\u9e73\u96c0\u697c\u300b\nD. \u675c\u752b\u2014\u2014\u300a\u957f\u6068\u6b4c\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.32205625344145955, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ecf\u6d4e\u5b66\u4e0a\u6240\u63a8\u5d07\u7684\u201c\u6a44\u6984\u578b\u201d\u6536\u5165\u5206\u914d\u7ed3\u6784\uff0c\u662f\u6307\u4f4e\u6536\u5165\u548c\u9ad8\u6536\u5165\u76f8\u5bf9\u8f83\u5c11\u3001\u4e2d\u7b49\u6536\u5165\u5360\u7edd\u5927\u591a\u6570\u7684\u5206\u914d\u7ed3\u6784\u3002\u6211\u56fd\u6b63\u5728\u91c7\u53d6\u63aa\u65bd\uff0c\u5b9e\u65bd\u201c\u63d0\u4f4e\u3001\u6269\u4e2d\u3001\u8c03\u9ad8\u3001\u6253\u975e\u3001\u4fdd\u56f0\u201d\u7684\u65b9\u9488\uff0c\u4f7f\u6536\u5165\u5206\u914d\u671d\u7740\u201c\u6a44\u6984\u578b\u201d\u65b9\u5411\u53d1\u5c55\u3002\u8fd9\u4e3b\u8981\u662f\u4e3a\u4e86\u4fc3\u8fdb____\u3002\nA. \u751f\u4ea7\u7684\u53d1\u5c55\nB. \u6548\u7387\u7684\u63d0\u9ad8\nC. \u793e\u4f1a\u7684\u516c\u5e73\nD. \u5185\u9700\u7684\u6269\u5927\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7146656444769119, "meta-math/MetaMath-Mistral-7B": 0.8820904260942921, "itpossible/Chinese-Mistral-7B-v0.1": 0.745115257667703, "HuggingFaceH4/zephyr-7b-beta": 0.9557303631467945, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9388041629321962, "meta-llama/Meta-Llama-3-8B": 0.9030422852345626, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9893488236990574}}, {"question": "-81\uff0c-36\uff0c-9\uff0c0\uff0c9\uff0c36\uff0c____\nA. 49\nB. 64\nC. 81\nD. 100\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3127242143872847, "meta-math/MetaMath-Mistral-7B": 0.38336773256430384, "itpossible/Chinese-Mistral-7B-v0.1": 0.325455072595945, "HuggingFaceH4/zephyr-7b-beta": 0.7276845242121183, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3632122790984035, "meta-llama/Meta-Llama-3-8B": 0.34478590299221606, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.44229888016213803}}, {"question": "VIP\u670d\u52a1\u672c\u6765\u662f\u4e2a\u597d\u4e1c\u897f\uff0c\u5927\u4f01\u4e1a\u4f5c\u4e3a\u5e02\u573a\u7ade\u4e89\u7684\u4e3b\u4f53\uff0c\u5b9e\u884c\u5dee\u522b\u5316\u670d\u52a1\uff0c\u65e0\u53ef\u539a\u975e\u3002\u4f46\u8fd1\u5e74\u6765\uff0c\u4e00\u4e9b\u4f01\u4e1a\u7eb7\u7eb7\u8fdb\u519b\u533b\u9662\u3001\u673a\u573a\u3001\u8f66\u7ad9\u7b49\u516c\u5171\u573a\u6240\uff0c\u638f\u4e9b\u8d5e\u52a9\u8d39\uff0c\u8bbe\u7acb\u6240\u8c13\u201c\u8d35\u5bbe\u5385\u201d\uff0c\u9738\u5360\u516c\u5171\u8d44\u6e90\uff0c\u4e0d\u4ec5\u5e26\u6765\u6d6a\u8d39\uff0c\u66f4\u9020\u6210\u516c\u5171\u8d44\u6e90\u5206\u914d\u7684\u4e0d\u516c\u3002\u8fd9\u6bb5\u6587\u5b57\u4e3b\u8981\u5f3a\u8c03\u7684\u662f____\u3002\nA. \u516c\u5171\u8d44\u6e90\u4e0d\u8be5\u8fc7\u5ea6VIP\nB. VIP\u670d\u52a1\u5bfc\u81f4\u4e86\u516c\u5171\u8d44\u6e90\u7684\u4e0d\u516c\u5e73\u5206\u914d\nC. \u4e00\u4e9b\u4f01\u4e1a\u642c\u8fdb\u533b\u9662\u3001\u673a\u573a\u3001\u8f66\u7ad9\u529e\u516c\nD. \u5b9e\u884c\u5dee\u522b\u5316\u670d\u52a1\u662fVIP\u670d\u52a1\u7684\u4f18\u52bf\u6240\u5728\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4909128015387219, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2\uff0c5\uff0c8\uff0c12\uff0c17\uff0c24\uff0c____\nA. 30\nB. 32\nC. 34\nD. 36\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2947319625574089, "meta-math/MetaMath-Mistral-7B": 0.325455072595945, "itpossible/Chinese-Mistral-7B-v0.1": 0.33424033456012464, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31712010892822357, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5483660273152502}}, {"question": "4\uff0c4\uff0c6\uff0c12\uff0c30\uff0c____\nA. 48\nB. 64\nC. 80\nD. 90\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f53\u4e0b\u4e2d\u56fd\u6587\u5b66\u63cf\u5199\u5b98\u6597\u3001\u804c\u6597\u3001\u5a5a\u6597\u3001\u5bb6\u6597\u7684\u4f5c\u54c1\u6bd4\u8f83\u6d41\u884c\uff0c\u8fd9\u4e9b\u4f5c\u54c1\u4e2d\u5305\u542b\u4e86\u4e0d\u5c11\u5bf9\u65e5\u5e38\u751f\u6d3b\u4e2d\u6743\u672f\u548c\u5fc3\u673a\u7684\u63cf\u5199\u3002\u8fd9\u6837\u7684\u5199\u4f5c\u6709\u53ef\u80fd\u524a\u5f31\u6587\u5b66\u5bf9\u793e\u4f1a\u7684\u79ef\u6781\u5f71\u54cd\u3002\u6587\u5b66\u6709\u5fc5\u8981\u4e0e\u6b63\u4e49\u7ed3\u76df\uff0c\u5f62\u6210\u8bd7\u6027\u6b63\u4e49\uff0c\u4ee5\u63d0\u5347\u751f\u6d3b\u3002 \u4f5c\u8005\u60f3\u8868\u8fbe\u7684\u4e3b\u8981\u89c2\u70b9\u662f____\u3002\nA. \u5f53\u4e0b\u6587\u5b66\u4f5c\u54c1\u7684\u793e\u4f1a\u5f71\u54cd\u529b\u6709\u4e0b\u964d\u7684\u8d8b\u52bf\nB. \u6d41\u884c\u4f5c\u54c1\u672a\u5fc5\u662f\u597d\u4f5c\u54c1\uff0c\u8fd9\u9700\u8981\u65f6\u95f4\u7684\u68c0\u9a8c\nC. \u6587\u5b66\u4e0d\u5e94\u8fc7\u5ea6\u6e32\u67d3\u6743\u672f\u673a\u8bc8\uff0c\u5426\u5219\u6709\u53ef\u80fd\u6cef\u706d\u6b63\u4e49\nD. \u751f\u6d3b\u4e2d\u6ca1\u90a3\u4e48\u591a\u6743\u672f\u673a\u8bc8\uff0c\u6587\u5b66\u521b\u4f5c\u5e94\u8be5\u8d34\u8fd1\u751f\u6d3b\uff0c\u4e0d\u80fd\u95ed\u95e8\u9020\u8f66\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8012465559990456, "meta-math/MetaMath-Mistral-7B": 0.9038756614174233, "itpossible/Chinese-Mistral-7B-v0.1": 0.9306282109254818, "HuggingFaceH4/zephyr-7b-beta": 0.9946248776929328, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.934578169811118, "meta-llama/Meta-Llama-3-8B": 0.9373576379247117, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9784068881592288}}, {"question": "\u4e00\u5929\uff0c\u4e00\u4e2a\u519c\u6c11\u7684\u9a74\u5b50\u6389\u5230\u67af\u4e95\u91cc\uff0c\u90a3\u53ef\u601c\u7684\u9a74\u5b50\u5728\u4e95\u91cc\u51c4\u51c9\u5730\u60e8\u53eb\u4e86\u51e0\u4e2a\u949f\u5934\uff0c\u519c\u6c11\u4ea6\u6025\u5f97\u56e2\u56e2\u8f6c\uff0c\u5c31\u662f\u6beb\u65e0\u529e\u6cd5\u628a\u5b83\u6551\u8d77\u6765\uff0c\u6700\u540e\uff0c\u4ed6\u65ad\u7136\u8ba4\u5b9a\uff1a\u9a74\u5b50\u5df2\u8001\u4e86\uff0c\u8fd9\u53e3\u67af\u4e95\u4e5f\u8be5\u586b\u8d77\u6765\uff0c\u4e0d\u503c\u5f97\u82b1\u7cbe\u529b\u53bb\u6551\u9a74\u5b50\u3002\u4ed6\u8bf7\u6765\u6240\u6709\u90bb\u5c45\u5e2e\u4ed6\u586b\u4e95\u3002\u5927\u5bb6\u6293\u8d77\u94c1\u9539\uff0c\u5f00\u59cb\u5f80\u4e95\u91cc\u586b\u571f\u3002\u9a74\u5b50\u5f88\u5feb\u610f\u8bc6\u5230\u53d1\u751f\u4e86\u4ec0\u4e48\u4e8b\uff0c\u8d77\u521d\uff0c\u5b83\u6050\u614c\u5730\u5927\u54ed\uff0c\u4e0d\u4e00\u4f1a\u513f\uff0c\u5c45\u7136\u5b89\u9759\u4e0b\u6765\u3002\u4eba\u4eec\u5fcd\u4e0d\u4f4f\u5f80\u4e95\u91cc\u770b\uff0c\u5947\u8ff9\u53d1\u751f\u4e86\u3002\u6bcf\u4e00\u94f2\u7838\u5230\u9a74\u5b50\u80cc\u4e0a\u7684\u571f\uff0c\u5b83\u90fd\u4f5c\u4e86\u51fa\u4eba\u610f\u6599\u7684\u5904\u7406\uff1a\u8fc5\u901f\u6296\u843d\u4e00\u8eab\u5c18\u571f\uff0c\u7136\u540e\u72e0\u72e0\u5730\u7528\u811a\u8e29\u7d27\u3002\u8fd9\u6837\uff0c\u6ca1\u8fc7\u591a\u4e45\uff0c\u9a74\u5b50\u7adf\u7136\u81ea\u5df1\u628a\u81ea\u5df1\u5347\u4e86\u8d77\u6765\uff0c\u5230\u4e86\u4e95\u53e3\uff0c\u5b83\u7eb5\u8eab\u4e00\u8df3\uff0c\u5e73\u5b89\u5730\u8dd1\u5f00\u4e86\uff0c\u5728\u573a\u7684\u4eba\u5747\u60ca\u8be7\u4e0d\u5df2\u3002 \u8fd9\u6bb5\u6587\u5b57\u544a\u8bc9\u6211\u4eec\u7684\u9053\u7406\u662f____\u3002\nA. \u4eba\u751f\u4e2d\u7684\u6bcf\u4e00\u4e2a\u56f0\u96be\u90fd\u662f\u901a\u5f80\u6210\u529f\u7684\u57ab\u811a\u77f3\nB. \u6362\u4e00\u79cd\u601d\u7ef4\u5e38\u5e38\u80fd\u591f\u4ea7\u751f\u610f\u60f3\u4e0d\u5230\u7684\u6548\u679c\nC. \u51b7\u9759\u601d\u8003\u662f\u514b\u670d\u56f0\u96be\u7684\u9996\u8981\u6761\u4ef6\nD. \u6c42\u4eba\u4e0d\u5982\u6c42\u5df1\uff0c\u5f88\u591a\u65f6\u5019\uff0c\u81ea\u5df1\u624d\u662f\u81ea\u5df1\u6700\u5927\u7684\u6551\u661f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u73b0\u4ee3\u793e\u4f1a\uff0c\u6559\u80b2\u7b26\u53f7\u4e5f\u5373\u6587\u51ed\u548c\u5b66\u5386\u662f\u4e00\u79cd\u91cd\u8981\u7684\u6587\u5316\u8d27\u5e01\uff0c\u624b\u6301\u7b26\u53f7\u8d44\u672c\uff0c\u53ef\u8fdb\u5165\u76f8\u5e94\u804c\u4e1a\u7fa4\u4f53\u3001\u8eab\u4efd\u56e2\u4f53\u548c\u793e\u4f1a\u4f4d\u7f6e\u3002\u8b6c\u5982\uff0c\u51ed\u501f\u533b\u5b66\u535a\u58eb\u6587\u51ed\uff0c\u53ef\u6210\u4e3a\u533b\u751f\u3002\u6b64\u4e3a\u6559\u80b2\u7684\u7b5b\u9009\u529f\u80fd\uff0c\u4ea6\u88ab\u55bb\u4e3a\u4eba\u624d\u7684\u5206\u7c7b\u7f16\u7801\u573a\uff0c\u5982\u540c\u516c\u5171\u6c7d\u8f66\u603b\u7ad9\uff0c\u76ee\u7684\u5730\u4e0d\u540c\u7684\u4eba\u9009\u62e9\u4e0d\u540c\u7684\u8def\u7ebf\uff0c\u4e58\u5750\u4e0d\u540c\u7684\u8f66\u8f86\uff0c\u5230\u8fbe\u4e0d\u540c\u7684\u5730\u65b9\u3002 \u4e0b\u5217\u9009\u9879\u4e0d\u7b26\u5408\u6587\u610f\u7684\u4e00\u9879\u662f____\u3002\nA. \u6587\u51ed\u4e0e\u5b66\u5386\u90fd\u662f\u7b26\u53f7\u8d44\u672c\nB. \u6559\u80b2\u7b26\u53f7\u662f\u4eba\u624d\u7684\u5206\u7c7b\u7f16\u7801\nC. \u6587\u51ed\u4f53\u73b0\u4e86\u6559\u80b2\u7684\u7b5b\u9009\u529f\u80fd\nD. \u624b\u6301\u76f8\u5e94\u7684\u7b26\u53f7\u8d44\u672c\u624d\u80fd\u8fdb\u5165\u76f8\u5e94\u7684\u804c\u4e1a\u7fa4\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3726141238768168, "meta-math/MetaMath-Mistral-7B": 0.4577567358487682, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4faf\u65b9\u57df\uff1a\u300a\u6843\u82b1\u6247\u300b____\nA. \u84b2\u677e\u9f84\uff1a\u300a\u804a\u658b\u5fd7\u5f02\u300b\nB. \u77f3\u5934\u8bb0\uff1a\u300a\u7ea2\u697c\u68a6\u300b\nC. \u5d14\u83ba\u83ba\uff1a\u300a\u897f\u53a2\u8bb0\u300b\nD. \u79e6\u59cb\u7687\uff1a\u300a\u540e\u6c49\u4e66\u300b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.542942982460123, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5530822578835833}}, {"question": "____\u5168\u515a\u540c\u5fd7\u548c\u5168\u56fd\u4eba\u6c11\u56e2\u7ed3\u4e00\u5fc3\uff0c\u575a\u6301\u4e0d\u61c8\u5730\u594b\u6597\uff0c\u4e0d\u65ad\u53d6\u5f97\u624e\u624e\u5b9e\u5b9e\u7684\u6210\u6548\uff0c\u6211\u4eec____\u4e00\u5b9a\u80fd\u591f\u4f7f\u793e\u4f1a\u4e3b\u4e49\u65b0\u519c\u6751\u5efa\u8bbe\u771f\u6b63\u6210\u4e3a\u60e0\u53ca\u5e7f\u5927\u519c\u6c11\u7fa4\u4f17\u7684\u6c11\u5fc3\u5de5\u7a0b\u3002 \u586b\u5165\u753b\u6a2a\u7ebf\u90e8\u5206\u6700\u6070\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u5982\u679c \u5c31\nB. \u53ea\u6709 \u624d\u80fd\nC. \u53ea\u8981 \u5c31\nD. \u5018\u82e5 \u4e5f\u5c31\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4842603604609771, "meta-math/MetaMath-Mistral-7B": 0.9666742089923368, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9963771092066921, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9301188201362682, "meta-llama/Meta-Llama-3-8B": 0.38253225505393756, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4242631597241338}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u4e16\u754c\u94f6\u884c\u7684\u8bf4\u6cd5\u4e2d\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u539f\u540d\u56fd\u9645\u590d\u5174\u5f00\u53d1\u94f6\u884c\uff0c\u4e8e1944\u5e74\u5f00\u59cb\u8425\u4e1a\nB. \u5b83\u662f\u8054\u5408\u56fd\u4e0b\u5c5e\u7684\u4e00\u4e2a\u4e13\u95e8\u673a\u6784\nC. \u662f\u8d1f\u8d23\u957f\u671f\u8d37\u6b3e\u7684\u56fd\u9645\u91d1\u878d\u673a\u6784\nD. \u8d37\u6b3e\u671f\u9650\u8f83\u957f\uff0c\u4e00\u822c\u4e3a\u6570\u5e74\uff0c\u6700\u957f\u53ef\u8fbe30\u5e74\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5014154826951555, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3588823130168717, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5916\u8d44\u94f6\u884c\u8fdb\u5165\u65b0\u5174\u5e02\u573a\u56fd\u5bb6\uff0c\u65b0\u5174\u5e02\u573a\u56fd\u5bb6\u94f6\u884c\u4e1a\u7684\u5404\u4e3b\u4f53\u4e3a\u4e86\u7ef4\u6301\u81ea\u8eab\u7684\u751f\u5b58\uff0c\u4f1a\u5c3d\u53ef\u80fd\u4e89\u53d6\u8f83\u5927\u7684\u5e02\u573a\u4efd\u989d\uff0c\u5145\u5206\u62d3\u5c55\u81ea\u8eab\u7ade\u4e89\u4f18\u52bf\uff0c\u52aa\u529b\u5411\u5ba2\u6237\u63d0\u4f9b\u8d28\u4f18\u4ef7\u5ec9\u7684\u91d1\u878d\u4ea7\u54c1\u548c\u91d1\u878d\u670d\u52a1\uff0c\u8fd9\u4e2a\u8fc7\u7a0b\u5fc5\u7136\u5e26\u52a8\u94f6\u884c\u4e1a\u5fae\u89c2\u6548\u7387\u7684\u63d0\u5347\u3002 \u201c\u8fd9\u4e2a\u8fc7\u7a0b\u201d\u6307\u7684\u662f____\u3002\nA. \u5916\u8d44\u94f6\u884c\u8fdb\u5165\u65b0\u5174\u5e02\u573a\u56fd\u5bb6\u7684\u8fc7\u7a0b\nB. \u65b0\u5174\u5e02\u573a\u56fd\u5bb6\u94f6\u884c\u4e1a\u53d1\u5c55\u7684\u8fc7\u7a0b\nC. \u5916\u8d44\u94f6\u884c\u63d0\u4f9b\u4f18\u8d28\u670d\u52a1\u7684\u8fc7\u7a0b\nD. \u65b0\u5174\u5e02\u573a\u56fd\u5bb6\u94f6\u884c\u4e1a\u6269\u5927\u5e02\u573a\u4efd\u989d\u7684\u8fc7\u7a0b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6309\u7167\u884c\u653f\u5c42\u7ea7\u6807\u51c6\u6765\u5212\u5206\uff0c\u6211\u56fd\u653f\u5e9c\u673a\u6784\u7684\u7c7b\u578b\u6709____\u3002\nA. \u4e00\u822c\u5730\u65b9\u56fd\u5bb6\u884c\u653f\u673a\u5173\u548c\u57fa\u5c42\u56fd\u5bb6\u884c\u653f\u673a\u5173\u4e24\u5927\u7c7b\nB. \u5e38\u8bbe\u673a\u6784\u4e0e\u975e\u5e38\u8bbe\u673a\u6784\u4e24\u7c7b\nC. \u9886\u5bfc\u673a\u6784\u3001\u529e\u516c\u529e\u4e8b\u673a\u6784\u3001\u804c\u80fd\u673a\u6784\u548c\u6d3e\u51fa\u673a\u6784\u56db\u7c7b\nD. \u4e2d\u592e\u56fd\u5bb6\u884c\u653f\u673a\u5173\u548c\u5730\u65b9\u56fd\u5bb6\u884c\u653f\u673a\u5173\u4e24\u5927\u7c7b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9499454788535936, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5078567302974059, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5519925134984398}}, {"question": "\u5728\u67d0\u5e02\u4e00\u9879\u5bf9\u516c\u53f8\u5e74\u8f7b\u4eba\u5458\u7684\u6700\u65b0\u8c03\u67e5\u4e2d\uff0c\u4e0e\u5f80\u5e74\u76f8\u6bd4\uff0c\u4eca\u5e74\u670970\uff05\u7684\u4eba\u6253\u7b97\u8d2d\u4e70\u623f\u5c4b\uff0c\u8fd9\u4e00\u6bd4\u4f8b\u5df2\u8fbe\u5230\u5386\u53f2\u6700\u9ad8\u503c\u3002\u7136\u800c\uff0c\u5728\u623f\u5c4b\u7ba1\u7406\u5c40\u7684\u7edf\u8ba1\u4e2d\uff0c\u8be5\u5e02\u4eca\u5e74\u7684\u623f\u5c4b\u6210\u4ea4\u91cf\u5374\u6bd4\u5f80\u5e74\u6709\u6240\u4e0b\u964d\u3002\u4ee5\u4e0b\u54ea\u9879\u5982\u679c\u4e3a\u771f\uff0c\u6700\u4e0d\u80fd\u89e3\u91ca\u4e0a\u8ff0\u73b0\u8c61?____\nA. \u4e00\u4e9b\u6253\u7b97\u8d2d\u4e70\u623f\u5c4b\u7684\u5e74\u8f7b\u4eba\u76ee\u524d\u5e76\u4e0d\u5177\u5907\u8be5\u5e02\u8d2d\u4e70\u623f\u5c4b\u7684\u6761\u4ef6\nB. \u5f80\u5e74\u8d44\u6599\u8868\u660e\uff0c\u5e74\u8f7b\u4eba\u5458\u8d2d\u4e70\u623f\u5c4b\u7684\u6bd4\u4f8b\u4e0d\u8db3\u8d2d\u4e70\u623f\u5c4b\u6210\u5458\u768430\uff05\nC. \u8fd1\u5e74\u6765\u7206\u53d1\u7684\u91d1\u878d\u98ce\u66b4\uff0c\u5bf9\u623f\u5730\u4ea7\u884c\u4e1a\u6709\u4e00\u5b9a\u7684\u6253\u51fb\nD. \u8fd1\u51e0\u4e2a\u6708\u8be5\u5e02\u697c\u5e02\u4ef7\u683c\u4e0d\u7a33\u5b9a\uff0c\u4f7f\u5f97\u4e00\u4e9b\u8d2d\u623f\u8005\u6301\u89c2\u671b\u6001\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u4eec\u4ee5\u5f80\u6240\u7406\u89e3\u7684\u201c\u73b0\u4ee3\u5316\u201d\u6982\u5ff5\u4ec5\u4ec5\u5c40\u9650\u4e8e\u7269\u8d28\u5c42\u9762\uff0c\u5c40\u9650\u4e8e\u8868\u5c42\u7ecf\u6d4e\u73b0\u4ee3\u5316\uff0c\u8fd9\u4e5f\u662f\u8fdf\u53d1\u5c55\u56fd\u5bb6\u957f\u671f\u5b58\u5728\u7684\u4e00\u4e2a\u666e\u904d\u6027\u95ee\u9898\uff1a\u5728\u7269\u8d28\u5c42\u9762\u4e0a\u6c42\u53d8\u7684\u6b32\u671b\u5f88\u5f3a\uff0c\u800c\u5728\u5236\u5ea6\u5c42\u9762\u548c\u89c2\u5ff5\u5c42\u9762\u4e0a\u5374\u662f\u6587\u5316\u5b88\u6210\u4e3b\u4e49\u7684\uff0c\u8fd9\u79cd\u72b6\u51b5\u5bf9\u4e8e\u73b0\u4ee3\u5316\u5b9e\u9645\u8fdb\u7a0b\u7684\u5f71\u54cd\u81ea\u4e0d\u5fc5\u8bf4\uff0c\u5b83\u5bf9\u4e8e\u5b66\u672f\u7684\u5f71\u54cd\u662f\u5bfc\u81f4\u77e5\u8bc6\u7684\u6d41\u4fd7\u5316\u3002\u4e0d\u65ad\u5730\u66f4\u6362\u65b0\u8bcd\u8bed\uff0c\u5728\u65b0\u8bcd\u8bed\u7684\u88c5\u6f62\u4e0b\u91cd\u590d\u53e4\u8001\u7684\u601d\u60f3\u89c2\u5ff5\uff0c\u7ed3\u679c\u662f\u8bcd\u8bed\u548c\u53e3\u53f7\u4e0d\u65ad\u5730\u66f4\u6362\u800c\u793e\u4f1a\u7cbe\u795e\u6c14\u8d28\u5219\u6ca1\u6709\u5b9e\u8d28\u6027\u7684\u53d8\u5316\u3002 \u8fd9\u6bb5\u6587\u5b57\u8981\u8868\u8fbe\u7684\u4e3b\u8981\u610f\u601d\u662f____\u3002\nA. \u73b0\u4ee3\u5316\u5e94\u5305\u62ec\u7269\u8d28\u7684\u3001\u5236\u5ea6\u7684\u3001\u89c2\u5ff5\u7684\u4e09\u4e2a\u5c42\u9762\nB. \u7247\u9762\u7406\u89e3\u73b0\u4ee3\u5316\u662f\u8fdf\u53d1\u5c55\u56fd\u5bb6\u957f\u671f\u5b58\u5728\u7684\u4e00\u4e2a\u666e\u904d\u6027\u95ee\u9898\nC. \u7269\u8d28\u5c42\u9762\u7684\u843d\u540e\u73b0\u72b6\u662f\u8fdf\u53d1\u5c55\u56fd\u5bb6\u7247\u9762\u7406\u89e3\u73b0\u4ee3\u5316\u7684\u4e00\u4e2a\u91cd\u8981\u56e0\u7d20\nD. \u7247\u9762\u7406\u89e3\u73b0\u4ee3\u5316\u4f1a\u5bfc\u81f4\u77e5\u8bc6\u7684\u6d41\u4fd7\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34012114524656833, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3468666740605408}}, {"question": "\u76ae\u80a4\u7834\u635f\u51fa\u8840\u3001\u9888\u9ad3\u635f\u4f24\u3001\u9510\u5668\u63d2\u5165\u4f53\u5185\u3001\u4e25\u91cd\u6324\u538b\u4f24\u7b49\u662f\u707e\u5bb3\u53d1\u751f\u65f6\u7684\u5e38\u89c1\u635f\u4f24\u7c7b\u578b\uff0e\u638c\u63e1\u79d1\u5b66\u7684\u81ea\u6551\u65b9\u6cd5\u5bf9\u4e8e\u5ef6\u7eed\u751f\u547d\u3001\u7b49\u5f85\u6551\u63f4\u5f88\u91cd\u8981\u3002\u4e0b\u5217\u81ea\u6551\u63aa\u65bd\u4e2d\uff0c\u6070\u5f53\u7684\u662f____\u3002\nA. \u9510\u5668\u63d2\u4eba\u4f53\u5185\u540e\uff0c\u5e94\u5feb\u901f\u5c06\u9510\u5668\u62d4\u51fa\uff0c\u7b80\u5355\u5904\u7406\u4f24\u53e3\u540e\u7acb\u5373\u9001\u5f80\u533b\u9662\u6551\u6cbb\nB. \u5bf9\u9888\u540e\u9510\u75db\u3001\u6d3b\u52a8\u65f6\u75bc\u75db\u52a0\u5267\u7b49\u75c7\u72b6\uff0c\u5373\u7528\u9888\u6258\uff0c\u4e00\u65f6\u65e0\u9888\u6258\uff0c\u53ef\u4e34\u65f6\u7528\u6577\u6599\u3001\u786c\u677f\u7eb8\u6216\u5851\u6599\u677f\u505a\u6210\u9888\u5708\u56fa\u5b9a\u9888\u90e8\nC. \u4f24\u53e3\u53d1\u751f\u55b7\u5c04\u72b6\u51fa\u8840\u65f6\uff0c\u5e94\u7acb\u5373\u7528\u539a\u6d88\u6bd2\u7eb1\u5e03(\u6216\u6bdb\u5dfe)\u5305\u624e\u597d\u4f24\u53e3\nD. \u88ab\u91cd\u7269\u6324\u538b\u5f15\u8d77\u80a2\u4f53\u80bf\u80c0\u6216\u9752\u7d2b\u65f6\uff0c\u5e94\u5c3d\u5feb\u5728\u60a3\u5904\u7528\u70ed\u6bdb\u5dfe\u6e7f\u6577\u6d88\u80bf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u591a\u5e74\u4ee5\u6765\uff0c\u533b\u751f\u548c\u5bb6\u5c5e\u5bf9\u5f85\u764c\u75c7\u60a3\u8005\u5927\u591a\u91c7\u53d6\u8fd9\u6837\u7684\u6001\u5ea6\uff1a\u5373\u5411\u60a3\u8005\u9690\u7792\u5df2\u5f97\u764c\u75c7\u7684\u5b9e\u60c5\uff0c\u8fd9\u6837\u7684\u505a\u6cd5\u5728\u533b\u5b66\u4e0a\u53eb\u4f5c\u201c\u4fdd\u62a4\u6027\u533b\u7597\u201d\uff0c\u5176\u76ee\u7684\u5728\u4e8e\u51cf\u5c11\u60a3\u8005\u7684\u5fc3\u7406\u8d1f\u62c5\u3002\u4f46\u662f\uff0c\u67d0\u80bf\u7624\u533b\u751f\u65b0\u8bbe\u7acb\u7684\u5eb7\u590d\u79d1\u7684\u5f20\u4e3b\u4efb\u5374\u4e3b\u5f20\u5b9e\u884c\u201c\u516c\u5f00\u6027\u6cbb\u7597\u201d\u3002 \u7531\u6b64\u53ef\u63a8\u77e5\u4e0b\u6587\u5c06\u8981\u8bba\u8ff0\u7684\u662f____\u3002\nA. \u5bb6\u5c5e\u5bf9\u5b9e\u884c\u201c\u516c\u5f00\u6027\u6cbb\u7597\u201d\u7684\u6001\u5ea6\nB. \u201c\u4fdd\u62a4\u6027\u533b\u7597\u201d\u7684\u5f0a\u7aef\nC. \u201c\u516c\u5f00\u6027\u6cbb\u7597\u201d\u5c06\u4f7f\u75c5\u60c5\u5f97\u5230\u63a7\u5236\u548c\u597d\u8f6c\nD. \u201c\u516c\u5f00\u6027\u6cbb\u7597\u201d\u7684\u542b\u4e49\u548c\u5f62\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4046399692515218, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4721576022675098, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7928833972178314}}, {"question": "\u53e4\u4eba\u5f52\u7eb3\u603b\u7ed3\u51fa\u8bb8\u591a\u89c2\u5929\u8c61\u8bc6\u5929\u6c14\u7684\u8c1a\u8bed\u3002\u4e0b\u5217\u4e0e\u5929\u6c14\u53d8\u5316\u65e0\u5173\u7684\u8c1a\u8bed\u662f____\u3002\nA. \u671d\u971e\u4e0d\u51fa\u95e8\uff0c\u665a\u971e\u884c\u5343\u91cc\nB. \u5929\u4e0a\u9c7c\u9cde\u4e91\uff0c\u5730\u4e0b\u96e8\u6dcb\u6dcb\nC. \u4e1c\u98ce\u662f\u4e2a\u7cbe\uff0c\u4e0d\u4e0b\u4e5f\u8981\u9634\nD. \u767e\u65e5\u8fde\u9634\u96e8\uff0c\u603b\u6709\u4e00\u65e5\u6674\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ece\u300a\u8bba\u8bed\u300b\u770b\uff0c\u5b54\u5b50\u5bf9\u97f3\u4e50\u7684\u91cd\u89c6\uff0c\u53ef\u4ee5\u8bf4\u8fdc\u8fdc\u8d85\u51fa\u4e86\u540e\u4e16\u90a3\u4e9b\u5c0a\u656c\u4ed6\u7684\u4eba\u7684\u60f3\u8c61\uff0c\u8fd9\u4e00\u65b9\u9762\u6765\u81ea\u4ed6\u5bf9\u4e8e\u4e50\u7684\u7cbe\u795e\u827a\u672f\u7684\u65b0\u53d1\u73b0\u3002\u827a\u672f\uff0c\u53ea\u5728\u4eba\u4eec\u7cbe\u795e\u7684\u53d1\u73b0\u4e2d\u624d\u5b58\u5728\uff0c\u53ef\u4ee5\u8bf4\uff0c\u5c31\u73b0\u5728\u89c1\u5230\u7684\u6750\u6599\u770b\uff0c\u5b54\u5b50\u53ef\u80fd\u662f\u4e2d\u56fd\u5386\u53f2\u4e0a\u6700\u4f1f\u5927\u7684\u827a\u672f\u7cbe\u795e\u7684\u53d1\u73b0\u8005\u3002\u8fd9\u6bb5\u6587\u5b57\u91cd\u70b9\u5f3a\u8c03____\u3002\nA. \u5b54\u5b50\u5728\u97f3\u4e50\u65b9\u9762\u7684\u6210\u5c31\u4e0e\u8d21\u732e\nB. \u540e\u4eba\u8bc4\u4ef7\u5b54\u5b50\u65f6\u6240\u5b58\u5728\u7684\u504f\u9887\nC. \u827a\u672f\u7cbe\u795e\u5728\u4e50\u6559\u4f20\u627f\u4e2d\u7684\u4f5c\u7528\nD. \u300a\u8bba\u8bed\u300b\u4f5c\u4e3a\u6587\u732e\u7684\u91cd\u8981\u610f\u4e49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5511750455070216, "itpossible/Chinese-Mistral-7B-v0.1": 0.3395893495876965, "HuggingFaceH4/zephyr-7b-beta": 0.4272014644843804, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.978797037669662, "meta-llama/Meta-Llama-3-8B": 0.5858957688113233, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6120688273226207}}, {"question": "\u2460\u5f53\u5730\u7403\u649e\u8fdb\u5c18\u57c3\u5e26\u65f6\uff0c\u4ece\u5730\u7403\u4e0a\u770b\uff0c\u662f\u77ed\u65f6\u95f4\u5185\u65e0\u6570\u5c18\u57c3\u4ee5\u6781\u9ad8\u7684\u901f\u5ea6\u5212\u7834\u5927\u6c14\u5c42\u4e0b\u843d \u2461\u56e0\u6b64\uff0c\u6d41\u661f\u96e8\u5b9e\u9645\u4e0a\u662f\u5f57\u661f\u7559\u4e0b\u7684\u65e0\u6570\u5c18\u57c3\u5f62\u6210\u7684 \u2462\u8fdb\u5165\u5927\u6c14\u5c42\u7684\u5c18\u57c3\u88ab\u5927\u6c14\u52a0\u70ed\uff0c\u53d1\u51fa\u660e\u4eae\u7684\u5149 \u2463\u5f57\u661f\u91ca\u653e\u51fa\u7684\u5c18\u57c3\uff0c\u5e76\u975e\u9877\u523b\u6269\u6563\u5230\u5b87\u5b99\u7a7a\u95f4\uff0c\u6d88\u5931\u5f97\u65e0\u5f71\u65e0\u8e2a\uff0c\u800c\u662f\u7559\u5728\u5f57\u661f\u7684\u8f68\u9053\u4e0a\u7ee7\u7eed\u516c\u8f6c \u2464\u8fd9\u6837\u770b\u4e0a\u53bb\u5c31\u6709\u8bb8\u591a\u6d41\u661f\uff0c\u4e5f\u5c31\u662f\u6d41\u661f\u96e8 \u2465\u8fd9\u6837\u5f62\u6210\u7684\u201c\u5c18\u57c3\u5e26\u201d\uff0c\u6709\u4e9b\u548c\u5730\u7403\u7684\u516c\u8f6c\u8f68\u9053\u4ea4\u53c9 \u5c06\u4ee5\u4e0a6\u4e2a\u53e5\u5b50\u91cd\u65b0\u6392\u5217\uff0c\u8bed\u5e8f\u6b63\u786e\u7684\u662f____\u3002\nA. \u2463\u2461\u2465\u2462\u2464\u2460\nB. \u2460\u2463\u2462\u2465\u2464\u2461\nC. \u2463\u2465\u2460\u2462\u2464\u2461\nD. \u2460\u2462\u2464\u2461\u2463\u2465\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29539205153207015, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5303749243146503, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.308176776288574, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "3\uff0c7\uff0c16\uff0c107\uff0c____\nA. 1704\nB. 1072\nC. 1707\nD. 1068\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45092007275187534, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3160424181481997, "HuggingFaceH4/zephyr-7b-beta": 0.8241570460972242, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4426772797543757, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6211\u59cb\u7ec8____\uff0c\u5f00\u59cb\u5728\u5185\u5fc3\u751f\u6d3b\u5f97\u66f4\u4e25\u8083\u7684\u4eba\uff0c\u4e5f\u4f1a\u5728\u5916\u5728\u4e0a\u5f00\u59cb\u751f\u6d3b\u5f97\u66f4____\u3002\u5728\u4e00\u4e2a\u5962\u534e\u6d6a\u8d39\u7684\u5e74\u4ee3\uff0c\u6211\u5e0c\u671b\u80fd\u5411\u4e16\u754c____\uff0c\u4eba\u7c7b\u771f\u6b63\u8981\u7684\u4e1c\u897f\u662f\u975e\u5e38\u4e4b\u5fae\u5c0f\u7684\u3002 \u586b\u5165\u753b\u6a2a\u7ebf\u90e8\u5206\u6700\u6070\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u786e\u8ba4 \u6734\u7d20 \u8868\u660e\nB. \u76f8\u4fe1 \u8d28\u6734 \u8bc1\u660e\nC. \u786e\u8ba4 \u8d28\u6734 \u8bc1\u660e\nD. \u76f8\u4fe1 \u6734\u7d20 \u8868\u660e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.31712010892822357, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u7279\u6b8a\u8dd1\u9053\u4e3a\u6b63\u4e09\u89d2\u5f62\uff0c\u67d0\u8fd0\u52a8\u5458\u75286\u7c73\uff0f\u79d2\u7684\u901f\u5ea6\u8dd1\u4e00\u5708\u8017\u65f650\u79d2\uff0c\u95ee\u8be5\u8fd0\u52a8\u5458\u63d0\u901f10\uff05\u540e\u4ece\u8dd1\u9053\u7684\u67d0\u4e2a\u9876\u70b9\u6a2a\u7a7f\u8dd1\u9053\u8dd1\u5411\u5bf9\u8fb9\uff0c\u95ee\u6700\u5c11\u7ea6\u9700\u591a\u5c11\u79d2\u53ef\u8e0f\u8db3\u5bf9\u8fb9?(\u56db\u820d\u4e94\u5165\u5230\u4e2a\u4f4d)____\nA. 9\u79d2\nB. 10\u79d2\nC. 13\u79d2\nD. 15\u79d2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3293945554888329, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3233250233605477, "HuggingFaceH4/zephyr-7b-beta": 0.9093394687036974, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3638582843838116, "meta-llama/Meta-Llama-3-8B": 0.3423962339378881, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5509854654117832}}, {"question": "\u6587\u5b66\u8d44\u6599\u5728\u601d\u60f3\u53f2\u9886\u57df\u8457\u4f5c\u4e2d\uff0c\u88ab\u4f7f\u7528\u5f97\u8fd8\u662f\u76f8\u5f53\u5c11\u3002\u5176\u5b9e\uff0c\u4f5c\u4e3a\u8bb0\u8ff0\u53f2\u5b9e\u7684\u5386\u53f2\uff0c\u53ef\u80fd\u5bf9\u6709\u4e9b\u5938\u5f20\u548c\u865a\u6784\u7684\u5c0f\u8bf4\u9700\u8981\u8b66\u60d5\uff0c\u4f46\u662f\uff0c\u4f5c\u4e3a\u8003\u5bdf\u7406\u6027\u548c\u60c5\u611f\u7684\u601d\u60f3\u53f2\uff0c\u5374\u4e0d\u5fc5\u80f6\u67f1\u9f13\u745f\u6216\u56e0\u564e\u5e9f\u98df\uff0c\u4efb\u4f55\u6587\u5b66\u4f5c\u54c1\u4e5f\u8bb8\u5728\u4e8b\u5b9e\u4e0a\u6709\u60f3\u8c61\uff0c\u4f46\u5728\u8bed\u8a00\u3001\u7acb\u573a\u548c\u60c5\u611f\u4e0a\uff0c\u5374\u4eff\u4f5b\u201c\u5f53\u5802\u5448\u4f9b\u201d\uff0c\u5e76\u4e0d\u80fd\u628a\u81ea\u5df1\u7684\u672c\u76f8\u5168\u76d8\u9690\u533f\u3002 \u5bf9\u8fd9\u6bb5\u6587\u5b57\u7684\u4e3b\u65e8\u7406\u89e3\u6700\u51c6\u786e\u7684\u662f____\u3002\nA. \u6587\u5b66\u4f5c\u54c1\u5448\u73b0\u827a\u672f\u7684\u771f\u5b9e\nB. \u601d\u60f3\u53f2\u7814\u7a76\u5e94\u4f53\u73b0\u7406\u6027\u548c\u60c5\u611f\nC. \u6587\u5b66\u8d44\u6599\u53ef\u4ee5\u4f5c\u4e3a\u601d\u60f3\u53f2\u7814\u7a76\u7684\u53f2\u6599\nD. \u601d\u60f3\u53f2\u7814\u7a76\u4e2d\u8981\u614e\u7528\u6587\u5b66\u8d44\u6599\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.41804968818897237, "meta-math/MetaMath-Mistral-7B": 0.7557410348759773, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8146922034948447, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.47848099770734887, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7108692253241838}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u56fd\u9645\u7ec4\u7ec7\u7684\u8868\u8ff0\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u77f3\u6cb9\u8f93\u51fa\u56fd\u7ec4\u7ec7\u901a\u8fc7\u5b9e\u884c\u77f3\u6cb9\u751f\u4ea7\u914d\u989d\u9650\u5236\u7ef4\u62a4\u77f3\u6cb9\u751f\u4ea7\u56fd\u5229\u76ca\nB. \u535a\u9ccc\u4e9a\u6d32\u8bba\u575b\u662f\u7b2c\u4e00\u4e2a\u603b\u90e8\u8bbe\u5728\u4e2d\u56fd\u7684\u56fd\u9645\u4f1a\u8bae\u7ec4\u7ec7\nC. \u8499\u53e4\u56fd\u662f\u4e0a\u6d77\u5408\u4f5c\u7ec4\u7ec7\u7684\u6210\u5458\u56fd\u4e4b\u4e00\nD. \u56fd\u9645\u8d27\u5e01\u57fa\u91d1\u7ec4\u7ec7\u662f\u8054\u5408\u56fd\u7684\u4e13\u95e8\u673a\u6784\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7250476082028394, "itpossible/Chinese-Mistral-7B-v0.1": 0.4201996519262058, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5b9e\u9a8c\u8bc1\u660e\uff0c\u690d\u7269\u4f53\u5185\u542b\u6709\u4e00\u79cd\u89c9\u5bdf\u5149\u7684\u86cb\u767d\u8d28\uff0c\u53ef\u4ee5\u201c\u5206\u8fa8\u201d\u5149\u7684\u5f3a\u5f31\u3002\u8fd9\u79cd\u80fd\u529b\u5f88\u53ef\u80fd\u4f7f\u690d\u7269\u770b\u5230\u4eba\u7c7b\u89c6\u529b\u6240\u770b\u4e0d\u5230\u7684\u6ce2\u957f\uff0c\u800c\u4e14\u5177\u6709\u8f83\u9ad8\u7684\u7075\u654f\u5ea6\u3002\u690d\u7269\u80fd\u611f\u89c9\u5149\u7167\u5c04\u8fc7\u6765\u7684\u65b9\u5411\uff0c\u5149\u4f7f\u690d\u7269\u77e5\u9053\u65e9\u4e0a\u4ec0\u4e48\u65f6\u5019\u8be5\u9192\u6765\uff0c\u540c\u6837\u4e5f\u80fd\u4fc3\u4f7f\u690d\u7269\u989d\u5916\u5206\u6ccc\u680e\u7cbe\u548c\u582a\u975e\u9187\u8fd9\u4e24\u79cd\u65e0\u8272\u8272\u7d20\uff0c\u4ed6\u4eec\u80fd\u8fc7\u6ee4\u5f3a\u70c8\u7684\u9633\u5149\uff0c\u5145\u5206\u53d1\u6325\u906e\u5149\u5242\u7684\u4f5c\u7528\uff0c\u4ece\u800c\u4fdd\u62a4\u690d\u7269\u514d\u53d7\u7d2b\u5916\u7ebf\u7684\u5f3a\u70c8\u7167\u5c04\u3002 \u8fd9\u6bb5\u6587\u5b57\u4e3b\u8981\u4ecb\u7ecd\u7684\u662f____\u3002\nA. \u690d\u7269\u662f\u600e\u4e48\u8fa8\u522b\u65b9\u5411\u7684\nB. \u690d\u7269\u662f\u5982\u4f55\u907f\u514d\u9633\u5149\u66b4\u6652\u7684\nC. \u690d\u7269\u5177\u6709\u4e00\u5b9a\u610f\u4e49\u4e0a\u7684\u201c\u89c6\u89c9\u201d\nD. \u611f\u77e5\u9633\u5149\u5bf9\u690d\u7269\u751f\u957f\u7684\u91cd\u8981\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5967467526265228, "meta-math/MetaMath-Mistral-7B": 0.8790678201838291, "itpossible/Chinese-Mistral-7B-v0.1": 0.4702008361011121, "HuggingFaceH4/zephyr-7b-beta": 0.6458557638875921, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6060856470096699, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6466210332645304}}, {"question": "1\uff0c10\uff0c37\uff0c82\uff0c145\uff0c____\nA. 170\nB. 197\nC. 224\nD. 226\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.346689335021255, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.829153827025136, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.53854859190474}}, {"question": "\u67d0\u53bf\u5728\u4e00\u6b21\u62db\u5546\u5f15\u8d44\u6d3b\u52a8\u4e2d\uff0c\u6295\u8d44\u5546\u5201\u96be\u5f15\u8d44\u65b9\u8bf4\uff1a\u201c\u6211\u6709\u4e09\u4e2a\u9879\u76ee\uff1a\u73af\u5883\u9879\u76ee\u3001\u65c5\u6e38\u9879\u76ee\u548c\u5316\u5de5\u9879\u76ee\u3002\u5982\u679c\u4f60\u8bf4\u7684\u8bdd\u662f\u6b63\u786e\u7684\uff0c\u6211\u4f1a\u628a\u5176\u4e2d\u4e00\u4e2a\u9879\u76ee\u6295\u8d44\u5230\u8d35\u53bf\uff0c\u4f46\u662f\u5982\u679c\u4f60\u8bf4\u7684\u8bdd\u662f\u9519\u8bef\u7684\uff0c\u6211\u5c31\u4e00\u4e2a\u9879\u76ee\u4e5f\u4e0d\u6295\u8d44\u3002\u201d\u5f15\u8d44\u65b9\u5f53\u7136\u60f3\u83b7\u5f97\u73af\u5883\u9879\u76ee\uff0c\u90a3\u4e48\u5f15\u8d44\u65b9\u8be5\u5982\u4f55\u8bf4\u5462?____\nA. \u4f60\u4e0d\u4f1a\u628a\u73af\u5883\u9879\u76ee\u6216\u65c5\u6e38\u9879\u76ee\u6295\u8d44\u5230\u6211\u53bf\nB. \u4f60\u4e0d\u4f1a\u628a\u73af\u5883\u9879\u76ee\u6216\u5316\u5de5\u9879\u76ee\u6295\u8d44\u5230\u6211\u53bf\nC. \u4f60\u4e0d\u4f1a\u628a\u65c5\u6e38\u9879\u76ee\u6216\u5316\u5de5\u9879\u76ee\u6295\u8d44\u5230\u6211\u53bf\nD. \u4f60\u4e0d\u4f1a\u628a\u65c5\u6e38\u9879\u76ee\u548c\u5316\u5de5\u9879\u76ee\u90fd\u6295\u8d44\u5230\u6211\u53bf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6c11\u610f\u201c\u88ab\u6ee1\u610f\u201d\uff0c\u6c11\u4f17\u201c\u4e0d\u6ee1\u610f\u201d\uff0c\u751a\u81f3\u201c\u5f88\u751f\u6c14\u201d\u3002\u5c0a\u91cd\u6c11\u610f\u3001\u987a\u5e94\u6c11\u610f\u3001\u91c7\u7eb3\u6c11\u610f\u662f\u670d\u52a1\u578b\u653f\u5e9c\u7684\u6267\u653f\u8981\u4e49\uff0c\u662f\u653f\u6cbb\u6587\u660e\u5efa\u8bbe\u7684\u9898\u4e2d\u4e4b\u610f\u3002\u6c11\u610f\u7684\u529b\u91cf\u4e00\u65b9\u9762\u53d6\u51b3\u4e8e\u6c11\u610f\u5f81\u96c6\u5360\u5168\u6c11\u7684\u6bd4\u4f8b\uff0c\u5373\u5e7f\u6cdb\u6027\uff1b\u53e6\u4e00\u65b9\u9762\u4e5f\u4f53\u73b0\u5728\u653f\u5e9c\u5bf9\u6c11\u610f\u7684\u5c0a\u91cd\u7a0b\u5ea6\u4e0a\u3002\u4fdd\u969c\u6c11\u4f17\u7684\u77e5\u60c5\u6743\u3001\u53c2\u4e0e\u6743\u3001\u8868\u8fbe\u6743\u548c\u76d1\u7763\u6743\uff0c\u5c31\u662f\u8981\u968f\u65f6\u968f\u5730\u4e0e\u6c11\u4f17\u8fdb\u884c\u591a\u79cd\u9014\u5f84\u7684\u6c9f\u901a\u3001\u4ea4\u6d41\u3002\u6c11\u610f\u5185\u6db5\u6c11\u667a\uff0c\u6c11\u610f\u5173\u4e4e\u6c11\u751f\u3002\u6211\u4eec\u4e0d\u4ec5\u8981\u4ece\u6c11\u610f\u4e2d\u770b\u5230\u6c11\u4f17\u6b22\u8fce\u4ec0\u4e48\u3001\u53cd\u5bf9\u4ec0\u4e48\uff0c\u4e3a\u79d1\u5b66\u51b3\u7b56\u63d0\u4f9b\u4f9d\u636e\uff0c\u800c\u4e14\u8981\u5145\u5206\u53d1\u6325\u6c11\u667a\u7684\u4f5c\u7528\u3002\u5c0a\u91cd\u6c11\u610f\u3001\u5438\u7eb3\u6c11\u667a\u662f\u79d1\u5b66\u51b3\u7b56\u7684\u91cd\u8981\u4fdd\u8bc1\uff0c\u4e5f\u662f\u8861\u91cf\u653f\u5e9c\u4eb2\u6c11\u4e3a\u6c11\u7684\u91cd\u8981\u6807\u5fd7\u3002\u9605\u8bfb\u4e0a\u9762\u6587\u5b57\uff0c\u6700\u7b26\u5408\u6587\u610f\u7684\u4e00\u9879\u662f____\u3002\nA. \u8ba9\u6c11\u4f17\u201c\u4e0d\u6ee1\u610f\u201d\u201c\u5f88\u751f\u6c14\u201d\u7684\u653f\u5e9c\u5c31\u4e0d\u662f\u670d\u52a1\u578b\u653f\u5e9c\nB. \u77e5\u60c5\u6743\u662f\u76d1\u7763\u6743\u7684\u524d\u63d0\uff0c\u53c2\u4e0e\u6743\u662f\u8868\u8fbe\u6743\u7684\u524d\u63d0\nC. \u5c0a\u91cd\u6c11\u610f\u3001\u5438\u7eb3\u6c11\u667a\u662f\u79d1\u5b66\u51b3\u7b56\u7684\u51b3\u5b9a\u6027\u56e0\u7d20\nD. \u6c11\u610f\u529b\u91cf\u7684\u53d1\u6325\u53d6\u51b3\u4e8e\u6c11\u610f\u5f81\u96c6\u7684\u5e7f\u5ea6\u548c\u5c0a\u91cd\u6c11\u610f\u7684\u7a0b\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5406551955234641, "meta-math/MetaMath-Mistral-7B": 0.7002206283825751, "itpossible/Chinese-Mistral-7B-v0.1": 0.691705701997066, "HuggingFaceH4/zephyr-7b-beta": 0.9990944731650088, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7589224809142903, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "3\uff0c5\uff0c16\uff0c82\uff0c1315\uff0c____\nA. 107834\nB. 12849\nC. 12847\nD. 108847\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44238634378672315, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u53ef\u4ee5\u53cd\u6620\u6c14\u5019\u5782\u76f4\u53d8\u5316\u7684\u8bd7\u53e5\u662f____\u3002\nA. \u4e1c\u8fb9\u65e5\u51fa\u897f\u8fb9\u96e8\uff0c\u9053\u662f\u65e0\u6674\u5374\u6709\u6674\nB. \u7f57\u6d6e\u5c71\u4e0b\u56db\u65f6\u6625\uff0c\u5362\u6a58\u6768\u6885\u6b21\u7b2c\u65b0\nC. \u4eba\u95f4\u56db\u6708\u82b3\u83f2\u5c3d\uff0c\u5c71\u5bfa\u6843\u82b1\u59cb\u76db\u5f00\nD. \u6a2a\u770b\u6210\u5cad\u4fa7\u6210\u5cf0\uff0c\u8fdc\u8fd1\u9ad8\u4f4e\u5404\u4e0d\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3689108554330874, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65e5\u672c\u677e\u4e0b\u516c\u53f8\u65e5\u524d\u5728\u4e1c\u4eac\u201c\u677e\u4e0b\u4e2d\u5fc3\u201d\u5411\u5f53\u5730\u5a92\u4f53\u5c55\u793a\u4e86\u5176\u9762\u5411\u672a\u6765\u7684\u201c\u96f6\u6392\u653e\u6982\u5ff5\u73af\u4fdd\u623f\u5c4b\u201d\u3002\u73af\u4fdd\u5c4b\u7684\u4e3b\u8981\u7279\u70b9\u662f\u201c\u8282\u80fd\u3001\u521b\u80fd\u3001\u84c4\u80fd\u201d\u3002\u201c\u8282\u80fd\u201d\u5c31\u662f\u63d0\u9ad8\u5bf9\u81ea\u7136\u754c\u65e2\u6709\u8d44\u6e90\u7684\u5229\u7528\u7387\uff0c\u540c\u65f6\u91c7\u7528\u73af\u4fdd\u9694\u70ed\u7684\u5efa\u7b51\u6750\u6599\u4ee5\u53ca\u6700\u5148\u8fdb\u7684\u73af\u4fdd\u8282\u80fd\u5bb6\u7535\u8bbe\u5907\u7b49\u3002 \u4e0b\u6587\u6700\u6709\u53ef\u80fd\u4ecb\u7ecd\u7684\u662f____\u3002\nA. \u73af\u4fdd\u5c4b\u662f\u600e\u6837\u8bbe\u8ba1\u51fa\u6765\u7684\nB. \u73af\u4fdd\u5c4b\u7684\u521b\u80fd\u3001\u84c4\u80fd\u7279\u70b9\nC. \u73af\u4fdd\u5c4b\u7684\u63a8\u5e7f\nD. \u73af\u4fdd\u5c4b\u7684\u6750\u6599\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3265980288635183, "meta-math/MetaMath-Mistral-7B": 0.4221216269834628, "itpossible/Chinese-Mistral-7B-v0.1": 0.37106892011530584, "HuggingFaceH4/zephyr-7b-beta": 0.9659485265112587, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5369445934624774, "meta-llama/Meta-Llama-3-8B": 0.4725528207889908, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6ca1\u6709\u6b67\u4e49\u7684\u4e00\u9879\u662f____\u3002\nA. \u51e0\u4e2a\u6d3e\u51fa\u6240\u7684\u6c11\u8b66\u3002\nB. \u6cd5\u9662\u95e8\u524d\u7684\u77f3\u72ee\u5b50\u3002\nC. \u8fd9\u4efd\u8d77\u8bc9\u4e66\u6211\u5199\u4e0d\u597d\u3002\nD. \u54ac\u6b7b\u4e86\u4e3b\u4eba\u7684\u85cf\u7352\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.26943095492400354, "meta-math/MetaMath-Mistral-7B": 0.4488746851960499, "itpossible/Chinese-Mistral-7B-v0.1": 0.300639380654072, "HuggingFaceH4/zephyr-7b-beta": 0.5331968205810491, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4479780596806147, "meta-llama/Meta-Llama-3-8B": 0.264634220591857, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7466118889057977}}, {"question": "\u6211\u4eec\u53d1\u73b0\u96f6\u5de5\u5236\u5ea6\u6709\u4e00\u4e2a\u91cd\u8981\u7684\u652f\u6301\u673a\u5236\u5c31\u662f\u5b8c\u5584\u7684\u3001\u79d1\u5b66\u5316\u7684\u5458\u5de5\u57f9\u8bad\u7cfb\u7edf\u3002\u51e0\u4e4e\u6240\u6709\u7684\u73b0\u4ee3\u4f01\u4e1a\u548c\u516c\u53f8\u90fd\u975e\u5e38\u91cd\u89c6\u5185\u90e8\u57f9\u8bad\uff0c\u6709\u7684\u4f01\u4e1a\u4e3b\u751a\u81f3\u6210\u4e3a\u4e86\u57f9\u8bad\u72c2\uff0c\u54ea\u6015\u6709\u4e00\u79d2\u949f\u7684\u7a7a\u95f2\u4e5f\u8981\u4e3a\u5458\u5de5\u5b89\u6392\u4e00\u6b21\u57f9\u8bad\u3002\u4f46\u771f\u6b63\u6709\u6548\u7684\u57f9\u8bad\u5e76\u4e0d\u662f\u65e0\u4f11\u6b62\u7684\u6d17\u8111\u548c\u8bfe\u7a0b\u8f70\u70b8\uff0c\u4e0d\u662f\u201c\u6f5c\u80fd\u6fc0\u53d1\u201d\u548c\u201c\u611f\u6069\u6559\u80b2\u201d\uff0c\u800c\u662f\u9002\u5408\u516c\u53f8\u8fd0\u8425\u9700\u6c42\u7684\u4e13\u4e1a\u6027\u3001\u9488\u5bf9\u6027\u3001\u79d1\u5b66\u6027\u7684\u4e1a\u52a1\u8bad\u7ec3\u3002\u8fd9\u79cd\u57f9\u8bad\u673a\u5236\u5982\u679c\u80fd\u591f\u5efa\u7acb\u8d77\u6765\uff0c\u65e0\u8bba\u4f60\u662f\u5426\u91c7\u7528\u96f6\u5de5\u5236\u5ea6\u90fd\u4f1a\u5bf9\u4f01\u4e1a\u7684\u53d1\u5c55\u8d77\u5230\u91cd\u8981\u7684\u63a8\u52a8\u4f5c\u7528\u3002 \u8fd9\u6bb5\u6587\u5b57\u610f\u5728\u8bf4\u660e____\u3002\nA. \u5f88\u591a\u516c\u53f8\u57f9\u8bad\u7f3a\u4e4f\u79d1\u5b66\u6027\nB. \u79d1\u5b66\u7684\u5458\u5de5\u57f9\u8bad\u5bf9\u4f01\u4e1a\u5f88\u91cd\u8981\nC. \u96f6\u5de5\u5236\u5ea6\u4e0d\u4e00\u5b9a\u9002\u5408\u6240\u6709\u4f01\u4e1a\nD. \u8fc7\u5ea6\u57f9\u8bad\u53ef\u80fd\u4f1a\u9020\u6210\u76f8\u53cd\u6548\u679c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.769617223340909, "meta-math/MetaMath-Mistral-7B": 0.983355255046808, "itpossible/Chinese-Mistral-7B-v0.1": 0.9134665168986292, "HuggingFaceH4/zephyr-7b-beta": 0.9979435002822701, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9810169365056054, "meta-llama/Meta-Llama-3-8B": 0.7173140554566618, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.919439146655409}}, {"question": "\u5168\u56fd\u4eba\u6c11\u4ee3\u8868\u5927\u4f1a\u4e3e\u884c\u4f1a\u8bae\u65f6\uff0c\u4e3b\u6301\u5927\u4f1a\u6b63\u5f0f\u4f1a\u8bae\u7684\u662f____\u3002\nA. \u5168\u56fd\u4eba\u5927\u5e38\u59d4\u4f1a\nB. \u5927\u4f1a\u4e3b\u5e2d\u56e2\nC. \u5168\u56fd\u4eba\u5927\u5e38\u59d4\u4f1a\u59d4\u5458\u957f\nD. \u5927\u4f1a\u79d8\u4e66\u957f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3419216904345336, "meta-math/MetaMath-Mistral-7B": 0.7187312058764217, "itpossible/Chinese-Mistral-7B-v0.1": 0.6563475883348802, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5101839830120497, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6539\u9769\u5f00\u653e\u4ee5\u6765\uff0c\u4e2d\u56fd\u519c\u5b66\u4f1a____\u201c\u732e\u8eab\u3001\u521b\u65b0\u3001\u6c42\u5b9e\u3001\u534f\u4f5c\u201d\u7684\u5b97\u65e8\uff0c\u59cb\u7ec8\u4e0d\u6e1d\u5730\u575a\u6301\u4ee5\u63a8\u52a8\u519c\u4e1a\u79d1\u6280\u8fdb\u6b65\u3001\u4fc3\u8fdb\u519c\u6751\u53d1\u5c55\u4e3a\u5df1\u4efb\uff0c\u5927\u529b\u5f00\u5c55\u5b66\u672f\u4ea4\u6d41\u548c\u79d1\u6280\u666e\u53ca\uff0c\u79ef\u6781____\u548c\u4e3e\u8350\u4eba\u624d\uff0c\u4e3a\u63d0\u9ad8\u5e7f\u5927\u519c\u6c11\u79d1\u6280\u7d20\u8d28\u3001\u52a0\u5feb\u519c\u4e1a\u79d1\u6280\u8fdb\u6b65\u4f5c\u51fa\u4e86\u91cd\u8981\u8d21\u732e\u3002 \u586b\u5165\u753b\u6a2a\u7ebf\u90e8\u5206\u6700\u6070\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u7ee7\u627f \u51fa\u8c0b\u5212\u7b56\nB. \u7ee7\u627f \u5efa\u8a00\u732e\u7b56\nC. \u79c9\u627f \u5efa\u8a00\u732e\u7b56\nD. \u79c9\u627f \u51fa\u8c0b\u5212\u7b56\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.32205625344145955, "meta-llama/Meta-Llama-3-8B": 0.43291965339034155, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.634569475326374}}, {"question": "0\uff0c 4\uff0c 3\uff0c 10\uff0c 6\uff0c 7\uff0c ____\nA. 101\nB. 102\nC. 103\nD. 104\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u65b0\u751f\u4ee3\u6563\u6587\u201d\u4f5c\u5bb6\u5927\u591a\u6709\u5199\u73b0\u4ee3\u8bd7\u7684\u80cc\u666f\uff0c\u8bd7\u4eba\u6240\u62e5\u6709\u7684____\u7684\u601d\u7ef4\u3001\u5927\u80c6\u7684\u60f3\u8c61\u3001\u654f\u9510\u7684\u611f\u89c9\uff0c\u5c06\u201c\u8bd7\u8d28\u201d____\u5728\u6563\u6587\u8bed\u8a00\u7684\u8840\u6db2\u548c\u808c\u7406\u91cc\u3002\u8fd9\u4e0d\u540c\u4e8e\u5e73\u94fa\u76f4\u53d9\u5f0f\u7684\u6d45\u6d6e\u7684\u8bd7\u610f\uff0c\u800c\u662f\u81ea\u6211\u5fc3\u7075\u7684\u4f53\u8ba4\u4e2d____\u800c\u6210\u7684\u8bd7\u8d28\u3002 \u586b\u5165\u753b\u6a2a\u7ebf\u90e8\u5206\u6700\u6070\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u8df3\u8131 \u9576\u5d4c \u51dd\u7ed3\nB. \u53e6\u7c7b \u6d53\u7f29 \u5347\u534e\nC. \u611f\u6027 \u6e17\u900f \u94f8\u5c31\nD. \u6d3b\u8dc3 \u6563\u64ad \u63d0\u70bc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u636e\u300a\u54ac\u6587\u56bc\u5b57\u300b\u7f16\u8f91\u90e8\u900f\u9732\uff0c\u7f16\u5236\u5e74\u5ea6\u201c\u5341\u5927\u6d41\u884c\u8bed\u201d\u662f\u4e00\u9879\u5341\u5206\u4e25\u8083\u7684\u4e8b\uff0c\u65e2\u8981____\u5230\u8bcd\u8bed\u5728\u5f53\u5e74\u7684\u6d41\u884c\u5ea6\uff0c\u53c8\u8981\u4ece\u8bed\u6587\u4f26\u7406\u89d2\u5ea6\u52a0\u4ee5\u5fc5\u8981\u7684____\uff0c\u9009\u4f18\u6c70\u52a3\uff0c\u529b\u4e89\u901a\u8fc7\u201c\u5341\u5927\u6d41\u884c\u8bed\u201d\u5411\u793e\u4f1a____\u6b63\u80fd\u91cf\u3002 \u586b\u5165\u753b\u6a2a\u7ebf\u90e8\u5206\u6700\u6070\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u659f\u914c \u4f30\u91cf \u4f20\u64ad\nB. \u601d\u8003 \u6743\u8861 \u4f20\u9001\nC. \u601d\u7d22 \u8003\u5bdf \u4f20\u8fbe\nD. \u8003\u8651 \u8003\u91cf \u4f20\u9012\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.32332502336054775, "HuggingFaceH4/zephyr-7b-beta": 0.6105002945167565, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3436615088034303}}, {"question": "20\u4e16\u7eaa60\u5e74\u4ee3\u4ee5\u524d\uff0c\u4e16\u754c\u5404\u56fd\u666e\u904d\u6ce8\u91cd\u9632\u6d2a\u7684\u5de5\u7a0b\u63aa\u65bd\uff0c\u5373\u901a\u8fc7\u4fee\u5efa\u5927\u5824\u3001\u6c34\u5e93\u6c34\u5229\u8bbe\u65bd\u5bf9\u6d2a\u6c34\u8fdb\u884c\u63a7\u5236\u3002\u4f46\u572860\u5e74\u4ee3\u4ee5\u540e\uff0c\u4e16\u754c\u5404\u56fd\u5728\u9632\u6d2a\u89c4\u5212\u4e2d\u8d8a\u6765\u8d8a\u91cd\u89c6\u975e\u5de5\u7a0b\u63aa\u65bd\u7684\u8fd0\u7528\uff0c\u5373\u901a\u8fc7\u6d2a\u6c34\u9884\u8b66\u3001\u707e\u60c5\u8bc4\u4f30\u3001\u6d2a\u707e\u4fdd\u9669\u7b49\u591a\u79cd\u624b\u6bb5\uff0c\u7ed3\u5408\u5404\u79cd\u5de5\u7a0b\u63aa\u65bd\uff0c\u4ece\u800c\u5c3d\u53ef\u80fd\u51cf\u5c11\u6d2a\u707e\u5bf9\u4eba\u7c7b\u7ecf\u6d4e\u3001\u73af\u5883\u548c\u793e\u4f1a\u53d1\u5c55\u7684\u5f71\u54cd\u3002 \u8fd9\u6bb5\u6587\u5b57\u4e3b\u8981\u8c08\u7684\u662f____\u3002\nA. \u4e16\u754c\u5404\u56fd\u9632\u6d2a\u7406\u5ff5\u7684\u8f6c\u53d8\nB. \u4e16\u754c\u5404\u56fd\u63a7\u5236\u6d2a\u6c34\u7684\u65b0\u9014\u5f84\nC. \u5355\u7eaf\u91cd\u89c6\u9632\u6d2a\u5de5\u7a0b\u4e0d\u80fd\u6709\u6548\u63a7\u5236\u6d2a\u6c34\nD. \u975e\u5de5\u7a0b\u63aa\u65bd\u9010\u6e10\u6210\u4e3a\u9632\u6d2a\u89c4\u5212\u7684\u4e3b\u5bfc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.45396487768132265, "meta-math/MetaMath-Mistral-7B": 0.5861550067890196, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8000111840764974, "meta-llama/Meta-Llama-3-8B": 0.6978847778096573, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6988825059796917}}, {"question": "\u8fd1\u5e74\u6765\uff0c\u56fd\u5bb6\u623f\u5730\u4ea7\u8c03\u63a7\u63aa\u65bd\u7684\u51fa\u53f0\u5341\u5206\u5bc6\u96c6\uff0c\u9664\u4e86\u589e\u52a0\u516c\u5171\u79df\u8d41\u4f4f\u623f\u4f9b\u5e94\u5916\uff0c\u518d\u52a0\u4e0a\u592e\u884c\u52a0\u606f\uff0c\u591a\u4e2a\u57ce\u5e02\u51fa\u73b0\u4e86\u623f\u5c4b\u6210\u4ea4\u91cf\u4e0b\u8dcc\u7684\u6001\u52bf\uff0c\u623f\u4ef7\u6da8\u5e45\u5f00\u59cb\u653e\u7f13\u3002\u8fd9\u8868\u660e____\u3002\nA. \u56fd\u5bb6\u901a\u8fc7\u5b8f\u89c2\u8c03\u63a7\u5e73\u8861\u4f9b\u6c42\u5173\u7cfb\nB. \u4ef7\u683c\u7684\u6ce2\u52a8\u901a\u8fc7\u4f9b\u6c42\u5173\u7cfb\u8868\u73b0\u51fa\u6765\nC. \u5b8f\u89c2\u8c03\u63a7\u662f\u8d44\u6e90\u914d\u7f6e\u7684\u57fa\u7840\u6027\u624b\u6bb5\nD. \u5b8f\u89c2\u8c03\u63a7\u53ef\u4ee5\u514b\u670d\u5e02\u573a\u8c03\u8282\u7684\u6ede\u540e\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32165926937517475, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4181874685359794, "HuggingFaceH4/zephyr-7b-beta": 0.9617883326019233, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6593283892292636, "meta-llama/Meta-Llama-3-8B": 0.7464284002573658, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6355004961273186}}, {"question": "\u5b66\u751f\u5728\u64cd\u573a\u4e0a\u5217\u961f\u505a\u64cd\uff0c\u53ea\u77e5\u4eba\u6570\u572890-110\u4e4b\u95f4\u3002\u5982\u679c\u6392\u62103\u6392\u5219\u4e0d\u591a\u4e0d\u5c11\uff1a\u6392\u62105\u6392\u5219\u5c112\u4eba\uff1b\u6392\u62107\u6392\u5219\u5c114\u4eba\u3002\u95ee\u5b66\u751f\u4eba\u6570\u662f\u591a\u5c11\u4eba?____\nA. 102\nB. 98\nC. 104\nD. 108\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u4eba\u8bf4\uff1a\u4eba\u672c\u662f\u6563\u843d\u7684\u73cd\u73e0\uff0c\u968f\u5730\u4e71\u6eda\u3002\u6587\u5316\u5c31\u662f\u90a3\u6781____\u53c8\u5f3a\u97e7\u7684\u7ec6\u7ebf\uff0c\u5c06\u73e0\u5b50\u4e32\u8d77\u6765\u6210\u4e3a\u793e\u4f1a\u3002\u4e5f\u6709\u4eba\u8bf4\uff1a\u6587\u5316\u72b9\u5982\u7a7a\u6c14\u4e2d\u7684\u6c27\u6c14\uff0c\u81ea\u7136\u754c\u7684\u6625\u96e8\uff0c\u4e0d\u53ef\u6216\u7f3a\u5374____\uff0c\u98d8\u98d8\u6d12\u6d12\uff0c\u6da6\u7269\u65e0\u58f0\u3002\u53ef\u89c1\uff0c\u6587\u5316\u8d44\u6e90\u4ef7\u503c\u662f\u65e0\u6cd5\u7528\u5c3a\u5ea6\u8861\u91cf\u7684\u3002 \u586b\u5165\u753b\u6a2a\u7ebf\u90e8\u5206\u6700\u6070\u5f53\u7684\u4e00\u9879\u662f____\u3002\nA. \u67d4\u5f31 \u89c6\u4e4b\u65e0\u5f62\nB. \u7ea4\u7ec6 \u4e0d\u53ef\u540d\u72b6\nC. \u7ed3\u5b9e \u89c6\u800c\u4e0d\u89c1\nD. \u8584\u5f31 \u4e0d\u53ef\u6349\u6478\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u653f\u5e9c\u804c\u80fd\u4e0e\u6210\u672c\u95ee\u9898\u4e00\u76f4\u5907\u53d7\u4e89\u8bae\uff0c\u4f46\u8fd9\u65b9\u9762\u7684\u7814\u7a76\u4f3c\u4e4e\u8fd8\u5904\u4e8e\u4e00\u79cd\u89c2\u70b9\u4e0e\u7acb\u573a\u8fdc\u672a\u4e00\u81f4\u7684\u72b6\u6001\uff0c\u4e00\u4e2a\u91cd\u8981\u539f\u56e0\u662f\u7814\u7a76\u89c6\u89d2\u4e0e\u65b9\u6cd5\u7684\u5c40\u9650\u3002\u5927\u4f53\u4e0a\u770b\uff0c\u8fd9\u7c7b\u7814\u7a76\u6709\u4e24\u6761\u601d\u8def\uff0c\u4e00\u6761\u662f\u4fe1\u5b88\u65b0\u53e4\u5178\u7ecf\u6d4e\u5b66\u7406\u8bba\u9884\u8bbe\uff0c\u8ba4\u4e3a\u5e02\u573a\u53ef\u4ee5\u6709\u6548\u89e3\u51b3\u7ecf\u6d4e\u793e\u4f1a\u53d1\u5c55\u4e2d\u7684\u95ee\u9898\uff0c\u6301\u201c\u5c0f\u653f\u5e9c\u201d\u89c2\u70b9\uff1b\u53e6\u4e00\u6761\u662f\u4fe1\u5b88\u653f\u5e9c\u5e72\u9884\u4e3b\u4e49\u7406\u8bba\u9884\u8bbe\uff0c\u8ba4\u4e3a\u653f\u5e9c\u4e0d\u65f6\u5e72\u9884\u662f\u5e02\u573a\u80fd\u591f\u5065\u5eb7\u8fd0\u8f6c\u7684\u5fc5\u8981\u6761\u4ef6\u3002\u7b14\u8005\u8ba4\u4e3a\uff0c\u8981\u89e3\u51b3\u8fd9\u79cd\u56f0\u5883\uff0c\u5fc5\u987b\u6709\u65b0\u7684\u7406\u8bba\u89c6\u91ce\u548c\u65b0\u7684\u7814\u7a76\u65b9\u6cd5\uff0c\u800c\u65b0\u5174\u53e4\u5178\u7ecf\u6d4e\u5b66\u7406\u8bba\u5c31\u662f\u5176\u4e2d\u4e4b\u4e00\u3002 \u8fd9\u6bb5\u6587\u5b57\u63a5\u4e0b\u6765\u6700\u6709\u53ef\u80fd\u8bb2\u8ff0\u7684\u662f____\u3002\nA. \u65b0\u5174\u53e4\u5178\u7ecf\u6d4e\u5b66\u7684\u7406\u8bba\u6846\u67b6\u4e0e\u7814\u7a76\u65b9\u6cd5\nB. \u65b0\u7406\u8bba\u89c6\u91ce\u5bf9\u63d0\u9ad8\u653f\u5e9c\u7684\u884c\u653f\u6548\u7387\u6709\u4f55\u5e2e\u52a9\nC. \u65b0\u53e4\u5178\u7ecf\u6d4e\u5b66\u7406\u8bba\u9884\u8bbe\u7684\u5c40\u9650\u6027\nD. \u653f\u5e9c\u804c\u80fd\u4e0e\u6210\u672c\u4e4b\u95f4\u77db\u76fe\u96be\u89e3\u7684\u539f\u56e0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40292682366042276, "meta-math/MetaMath-Mistral-7B": 0.826755986160347, "itpossible/Chinese-Mistral-7B-v0.1": 0.4575160312128929, "HuggingFaceH4/zephyr-7b-beta": 0.5823559501530173, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.951079136307919, "meta-llama/Meta-Llama-3-8B": 0.6875888133287652, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9512941537765797}}, {"question": "2009\u5e74\u6709\u4e24\u6b21\u201c\u7acb\u6625\u201d\uff0c\u5f88\u5bb9\u6613\u8ba9\u4eba\u8054\u60f3\u5230\u201c\u7b2c\u4e8c\u6625\u201d\u201c\u4e8c\u5ea6\u6625\u201d\uff0c\u53ef\u60f3\u800c\u77e5\u8fd9\u6837\u7684\u5a5a\u59fb\u4e0d\u7a33\u5b9a\uff0c\u6240\u4ee5\u7f51\u7edc\u4e0a\u6709\u201c2009\u5e74\u4e0d\u80fd\u7ed3\u5a5a\uff0c\u6216\u80052009\u5e74\u7231\u60c5\u4e0d\u4f1a\u957f\u4e45\u201d\u7b49\u4f20\u95fb\u3002\u4f46\u662f\uff0c\u5927\u591a\u6570\u5e74\u8f7b\u4eba\u8ba4\u4e3a\uff0c\u767b\u8bb0\u7ed3\u5a5a\u662f\u4ef6\u6c34\u5230\u6e20\u6210\u7684\u4e8b\uff0c\u4e0d\u4f1a\u56e0\u4e3a\u8d76\u65e5\u5b50\u4ed3\u4fc3\u63d0\u524d\u6216\u5ef6\u8fdf\u3002 \u6839\u636e\u8fd9\u6bb5\u6587\u5b57\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u4f5c\u8005\u8ba4\u4e3a2009\u5e74\u4e0d\u9002\u5408\u7ed3\u5a5a\nB. \u5927\u591a\u6570\u5e74\u8f7b\u4eba\u8ba4\u4e3a2009\u5e74\u662f\u7ed3\u5a5a\u7684\u597d\u5e74\u5934\nC. 2009\u5e74\u7ed3\u5a5a\u4f1a\u4f7f\u5a5a\u59fb\u4e0d\u7a33\u5b9a\u7684\u8bf4\u6cd5\u662f\u65e0\u7a3d\u4e4b\u8c08\nD. \u5927\u591a\u6570\u5e74\u8f7b\u4eba\u4e0d\u4f1a\u56e0\u4e3a2009\u5e74\u6709\u4e24\u6b21\u201c\u7acb\u6625\u201d\u800c\u6539\u53d8\u81ea\u5df1\u7684\u7ed3\u5a5a\u8ba1\u5212\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.48648137569770067, "meta-math/MetaMath-Mistral-7B": 0.6068251007732914, "itpossible/Chinese-Mistral-7B-v0.1": 0.6445706176622844, "HuggingFaceH4/zephyr-7b-beta": 0.9997978745115025, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5709984812634811, "meta-llama/Meta-Llama-3-8B": 0.741359390281093, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9409309414324476}}, {"question": "\u5728\u6781\u9650\u5f3a\u5ea6\u8fd0\u52a8\u4e2d\uff0c\u808c\u8089\u4e2d\u7684ATP\u548cCP\u5728\u591a\u5c11\u79d2\u5185\u5c31\u51e0\u4e4e\u8017\u7aed____\nA. 15\nB. 30\nC. 10\nD. 20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37407817956874767, "meta-math/MetaMath-Mistral-7B": 0.6216065019834867, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5171541131181945, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3554064215291941}}, {"question": "\u51b3\u5b9aVO2max\u7684\u5916\u5468\u673a\u5236\u662f____\nA. \u808c\u7ea4\u7ef4\u7ec4\u6210\nB. \u6709\u6c27\u4ee3\u8c22\u80fd\u529b\nC. \u808c\u7ec4\u7ec7\u5229\u7528\u6c27\u7684\u80fd\u529b\nD. \u6c27\u8fd0\u8f93\u7cfb\u7edf\u7684\u673a\u80fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u201c\u6781\u70b9\u201d\u4ea7\u751f\u65e9\u665a\u4e0e____\nA. \u5e74\u9f84\u65e0\u5173\nB. \u8bad\u7ec3\u7a0b\u5ea6\u65e0\u5173\nC. \u6c14\u5019\u6761\u4ef6\u65e0\u5173\nD. \u6559\u7ec3\u5458\u65e0\u5173\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f18\u79c0\u8fd0\u52a8\u5458\u5168\u7a0b\u6027\u591a\u5e74\u8bad\u7ec3\u8fc7\u7a0b\u4e2d\uff0c\u8bad\u7ec3\u8d1f\u8377\u59cb\u7ec8\u4fdd\u6301\u5728\u9ad8\u6c34\u5e73\u533a\u95f4\u8d77\u4f0f\u7684\u662f____\nA. \u57fa\u7840\u8bad\u7ec3\u9636\u6bb5\nB. \u4e13\u9879\u63d0\u9ad8\u9636\u6bb5\nC. \u6700\u4f73\u7ade\u6280\u9636\u6bb5\nD. \u7ade\u6280\u4fdd\u6301\u9636\u6bb5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.32545507259594497, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4e0d\u662f\u51c6\u5907\u6d3b\u52a8\u7684\u4f5c\u7528\u7684\u662f____\nA. \u8c03\u8282\u8d5b\u524d\u72b6\u6001\nB. \u7f29\u77ed\u8fdb\u5165\u5de5\u4f5c\u72b6\u6001\nC. \u51cf\u8f7b\u201c\u6781\u70b9\u201d\u7a0b\u5ea6\nD. \u52a0\u901f\u8fd0\u52a8\u75b2\u52b3\u7684\u6062\u590d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.41575303099435373, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6831232502127743, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.571719680155505, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u817f\u90e8\u808c\u8089\u4e2d\u5feb\u808c\u7ea4\u7ef4\u767e\u5206\u7ec4\u6210\u5360\u4f18\u52bf\u7684\u4eba\uff0c\u8f83\u9002\u5b9c\u4ece\u4e8b\u7684\u8fd0\u52a8\u9879\u76ee\u662f____\nA. 800m\u8dd1\nB. 1 500m\u8dd1\nC. 100m\u8dd1\nD. 1 500m\u6e38\u6cf3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33998063708019177, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8442300171980374, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6505759823284231, "meta-llama/Meta-Llama-3-8B": 0.4430448286815293, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.40826373232188745}}, {"question": "\u8fd0\u52a8\u65f6\uff0c\u673a\u4f53\u5de5\u4f5c\u80fd\u529b\u9010\u6b65\u63d0\u9ad8\u662f\u56e0\u4e3a____\nA. \u7269\u7406\u60f0\u6027\u548c\u690d\u7269\u6027\u529f\u80fd\u60f0\u6027\nB. \u8fd0\u52a8\u5668\u5b98\u529f\u80fd\u60f0\u6027\u548c\u7269\u7406\u60f0\u6027\nC. \u690d\u7269\u6027\u529f\u80fd\u60f0\u6027\u548c\u8fd0\u52a8\u5668\u5b98\u529f\u80fd\u60f0\u6027\nD. \u7269\u7406\u60f0\u6027\u548c\u751f\u7406\u60f0\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bfe\u5916\u8fd0\u52a8\u7ade\u8d5b\u7684\u4e3b\u8981\u7279\u70b9\u6709\u7ade\u4e89\u6027\u3001\u96c6\u4f53\u6027\u4e0e\u6559\u80b2\u6027\u3001\u591a\u5c42\u6b21\u4e0e\u7fa4\u4f17\u6027\u4ee5\u53ca____\nA. \u77e5\u8bc6\u6027\u4e0e\u534f\u4f5c\u6027\nB. \u751f\u7406\u6027\u4e0e\u5fc3\u7406\u6027\nC. \u8da3\u5473\u6027\u4e0e\u5a31\u4e50\u6027\nD. \u516c\u6b63\u6027\u4e0e\u8868\u73b0\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.325455072595945, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.308176776288574, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u897f\u5468\u7684\u201c\u56fd\u5b66\u201d\u548c\u201c\u4e61\u5b66\u201d\u7684\u6559\u5b66\u5185\u5bb9\u4e3a____\nA. \u5b97\u6559\u548c\u519b\u4e8b\nB. \u4e60\u5c04\u53ca\u4f20\u4e60\u591a\u79cd\u6b66\u827a\nC. \u793c\u3001\u4e50\u3001\u5c04\u3001\u5fa1\u3001\u4e66\u3001\u6570\nD. \u201c\u4e94\u9879\u7ade\u6280\u201d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37727685017148116, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8643119541808408, "HuggingFaceH4/zephyr-7b-beta": 0.9124182742889938, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5172434597481692, "meta-llama/Meta-Llama-3-8B": 0.5942154620923301, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8885568331648755}}, {"question": "\u80fd\u591f\u5bfc\u81f4\u6c27\u89e3\u79bb\u66f2\u7ebf\u53f3\u79fb\u7684\u60c5\u51b5\u662f____\nA. \u8840\u6db2\u4e2dPCO2\u589e\u9ad8\nB. \u8840\u6db2\u4e2dPCO2\u964d\u4f4e\nC. \u8840\u6db2\u4e2dpH\u503c\u589e\u9ad8\nD. \u8840\u6db2\u4e2dPN2\u5f20\u529b\u589e\u9ad8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.35428004947894953, "meta-math/MetaMath-Mistral-7B": 0.4453450713474242, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.517503425492201, "meta-llama/Meta-Llama-3-8B": 0.44887468519604984, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5470856660187318}}, {"question": "\u4e0b\u9762\u4e0d\u5c5e\u4e8e\u514b\u670d\u81ea\u8eab\u4f53\u91cd\u7684\u7ec3\u4e60\u662f____\nA. \u5f15\u4f53\u5411\u4e0a\nB. \u5012\u7acb\u63a8\u8d77\nC. \u4f7f\u7528\u62c9\u529b\u5668\nD. \u7eb5\u8df3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.40101791712441026, "meta-math/MetaMath-Mistral-7B": 0.5939475280115325, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9756873339786516, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7555819167955686, "meta-llama/Meta-Llama-3-8B": 0.5463490701810393, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d4\u9053\u9879\u76ee\u4e2d\u7684\u201c\u5f97\u610f\u6280\u201d\u6307\u7684\u662f____\nA. \u57fa\u672c\u6280\u672f\nB. \u7279\u957f\u6280\u672f\nC. \u9ad8\u96be\u5ea6\u6280\u672f\nD. \u5168\u9762\u6280\u672f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7943870740874892, "meta-math/MetaMath-Mistral-7B": 0.9474560211967603, "itpossible/Chinese-Mistral-7B-v0.1": 0.4065059027901228, "HuggingFaceH4/zephyr-7b-beta": 0.9983475322470254, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9620560174601736, "meta-llama/Meta-Llama-3-8B": 0.45717163308118897, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u7cd6\u7684\u5206\u89e3\u4ee3\u8c22\uff0c\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\nA. \u5728\u4e0d\u9700\u8981\u6c27\u7684\u60c5\u51b5\u4e0b\uff0c\u7cd6\u8fdb\u884c\u65e0\u6c27\u9175\u89e3\uff0c\u53cd\u5e94\u5728\u7ec6\u80de\u6d46\u4e2d\u8fdb\u884c\nB. \u7cd6\u8fdb\u884c\u65e0\u6c27\u9175\u89e3\u65f6\uff0c\u80fd\u91cf\u5229\u7528\u7387\u5f88\u4f4e\nC. \u5728\u6c27\u6c14\u4f9b\u5e94\u5145\u8db3\u65f6\uff0c\u808c\u8089\u4e2d\u7684\u4e73\u9178\u53ef\u4ee5\u518d\u8f6c\u53d8\u4e3a\u8461\u8404\u7cd6\u8fdb\u4e00\u6b65\u6c27\u5316\u4f9b\u80fd\nD. \u8461\u8404\u7cd6\u6216\u7cd6\u539f\u751f\u6210\u4e19\u916e\u9178\u662f\u6709\u6c27\u548c\u65e0\u6c27\u4f9b\u80fd\u7684\u5171\u540c\u9014\u5f84\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.585978727918457, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5541352873506525}}, {"question": "\u4e0b\u5217\u80fd\u6700\u597d\u8bc4\u4ef7\u80ba\u901a\u6c14\u529f\u80fd\u7684\u6307\u6807\u662f____\nA. \u80ba\u901a\u6c14\u91cf\nB. \u80ba\u6d3b\u91cf\nC. \u8865\u5438\u6c14\u91cf\nD. \u65f6\u95f4\u80ba\u6d3b\u91cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4391305514521417, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ece\u8fd0\u52a8\u5458\u7ade\u6280\u80fd\u529b\u7684\u51b3\u5b9a\u56e0\u7d20\u770b\uff0c\u4e0b\u5217\u9879\u76ee\u5bf9\u8fd0\u52a8\u5458\u5fc3\u7406\u80fd\u529b\u8981\u6c42\u6700\u9ad8\u7684\u662f____\nA. \u6e38\u6cf3\nB. \u8df3\u6c34\nC. \u5c04\u7bad\nD. \u6454\u8de4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e73\u9178\u9608\u53ef\u7528\u6765\u8bc4\u5b9a\u673a\u4f53____\nA. \u65e0\u6c27\u80fd\u529b\nB. \u6709\u6c27\u80fd\u529b\nC. \u8840\u4e73\u9178\u80fd\u529b\nD. ATP\u2014CP\u7cfb\u7edf\u80fd\u529b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3750518345014868, "meta-math/MetaMath-Mistral-7B": 0.6406446073375266, "itpossible/Chinese-Mistral-7B-v0.1": 0.30300686740596605, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fd0\u52a8\u5458\u8d1f\u8377\u91cf\u5ea6\u4e34\u754c\u503c\u7684\u5927\u5c0f\u53d7\u6559\u80b2\u7a0b\u5ea6\u3001\u7ade\u6280\u6c34\u5e73\u53ca\u5065\u5eb7\u7b49\u56e0\u7d20\u7684\u5f71\u54cd\uff0c\u56e0\u6b64\u5728\u8bad\u7ec3\u4e2d\u9700\u8981____\nA. \u6b63\u786e\u5904\u7406\u8d1f\u8377\u4e0e\u6062\u590d\u7684\u5173\u7cfb\nB. \u6b63\u786e\u7406\u89e3\u8bad\u7ec3\u8d1f\u8377\u6784\u6210\nC. \u79d1\u5b66\u52a8\u6001\u63a2\u6c42\u8d1f\u8377\u91cf\u5ea6\u4e34\u754c\u503c\nD. \u5bf9\u8fd0\u52a8\u5458\u8fdb\u884c\u533a\u522b\u5bf9\u5f85\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4305169802404614, "meta-math/MetaMath-Mistral-7B": 0.4184174010079213, "itpossible/Chinese-Mistral-7B-v0.1": 0.5560350077669256, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8574569954594163}}, {"question": "\u540c\u4e3a\u7403\u7c7b\u9879\u76ee\uff0c\u7bee\u7403\u4e0e\u8db3\u7403\u5bf9\u8fd0\u52a8\u5458\u8eab\u4f53\u5f62\u6001\u3001\u7d20\u8d28\u3001\u6280\u6218\u672f\u7684\u8981\u6c42\u5374\u5927\u4e0d\u76f8\u540c\uff0c\u4e3b\u8981\u662f\u56e0\u4e3a____\nA. \u8fd0\u52a8\u5458\u4e2a\u4f53\u7684\u4e0d\u540c\nB. \u6559\u7ec3\u5458\u6267\u6559\u80fd\u529b\u7684\u4e0d\u540c\nC. \u5404\u9879\u76ee\u8bad\u7ec3\u6761\u4ef6\u7684\u4e0d\u540c\nD. \u4e13\u9879\u7ade\u6280\u80fd\u529b\u7684\u4e0d\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8257205504292616, "HuggingFaceH4/zephyr-7b-beta": 0.9932835789307997, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6295611594228688, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5f71\u54cd\u8840\u7ea2\u86cb\u767d\u6c27\u9971\u548c\u5ea6\u7684\u6700\u4e3b\u8981\u56e0\u7d20\u662f____\nA. PO2\nB. \u8840\u6db2pH\u503c\nC. PCO2\nD. \u8840\u6db2\u7684\u6e29\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38727412187207844, "meta-math/MetaMath-Mistral-7B": 0.6547335015313048, "itpossible/Chinese-Mistral-7B-v0.1": 0.8286861715339925, "HuggingFaceH4/zephyr-7b-beta": 0.8973338179706344, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4629909441063661, "meta-llama/Meta-Llama-3-8B": 0.9254297994803996, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5164139943355841}}, {"question": "\u4e0e\u4fdd\u536b\u7ec6\u80de\u7684\u6c34\u52bf\u53d8\u5316\u5173\u7cfb\u6700\u5bc6\u5207\u7684\u79bb\u5b50\u662f____\u3002\nA. $Ca^{2+}$\nB. $K^+$\nC. $Cl^-$\nD. $Mg^{2+}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4702008436521869, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7641912889083301}}, {"question": "\u5df2\u7ecf\u53d1\u751f\u8d28\u58c1\u5206\u79bb\u7684\u7ec6\u80de\uff0c\u7ec6\u80de\u7684\u6c34\u52bf\u51b3\u5b9a\u4e8e\u7ec6\u80de\u7684____\u3002\nA. \u6e17\u900f\u52bf\nB. \u538b\u529b\u52bf\nC. \u886c\u8d28\u52bf\nD. \u81a8\u538b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3378708558085521, "meta-math/MetaMath-Mistral-7B": 0.49449535700214714, "itpossible/Chinese-Mistral-7B-v0.1": 0.29660173325630934, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5793345768961764, "meta-llama/Meta-Llama-3-8B": 0.4761785615465048, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8183883748287702}}, {"question": "\u79cd\u5b50\u7684\u840c\u53d1\u8fc7\u7a0b\u5bf9\u6c34\u5206\u7684\u5438\u6536\u901f\u5ea6\u6709\u6240\u4e0d\u540c\uff0c\u4e00\u822c\u8868\u73b0\u4e3a____\u3002\nA. \u5feb\u2014\u6162\u2014\u5feb\nB. \u6162\u2014\u5feb\u2014\u6162\nC. \u5feb\u2014\u6162\nD. \u6162\u2014\u5feb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6109588439239166, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4358945544258509, "meta-llama/Meta-Llama-3-8B": 0.45787067928023345, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6387729411173252}}, {"question": "\u5728\u7ec6\u80de\u4f38\u957f\u8fc7\u7a0b\u4e2d\uff0c\u65b0\u7684\u7ec6\u80de\u58c1\u7269\u8d28\u4e2d\u7ea4\u7ef4\u7d20\u662f\u5728____\u4e2d\u5408\u6210\uff0c\u7136\u540e\u5206\u6ccc\u5230\u7ec6\u80de\u58c1\u4e2d\u3002\nA. \u7ec6\u80de\u8d28\u819c\nB. \u9ad8\u5c14\u57fa\u4f53\nC. \u7ebf\u7c92\u4f53\nD. \u53f6\u7eff\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.44626809489683156, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5fae\u7ba1\u662f\u4e24\u79cd\u5fae\u7ba1\u86cb\u767d\u7ec4\u6210\u7684\u5f02\u4e8c\u805a\u4f53\uff0c\u8fd9\u4e24\u79cd\u5fae\u7ba1\u86cb\u767d\u662f____\u3002\nA. \u808c\u52a8\u86cb\u767d\uff0c\u808c\u52a8\u86cb\u767d\u7ed3\u5408\u86cb\u767d\nB. \u9a6c\u8fbe\u86cb\u767d\uff0c\u808c\u7403\u86cb\u767d\nC. \u03b1-\u5fae\u7ba1\u86cb\u767d\uff0c\u03b2-\u5fae\u7ba1\u86cb\u767d\nD. \u52a8\u86cb\u767d\uff0c\u529b\u86cb\u767d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8405847910362798, "meta-math/MetaMath-Mistral-7B": 0.9786424571726745, "itpossible/Chinese-Mistral-7B-v0.1": 0.8158315492946424, "HuggingFaceH4/zephyr-7b-beta": 0.9999569167477558, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9625273607269871, "meta-llama/Meta-Llama-3-8B": 0.9595877001344195, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9947610619014902}}, {"question": "\u5728\u690d\u7269\u5bf9\u9006\u5883\u7684\u9002\u5e94\u4e2d\u6700\u4e3a\u91cd\u8981\u7684\u690d\u7269\u6fc0\u7d20\u662f____\u3002\nA. \u7ec6\u80de\u5206\u88c2\u7d20\nB. \u4e59\u70ef\nC. \u8309\u8389\u9178\u7532\u916f\nD. \u8131\u843d\u9178\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6837780968252336, "meta-math/MetaMath-Mistral-7B": 0.6109588453425332, "itpossible/Chinese-Mistral-7B-v0.1": 0.645053474651642, "HuggingFaceH4/zephyr-7b-beta": 0.8880474195528043, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6079974812858236, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u56db\u7ec4\u77ff\u8d28\u5143\u7d20\uff0c\u54ea\u7ec4\u5143\u7d20\u7684\u7f3a\u7d20\u75c7\u8868\u73b0\u4e3a\u53f6\u7247\u7f3a\u7eff?____\nA. Fe\uff0cCl\uff0cN\uff0cCa\nB. Mg\uff0cFe\uff0cN\uff0cS\nC. P\uff0cN\uff0cMg\uff0cS\nD. P\uff0cMo\uff0cMg\uff0cS\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3160424181481997, "HuggingFaceH4/zephyr-7b-beta": 0.8373424305061358, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3728641892601242, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6522162705922266}}, {"question": "\u5728\u8870\u8001\u7684\u690d\u7269\u7ec4\u7ec7\u6216\u5668\u5b98\u4e2d\uff0c\u86cb\u767d\u8d28\u542b\u91cf\u663e\u8457\u4e0b\u964d\uff0c\u5176\u4e3b\u8981\u539f\u56e0\u662f____\u3002\nA. \u86cb\u767d\u8d28\u5468\u8f6c\u901f\u7387\u964d\u4f4e\nB. \u6c28\u57fa\u9178\u7684\u751f\u7269\u5408\u6210\u53d7\u963b\nC. \u86cb\u767d\u8d28\u6c34\u89e3\u9176\u6d3b\u6027\u589e\u52a0\nD. \u571f\u58e4\u4e2d\u6c2e\u7d20\u542b\u91cf\u4e0b\u964d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9413452629719352, "meta-math/MetaMath-Mistral-7B": 0.995602353963928, "itpossible/Chinese-Mistral-7B-v0.1": 0.9498647839549491, "HuggingFaceH4/zephyr-7b-beta": 0.9999286106453203, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9771414990472547, "meta-llama/Meta-Llama-3-8B": 0.9113816885487742, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "G\u86cb\u767d\u662f\u7531\u03b1\u3001\u03b2\u3001\u03b33\u79cd\u4e9a\u57fa\u6784\u6210\u7684\u5f02\u4e09\u805a\u4f53\uff0c\u4e0eGTP\u7ed3\u5408\u7684\u6d3b\u6027\u4f4d\u70b9\u5728____\u4e0a\u3002\nA. \u03b1\u4e9a\u57fa\nB. \u03b2\u4e9a\u57fa\nC. \u03b3\u4e9a\u57fa\nD. \u03b2\u03b3\u4e9a\u57fa\u590d\u5408\u4f53\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8552502573045003, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5df2\u5206\u5316\u7684\u7ec6\u80de\u5728\u7279\u5b9a\u60c5\u51b5\u4e0b\u6062\u590d\u5206\u88c2\u80fd\u529b\uff0c\u91cd\u65b0\u8fdb\u884c\u7ec6\u80de\u5206\u88c2\u7684\u8fc7\u7a0b\u4e3a____\u3002\nA. \u7ec6\u80de\u5206\u5316\nB. \u7ec6\u80de\u5206\u88c2\nC. \u518d\u5206\u5316\nD. \u8131\u5206\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8951799697705923, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9519995857506756, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u690d\u7269\u5668\u5b98\u3001\u7ec4\u7ec7\u6216\u7ec6\u80de\u5728\u5f62\u6001\u7ed3\u6784\u3001\u751f\u5316\u7ec4\u6210\u4ee5\u53ca\u751f\u7406\u529f\u80fd\u4e0a\u7684\u4e0d\u5bf9\u79f0\u6027\u662f____\u3002\nA. \u7ec6\u80de\u751f\u957f\nB. \u7ec6\u80de\u5206\u5316\nC. \u6781\u6027\nD. \u7ec6\u80de\u5168\u80fd\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.9294052774863714, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8682363676431559, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9976639484083815}}, {"question": "\u8010\u70ed\u6027\u5f3a\u7684\u690d\u7269\u539f\u751f\u8d28\u86cb\u767d\u8d28\u5177\u6709\u7684\u7279\u70b9\u662f____\u3002\nA. \u6613\u53d1\u751f\u4e0d\u53ef\u9006\u7684\u53d8\u6027\u4e0e\u51dd\u805a\nB. \u758f\u6c34\u952e\u591a\uff0c\u4e8c\u786b\u952e\u5c11\nC. \u5bf9\u70ed\u7a33\u5b9a\uff0c\u758f\u6c34\u952e\u548c\u4e8c\u786b\u952e\u591a\nD. \u5bf9\u70ed\u7a33\u5b9a\uff0c\u758f\u6c34\u952e\u548c\u4e8c\u786b\u952e\u5c11\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5776604671852256, "meta-math/MetaMath-Mistral-7B": 0.5102906824492538, "itpossible/Chinese-Mistral-7B-v0.1": 0.3632122790984034, "HuggingFaceH4/zephyr-7b-beta": 0.9990959463380029, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8838463279012228, "meta-llama/Meta-Llama-3-8B": 0.6942883168459142, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9502884460222528}}, {"question": "\u7ec6\u80de\u5728\u5f62\u6001\u7ed3\u6784\u3001\u5185\u90e8\u4ee3\u8c22\u548c\u751f\u7406\u529f\u80fd\u4e0a\u533a\u522b\u4e8e\u539f\u5206\u751f\u7ec6\u80de\u7684\u8fc7\u7a0b\u662f____\u3002\nA. \u7ec6\u80de\u751f\u957f\nB. \u7ec6\u80de\u5206\u5316\nC. \u7ec6\u80de\u8131\u5206\u5316\nD. \u7ec6\u80de\u518d\u5206\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9147787550418661, "meta-math/MetaMath-Mistral-7B": 0.9926404424971623, "itpossible/Chinese-Mistral-7B-v0.1": 0.9556267385352559, "HuggingFaceH4/zephyr-7b-beta": 0.9999965901254739, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9851565930567387, "meta-llama/Meta-Llama-3-8B": 0.8471273257883789, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9960704877596216}}, {"question": "\u5149\u5b66\u663e\u5fae\u955c\u4e0b\u5448\u73b0\u51fa\u7684\u7ec6\u80de\u7ed3\u6784\u88ab\u79f0\u4e3a____\u3002\nA. \u663e\u5fae\u7ed3\u6784\nB. \u4e9a\u663e\u5fae\u7ed3\u6784\nC. \u8d85\u663e\u5fae\u7ed3\u6784\nD. \u4e9a\u7ec6\u80de\u7ed3\u6784\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38726021944100125, "meta-math/MetaMath-Mistral-7B": 0.8455035909434825, "itpossible/Chinese-Mistral-7B-v0.1": 0.3699091098241171, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36109239716058705, "meta-llama/Meta-Llama-3-8B": 0.4323369499775249, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.910539869481446}}, {"question": "\u6839\u5c16\u4e2d\u6839\u7684\u5e72\u7ec6\u80de\u7fa4\u662f\u6307____\u3002\nA. \u6839\u51a0\nB. \u9759\u6b62\u4e2d\u5fc3\nC. \u5206\u751f\u7ec4\u7ec7\nD. \u6839\u6bdb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3160424181481997, "meta-math/MetaMath-Mistral-7B": 0.4393224705824004, "itpossible/Chinese-Mistral-7B-v0.1": 0.40025192808675997, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3128363857141096, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8d28\u819c\u4e0a\u5df2\u77e5\u7684\u79bb\u5b50\u901a\u9053\u6709____\u3002\nA. $K^+$\uff0c$Mg^{2+}$\uff0c$Ca^{2+}$\nB. $K^+$\uff0c$Cl^-$\uff0c$Ca^{2+}$\nC. $K^+$\uff0c$Cl^-$\uff0c$Mg^{2+}$\nD. $K^+$\uff0c$Zn^{2+}$\uff0c$Ca^{2+}$\u548c$Fe^{2+}$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3460058095032024, "meta-math/MetaMath-Mistral-7B": 0.35832757394471465, "itpossible/Chinese-Mistral-7B-v0.1": 0.3160424181481997, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u628a\u690d\u7269\u7ec4\u7ec7\u653e\u5728\u9ad8\u6e17\u6eb6\u6db2\u4e2d\uff0c\u690d\u7269\u7ec4\u7ec7____\u3002\nA. \u5438\u6c34\nB. \u5931\u6c34\nC. \u6c34\u5206\u52a8\u6001\u5e73\u8861\nD. \u6c34\u5206\u4e0d\u53d8\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6190598120382191, "itpossible/Chinese-Mistral-7B-v0.1": 0.8281417181367481, "HuggingFaceH4/zephyr-7b-beta": 0.6730078195044212, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5505693044435593, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u54ea\u79cd\u5143\u7d20\u7684\u7f3a\u7d20\u75c7\u8868\u73b0\u4e3a\u690d\u7269\u53f6\u5c16\u79ef\u7d2f\u8fc7\u591a\u7684\u8132\uff0c\u4e25\u91cd\u51fa\u73b0\u574f\u6b7b?____\nA. Ni\nB. Mn\nC. Fe\nD. Ca\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5351456304201471, "meta-math/MetaMath-Mistral-7B": 0.8618906039834056, "itpossible/Chinese-Mistral-7B-v0.1": 0.32659802886351824, "HuggingFaceH4/zephyr-7b-beta": 0.8747518692973382, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5801904428898996, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.417028149212408}}, {"question": "\u690d\u7269\u6839\u7cfb\u5438\u6536\u540e\uff0c\u5728____\u88ab\u8fd8\u539f\u3002\nA. \u53f6\u8089\u7ec6\u80de\nB. \u6839\u7ec4\u7ec7\nC. \u690d\u7269\u4f53\u5730\u4e0a\u90e8\nD. \u6839\u7ec4\u7ec7\u548c\u53f6\u8089\u7ec6\u80de\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5623246004525958, "meta-math/MetaMath-Mistral-7B": 0.8798885971436787, "itpossible/Chinese-Mistral-7B-v0.1": 0.5709262474332626, "HuggingFaceH4/zephyr-7b-beta": 0.9902954636533084, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8022147061160964, "meta-llama/Meta-Llama-3-8B": 0.5014154751172246, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8344029635139545}}, {"question": "\u5728\u9ad8\u6e29\u6c14\u5019\u6761\u4ef6\u4e0b\u7528\u51b7\u6c34\u704c\u6e89\u690d\u7269\u5f80\u5f80\u4f1a\u5f15\u8d77____\u3002\nA. \u690d\u7269\u84b8\u817e\u52a0\u5267\nB. \u690d\u7269\u840e\u852b\nC. \u690d\u7269\u5feb\u901f\u5438\u6c34\nD. \u690d\u7269\u751f\u957f\u52a0\u901f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4135365045257948, "meta-math/MetaMath-Mistral-7B": 0.7774948989040723, "itpossible/Chinese-Mistral-7B-v0.1": 0.8733796738449088, "HuggingFaceH4/zephyr-7b-beta": 0.9959793731357105, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7432269057991209, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9713603061236431}}, {"question": "\u9ad8\u7b49\u690d\u7269\u82b1\u7c89\u7ba1\u5411\u7740\u80da\u73e0\u7684\u751f\u957f\u662f____\u8fd0\u52a8\u3002\nA. \u5411\u5149\u6027\nB. \u5411\u5316\u6027\nC. \u5411\u91cd\u6027\nD. \u5411\u89e6\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38733798186243046, "meta-math/MetaMath-Mistral-7B": 0.5830003730536563, "itpossible/Chinese-Mistral-7B-v0.1": 0.28661281177772774, "HuggingFaceH4/zephyr-7b-beta": 0.9339939575500508, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7458015901050074, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5c5e\u4e8e\u751f\u7406\u78b1\u6027\u76d0\u7684\u662f____\u3002\nA. $NaNO_3$\nB. $(NH_4)_2SO_4$\nC. $NH_4NO_3$\nD. $MgSO_4$\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.6760898240827916, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5525763833690671, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4415437293991451, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5015219596483348}}, {"question": "\u4e0d\u5c5e\u4e8e\u7b2c\u4e8c\u4fe1\u4f7f\u7684\u7269\u8d28\u662f____\nA. cAMP\nB. cGMP\nC. $IP_3$\nD. \u80f0\u5c9b\u7d20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7221269066243576, "meta-math/MetaMath-Mistral-7B": 0.7131773552682129, "itpossible/Chinese-Mistral-7B-v0.1": 0.8466661795889283, "HuggingFaceH4/zephyr-7b-beta": 0.9994205839251044, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9518837663273158, "meta-llama/Meta-Llama-3-8B": 0.8065967043383507, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8065966950401178}}, {"question": "\u8131\u7fa7\u9176\u7684\u8f85\u9176____\nA. \u751f\u7269\u7d20\nB. \u53f6\u9178\nC. \u78f7\u9178\u5421\u54c6\u919b\nD. \u786b\u80fa\u7d20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.33350089681109407, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.36385828438381157, "HuggingFaceH4/zephyr-7b-beta": 0.8319765894116793, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6438812365803288, "meta-llama/Meta-Llama-3-8B": 0.4799561314620879, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5633824199702433}}, {"question": "\u5173\u4e8e\u6e7f\u6027\u574f\u75bd\u7684\u63cf\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u5408\u5e76\u8150\u8d25\u83cc\u611f\u67d3\nB. \u5177\u6709\u6076\u81ed\u5473\nC. \u5e38\u6709\u5168\u8eab\u4e2d\u6bd2\u75c7\u72b6\nD. \u574f\u6b7b\u7ec4\u7ec7\u4e0e\u5065\u5eb7\u7ec4\u7ec7\u4e4b\u95f4\u754c\u9650\u6e05\u695a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8511535604462174, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6366677267406229, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5062980207689856}}, {"question": "\u80ba\u6897\u6b7b\u5f62\u6210\u7684\u5148\u51b3\u6761\u4ef6\u662f____\nA. \u7ec4\u7ec7\u758f\u677e\nB. \u4e25\u91cd\u6de4\u8840\nC. \u86cb\u767d\u542b\u91cf\u9ad8\nD. \u4fa7\u652f\u5faa\u73af\u4e0d\u5145\u5206\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3328460403830469, "meta-math/MetaMath-Mistral-7B": 0.5413407980551798, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6307955432474668, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.648355484686756, "meta-llama/Meta-Llama-3-8B": 0.6594839752678936, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5804725773960749}}, {"question": "\u5173\u4e8e\u7ef4\u751f\u7d20\u7f3a\u4e4f\u75c7\u7684\u53d9\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u7ef4\u751f\u7d20A\u7f3a\u4e4f\u2014\u2014\u591c\u76f2\u75c7\nB. \u7ef4\u751f\u7d20D\u7f3a\u4e4f\u2014\u2014\u8f6f\u9aa8\u75c5\nC. \u7ef4\u751f\u7d20$B_1$ \u7f3a\u4e4f\u2014\u2014\u811a\u6c14\u75c5\nD. \u7ef4\u751f\u7d20$B_6$\u7f3a\u4e4f\u2014\u2014\u53e3\u89d2\u708e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3567115874534865, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.34714589404225377, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.45669491080665153, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6437577371725397}}, {"question": "cGMP\u80fd\u6fc0\u6d3b____\nA. \u78f7\u8102\u9176C\nB. \u86cb\u767d\u6fc0\u9176A\nC. \u86cb\u767d\u6fc0\u9176G\nD. \u916a\u6c28\u9178\u86cb\u767d\u6fc0\u9176\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7512053268735018, "meta-llama/Meta-Llama-3-8B": 0.6450534584253055, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7518740015321973}}, {"question": "\u5168\u8eab\u8425\u517b\u4e0d\u826f\u65f6\uff0c\u9996\u5148\u53d1\u751f\u840e\u7f29\u7684\u7ec4\u7ec7\u6216\u5668\u5b98\u662f____\nA. \u9aa8\u9abc\u808c\nB. \u8102\u80aa\u7ec4\u7ec7\nC. \u809d\nD. \u8111\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.3491611317439413, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6108\u5408\u5c5e\u4e8e\u5b8c\u5168\u518d\u751f\u7684\u662f____\nA. \u795e\u7ecf\u4fee\u590d\nB. \u76ae\u80a4\u7622\u75d5\nC. \u5fc3\u6897\u540e\u5fc3\u808c\u4fee\u590d\nD. \u9aa8\u6298\u6108\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36959451779581176, "meta-math/MetaMath-Mistral-7B": 0.7089109572719805, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4827289612474296, "meta-llama/Meta-Llama-3-8B": 0.39241037626455405, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7440535114906213}}, {"question": "PCR\u53cd\u5e94\u4e2d\uff0c\u6240\u8bbe\u8ba1\u5f15\u7269\u7684\u957f\u5ea6\u4e00\u822c\u4e3a____\nA. 5\uff5e10\u4e2a\u6838\u82f7\u9178\nB. 15\uff5e30\u4e2a\u6838\u82f7\u9178\nC. <50\u4e2a\u6838\u82f7\u9178\nD. \u957f\u5ea6\u4efb\u610f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5612835042362445, "meta-math/MetaMath-Mistral-7B": 0.9292195018073204, "itpossible/Chinese-Mistral-7B-v0.1": 0.5174255073248947, "HuggingFaceH4/zephyr-7b-beta": 0.9818963788621401, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8133781221212755, "meta-llama/Meta-Llama-3-8B": 0.44628198686171044, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.48366788394244203}}, {"question": "\u8f6c\u6c28\u9176\u7684\u8f85\u9176____\nA. \u751f\u7269\u7d20\nB. \u53f6\u9178\nC. \u78f7\u9178\u5421\u54c6\u919b\nD. \u786b\u80fa\u7d20\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32769911232432153, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.474069820068834, "HuggingFaceH4/zephyr-7b-beta": 0.700809429434131, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6255107118508688, "meta-llama/Meta-Llama-3-8B": 0.47020083610111213, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6011202593334525}}, {"question": "\u4e0b\u5217\u809d\u7ec6\u80de\u574f\u6b7b\u7684\u75c5\u53d8\u4e2d\uff0c\u75c5\u6bd2\u6027\u809d\u708e\u6700\u5e38\u89c1\u7684\u75c5\u7406\u53d8\u5316\u662f____\nA. \u6eb6\u89e3\u6027\u574f\u6b7b\nB. \u55dc\u9178\u6027\u574f\u6b7b\nC. \u70b9\u72b6\u574f\u6b7b\nD. \u788e\u7247\u574f\u6b7b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u809d\u810f\u5728\u8102\u7c7b\u4ee3\u8c22\u4e2d\u6240\u7279\u6709\u7684\u4f5c\u7528\u662f____\nA. \u5c06\u7cd6\u8f6c\u53d8\u4e3a\u8102\u80aa\nB. \u7531\u80c6\u56fa\u9187\u8f6c\u53d8\u4e3a\u80c6\u6c41\u9178\nC. \u751f\u6210\u916e\u4f53\nD. \u5408\u6210\u78f7\u8102\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5bfc\u81f4\u7532\u72b6\u817a\u80bf\u5927\u6700\u5e38\u89c1\u7684\u539f\u56e0\u662f____\nA. \u5782\u4f53\u80bf\u7624\nB. \u7f3a\u7898\nC. \u81ea\u8eab\u514d\u75ab\u53cd\u5e94\nD. \u5148\u5929\u6027\u75be\u60a3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4077116391115906, "itpossible/Chinese-Mistral-7B-v0.1": 0.6487905325765783, "HuggingFaceH4/zephyr-7b-beta": 0.4994680251040403, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4179373142767413, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u809d\u662f\u751f\u6210\u5c3f\u7d20\u7684\u552f\u4e00\u5668\u5b98\uff0c\u662f\u7531\u4e8e\u809d\u7ec6\u80de\u542b\u6709____\nA. \u8c37\u6c28\u9178\u8131\u6c22\u9176\nB. \u8c37\u4e19\u8f6c\u6c28\u9176\nC. \u8c37\u8349\u8f6c\u6c28\u9176\nD. \u7cbe\u6c28\u9178\u9176\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8840\u6e05\u4e0e\u8840\u6d46\u7684\u533a\u522b\u5728\u4e8e\u8840\u6e05\u5185\u65e0____\nA. \u7ef4\u751f\u7d20\nB. \u7cd6\u7c7b\nC. \u4ee3\u8c22\u4ea7\u7269\nD. \u7ea4\u7ef4\u86cb\u767d\u539f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28496529561720413, "meta-math/MetaMath-Mistral-7B": 0.38745560485406555, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.704410880703659, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5280592663079243, "meta-llama/Meta-Llama-3-8B": 0.8015779944610822, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7402360612409338}}, {"question": "\u53ef\u76f4\u63a5\u6fc0\u6d3b\u86cb\u767d\u6fc0\u9176C\u7684\u662f____\nA. cAMP\nB. cGMP\nC. $IP_3$\nD. DAG\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5290911484236372, "itpossible/Chinese-Mistral-7B-v0.1": 0.586320347801881, "HuggingFaceH4/zephyr-7b-beta": 0.9982177381163853, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6810911196990496, "meta-llama/Meta-Llama-3-8B": 0.44667014224702756, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6887599548488148}}, {"question": "\u4e0b\u5217\u54ea\u9879\u539f\u56e0\u4e0d\u5f15\u8d77\u840e\u7f29____\nA. \u80be\u76c2\u79ef\u6c34\nB. \u6162\u6027\u809d\u6de4\u8840\nC. \u5782\u4f53\u529f\u80fd\u4f4e\u4e0b\nD. \u56db\u6c2f\u5316\u78b3\u4e2d\u6bd2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4141910258344756, "meta-math/MetaMath-Mistral-7B": 0.5104934221038552, "itpossible/Chinese-Mistral-7B-v0.1": 0.41245786313520105, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3749196223738779, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8669949497544649}}, {"question": "\u4ee5$IP_3$\u548cDAG\u4e3a\u7b2c\u4e8c\u4fe1\u4f7f\u7684\u53cc\u4fe1\u53f7\u9014\u5f84\u662f____\nA. cAMP-\u86cb\u767d\u6fc0\u9176\u9014\u5f84\nB. $Ca^{2+}$-\u78f7\u8102\u4f9d\u8d56\u6027\u86cb\u767d\u6fc0\u9176\u9014\u5f84\nC. cGMP-\u86cb\u767d\u6fc0\u9176\u9014\u5f84\nD. \u916a\u6c28\u9178\u86cb\u767d\u6fc0\u9176\u9014\u5f84\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9099932818927403, "meta-math/MetaMath-Mistral-7B": 0.9769410574050476, "itpossible/Chinese-Mistral-7B-v0.1": 0.7464090559600909, "HuggingFaceH4/zephyr-7b-beta": 0.9985050318469957, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.972910543355297, "meta-llama/Meta-Llama-3-8B": 0.9194818522914309, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9498923975422875}}, {"question": "\u4e59\u578b\u8111\u708e\u7684\u7279\u5f81\u6027\u75c5\u53d8\u662f____\nA. \u8840\u7ba1\u6dcb\u5df4\u5957\u5f62\u6210\nB. \u8f6f\u5316\u7076\u5f62\u6210\nC. \u80f6\u8d28\u7ec6\u80de\u589e\u751f\nD. \u536b\u661f\u73b0\u8c61\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6964559345261535}}, {"question": "\u9644\u777e\u7cbe\u6db2\u56ca\u80bf____\nA. \u7cbe\u5b50\u81ea\u9644\u777e\u7ba1\u6ea2\u51fa\u81f3\u5468\u56f4\u7ec4\u7ec7\u5f62\u6210\u7684\u56ca\u80bf\nB. \u777e\u4e38\u7f51\u6216\u8f93\u51fa\u5c0f\u7ba1\u6269\u5f20\u5f62\u6210\u56ca\u80bf\uff0c\u56ca\u80bf\u6db2\u4e2d\u53ef\u89c1\u7cbe\u5b50\u6216\u7cbe\u5b50\u788e\u7247\nC. \u56ca\u80bf\u4e3a\u8d28\u786c\u7684\u5706\u5f62\u5305\u5757\nD. \u56ca\u80bf\u4e0e\u5468\u56f4\u7ec4\u7ec7\u754c\u9650\u4e0d\u6e05\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6391206668851361, "meta-math/MetaMath-Mistral-7B": 0.4319475731929948, "itpossible/Chinese-Mistral-7B-v0.1": 0.8514514112925544, "HuggingFaceH4/zephyr-7b-beta": 0.9976079558353749, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7909196689841052, "meta-llama/Meta-Llama-3-8B": 0.6206149522767141, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9853690206817818}}, {"question": "\u6709\u5173\u975eST\u6bb5\u62ac\u9ad8\u5fc3\u808c\u6897\u6b7b\u7684\u6cbb\u7597\u65b9\u6848\uff0c\u4ee5\u4e0b\u54ea\u9879\u6b63\u786e____\nA. \u6eb6\u6813\u662f\u57fa\u7840\u6cbb\u7597\nB. \u4f4e\u5371\u9669\u7ec4\u4e0d\u5fc5\u4f7f\u7528\u836f\u7269\nC. \u4e2d\u5371\u9669\u7ec4\u4ee5\u963f\u53f8\u5339\u6797\u548c\u809d\u7d20\u5c24\u5176\u662f\u4f4e\u5206\u5b50\u91cf\u809d\u7d20\u6cbb\u7597\u4e3a\u4e3b\nD. \u9ad8\u5371\u9669\u7ec4\u4ee5\u4ecb\u5165\u6cbb\u7597\u4e3a\u9996\u9009\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.42975326665904984, "meta-math/MetaMath-Mistral-7B": 0.7274271780987663, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6162\u6027\u80c3\u6e83\u75a1\u6700\u5e38\u89c1\u7684\u5e76\u53d1\u75c7\u662f____\nA. \u5e7d\u95e8\u72ed\u7a84\nB. \u7a7f\u5b54\nC. \u51fa\u8840\nD. \u764c\u53d8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4308879507648792, "meta-math/MetaMath-Mistral-7B": 0.4548907353686772, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.935073524207258, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.522114572448794, "meta-llama/Meta-Llama-3-8B": 0.6248486901872962, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9760002513061031}}, {"question": "\u7537\u6027\uff0c65\u5c81\u3002\u660f\u8ff710\u5c0f\u65f6\u3002\u8840\u6c14\u5206\u6790\uff1a$pH$ 7\uff0e26\uff0c$PaCO_2$82mmHg\uff0c$PaO_2$ 45mmHg\u3002\u4e0b\u5217\u54ea\u9879\u5904\u7406\u4e0d\u9002\u5b9c____\nA. \u673a\u68b0\u901a\u6c14\nB. \u547c\u5438\u5174\u594b\u5242\nC. \u652f\u6301\u7597\u6cd5\nD. \u9ad8\u6d53\u5ea6\u7ed9\u6c27\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29727732270820134, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3689108554330874, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0e\u809d\u764c\u53d1\u75c5\u65e0\u5173\u7684\u56e0\u7d20\u662f____\nA. \u7532\u578b\u809d\u708e\nB. \u4e59\u578b\u809d\u708e\nC. \u9152\u7cbe\u6027\u809d\u786c\u5316\nD. \u574f\u6b7b\u540e\u6027\u809d\u786c\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u60a3\u8005\uff0c5\u6708\u524d\u66fe\u8fdb\u884c\u94fe\u6fc0\u9176\u6cbb\u7597\u5fc3\u808c\u6897\u6b7b\uff0c\u73b0\u51fa\u73b0\u5927\u9762\u79ef\u80ba\u8840\u6813\u6813\u585e\u75c7\uff0c\u5e94\u8be5\u5982\u4f55\u6cbb\u7597____\nA. \u7ee7\u7eed\u4f7f\u7528\u94fe\u6fc0\u9176\u6eb6\u6813\nB. \u7528\u5c3f\u6fc0\u9176\u6eb6\u6813\nC. \u4e25\u7981\u7528\u4efb\u4f55\u7684\u6eb6\u6813\u836f\nD. \u7acb\u523b\u4f7f\u7528\u8d1f\u8377\u91cf\u7684\u534e\u6cd5\u6797\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3923431263183018, "meta-math/MetaMath-Mistral-7B": 0.5778375432010247, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0d\u7b26\u5408\u75c5\u6bd2\u6027\u80ba\u708e\u63cf\u8ff0\u7684\u662f____\nA. \u75c5\u7076\u53ef\u5448\u5c0f\u53f6\u6027\u5206\u5e03\nB. \u80ba\u6ce1\u8154\u5185\u6709\u5927\u91cf\u6e17\u51fa\u7269\nC. \u53ef\u6709\u900f\u660e\u819c\u5f62\u6210\nD. \u8089\u773c\u89c2\u75c5\u53d8\u4e0d\u660e\u663e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6615534004881103}}, {"question": "\u57fa\u5e95\u7ec6\u80de\u764c\u6700\u5e38\u89c1\u7684\u597d\u53d1\u90e8\u4f4d\u662f____\nA. \u5c0f\u9634\u5507\nB. \u524d\u5ead\nC. \u9634\u8482\nD. \u5927\u9634\u5507\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.32659802886351824, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6025\u6027\u547c\u5438\u8870\u7aed\u6700\u65e9\u51fa\u73b0\u7684\u75c7\u72b6\u662f____\nA. \u53d1\u7ec0\nB. \u547c\u5438\u56f0\u96be\nC. \u7cbe\u795e\u9519\u4e71\nD. \u5fc3\u52a8\u8fc7\u901f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7217816774029284, "meta-math/MetaMath-Mistral-7B": 0.9768885324958564, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9942155208138904, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9756934782315428, "meta-llama/Meta-Llama-3-8B": 0.5109596959351621, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9822927004225082}}, {"question": "\u2161\u578b\u547c\u5438\u8870\u7aed\u4e0d\u80fd\u7ed9\u4e88\u9ad8\u6d53\u5ea6\u5438\u6c27\u7684\u539f\u56e0\u4e3b\u8981\u662f____\nA. \u4f34$CO_2$\u6f74\u7559\nB. \u8bf1\u53d1\u547c\u5438\u6027\u78b1\u4e2d\u6bd2\nC. \u964d\u4f4e\u4e86\u9888\u52a8\u8109\u4f53\u3001\u4e3b\u52a8\u8109\u4f53\u7684\u5174\u594b\u6027\nD. \u53ef\u5f15\u8d77\u6c27\u4e2d\u6bd2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2777229469001534, "meta-math/MetaMath-Mistral-7B": 0.35125369870111733, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6d0b\u5730\u9ec4\u4e2d\u6bd2\u5408\u5e76\u4f4e\u94be\u8840\u75c7\u65f6\u6613\u53d1\u751f\u7684\u5fc3\u5f8b\u5931\u5e38\u662f____\nA. \u9635\u53d1\u6027\u623f\u6027\u5fc3\u52a8\u8fc7\u901f\u4f34\u4f20\u5bfc\u963b\u6ede\nB. \u623f\u6027\u671f\u524d\u6536\u7f29\nC. \u623f\u98a4\nD. \u5ba4\u98a4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3160424181481998, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.903442816326039}}, {"question": "\u4e0b\u5217\u54ea\u9879\u4e0d\u7b26\u5408\u7cd6\u5c3f\u75c5\u916e\u75c7\u9178\u4e2d\u6bd2\u7684\u5b9e\u9a8c\u5ba4\u68c0\u67e5\u7ed3\u679c____\nA. pH\uff1c7\uff0e35\nB. \u8840\u916e\u4f53\uff1e4\uff0e8mmol\uff0fL\nC. \u8840\u7cd6\u591a\uff1e33\uff0e3mmol\uff0fL\nD. \u8840\u767d\u7ec6\u80de\u8ba1\u6570\uff1e10\u00d710^9 \uff0fL\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7537\u6027\uff0c70\u5c81\u3002\u6162\u6027\u963b\u585e\u6027\u80ba\u75c5\u53f220\u4f59\u5e74\uff0c\u795e\u5fd7\u4e0d\u6e055\u5c0f\u65f6\u3002\u4f53\u68c0\uff1a\u53d1\u7ec0\uff0c\u547c\u5438\u6d45\u4fc3\uff0c\u5fc3\u7387\uff1a120\u6b21\uff0f\u5206\uff0c\u5f8b\u9f50\uff0c\u4e24\u80ba\u95fb\u53ca\u5e72\u6e7f\u5570\u97f3\u3002\u8840\u538b75\uff0f45mmHg\u3002\u8840pH7\uff0e18\uff0c$PaCO_2$ 5mmHg\uff0c$PaO_2$ 49mmHg\u3002\u6b64\u65f6\u54ea\u9879\u6cbb\u7597\u63aa\u65bd\u4e0d\u9002\u5b9c____\nA. \u547c\u5438\u673a\u8f85\u52a9\u901a\u6c14\nB. \u7ea0\u6b63\u4f4e\u8840\u538b\nC. \u6301\u7eed\u4f4e\u6d53\u5ea6\u5438\u6c27\nD. \u547c\u5438\u5174\u594b\u5242\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5973\u6027\uff0c29\u5c81\uff0c\u56e0\u7259\u9f88\u6e17\u8840\u4f34\u4f4e\u70ed1\u5468\u5165\u9662\uff0c\u5b9e\u9a8c\u5ba4\u68c0\u67e5\u8840\u5e38\u89c4\uff1a\u767d\u7ec6\u80de11\uff0e3\u00d710^9 \uff0fL\u3001\u7ea2\u7ec6\u80de2\uff0e6\u00d710^12 \uff0fL\u3001 \u8840\u7ea2\u86cb\u767d68g\uff0fL\u3001\u8840\u5c0f\u677f30\u00d710^9 \uff0fL\uff0c\u9aa8\u9ad3\u7a7f\u523a\u7ed3\u679c\u63d0\u793a\u6025\u6027\u5355\u6838\u7ec6\u80de\u767d\u8840\u75c5(M5)\uff0c\u4ee5\u4e0b\u54ea\u4e2a\u4f53\u5f81\u6700\u5c11\u89c1____\nA. \u7259\u9f88\u80bf\u80c0\nB. \u80f8\u9aa8\u538b\u75db\nC. \u809d\u8f9f\u80bf\u5927\nD. \u5de9\u819c\u9ec4\u67d3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.34412869855849515, "HuggingFaceH4/zephyr-7b-beta": 0.6098133252908337, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7533382129899123}}, {"question": "\u65e9\u671f\u80c3\u764c\u6700\u591a\u89c1\u7684\u7c7b\u578b\u662f____\nA. \u9686\u8d77\u578b\nB. \u8868\u6d45\u578b\nC. \u51f9\u9677\u578b\nD. \u8868\u6d45\u5e73\u5766\u578b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6700\u6613\u548c\u80ba\u8f6c\u79fb\u764c\u76f8\u6df7\u6dc6\u7684\u662f____\nA. \u4e2d\u592e\u578b\u80ba\u764c\nB. \u5468\u56f4\u578b\u80ba\u764c\nC. \u5f25\u6f2b\u578b\u80ba\u764c\nD. \u5927\u7ec6\u80de\u80ba\u764c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3542800494789495, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8141509585627105}}, {"question": "\u6cbb\u7597\u7cd6\u5c3f\u75c5\u916e\u75c7\u9178\u4e2d\u6bd2\u65f6\u6700\u5e94\u6ce8\u610f\u7684\u7535\u89e3\u8d28\u7d0a\u4e71\u662f____\nA. \u4f4e\u94a0\u8840\u75c7\nB. \u4f4e\u94be\u8840\u75c7\nC. \u9ad8\u6c2f\u8840\u75c7\nD. \u9ad8\u9499\u8840\u75c7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37924132665196936, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.43857066861238536, "HuggingFaceH4/zephyr-7b-beta": 0.945072003616753, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4814833823548698, "meta-llama/Meta-Llama-3-8B": 0.7834686175882121, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7081605084666959}}, {"question": "\u7845\u5c18\u53ef\u5bfc\u81f4\u7845\u6c89\u7740\u75c5\uff0c\u5176\u4e2d\u81f4\u75c5\u529b\u6700\u5f3a\u7684\u7845\u5c18\u9897\u7c92\u76f4\u5f84\u4e3a____\nA. \uff1e5\u03bcm\nB. 4\uff5e5\u03bcm\nC. 2\uff5e3\uff0f\u03bcm\nD. 1\uff5e2\u03bcm\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "X\u7ebf\u7247\u4e0a\u6700\u6613\u4e0e\u5468\u540c\u578b\u80ba\u764c\u76f8\u6df7\u6dc6\u7684\u80ba\u7ed3\u6838\u75c5\u662f____\nA. \u7ed3\u6838\u7403\nB. \u539f\u53d1\u7efc\u5408\u5f81\nC. \u5c40\u7076\u578b\u80ba\u7ed3\u6838\nD. \u7ed3\u6838\u6027\u80f8\u819c\u708e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4606796658671746, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u98ce\u6e7f\u6027\u5fc3\u810f\u74e3\u819c\u75c5\u6700\u5e38\u53d7\u7d2f\u7684\u74e3\u819c\u662f____\nA. \u4e8c\u5c16\u74e3\nB. \u4e09\u5c16\u74e3\nC. \u80ba\u52a8\u8109\u74e3\nD. \u4e3b\u52a8\u8109\u74e3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.45766686862610395, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8306398517833614}}, {"question": "\u6025\u6027\u7c92\u7ec6\u80de\u6027\u767d\u8840\u75c5\u65f6\uff0c\u7624\u7ec6\u80de\u5728\u9aa8\u819c\u4e0b\u6d78\u6da6\uff0c\u805a\u96c6\u6210\u80bf\u5757\uff0c\u79f0\u4e3a____\nA. \u68d5\u8272\u7624\nB. \u9ec4\u8272\u7624\nC. \u7eff\u8272\u7624\nD. Wilms\u7624\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u54ea\u9879\u68c0\u67e5\u4e0d\u662f\u53cd\u6620\u6162\u6027\u6eb6\u8840\u6027\u8d2b\u8840\u65f6\u9aa8\u9ad3\u4ee3\u507f\u589e\u751f\u7684\u8bc1\u636e____\nA. \u9aa8\u9ad3\u4ee3\u507f\u589e\u751f\nB. \u672b\u68a2\u8840\u51fa\u73b0\u5e7c\u7ea2\u7ec6\u80de\nC. \u9aa8\u9ad3\u5e7c\u7ea2\u7ec6\u80de\u589e\u751f\u6d3b\u8dc3\nD. \u5916\u5468\u8840\u6d82\u7247\u53d1\u73b0\u7ea2\u7ec6\u80de\u788e\u7247\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.31685026116490644, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4619154283166679, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5421114172020054}}, {"question": "\u5bf9\u4e8e\u56fa\u4f53\u6c61\u67d3\u7269\u7684\u63a7\u5236\u89c4\u5212\u5185\u5bb9\uff0c\u4e0d\u591f\u7a81\u51fa\u7684\u662f____\u3002\nA. \u7535\u5b50\u6c61\u67d3\u7269\nB. \u751f\u6d3b\u5783\u573e\nC. \u533b\u7597\u5e9f\u7269\nD. \u5de5\u4e1a\u56fa\u4f53\u5e9f\u7269\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.31188662878965634, "meta-math/MetaMath-Mistral-7B": 0.6411773600657156, "itpossible/Chinese-Mistral-7B-v0.1": 0.4270450203246948, "HuggingFaceH4/zephyr-7b-beta": 0.8195061442814391, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8552502591492231, "meta-llama/Meta-Llama-3-8B": 0.3436615088034304, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ad6\u5411\u8bbe\u8ba1\u8bbe\u8ba1\u6807\u9ad8\u4e2d\uff0c\u5f53\u5efa\u7b51\u7269\u65e0\u8fdb\u8f66\u9053\u65f6\uff0c\u4e00\u822c\u5ba4\u5185\u5730\u576a\u6bd4\u5ba4\u5916\u5730\u576a\u9762\u9ad8\u51fa____\nA. 0.30\uff5e0.90m\nB. 0.45\uff5e0.60m\nC. 0.25\uff5e0.30m\nD. 0.25\uff5e0.35m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4010179054081059, "itpossible/Chinese-Mistral-7B-v0.1": 0.3331832353540621, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u57ce\u5e02\u603b\u4f53\u89c4\u5212\u7684\u5f3a\u5236\u6027\u5185\u5bb9\uff0c\u5728\u9632\u707e\u65b9\u9762\u6ca1\u6d89\u53ca\u7684\u707e\u5bb3\u662f____\u3002\nA. \u6d2a\u707e\nB. \u9707\u707e\nC. \u6d9d\u707e\nD. \u706b\u707e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4737435543170778, "meta-math/MetaMath-Mistral-7B": 0.9621528377047392, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.7760413616302589, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5730\u4e0b\u7535\u529b\u7f06\u4fdd\u62a4\u533a\u7684\u5bbd\u5ea6\u4e3a\u5730\u4e0b\u7535\u529b\u7535\u7f06\u7ebf\u8def\u5730\u9762\u6807\u6869\u4e24\u4fa7\u5404____\u6240\u5f62\u6210\u4e24\u5e73\u884c\u7ebf\u5185\u533a\u57df\u3002\nA. 0.5m\nB. 0.75m\nC. 1.0m\nD. 1.5m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u57ce\u5e02\u5168\u90e8\u7531\u56fd\u52a1\u9662\u516c\u5e03\u4e3a\u5386\u53f2\u6587\u5316\u540d\u57ce\u7684\u662f____\nA. \u5ef6\u5b89\u3001\u6dee\u5b89\u3001\u6cf0\u5b89\u3001\u745e\u5b89\u3001\u96c5\u5b89\nB. \u91d1\u534e\u3001\u94f6\u5ddd\u3001\u540c\u4ec1\u3001\u94c1\u5cad\u3001\u65e0\u9521\nC. \u97e9\u57ce\u3001\u804a\u57ce\u3001\u90b9\u57ce\u3001\u664b\u57ce\u3001\u5854\u57ce\nD. \u6b59\u53bf\u3001\u5bff\u53bf\u3001\u7941\u53bf\u3001\u6d5a\u53bf\u3001\u4ee3\u53bf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u6751\u5e84\u6574\u6cbb\u6280\u672f\u5bfc\u5219\u300b\u4e2d\u63d0\u51fa\uff0c\u5bf9\u4e8e\u201c\u7a7a\u5fc3\u6751\u201d\uff0c\u5728\u4f4f\u623f\u5236\u5ea6\u4e0a\u63d0\u51fa\u7684\u653f\u7b56\u662f____\u3002\nA. \u62c6\u9664\u5df2\u574d\u584c\u7684\u623f\u5c4b\nB. \u4e00\u6237\u4e00\u5b85\nC. \u8fc1\u6751\u5e76\u70b9\nD. \u5b85\u57fa\u5730\u5411\u6751\u4e2d\u5fc3\u96c6\u4e2d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.32871459371036227, "meta-math/MetaMath-Mistral-7B": 0.36078609119776345, "itpossible/Chinese-Mistral-7B-v0.1": 0.303006867405966, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44864321384958533, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4e0d\u5c5e\u4e8e\u6751\u5e84\u89c4\u5212\u7684\u5177\u4f53\u5185\u5bb9\u7684\u662f____\u3002\nA. \u793e\u4f1a\u7ecf\u6d4e\u89c4\u5212\nB. \u9053\u8def\u4ea4\u901a\u89c4\u5212\nC. \u7eff\u5316\u666f\u89c2\u89c4\u5212\nD. \u5e02\u653f\u89c4\u5212\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5c45\u4f4f\u533a\u7684\u89c4\u5212\u5e03\u5c40\u5f62\u5f0f\u7c7b\u578b\u4e2d\u4e0d\u5305\u62ec____\u3002\nA. \u5c45\u4f4f\u533a\u2014\u5c0f\u533a\u2014\u7ec4\u56e2\nB. \u5c45\u4f4f\u533a\u2014\u7ec4\u56e2\nC. \u8857\u574a\u5f0f\nD. \u8054\u5408\u5f0f\u7ec4\u56e2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8430221234258279}}, {"question": "\u9020\u6210\u57ce\u4e61\u751f\u4ea7\u529b\u7ed3\u6784\u6839\u672c\u533a\u522b\u7684\u662f____\u3002\nA. \u6587\u5316\u89c2\u5ff5\u7684\u5dee\u5f02\nB. \u751f\u4ea7\u529b\u7ed3\u6784\u7684\u5dee\u5f02\nC. \u804c\u80fd\u7684\u5dee\u5f02\nD. \u7269\u8d28\u5f62\u6001\u7684\u5dee\u5f02\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3213637558640315, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.727695456373352, "HuggingFaceH4/zephyr-7b-beta": 0.5954503482639393, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3860362730051737, "meta-llama/Meta-Llama-3-8B": 0.8102052807995092, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8769129698095329}}, {"question": "\u4ee5\u4e0b\u4e0d\u5c5e\u4e8e\u6db2\u5316\u77f3\u6cb9\u6c14\u6c14\u5316\u7ad9\u4e0e\u6df7\u6c14\u7ad9\u7684\u5e03\u7f6e\u539f\u5219\u7684\u662f____\u3002\nA. \u6db2\u5316\u77f3\u6cb9\u6c14\u6c14\u5316\u7ad9\u4e0e\u6df7\u6c14\u7ad9\u7684\u7ad9\u5740\u5e94\u9760\u8fd1\u8d1f\u8377\u533a\nB. \u7ad9\u5740\u5e94\u662f\u5730\u52bf\u5e73\u5766\u3001\u5f00\u9614\u3001\u4e0d\u6613\u79ef\u5b58\u6db2\u5316\u77f3\u6cb9\u6c14\u7684\u5730\u6bb5\nC. \u7ad9\u5740\u5e94\u4e0e\u7ad9\u5916\u5efa\u7b51\u7269\u4fdd\u6301\u89c4\u8303\u6240\u89c4\u5b9a\u7684\u9632\u706b\u95f4\u8ddd\u8981\u6c42\nD. \u4f5c\u4e3a\u673a\u52a8\u6c14\u6e90\u7684\u6df7\u6c14\u7ad9\u4e0d\u80fd\u4e0e\u6c14\u6e90\u5382\u3001\u57ce\u5e02\u7164\u6c14\u50a8\u914d\u7ad9\u5408\u8bbe\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8053735878371133, "meta-math/MetaMath-Mistral-7B": 0.8844540980350476, "itpossible/Chinese-Mistral-7B-v0.1": 0.5632763502929297, "HuggingFaceH4/zephyr-7b-beta": 0.9981296354807598, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.881434766499933, "meta-llama/Meta-Llama-3-8B": 0.618100704978697, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8796194569789942}}, {"question": "\u4e16\u754c\u4e0a\u73b0\u5b58\u6700\u9ad8\u7684\u6728\u5854\u662f\u4e2d\u56fd____\nA. \u6cb3\u5357\u767b\u5c01\u5d69\u5cb3\u5bfa\u5854\nB. \u5c71\u897f\u5e94\u53bf\u4f5b\u5bab\u5bfa\u91ca\u8fe6\u5854\nC. \u5c71\u4e1c\u6d4e\u5357\u795e\u901a\u5bfa\u56db\u95e8\u5854\nD. \u9655\u897f\u6276\u98ce\u6cd5\u95e8\u5bfa\u5854\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8546051269456595, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4799561017076586, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6038079711475693}}, {"question": "\u91c7\u7528\u4e00\u5143\u7ebf\u6027\u56de\u5f52\u7684\u65b9\u6cd5\u5206\u6790\u9884\u6d4b\u89c4\u5212\u671f\u57ce\u5e02\u4eba\u53e3\u89c4\u6a21\u7684\u4e3b\u8981\u4f9d\u636e\u662f____\u3002\nA. \u53ef\u4ee5\u51c6\u786e\u9884\u6d4b\u89c4\u5212\u8fdc\u671f\u7684\u4eba\u53e3\u6570\u91cf\nB. \u5728\u67d0\u4e00\u65f6\u95f4\u6bb5\u5185\u57ce\u5e02\u4eba\u53e3\u7684\u6570\u91cf\u4e0e\u65f6\u95f4\uff0c\u662f\u4e00\u7ec4\u76f8\u5173\u7684\u7ebf\u6027\u51fd\u6570\u5173\u7cfb\nC. \u57ce\u5e02\u4eba\u53e3\u9075\u5faa\u76f4\u7ebf\u589e\u957f\u7684\u89c4\u5f8b\nD. \u5df2\u638c\u63e1\u4e86\u5145\u8db3\u7684\u57ce\u5e02\u4eba\u53e3\u5386\u5e74\u53d8\u52a8\u7684\u8d44\u6599\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9190490655534008, "meta-math/MetaMath-Mistral-7B": 0.9911317100403598, "itpossible/Chinese-Mistral-7B-v0.1": 0.7961421808730595, "HuggingFaceH4/zephyr-7b-beta": 0.9732546816230966, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9473549567106647, "meta-llama/Meta-Llama-3-8B": 0.7772385851589835, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8954861475284769}}, {"question": "\u4e0b\u5217\u5c5e\u4e8e\u5de5\u4e1a\u56fa\u4f53\u5e9f\u7269\u7684\u4ea7\u751f\u91cf\u7684\u9884\u6d4b\u65b9\u6cd5\u7684\u662f____\nA. \u5355\u4f4d\u4ea7\u54c1\u6cd5\nB. \u767e\u5143\u4ea7\u503c\u6cd5\nC. \u4eba\u5747\u6307\u6807\u6cd5\nD. \u589e\u957f\u7387\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2909633459929373, "meta-math/MetaMath-Mistral-7B": 0.38495463460321405, "itpossible/Chinese-Mistral-7B-v0.1": 0.36260628017702756, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.457516060800056, "meta-llama/Meta-Llama-3-8B": 0.5528630957959901, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9867826957942665}}, {"question": "\u4ee5\u4e0b\u6709\u5173\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u8d44\u8d28\u7ba1\u7406\u7684\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u4e09\u4e2a\u4ee5\u4e0a\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u5408\u4f5c\u7f16\u5236\u57ce\u5e02\u89c4\u5212\u65f6\uff0c\u6709\u5173\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u5e94\u5f53\u5171\u540c\u5411\u4efb\u52a1\u6240\u5728\u5730\u76f8\u5e94\u7684\u4e3b\u7ba1\u90e8\u95e8\u5907\u6848\nB. \u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u5408\u5e76\u6216\u8005\u5206\u7acb\uff0c\u5e94\u5f53\u5728\u6279\u51c6\u4e4b\u65e5\u8d7715\u65e5\u5185\u91cd\u65b0\u7533\u8bf7\u529e\u7406\u300a\u8d44\u8d28\u8bc1\u4e66\u300b\nC. \u7533\u8bf7\u4e59\u7ea7\u3001\u4e19\u7ea7\u8d44\u8d28\u7684\uff0c\u7531\u6240\u5728\u5730\u5e02\u3001\u53bf\u4eba\u6c11\u653f\u5e9c\u57ce\u5e02\u89c4\u5212\u4e3b\u7ba1\u90e8\u95e8\u5ba1\u6279\uff0c\u6838\u53d1\u300a\u8d44\u8d28\u8bc1\u4e66\u300b\uff0c\u5e76\u62a5\u56fd\u52a1\u9662\u57ce\u5e02\u89c4\u5212\u4e3b\u7ba1\u90e8\u95e8\u5907\u6848\nD. \u4e59\u3001\u4e19\u7ea7\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u8de8\u7701\u3001\u81ea\u6cbb\u533a\u3001\u76f4\u8f96\u5e02\u8bbe\u7acb\u7684\u5206\u652f\u673a\u6784\u4e2d\uff0c\u975e\u72ec\u7acb\u6cd5\u4eba\u7684\u673a\u6784\uff0c\u4e0d\u5f97\u4ee5\u5206\u652f\u673a\u6784\u540d\u4e49\u627f\u63fd\u4e1a\u52a1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4432947163656108, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9625882613021054}}, {"question": "\u4e0b\u5217\u4e0d\u5c5e\u4e8e\u5806\u80a5\u65b9\u6cd5\u8fd0\u7528\u4e8e\u56fa\u4f53\u5783\u573e\u5904\u7406\u4f18\u70b9\u7684\u662f____\nA. \u5360\u5730\u8f83\u5c0f\nB. \u6295\u8d44\u8f83\u4f4e\nC. \u4ea7\u54c1\u53ef\u7528\u4f5c\u80a5\u6599\nD. \u65e0\u5bb3\u5316\u7a0b\u5ea6\u5f88\u9ad8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u516c\u6c11\u3001\u6cd5\u4eba\u548c\u793e\u4f1a\u56e2\u4f53\u4e3a\u4e86\u4fc3\u8fdb\u57ce\u5e02\u89c4\u5212\u6709\u6548\u3001\u5408\u7406\u5730\u5b9e\u65bd\uff0c\u4e3a\u4e86\u7ef4\u62a4\u81ea\u5df1\u7684\u5408\u6cd5\u6743\u5229\uff0c\u53ef\u4ee5\u4f9d\u6cd5\u5bf9\u57ce\u5e02\u89c4\u5212\u884c\u653f\u673a\u5173\u505a\u51fa\u7684\u5177\u4f53\u884c\u653f\u884c\u4e3a\u63d0\u51fa____\u3002\nA. \u884c\u653f\u8bc9\u8bbc\nB. \u6c11\u4e8b\u8bc9\u8bbc\nC. \u884c\u653f\u4ef2\u88c1\nD. \u7533\u8bc9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7356869216548311, "meta-llama/Meta-Llama-3-8B": 0.579334566587193, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9627475816630963}}, {"question": "\u4e0b\u5217\u54ea\u4e00\u9879\u4e0d\u662f\u57ce\u5e02\u603b\u4f53\u89c4\u5212\u4e2d\u57ce\u5e02\u53d1\u5c55\u76ee\u6807\u7684\u5185\u5bb9?____\nA. \u57ce\u5e02\u6027\u8d28\nB. \u7528\u5730\u89c4\u6a21\nC. \u4eba\u53e3\u89c4\u6a21\nD. \u57fa\u7840\u8bbe\u65bd\u548c\u516c\u5171\u8bbe\u65bd\u914d\u5957\u6c34\u5e73\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37866044072383814, "meta-math/MetaMath-Mistral-7B": 0.831484364156292, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9937926533816916, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.761171485969403, "meta-llama/Meta-Llama-3-8B": 0.41184369549978456, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5de5\u5546\u4e1a\u6d3b\u52a8\u96c6\u805a\u7684\u573a\u6240\u662f____\uff0c\u4e5f\u662f\u4ece\u4e8b\u5de5\u5546\u4e1a\u6d3b\u52a8\u7684\u4eba\u7fa4\u805a\u5c45\u7684\u573a\u6240\u3002\nA. \u4e61\u6751\nB. \u90ca\u533a\nC. \u7530\u56ed\nD. \u57ce\u5e02\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7546243990550782, "meta-math/MetaMath-Mistral-7B": 0.988287621955042, "itpossible/Chinese-Mistral-7B-v0.1": 0.7902353188841053, "HuggingFaceH4/zephyr-7b-beta": 0.9937202049406113, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9552432725787681, "meta-llama/Meta-Llama-3-8B": 0.9256137660978617, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9958629727726744}}, {"question": "\u5927\u4fee\u7684\u57ce\u5e02\u9053\u8def\u7ae3\u5de5\u540e____\u5e74\u5185\u4e0d\u5f97\u6316\u6398\uff1b\u56e0\u7279\u6b8a\u60c5\u51b5\u9700\u8981\u6316\u6398\u7684\uff0c\u987b\u7ecf\u53bf\u7ea7\u4ee5\u4e0a\u57ce\u5e02\u4eba\u6c11\u653f\u5e9c\u6279\u51c6\u3002\nA. 3\nB. 4\nC. 5\nD. 6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5085502903056711}}, {"question": "\u6d1b\u6749\u77f6\u7684\u4ea4\u901a\u53d1\u5c55\u6a21\u5f0f\u4e3a____\u3002\nA. \u4ee5\u5c0f\u6c7d\u8f66\u4e3a\u4e3b\u3001\u516c\u4ea4\u4e3a\u8f85\u7684\u4ea4\u901a\u6a21\u5f0f\nB. \u4ee5\u5c0f\u6c7d\u8f66\u4e3a\u4e3b\u4f53\u7684\u4ea4\u901a\u6a21\u5f0f\nC. \u4ee5\u8f68\u9053\u516c\u4ea4\u4e3a\u4e3b\u3001\u5c0f\u6c7d\u8f66\u548c\u5730\u9762\u516c\u4ea4\u4e3a\u8f85\u7684\u4ea4\u901a\u6a21\u5f0f\nD. \u516c\u4ea4\u4e3a\u4e3b\u3001\u5c0f\u6c7d\u8f66\u4e3a\u4e3b\u5bfc(\u516c\u4ea4\u4e0e\u5c0f\u6c7d\u8f66\u5e76\u91cd)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3220562534414596, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6cd5\u300b\u7684\u89c4\u5b9a\uff0c\u4e0b\u5217\u5173\u4e8e\u89c4\u5212\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u7684\u5185\u5bb9\u548c\u5ba1\u6279\u8868\u8ff0\u4e2d\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u672a\u7f16\u5199\u6709\u5173\u73af\u5883\u5f71\u54cd\u7684\u7bc7\u7ae0\u6216\u8005\u8bf4\u660e\u7684\u89c4\u5212\u8349\u6848\uff0c\u5ba1\u6279\u673a\u5173\u4e0d\u4e88\u5ba1\u6279\nB. \u4e13\u9879\u89c4\u5212\u7684\u7f16\u5236\u673a\u5173\u5728\u62a5\u6279\u89c4\u5212\u8349\u6848\u65f6\uff0c\u5fc5\u987b\u5c06\u73af\u5883\u5f71\u54cd\u767b\u8bb0\u8868\u4e00\u5e76\u9644\u9001\u5ba1\u6279\u673a\u5173\u5ba1\u67e5\nC. \u4e13\u9879\u89c4\u5212\u7684\u73af\u5883\u5f71\u54cd\u62a5\u544a\u4e66\u5e94\u5f53\u5305\u62ec\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u7684\u7ed3\u8bba\nD. \u89c4\u5212\u6709\u5173\u73af\u5883\u5f71\u54cd\u7684\u7bc7\u7ae0\u6216\u8005\u8bf4\u660e\uff0c\u5e94\u5f53\u5bf9\u89c4\u5212\u5b9e\u65bd\u540e\u53ef\u80fd\u9020\u6210\u7684\u73af\u5883\u5f71\u54cd\u4f5c\u51fa\u5206\u6790\u3001\u9884\u6d4b\u548c\u8bc4\u4f30\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38660562676527077, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5512254626484412, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5603370156820067, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u57ce\u5e02\u9053\u8def\u7eff\u5316\u89c4\u5212\u4e0e\u8bbe\u8ba1\u89c4\u8303\u300b\u7684\u89c4\u5b9a\uff0c\u57ce\u5e02\u9053\u8def\u7eff\u5316\u89c4\u5212\u4e0e\u8bbe\u8ba1\u7684\u57fa\u672c\u539f\u5219\u4e0d\u5305\u62ec____\u3002\nA. \u57ce\u5e02\u7eff\u5316\u6811\u6728\u4e0e\u5e02\u653f\u516c\u7528\u8bbe\u65bd\u7684\u76f8\u4e92\u4f4d\u7f6e\u5e94\u7edf\u7b79\u5b89\u6392\uff0c\u5e76\u5e94\u4fdd\u8bc1\u6811\u6728\u6709\u5fc5\u8981\u7684\u7acb\u5730\u6761\u4ef6\u4e0e\u751f\u957f\u7a7a\u95f4\nB. \u57ce\u5e02\u9053\u8def\u7eff\u5316\u5e94\u4ee5\u5730\u88ab\u690d\u7269\u4e3a\u4e3b\uff0c\u5730\u88ab\u690d\u7269\u3001\u4e54\u6728\u3001\u704c\u6728\u76f8\u7ed3\u5408\uff0c\u4e0d\u5f97\u88f8\u9732\u571f\u58e4\nC. \u4fee\u5efa\u57ce\u5e02\u9053\u8def\u65f6\uff0c\u5b9c\u4fdd\u7559\u6709\u4ef7\u503c\u7684\u539f\u6709\u6811\u6728\uff0c\u5bf9\u53e4\u6811\u540d\u6728\u5e94\u4e88\u4ee5\u4fdd\u62a4\nD. \u57ce\u5e02\u9053\u8def\u7eff\u5316\u5e94\u7b26\u5408\u8f66\u884c\u89c6\u7ebf\u548c\u884c\u8f66\u51c0\u7a7a\u8981\u6c42\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u5386\u53f2\u6587\u5316\u540d\u57ce\u540d\u9547\u540d\u6751\u4fdd\u62a4\u6761\u4f8b\u300b\uff0c\u4fdd\u62a4\u89c4\u5212\u5e94\u5f53\u81ea\u5386\u53f2\u6587\u5316\u540d\u57ce\u3001\u540d\u9547\u3001\u540d\u6751\u6279\u51c6\u516c\u5e03\u4e4b\u65e5\u8d77____\u5e74\u5185\u7f16\u5236\u5b8c\u6210\u3002\nA. \u534a\nB. 1\nC. 2\nD. 3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5414437969613116, "itpossible/Chinese-Mistral-7B-v0.1": 0.33065623127838456, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34565770216277425, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6709\u5173\u6cd5\u5f8b\u6548\u529b\u9009\u9879\u4e2d\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u5728\u4e00\u5b9a\u4e3b\u4f53\u5236\u5b9a\u7684\u6cd5\u5f8b\u89c4\u8303\u4e2d\uff0c\u6309\u7167\u7279\u5b9a\u7684\u3001\u66f4\u4e3a\u4e25\u683c\u7684\u7a0b\u5e8f\u5236\u5b9a\u7684\u6cd5\u5f8b\u89c4\u8303\uff0c\u5176\u6548\u529b\u7b49\u7ea7\u9ad8\u4e8e\u6309\u7167\u666e\u901a\u7a0b\u5e8f\u5236\u5b9a\u7684\u6cd5\u5f8b\u89c4\u8303\nB. \u5f53\u540c\u4e00\u5236\u5b9a\u673a\u5173\u6309\u7167\u76f8\u540c\u7a0b\u5e8f\u5c31\u540c\u4e00\u9886\u57df\u95ee\u9898\u5236\u5b9a\u4e86\u4e24\u4e2a\u4ee5\u4e0a\u6cd5\u5f8b\u89c4\u8303\u65f6\uff0c\u540e\u6765\u6cd5\u5f8b\u89c4\u8303\u7684\u6548\u529b\u9ad8\u4e8e\u5148\u524d\u5236\u5b9a\u7684\u6cd5\u5f8b\u89c4\u8303\nC. \u540c\u4e00\u4e3b\u4f53\u5728\u67d0\u9886\u57df\u65e2\u6709\u4e00\u822c\u6027\u7acb\u6cd5\u53c8\u6709\u7279\u6b8a\u7acb\u6cd5\u65f6\uff0c\u7279\u6b8a\u7acb\u6cd5\u901a\u5e38\u4f18\u4e8e\u4e00\u822c\u6027\u7acb\u6cd5\nD. \u56fd\u5bb6\u673a\u5173\u6388\u6743\u4e0b\u7ea7\u56fd\u5bb6\u673a\u5173\u5236\u5b9a\u7684\u6240\u6709\u7684\u6cd5\u5f8b\u3001\u6cd5\u89c4\uff0c\u5176\u5728\u6548\u529b\u4e0a\u7b49\u540c\u4e8e\u6388\u6743\u673a\u5173\u81ea\u5df1\u5236\u5b9a\u7684\u6cd5\u5f8b\u3001\u6cd5\u89c4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6723628161572658, "meta-math/MetaMath-Mistral-7B": 0.6235778107920359, "itpossible/Chinese-Mistral-7B-v0.1": 0.484420955398817, "HuggingFaceH4/zephyr-7b-beta": 0.9951101887558347, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.661818945115804, "meta-llama/Meta-Llama-3-8B": 0.41181127447724386, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6414079180913689}}, {"question": "\u57ce\u5e02\u516c\u5171\u4ea4\u901a\u7cfb\u7edf\u7684\u6838\u5fc3\u8bbe\u65bd\u662f____\u3002\nA. \u516c\u4ea4\u6362\u4e58\u67a2\u7ebd\nB. \u57ce\u5e02\u5404\u7ea7\u516c\u5171\u4e2d\u5fc3\nC. \u5e02\u7ea7\u516c\u4ea4\u5e72\u7ebf\nD. \u57ce\u5e02\u5bf9\u5916\u5ba2\u8fd0\u4ea4\u901a\u67a2\u7ebd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.47441372871853227, "itpossible/Chinese-Mistral-7B-v0.1": 0.33544561004293627, "HuggingFaceH4/zephyr-7b-beta": 0.9975309597818599, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3248694388439253, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u57ce\u5e02\u6297\u9707\u9632\u707e\u89c4\u5212\u7ba1\u7406\u89c4\u5b9a\u300b\uff0c\u4e0b\u5217\u5173\u4e8e\u57ce\u5e02\u6297\u9707\u9632\u707e\u89c4\u5212\u7f16\u5236\u8981\u6c42\u7684\u8868\u8ff0\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u57ce\u5e02\u6297\u9707\u9632\u707e\u89c4\u5212\u4e2d\u7684\u6297\u9707\u8bbe\u9632\u6807\u51c6\u3001\u5efa\u8bbe\u7528\u5730\u8bc4\u4ef7\u4e0e\u8981\u6c42\u3001\u6297\u9707\u9632\u707e\u63aa\u65bd\u5e94\u5f53\u5217\u4e3a\u57ce\u5e02\u603b\u4f53\u89c4\u5212\u7684\u5f3a\u5236\u6027\u5185\u5bb9\uff0c\u4f5c\u4e3a\u7f16\u5236\u57ce\u5e02\u8be6\u7ec6\u89c4\u5212\u7684\u4f9d\u636e\nB. \u57ce\u5e02\u6297\u9707\u9632\u707e\u89c4\u5212\u7684\u89c4\u5212\u8303\u56f4\u5e94\u5f53\u4e0e\u57ce\u5e02\u603b\u4f53\u89c4\u5212\u76f8\u4e00\u81f4\uff0c\u4f46\u5176\u5e94\u5728\u57ce\u5e02\u603b\u4f53\u89c4\u5212\u5b9e\u65bd\u4e4b\u540e\u8fdb\u884c\nC. \u57ce\u5e02\u6297\u9707\u9632\u707e\u89c4\u5212\u5e94\u5f53\u6309\u7167\u57ce\u5e02\u89c4\u6a21\u3001\u91cd\u8981\u6027\u548c\u6297\u9707\u9632\u707e\u7684\u8981\u6c42\uff0c\u5206\u4e3a\u7532\u3001\u4e59\u3001\u4e19\u4e09\u79cd\u6a21\u5f0f\nD. \u4f4d\u4e8e\u5730\u9707\u57fa\u672c\u70c8\u5ea6\u4e03\u5ea6\u53ca\u4e03\u5ea6\u4ee5\u4e0a\u5730\u533a\u7684\u5927\u57ce\u5e02\u5e94\u6309\u7167\u7532\u7c7b\u6a21\u5f0f\u7f16\u5236\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.46210931473548955, "meta-math/MetaMath-Mistral-7B": 0.6236103808077632, "itpossible/Chinese-Mistral-7B-v0.1": 0.7358913517707323, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6459058463183655, "meta-llama/Meta-Llama-3-8B": 0.6731278233003863, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8843324517050303}}, {"question": "\u6e2f\u53e3\u5cb8\u7ebf\u5206\u914d\u539f\u5219\u662f____\u3002\nA. \u4e3b\u8981\u8003\u8651\u4e0e\u57ce\u5e02\u9053\u8def\u8854\u63a5\nB. \u201c\u6df1\u6c34\u6df1\u7528\u3001\u6d45\u6c34\u6d45\u7528\u3001\u907f\u514d\u5e72\u6270\u3001\u5404\u5f97\u5176\u6240\u201d\nC. \u5ba2\u8fd0\u6e2f\u4f4d\u4e8e\u8d27\u8fd0\u6e2f\u7684\u4e0a\u98ce\u65b9\u5411\nD. \u7efc\u5408\u8003\u8651\u8239\u8236\u822a\u884c\u3001\u8d27\u7269\u88c5\u5378\u3001\u5e93\u573a\u50a8\u5b58\u53ca\u540e\u65b9\u96c6\u758f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.9243517708052742, "HuggingFaceH4/zephyr-7b-beta": 0.7473338176845494, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8175216713578637, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u7701\u7ea7\u56fd\u571f\u7a7a\u95f4\u89c4\u5212\u7f16\u5236\u6307\u5357(\u8bd5\u884c)\u300b\uff0c\u4ee5\u57ce\u9547\u5efa\u8bbe\u3001\u519c\u4e1a\u751f\u4ea7\u548c\u5de5\u4e1a\u751f\u4ea7\u7b49\u4e3a\u4e3b\u7684\u56fd\u571f\u7a7a\u95f4\u5f00\u53d1\u6d3b\u52a8\u662f\u6307____\nA. \u56fd\u571f\u7a7a\u95f4\u5f00\u53d1\nB. \u56fd\u571f\u7a7a\u95f4\u5229\u7528\nC. \u56fd\u571f\u7a7a\u95f4\u89c4\u5212\nD. \u56fd\u571f\u7a7a\u95f4\u4fdd\u62a4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5457764908884842, "meta-math/MetaMath-Mistral-7B": 0.6167399212609026, "itpossible/Chinese-Mistral-7B-v0.1": 0.4976938119561966, "HuggingFaceH4/zephyr-7b-beta": 0.9555456185829823, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5906121651176459, "meta-llama/Meta-Llama-3-8B": 0.6527204642503367, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.649190306686934}}, {"question": "\u4e0b\u5217\u4e0d\u7b26\u5408\u300a\u4eba\u6c11\u9632\u7a7a\u6cd5\u300b\u89c4\u5b9a\u7684\u662f____\nA. \u57ce\u5e02\u662f\u4eba\u6c11\u9632\u7a7a\u7684\u91cd\u70b9\nB. \u56fd\u5bb6\u5bf9\u57ce\u5e02\u5b9e\u884c\u5206\u7c7b\u9632\u62a4\nC. \u57ce\u5e02\u9632\u62a4\u7c7b\u522b\u3001\u9632\u62a4\u6807\u51c6\u7531\u4e2d\u592e\u519b\u4e8b\u59d4\u5458\u4f1a\u89c4\u5b9a\nD. \u57ce\u5e02\u4eba\u6c11\u653f\u5e9c\u5e94\u5f53\u5236\u5b9a\u9632\u7a7a\u88ad\u65b9\u6848\u53ca\u5b9e\u65bd\u8ba1\u5212\uff0c\u5fc5\u8981\u65f6\u53ef\u4ee5\u7ec4\u7ec7\u6f14\u4e60\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3931471463865646, "meta-math/MetaMath-Mistral-7B": 0.6485356509130065, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.48222250188488086, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5731662979611333, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6693882806489543}}, {"question": "\u5728\u57ce\u5e02\u89c4\u5212\u5206\u6790\u4e2d\uff0c\u4e0b\u5217\u7528\u6765\u53cd\u6620\u6570\u636e\u79bb\u6563\u7a0b\u5ea6\u7684\u662f____\nA. \u5e73\u5747\u6570\nB. \u4f17\u6570\nC. \u6807\u51c6\u5dee\nD. \u9891\u6570\u5206\u5e03\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.8471275110476544, "itpossible/Chinese-Mistral-7B-v0.1": 0.9488892772320916, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.9590912436476109, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9912564164647956}}, {"question": "\u57ce\u5e02\u4ea4\u901a\u8c03\u67e5\u7684\u76ee\u7684\u662f____\u3002\nA. \u8fdb\u884c\u57ce\u5e02\u4ea4\u901a\u89c4\u5212\u3001\u57ce\u5e02\u9053\u8def\u7cfb\u7edf\u89c4\u5212\u548c\u57ce\u5e02\u9053\u8def\u8bbe\u8ba1\u7684\u57fa\u7840\u5de5\u4f5c\nB. \u6536\u96c6\u57ce\u5e02\u516c\u5171\u4ea4\u901a\u5ba2\u8fd0\u603b\u91cf\u3001\u8d27\u8fd0\u603b\u91cf\uff0c\u5bf9\u5916\u4ea4\u901a\u5ba2\u3001\u8d27\u8fd0\u603b\u91cf\u7b49\u8fd0\u8f93\u73b0\u72b6\u4e0e\u53d1\u5c55\u8d44\u6599\nC. \u6839\u636e\u8c03\u67e5\u7684\u8d44\u6599\uff0c\u5206\u6790\u57ce\u5e02\u8f66\u8f86\u4ee5\u53ca\u5ba2\u3001\u8d27\u8fd0\u91cf\u7684\u589e\u957f\u7279\u70b9\u548c\u89c4\u5f8b\nD. \u6478\u6e05\u57ce\u5e02\u9053\u8def\u4e0a\u7684\u4ea4\u901a\u72b6\u51b5\uff0c\u57ce\u5e02\u4ea4\u901a\u7684\u4ea7\u751f\u3001\u5206\u5e03\u3001\u8fd0\u884c\u89c4\u5f8b\u4ee5\u53ca\u73b0\u72b6\u5b58\u5728\u7684\u4e3b\u8981\u95ee\u9898\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.705790233515356, "meta-math/MetaMath-Mistral-7B": 0.8724698803950027, "itpossible/Chinese-Mistral-7B-v0.1": 0.40880391239692143, "HuggingFaceH4/zephyr-7b-beta": 0.9935099773978587, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5136768193831663, "meta-llama/Meta-Llama-3-8B": 0.4180371707677268, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u4ee5\u6ee1\u8db3\u4ea4\u901a\u8fd0\u8f93\u7684\u8981\u6c42\u4e3a\u4e3b\u8981\u529f\u80fd\u5e76\u627f\u62c5\u57ce\u5e02\u4e3b\u8981\u7684\u4ea4\u901a\u91cf\u53ca\u4e0e\u5bf9\u5916\u4ea4\u901a\u8054\u7cfb\u7684\u9053\u8def\u662f____\u3002\nA. \u751f\u6d3b\u6027\u9053\u8def\nB. \u4ea4\u901a\u6027\u9053\u8def\nC. \u4e3b\u5e72\u8def\nD. \u5feb\u901f\u8def\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6428940477401015, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6067616152122792, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5527743507206179}}, {"question": "\u5efa\u8bbe\u5355\u4f4d\u5e94\u5f53\u6309\u7167\u89c4\u5212\u6761\u4ef6\u8fdb\u884c\u5efa\u8bbe\uff1b\u786e\u9700\u53d8\u66f4\u7684\uff0c\u5fc5\u987b\u5411____\u63d0\u51fa\u7533\u8bf7\u3002\nA. \u57ce\u5e02\u3001\u53bf\u4eba\u6c11\u653f\u5e9c\u571f\u5730\u4e3b\u7ba1\u90e8\u95e8\nB. \u57ce\u5e02\u3001\u53bf\u4eba\u6c11\u653f\u5e9c\u56fd\u571f\u8d44\u6e90\u90e8\u95e8\nC. \u57ce\u5e02\u3001\u53bf\u4eba\u6c11\u653f\u5e9c\u5efa\u8bbe\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\nD. \u57ce\u5e02\u3001\u53bf\u4eba\u6c11\u653f\u5e9c\u57ce\u4e61\u89c4\u5212\u4e3b\u7ba1\u90e8\u95e8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4914398248769956, "meta-math/MetaMath-Mistral-7B": 0.6683754035326355, "itpossible/Chinese-Mistral-7B-v0.1": 0.655234800130626, "HuggingFaceH4/zephyr-7b-beta": 0.9970922711885241, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49607638233654094, "meta-llama/Meta-Llama-3-8B": 0.8383749405950683, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9783514387683785}}, {"question": "\u5728\u57ce\u5e02\u8be6\u7ec6\u89c4\u5212\u9636\u6bb5\u9884\u6d4b\u7528\u7535\u8d1f\u8377\uff0c\u4e00\u822c\u91c7\u7528\u4e0b\u5217\u54ea\u79cd\u65b9\u6cd5?____\nA. \u4eba\u5747\u7efc\u5408\u7528\u7535\u91cf\u6307\u6807\u6cd5\nB. \u5355\u4f4d\u5efa\u8bbe\u7528\u5730\u8d1f\u8377\u6307\u6807\u6cd5\nC. \u5355\u4f4d\u5efa\u7b51\u9762\u79ef\u8d1f\u8377\u6307\u6807\u6cd5\nD. \u7535\u529b\u5f39\u6027\u7cfb\u6570\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8337732421639216, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u89c4\u5212\u5b9e\u65bd\u8fc7\u7a0b\u4e2d\u7531\u57ce\u4e61\u89c4\u5212\u4e3b\u7ba1\u90e8\u95e8\u6838\u53d1\u7684\u8bc1\u4e66\u4e0d\u5305\u62ec____\u3002\nA. \u5efa\u8bbe\u7528\u5730\u89c4\u5212\u8bb8\u53ef\u8bc1\nB. \u5efa\u8bbe\u5de5\u7a0b\u89c4\u5212\u8bb8\u53ef\u8bc1\nC. \u4e61\u6751\u5efa\u8bbe\u89c4\u5212\u8bb8\u53ef\u8bc1\nD. \u5efa\u8bbe\u5de5\u7a0b\u65bd\u5de5\u8bb8\u53ef\u8bc1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7576981244786177, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9057664514617597}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u5efa\u7b51\u4e0e\u7b49\u9ad8\u7ebf\u4e4b\u95f4\u5173\u7cfb\u7684\u8868\u8ff0\uff0c\u9519\u8bef\u7684\u662f____\nA. \u5efa\u7b51\u4e0e\u7b49\u9ad8\u7ebf\u5e73\u884c\nB. \u5efa\u7b51\u4e0e\u7b49\u9ad8\u7ebf\u5782\u76f4\nC. \u5efa\u7b51\u4e0e\u7b49\u9ad8\u7ebf\u91cd\u5408\nD. \u5efa\u7b51\u4e0e\u7b49\u9ad8\u7ebf\u659c\u4ea4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.50564134944733, "meta-math/MetaMath-Mistral-7B": 0.8747986915530968, "itpossible/Chinese-Mistral-7B-v0.1": 0.4167500334361728, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7751032735677242, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f9d\u636e\u300a\u57ce\u5e02\u7528\u5730\u5206\u7c7b\u4e0e\u89c4\u5212\u5efa\u8bbe\u7528\u5730\u6807\u51c6\u300b\uff0c\u5176\u89c4\u5212\u4eba\u5747\u516c\u5171\u7ba1\u7406\u4e0e\u516c\u5171\u670d\u52a1\u7528\u5730\u9762\u79ef\u6307\u6807\u4e0d\u5e94\u5c11\u4e8e____\u3002\nA. 5.0m^2/\u4eba\nB. 5.5m^2/\u4eba\nC. 6.0m^2/\u4eba\nD. 6.5m^2/\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u57ce\u5e02\u4f9b\u70ed\u4e00\u7ea7\u7ba1\u7f51\u5b9c\u91c7\u7528____\u3002\nA. \u95ed\u5f0f\nB. \u5f00\u5f0f\nC. \u5f00\u5f0f\u53cc\u7ba1\u5236\nD. \u95ed\u5f0f\u5355\u7ba1\u5236\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4097932893567426, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31283638571410965, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6751\u5e84\u89c4\u5212\u7684\u8868\u8ff0\uff0c\u54ea\u9879\u662f\u9519\u8bef\u7684?____\nA. \u5e94\u4ee5\u884c\u653f\u6751\u4e3a\u5355\u4f4d\nB. \u5e94\u5411\u6751\u6c11\u516c\u793a\nC. \u65b9\u6848\u7531\u53bf\u7ea7\u57ce\u4e61\u89c4\u5212\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u7ec4\u7ec7\u4e13\u5bb6\u548c\u76f8\u5173\u90e8\u95e8\u8fdb\u884c\u6280\u672f\u5ba1\u67e5\nD. \u6210\u679c\u7531\u6751\u59d4\u4f1a\u62a5\u53bf\u7ea7\u4eba\u6c11\u653f\u5e9c\u5ba1\u6279\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.476045154509653, "meta-math/MetaMath-Mistral-7B": 0.42400429803828177, "itpossible/Chinese-Mistral-7B-v0.1": 0.404639961229125, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.33767879625406966, "meta-llama/Meta-Llama-3-8B": 0.3454901351726419, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.368158584445395}}, {"question": "\u6839\u636e\u300a\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u8d44\u8d28\u7ba1\u7406\u89c4\u5b9a\u300b\uff0c\u4e0b\u5217\u5173\u4e8e\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u8d44\u8d28\u76d1\u7763\u7ba1\u7406\u7684\u8868\u8ff0\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u63d0\u4ea4\u7684\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u6210\u679c\uff0c\u5e94\u5f53\u5728\u6587\u4ef6\u6249\u9875\u6ce8\u660e\u5355\u4f4d\u8d44\u8d28\u7b49\u7ea7\u548c\u8bc1\u4e66\u7f16\u53f7\nB. \u7981\u6b62\u65e0\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u7684\u673a\u6784\u5bf9\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u5b9e\u884c\u8d44\u8d28\u5e74\u68c0\u5236\u5ea6\nC. \u53d1\u8bc1\u90e8\u95e8\u6216\u5176\u59d4\u6258\u7684\u673a\u6784\u5bf9\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u5b9e\u884c\u8d44\u8d28\u5e74\u68c0\u5236\u5ea6\nD. \u7532\u3001\u4e59\u7ea7\u57ce\u5e02\u89c4\u5212\u7f16\u5236\u5355\u4f4d\u8de8\u7701\u3001\u81ea\u6cbb\u533a\u3001\u76f4\u8f96\u5e02\u627f\u62c5\u89c4\u5212\u7f16\u5236\u4efb\u52a1\u65f6\uff0c\u672a\u5411\u5176\u4eba\u6c11\u653f\u5e9c\u57ce\u5e02\u89c4\u5212\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u5907\u6848\u7684\uff0c\u7531\u8be5\u4eba\u6c11\u653f\u5e9c\u57ce\u5e02\u89c4\u5212\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u7ed9\u4e88\u8b66\u544a\uff0c\u8d23\u4ee4\u5176\u8865\u529e\u5907\u6848\u624b\u7eed\uff0c\u5e76\u59041\u4e07\u5143\u4ee5\u4e0a5\u4e07\u5143\u4ee5\u4e0b\u7684\u7f5a\u6b3e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ee5\u4e0b\u5bf9\u57ce\u5e02\u6240\u5177\u6709\u7684\u57fa\u672c\u7279\u5f81\u7684\u6982\u62ec\uff0c\u8868\u8ff0\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u57ce\u5e02\u7684\u53d1\u5c55\u52a8\u6001\u662f\u53d8\u5316\u548c\u591a\u6837\u7684\nB. \u57ce\u5e02\u7684\u6982\u5ff5\u662f\u76f8\u5bf9\u5b58\u5728\u7684\nC. \u4ee5\u8981\u7d20\u805a\u96c6\u4e3a\u57fa\u672c\u7279\u5f81\nD. \u4e0d\u5177\u6709\u7cfb\u7edf\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6829880064292477, "meta-math/MetaMath-Mistral-7B": 0.820320019693847, "itpossible/Chinese-Mistral-7B-v0.1": 0.6670183978721118, "HuggingFaceH4/zephyr-7b-beta": 0.998877158227107, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7067729233857879, "meta-llama/Meta-Llama-3-8B": 0.9165360140988504, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u7b26\u5408\u6838\u7535\u5382\u9009\u5740\u8981\u6c42\u7684\u662f____\nA. \u4fbf\u4e8e\u62e6\u6cb3\u7b51\u575d\u7684\u6cb3\u6d41\u72ed\u7a84\u5904\u6216\u6c34\u5e93\u6c34\u6d41\u4e0b\u6e38\u5904\nB. \u7535\u5382\u94c1\u8def\u4e13\u7528\u7ebf\u9009\u7ebf\u8981\u5c3d\u91cf\u51cf\u5c11\u5bf9\u56fd\u5bb6\u5e72\u7ebf\u901a\u8fc7\u80fd\u529b\u7684\u5f71\u54cd\nC. \u9760\u8fd1\u8d1f\u8377\u4e2d\u5fc3\uff0c\u4ee5\u51cf\u5c11\u8f93\u7535\u8d39\u7528\nD. \u5de5\u7a0b\u5730\u8d28\u6761\u4ef6\u826f\u597d\uff0c\u571f\u5730\u8010\u529b\u9ad8\uff0c\u975e\u5730\u8d28\u65ad\u88c2\u5e26\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7279162704954131}}, {"question": "____\u662f\u5efa\u7acb\u57ce\u5e02\u827a\u672f\u9aa8\u67b6\u548c\u7ec4\u7ec7\u57ce\u5e02\u7a7a\u95f4\u7684\u91cd\u8981\u624b\u6bb5\u4e4b\u4e00\uff0c\u5b83\u53ef\u4ee5\u628a\u57ce\u5e02\u7a7a\u95f4\u7ec4\u7ec7\u6210\u4e00\u4e2a\u6709\u79e9\u5e8f\u3001\u6709\u97f5\u5f8b\u7684\u6574\u4f53\u3002\nA. \u57ce\u5e02\u7eff\u5316\nB. \u57ce\u5e02\u6c34\u9762\nC. \u57ce\u5e02\u5236\u9ad8\u70b9\nD. \u57ce\u5e02\u8f74\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8701500905687103, "meta-math/MetaMath-Mistral-7B": 0.9567642352530698, "itpossible/Chinese-Mistral-7B-v0.1": 0.8861037129103669, "HuggingFaceH4/zephyr-7b-beta": 0.9998037384477363, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8620426238323946, "meta-llama/Meta-Llama-3-8B": 0.9055250264330427, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.989064682517598}}, {"question": "\u4e3a\u4e86\u5b9a\u91cf\u5206\u6790\u91c7\u53d6\u67d0\u9879\u63aa\u65bd\u5bf9\u4e8e\u51cf\u5c11\u57ce\u5e02\u6c61\u67d3\u7684\u6548\u679c\uff0c\u6240\u5f00\u53d1\u7684\u7cfb\u7edf\u5c5e\u4e8e____\nA. \u51b3\u7b56\u652f\u6301\u7cfb\u7edf\nB. \u4e8b\u52a1\u7ba1\u7406\u7cfb\u7edf\nC. \u7ba1\u7406\u4fe1\u606f\u7cfb\u7edf\nD. \u4e13\u5bb6\u7cfb\u7edf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8ba1\u7b97\u9053\u8def\u7f51\u7684\u5bc6\u5ea6\uff0c\u5206\u6790\u7ba1\u7ebf\u7a7f\u8d8a\u5730\u5757\u7684\u95ee\u9898\uff0c\u53ef\u4ee5\u91c7\u7528\u77e2\u91cf\u53e0\u5408\u7684____\u7684\u53e0\u5408\u3002\nA. \u70b9\u548c\u9762\nB. \u7ebf\u548c\u9762\nC. \u9762\u548c\u9762\nD. \u70b9\u548c\u7ebf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5423436874778066, "HuggingFaceH4/zephyr-7b-beta": 0.9058926751284736, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7715117746857393, "meta-llama/Meta-Llama-3-8B": 0.38109590680712047, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.706584294614925}}, {"question": "\u6807\u5fd7\u7740\u6b27\u6d32\u8fdb\u5165\u5c01\u5efa\u793e\u4f1a\u7684\u4e2d\u4e16\u7eaa\u7684\u662f____\u3002\nA. \u5965\u5308\u5e1d\u56fd\u7684\u706d\u4ea1\nB. \u53e4\u5e0c\u814a\u7684\u706d\u4ea1\nC. \u6ce2\u65af\u5e1d\u56fd\u7684\u706d\u4ea1\nD. \u7f57\u9a6c\u5e1d\u56fd\u7684\u706d\u4ea1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8903078823637589, "meta-math/MetaMath-Mistral-7B": 0.8428216366187673, "itpossible/Chinese-Mistral-7B-v0.1": 0.5602456663271304, "HuggingFaceH4/zephyr-7b-beta": 0.9994509142301004, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8889098144270683, "meta-llama/Meta-Llama-3-8B": 0.8778650322885964, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u7a0e\u6cd5\u57fa\u672c\u539f\u5219\u7684\u8868\u8ff0\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u7a0e\u6536\u6cd5\u5b9a\u539f\u5219\u5305\u62ec\u7a0e\u6536\u8981\u4ef6\u6cd5\u5b9a\u539f\u5219\u548c\u7a0e\u52a1\u5408\u6cd5\u6027\u539f\u5219\nB. \u7a0e\u6536\u516c\u5e73\u539f\u5219\u6e90\u4e8e\u6cd5\u5f8b\u4e0a\u7684\u5e73\u7b49\u6027\u539f\u5219\nC. \u7a0e\u6536\u6548\u7387\u539f\u5219\u5305\u542b\u7ecf\u6d4e\u6548\u7387\u548c\u884c\u653f\u6548\u7387\u4e24\u4e2a\u65b9\u9762\nD. \u7a0e\u52a1\u673a\u5173\u6309\u6cd5\u5b9a\u7a0b\u5e8f\u4f9d\u6cd5\u5f81\u7a0e\uff0c\u53ef\u4ee5\u81ea\u7531\u505a\u51fa\u51cf\u5f81\u3001\u505c\u5f81\u6216\u514d\u5f81\u7a0e\u6b3e\u7684\u51b3\u5b9a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8849823206116187, "meta-math/MetaMath-Mistral-7B": 0.9430087250764244, "itpossible/Chinese-Mistral-7B-v0.1": 0.8320303331844887, "HuggingFaceH4/zephyr-7b-beta": 0.9966943101052675, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9700547176040429, "meta-llama/Meta-Llama-3-8B": 0.8086625453048681, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8575666165964256}}, {"question": "\u7532\u516c\u53f8\u662f\u56fd\u5185\u4e00\u5bb6\u9886\u5148\u7684\u65b0\u5a92\u4f53\u3001\u901a\u4fe1\u53ca\u79fb\u52a8\u589e\u503c\u670d\u52a1\u516c\u53f8\uff0c\u7531\u4e8e\u906d\u53d7\u4e16\u754c\u91d1\u878d\u5371\u673a\uff0c\u7532\u516c\u53f8\u7ecf\u6d4e\u5229\u6da6\u4e25\u91cd\u4e0b\u6ed1\uff0c\u7ecf\u8425\u9762\u4e34\u56f0\u5883\uff0c\u4f46\u4e3a\u4e86\u7a33\u5b9a\u804c\u5de5\u961f\u4f0d\uff0c\u516c\u53f8\u5e76\u672a\u8fdb\u884c\u88c1\u5458\uff0c\u800c\u662f\u5b9e\u884c\u9ad8\u5c42\u7ba1\u7406\u4eba\u5458\u51cf\u85aa\u63aa\u65bd\u3002\u7532\u516c\u53f8\u6b64\u4e3e\u91c7\u7528\u7684\u6536\u7f29\u6218\u7565\u65b9\u5f0f\u662f____\u3002\nA. \u8f6c\u5411\u6218\u7565\nB. \u653e\u5f03\u6218\u7565\nC. \u7d27\u7f29\u4e0e\u96c6\u4e2d\u6218\u7565\nD. \u7a33\u5b9a\u6218\u7565\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5690243741662157, "meta-math/MetaMath-Mistral-7B": 0.8924846544471211, "itpossible/Chinese-Mistral-7B-v0.1": 0.5011174645119835, "HuggingFaceH4/zephyr-7b-beta": 0.9739577956247212, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.92151474568528, "meta-llama/Meta-Llama-3-8B": 0.6198310913920404, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6456267569299599}}, {"question": "\u6839\u636e\u6211\u56fd\u300a\u5370\u82b1\u7a0e\u6682\u884c\u6761\u4f8b\u300b\u7684\u89c4\u5b9a\uff0c\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u5c5e\u4e8e\u5370\u82b1\u7a0e\u7684\u7eb3\u7a0e\u4eba\u7684\u662f____\u3002\nA. \u5408\u540c\u7684\u8bc1\u4eba\nB. \u5408\u540c\u7684\u62c5\u4fdd\u4eba\nC. \u5408\u540c\u7684\u9274\u5b9a\u4eba\nD. \u5408\u540c\u7684\u5f53\u4e8b\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4462759099580012, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6691964421484518, "HuggingFaceH4/zephyr-7b-beta": 0.89011019445542, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6061547765489288, "meta-llama/Meta-Llama-3-8B": 0.8675502068382132, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9152059734115957}}, {"question": "\u7a0e\u52a1\u884c\u653f\u590d\u8bae\u7684\u7533\u8bf7\u4eba\u53ef\u4ee5\u5728\u5f97\u77e5\u7a0e\u52a1\u673a\u5173\u4f5c\u51fa\u5177\u4f53\u884c\u653f\u884c\u4e3a\u4e4b\u65e5\u8d77____\u65e5\u5185\u63d0\u51fa\u884c\u653f\u590d\u8bae\u7533\u8bf7\u3002\nA. 60\nB. 30\nC. 7\nD. 3\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8377106625515479, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.636591480009827, "meta-llama/Meta-Llama-3-8B": 0.3035988665653362, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u6218\u7565\u7ba1\u7406\u8868\u8ff0\u9519\u8bef\u7684\u662f____\u3002\nA. \u662f\u4e00\u4e2a\u5faa\u73af\u5f80\u590d\u7684\u8fc7\u7a0b\nB. \u9700\u8981\u4fee\u6b63\u539f\u6765\u7684\u5206\u6790\u3001\u9009\u62e9\u4e0e\u5b9e\u65bd\u5de5\u4f5c\nC. \u662f\u4e00\u6b21\u6027\u7684\u5de5\u4f5c\nD. \u8981\u4e0d\u65ad\u76d1\u63a7\u548c\u8bc4\u4ef7\u6218\u7565\u7684\u5b9e\u65bd\u8fc7\u7a0b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.9099932812824967, "meta-math/MetaMath-Mistral-7B": 0.989623544049059, "itpossible/Chinese-Mistral-7B-v0.1": 0.9122856202516312, "HuggingFaceH4/zephyr-7b-beta": 0.9960175217462909, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9799662721802087, "meta-llama/Meta-Llama-3-8B": 0.9183233578105179, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9123277960951072}}, {"question": "\u5b8f\u8fdc\u6d77\u8fd0\u516c\u53f8\u4e3a\u4e86\u52a0\u5f3a\u5bf9\u635f\u5931\u4e8b\u4ef6\u7684\u7ba1\u7406\u6210\u7acb\u4e86\u4e00\u5bb6\u9644\u5c5e\u673a\u6784\uff0c\u5176\u804c\u8d23\u662f\u7528\u6bcd\u516c\u53f8\u63d0\u4f9b\u7684\u8d44\u91d1\u5efa\u7acb\u635f\u5931\u50a8\u5907\u91d1\uff0c\u5e76\u4e3a\u6bcd\u516c\u53f8\u63d0\u4f9b\u4fdd\u9669\u3002\u5b8f\u8fdc\u6d77\u8fd0\u516c\u53f8\u7ba1\u7406\u635f\u5931\u7684\u65b9\u6cd5\u662f____\u3002\nA. \u4e13\u4e1a\u81ea\u4fdd\nB. \u4fdd\u9669\nC. \u635f\u5931\u878d\u8d44\nD. \u98ce\u9669\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5470649465260758, "meta-math/MetaMath-Mistral-7B": 0.6891720986157109, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5526339299532405, "meta-llama/Meta-Llama-3-8B": 0.5014154675392932, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9225941239166189}}, {"question": "\u4e0b\u5217\u4f01\u4e1a\u91c7\u7528\u7684\u6210\u957f\u578b\u6218\u7565\u4e2d\uff0c\u5c5e\u4e8e\u591a\u5143\u5316\u6218\u7565\u7684\u662f____\u3002\nA. \u7532\u78b3\u9178\u996e\u6599\u751f\u4ea7\u4f01\u4e1a\u901a\u8fc7\u6309\u5b63\u66f4\u6362\u996e\u6599\u5305\u88c5\u3001\u5728\u5404\u4f20\u7edf\u8282\u65e5\u671f\u95f4\u9644\u8d60\u5c0f\u5305\u88c5\u996e\u6599\u7b49\u65b9\u5f0f\u589e\u52a0\u5e02\u573a\u4efd\u989d\nB. \u4e59\u6c7d\u8f66\u5236\u9020\u4f01\u4e1a\u5f00\u59cb\u5c06\u5176\u539f\u5728\u56fd\u5185\u751f\u4ea7\u9500\u552e\u7684\u5c0f\u578b\u5ba2\u8f66\u51fa\u53e3\u5230\u5357\u7f8e\u5730\u533a\nC. \u4e19\u6d17\u8863\u7c89\u751f\u4ea7\u4f01\u4e1a\u901a\u8fc7\u81ea\u884c\u7814\u53d1\uff0c\u5f00\u59cb\u751f\u4ea7\u9500\u552e\u5177\u6709\u4e0d\u540c\u529f\u6548\u7684\u6d17\u53d1\u6c34\nD. \u4e01\u9178\u5976\u751f\u4ea7\u4f01\u4e1a\u65b0\u5f00\u53d1\u51fa\u4e00\u79cd\u51dd\u56fa\u578b\u9178\u5976\uff0c\u5e76\u5c06\u5176\u63a8\u5411\u5e02\u573a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5530180755799183, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4f01\u4e1a2016\u5e74\u521d\u62e5\u6709\u571f\u57302\u4e07\u5e73\u65b9\u7c73\uff0c\u5305\u62ec\u5382\u533a\u5185\u6258\u513f\u6240\u5360\u57300.1\u4e07\u5e73\u65b9\u7c73\uff0c\u65e0\u507f\u63d0\u4f9b\u7ed9\u516c\u5b89\u5c40\u4f7f\u7528\u571f\u57300.3\u4e07\u5e73\u65b9\u7c73\uff0c\u5382\u533a\u5185\u7eff\u5316\u7528\u57300.4\u4e07\u5e73\u65b9\u7c73\u30025\u6708\u8be5\u4f01\u4e1a\u8d2d\u4e70\u4e00\u5757\u571f\u5730\u4f7f\u7528\u6743(\u975e\u8015\u5730)\u7528\u4e8e\u5382\u623f\u6269\u5efa\uff0c\u5360\u5730\u9762\u79ef\u4e3a2.4\u4e07\u5e73\u65b9\u7c73\uff0c\u5408\u540c\u89c4\u5b9a\uff0c5\u6708\u652f\u4ed8\u571f\u5730\u4ef7\u6b3e\u5e76\u4ea4\u4ed8\u571f\u5730\u3002\u8be5\u4f01\u4e1a\u6240\u5728\u5730\u533a\u57ce\u9547\u571f\u5730\u4f7f\u7528\u7a0e\u5e74\u7a0e\u989d\u4e3a10\u5143/\u5e73\u65b9\u7c73\uff0c\u8be5\u4f01\u4e1a2016\u5e74\u5e94\u7f34\u7eb3\u57ce\u9547\u571f\u5730\u4f7f\u7528\u7a0e____\u4e07\u5143\u3002\nA. 26\nB. 36\nC. 30\nD. 44\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36150852560561064, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36900588617464214, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5728\u51fa\u5177\u5ba1\u8ba1\u62a5\u544a\u65f6\uff0c\u5b58\u5728\u4ee5\u4e0b\u4e8b\u9879\uff0c\u5176\u4e2d\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u5ba1\u8ba1\u62a5\u544a\u91c7\u7528\u4e66\u9762\u5f62\u5f0f\nB. \u5ba1\u8ba1\u62a5\u544a\u7531\u4e0d\u662f\u6ce8\u518c\u4f1a\u8ba1\u5e08\u7684\u9879\u76ee\u7ecf\u7406\u7b7e\u5b57\u76d6\u7ae0\nC. \u5ba1\u8ba1\u62a5\u544a\u5e94\u5f53\u5177\u6709\u6807\u9898\uff0c\u7edf\u4e00\u89c4\u8303\u4e3a\u201c\u5ba1\u8ba1\u62a5\u544a\u201d\nD. \u5ba1\u8ba1\u62a5\u544a\u5e94\u5f53\u6309\u7167\u5ba1\u8ba1\u4e1a\u52a1\u7ea6\u5b9a\u7684\u8981\u6c42\u8f7d\u660e\u6536\u4ef6\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7809462705986164, "meta-math/MetaMath-Mistral-7B": 0.9555806275881304, "itpossible/Chinese-Mistral-7B-v0.1": 0.8831461166412261, "HuggingFaceH4/zephyr-7b-beta": 0.9994335281162176, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9682472160244222, "meta-llama/Meta-Llama-3-8B": 0.8312937380586004, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9767405681960245}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u9884\u4ed8\u5361\u7684\u8868\u8ff0\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u8bb0\u540d\u9884\u4ed8\u5361\u53ef\u6302\u5931\uff0c\u53ef\u8d4e\u56de\uff0c\u4e0d\u5f97\u8bbe\u7f6e\u6709\u6548\u671f\nB. \u4e0d\u8bb0\u540d\u9884\u4ed8\u5361\u4e00\u822c\u4e0d\u6302\u5931\uff0c\u4e0d\u8d4e\u56de\nC. \u9884\u4ed8\u5361\u53ef\u4ee5\u5177\u6709\u900f\u652f\u529f\u80fd\nD. \u4e0d\u8bb0\u540d\u9884\u4ed8\u5361\u6709\u6548\u671f\u4e0d\u5f97\u4f4e\u4e8e3\u5e74\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.7187311913227167, "itpossible/Chinese-Mistral-7B-v0.1": 0.35096048266444385, "HuggingFaceH4/zephyr-7b-beta": 0.8764850114709389, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6814523477487178, "meta-llama/Meta-Llama-3-8B": 0.3300364758848943, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u6ce8\u518c\u4f1a\u8ba1\u5e08\u804c\u4e1a\u9053\u5fb7\u5b88\u5219\u7981\u6b62\u7684\u5546\u4e1a\u5173\u7cfb\u7684\u662f____\u3002\nA. \u5ba1\u8ba1\u9879\u76ee\u7ec4\u6210\u5458\u6309\u7167\u6b63\u5e38\u7684\u5546\u4e1a\u7a0b\u5e8f\u4ece\u5ba1\u8ba1\u5ba2\u6237\u8d2d\u4e70\u65e0\u8bba\u4ece\u91d1\u989d\u8fd8\u662f\u4ece\u6027\u8d28\u7684\u89d2\u5ea6\u8003\u8651\u5747\u4e0d\u91cd\u5927\u6216\u7279\u6b8a\u7684\u5546\u54c1\u6216\u670d\u52a1\nB. \u6309\u7167\u534f\u8bae\uff0c\u5c06\u4f1a\u8ba1\u5e08\u4e8b\u52a1\u6240\u7684\u4ea7\u54c1\u6216\u670d\u52a1\u4e0e\u5ba2\u6237\u7684\u4ea7\u54c1\u6216\u670d\u52a1\u7ed3\u5408\u5728\u4e00\u8d77\uff0c\u5e76\u4ee5\u53cc\u65b9\u540d\u4e49\u6346\u7ed1\u9500\u552e\nC. \u6309\u7167\u534f\u8bae\uff0c\u4f1a\u8ba1\u5e08\u4e8b\u52a1\u6240\u9500\u552e\u6216\u63a8\u5e7f\u5ba2\u6237\u7684\u4ea7\u54c1\u6216\u670d\u52a1\nD. \u6309\u7167\u534f\u8bae\uff0c\u5ba2\u6237\u9500\u552e\u6216\u63a8\u5e7f\u4f1a\u8ba1\u5e08\u4e8b\u52a1\u6240\u7684\u4ea7\u54c1\u6216\u670d\u52a1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5567495501650369, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.671093077324936}}, {"question": "\u6ce8\u518c\u4f1a\u8ba1\u5e08\u7532\u9009\u62e9\u4e86A\u516c\u53f82017\u5e74\u6574\u4e2a\u4f1a\u8ba1\u671f\u95f4\u7684\u4f1a\u8ba1\u5206\u5f55\u548c\u5176\u4ed6\u8c03\u6574\u8fdb\u884c\u4f1a\u8ba1\u5206\u5f55\u6d4b\u8bd5\u65f6\uff0c\u5728\u786e\u5b9a\u5bf9\u603b\u4f53\u5b8c\u6574\u6027\u65f6\u6267\u884c\u4e86\u4e0b\u5217\u7a0b\u5e8f\u4e2d\u4e0d\u6070\u5f53\u7684\u662f____\u3002\nA. \u4ece\u88ab\u5ba1\u8ba1\u5355\u4f4d\u4f1a\u8ba1\u4fe1\u606f\u7cfb\u7edf\u4e2d\u5bfc\u51fa\u6240\u6709\u5f85\u6d4b\u8bd5\u4f1a\u8ba1\u5206\u5f55\u548c\u5176\u4ed6\u8c03\u6574\uff0c\u5e76\u5c06\u603b\u8d26\u4e0e\u8d22\u52a1\u62a5\u8868\u6838\u5bf9\uff0c\u4ee5\u68c0\u67e5\u662f\u5426\u5b58\u5728\u5176\u4ed6\u8c03\u6574\nB. \u52a0\u8ba1\u4ece\u4f1a\u8ba1\u4fe1\u606f\u7cfb\u7edf\u4e2d\u5bfc\u51fa\u7684\u6240\u6709\u4f1a\u8ba1\u5206\u5f55\u548c\u5176\u4ed6\u8c03\u6574\u4e2d\u7684\u672c\u671f\u53d1\u751f\u989d\uff0c\u4e0e\u79d1\u76ee\u4f59\u989d\u8868\u4e2d\u7684\u5404\u79d1\u76ee\u672c\u671f\u53d1\u751f\u989d\u6838\u5bf9\u76f8\u7b26\nC. \u5c06\u7cfb\u7edf\u751f\u6210\u7684\u91cd\u8981\u8d26\u6237\u4f59\u989d\u4e0e\u660e\u7ec6\u8d26\u548c\u603b\u8d26\u53ca\u79d1\u76ee\u4f59\u989d\u8868\u4e2d\u7684\u4f59\u989d\u6838\u5bf9\uff0c\u6d4b\u8bd5\u8ba1\u7b97\u51c6\u786e\u6027\nD. \u68c0\u67e5\u6240\u6709\u7ed3\u8d26\u524d\u4f5c\u51fa\u7684\u4e0e\u672c\u671f\u8d22\u52a1\u62a5\u8868\u6709\u5173\u7684\u4f1a\u8ba1\u5206\u5f55\u548c\u5176\u4ed6\u8c03\u6574\uff0c\u6d4b\u8bd5\u5176\u5b8c\u6574\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4257098344309756, "meta-llama/Meta-Llama-3-8B": 0.3171201089282236, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5982\u679c\u7528\u5408\u4f5c\u6027\u548c\u575a\u5b9a\u6027\u4e24\u7ef4\u5750\u6807\u6765\u63cf\u8ff0\u4f01\u4e1a\u67d0\u4e00\u5229\u76ca\u76f8\u5173\u8005\u5728\u4f01\u4e1a\u6218\u7565\u51b3\u7b56\u4e0e\u5b9e\u65bd\u8fc7\u7a0b\u884c\u4e3a\u6a21\u5f0f\uff0c\u201c\u548c\u89e3\u201d\u662f____\u3002\nA. \u4e2d\u7b49\u7a0b\u5ea6\u7684\u575a\u5b9a\u6027\u548c\u4e2d\u7b49\u7a0b\u5ea6\u7684\u5408\u4f5c\u6027\u884c\u4e3a\u7684\u7ec4\u5408\nB. \u4e0d\u575a\u5b9a\u884c\u4e3a\u4e0e\u5408\u4f5c\u884c\u4e3a\u7684\u7ec4\u5408\nC. \u575a\u5b9a\u884c\u4e3a\u548c\u4e0d\u5408\u4f5c\u884c\u4e3a\u7684\u7ec4\u5408\nD. \u575a\u5b9a\u884c\u4e3a\u4e0e\u5408\u4f5c\u884c\u4e3a\u7684\u7ec4\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u76ee\u524d\u8d8a\u6765\u8d8a\u666e\u904d\u7684\u663e\u793a\u4e3b\u8981\u7ee9\u6548\u6570\u636e\u7684\u65b9\u6cd5\u662f____\u3002\nA. \u4ee5\u56fe\u89e3\u65b9\u6cd5\u901a\u8fc7\u5c4f\u5e55\u663e\u793a\nB. \u4ee5\u53e3\u5934\u7684\u65b9\u5f0f\u516c\u5f00\u5c55\u793a\nC. \u4ee5\u6587\u5b57\u7684\u5f62\u5f0f\u51fa\u7248\u5c55\u793a\nD. \u4ee5\u62a5\u8868\u7684\u5f62\u5f0f\u5bf9\u5916\u5217\u62a5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4562021337442807, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.9116288687489925, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7466987386424969, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8360045403205678}}, {"question": "\u6839\u636e\u589e\u503c\u7a0e\u73b0\u884c\u653f\u7b56\u89c4\u5b9a\uff0c\u4e0b\u5217\u4e1a\u52a1\u5c5e\u4e8e\u5728\u5883\u5185\u9500\u552e\u670d\u52a1\u6216\u4e0d\u52a8\u4ea7\u7684\u662f____\u3002\nA. \u5883\u5916\u5355\u4f4d\u4e3a\u5883\u5185\u5355\u4f4d\u63d0\u4f9b\u5883\u5916\u77ff\u5c71\u52d8\u63a2\u670d\u52a1\nB. \u5883\u5916\u5355\u4f4d\u5411\u5883\u5185\u5355\u4f4d\u51fa\u79df\u5883\u5916\u7684\u5382\u623f\nC. \u5883\u5916\u5355\u4f4d\u5411\u5883\u5185\u5355\u4f4d\u9500\u552e\u5728\u5883\u5916\u7684\u4e0d\u52a8\u4ea7\nD. \u5883\u5916\u5355\u4f4d\u5728\u5883\u5185\u5411\u5883\u5185\u5355\u4f4d\u63d0\u4f9b\u8fd0\u8f93\u670d\u52a1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u8bc9\u8bbc\u65f6\u6548\u4e2d\u6b62\u7684\u8868\u8ff0\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u4e2d\u6b62\u8bc9\u8bbc\u65f6\u6548\u7684\u4e8b\u7531\u5305\u62ec\u4e0d\u53ef\u6297\u529b\u4e0e\u5176\u4ed6\u969c\u788d\nB. \u8bc9\u8bbc\u65f6\u6548\u4e2d\u6b62\u4f7f\u5df2\u7ecf\u8fdb\u884c\u7684\u8bc9\u8bbc\u65f6\u6548\u671f\u95f4\u5168\u90e8\u5f52\u4e8e\u65e0\u6548\nC. \u53ea\u6709\u5728\u8bc9\u8bbc\u65f6\u6548\u671f\u95f4\u7684\u6700\u540e6\u4e2a\u6708\u5185\u53d1\u751f\u4e0d\u53ef\u6297\u529b\u7684\u60c5\u51b5\u548c\u5176\u4ed6\u969c\u788d\uff0c\u624d\u80fd\u4e2d\u6b62\u65f6\u6548\u7684\u8fdb\u884c\nD. \u4e2d\u6b62\u4e8b\u7531\u53d1\u751f\u524d\u5df2\u7ecf\u7ecf\u8fc7\u7684\u8bc9\u8bbc\u65f6\u6548\u671f\u9650\u4ecd\u7136\u6709\u6548\uff0c\u81ea\u4e2d\u6b62\u65f6\u6548\u7684\u539f\u56e0\u6d88\u9664\u4e4b\u65e5\u8d77\u6ee16\u4e2a\u6708\uff0c\u8bc9\u8bbc\u65f6\u6548\u671f\u95f4\u5c51\u6ee1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3403147063768956, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u9009\u9879\u4e2d\uff0c\u5c5e\u4e8e\u6709\u6548\u7684\u6c11\u4e8b\u6cd5\u5f8b\u884c\u4e3a\u7684\u662f____\u3002\nA. 9\u5c81\u7684\u5c0f\u660e\u7528\u5bb6\u91cc\u7684\u4e00\u5f20\u5b58\u6298\u6362\u4e86\u4e00\u8f86\u6c7d\u8f66\nB. \u7532\u516c\u53f8\u4e0e\u4e59\u516c\u53f8\u53e3\u5934\u8fbe\u6210\u7684\u6280\u672f\u5f00\u53d1\u5408\u540c\nC. \u5f20\u67d0\u672a\u7ecf\u59bb\u5b50\u540c\u610f\u8d2d\u4e70\u4e86\u4e00\u4ef6\u6602\u8d35\u7684\u53e4\u73a9\nD. 16\u5c81\u7684\u4e2d\u5b66\u751f\u672a\u7ecf\u5bb6\u957f\u540c\u610f\u7528\u81ea\u5df1\u6512\u7684\u94b1\u4e70\u4e86\u4e00\u8f86\u6469\u6258\u8f66\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u7b26\u5408\u589e\u503c\u7a0e\u7eb3\u7a0e\u5730\u70b9\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u8fdb\u53e3\u8d27\u7269\uff0c\u5e94\u5f53\u7531\u8fdb\u53e3\u4eba\u6216\u5176\u4ee3\u7406\u4eba\u5411\u62a5\u5173\u5730\u6d77\u5173\u7533\u62a5\u7eb3\u7a0e\nB. \u56fa\u5b9a\u4e1a\u6237\u5230\u5916\u5e02\u9500\u552e\u8d27\u7269\u6216\u8005\u63d0\u4f9b\u5e94\u7a0e\u52b3\u52a1\uff0c\u4e00\u5f8b\u5411\u9500\u552e\u5730\u6216\u52b3\u52a1\u53d1\u751f\u5730\u4e3b\u7ba1\u7a0e\u52a1\u673a\u5173\u7533\u62a5\u7eb3\u7a0e\nC. \u975e\u56fa\u5b9a\u4e1a\u6237\u9500\u552e\u8d27\u7269\u6216\u8005\u5e94\u7a0e\u52b3\u52a1\u7684\uff0c\u5411\u5176\u673a\u6784\u6240\u5728\u5730\u6216\u5c45\u4f4f\u5730\u7684\u4e3b\u7ba1\u7a0e\u52a1\u673a\u5173\u7533\u62a5\u7f34\u7eb3\u7a0e\u6b3e\nD. \u6263\u7f34\u4e49\u52a1\u4eba\u5e94\u5f53\u5411\u9500\u552e\u5730\u6216\u8005\u52b3\u52a1\u53d1\u751f\u5730\u7684\u4e3b\u7ba1\u7a0e\u52a1\u673a\u5173\u7533\u62a5\u7eb3\u7a0e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u8ba1\u7b97\u673a\u751f\u4ea7\u5546\u5c06\u952e\u76d8\u548c\u9f20\u6807\u751f\u4ea7\u5916\u5305\u7ed9\u53e6\u4e00\u7535\u5b50\u7c7b\u5916\u8bbe\u751f\u4ea7\u4f01\u4e1a\uff0c\u7531\u5176\u6309\u7167\u8ba2\u5355\u8981\u6c42\u4f9b\u8d27\uff0c\u5219\u8be5\u8ba1\u7b97\u673a\u751f\u4ea7\u5546\u7684\u8d27\u6e90\u7b56\u7565\u5c5e\u4e8e____\u3002\nA. \u5355\u4e00\u8d27\u6e90\u7b56\u7565\nB. \u591a\u8d27\u6e90\u7b56\u7565\nC. \u7531\u4f9b\u5e94\u5546\u8d1f\u8d23\u4ea4\u4ed8\u4e00\u4e2a\u5b8c\u6574\u7684\u5b50\u90e8\u4ef6\nD. \u7531\u91c7\u8d2d\u5546\u8d1f\u8d23\u4ea4\u4ed8\u4e00\u4e2a\u5b8c\u6574\u7684\u5b50\u90e8\u4ef6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7217358301794508}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u6709\u9650\u5408\u4f19\u4f01\u4e1a\u4e2d\u6709\u9650\u5408\u4f19\u4eba\u5165\u4f19\u4e0e\u9000\u4f19\u7684\u8868\u8ff0\u4e2d\uff0c\u7b26\u5408\u300a\u5408\u4f19\u4f01\u4e1a\u6cd5\u300b\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u65b0\u5165\u4f19\u7684\u6709\u9650\u5408\u4f19\u4eba\u5bf9\u5165\u4f19\u524d\u6709\u9650\u5408\u4f19\u4f01\u4e1a\u7684\u503a\u52a1\uff0c\u4ee5\u5176\u5b9e\u7f34\u7684\u51fa\u8d44\u989d\u4e3a\u9650\u627f\u62c5\u8d23\u4efb\nB. \u4f5c\u4e3a\u6709\u9650\u5408\u4f19\u4eba\u7684\u81ea\u7136\u4eba\uff0c\u6709\u9650\u5408\u4f19\u4f01\u4e1a\u5b58\u7eed\u671f\u95f4\u4e27\u5931\u6c11\u4e8b\u884c\u4e3a\u80fd\u529b\u7684\uff0c\u8be5\u6709\u9650\u5408\u4f19\u4eba\u5f53\u7136\u9000\u4f19\nC. \u9000\u4f19\u540e\u7684\u6709\u9650\u5408\u4f19\u4eba\u5bf9\u57fa\u4e8e\u5176\u9000\u4f19\u524d\u7684\u539f\u56e0\u53d1\u751f\u7684\u6709\u9650\u5408\u4f19\u4f01\u4e1a\u7684\u503a\u52a1\uff0c\u4ee5\u5176\u9000\u4f19\u65f6\u4ece\u6709\u9650\u5408\u4f19\u4f01\u4e1a\u4e2d\u53d6\u56de\u7684\u8d22\u4ea7\u4e3a\u9650\u627f\u62c5\u8d23\u4efb\nD. \u9000\u4f19\u540e\u7684\u6709\u9650\u5408\u4f19\u4eba\u5bf9\u57fa\u4e8e\u5176\u9000\u4f19\u524d\u7684\u539f\u56e0\u53d1\u751f\u7684\u6709\u9650\u5408\u4f19\u4f01\u4e1a\u7684\u503a\u52a1\uff0c\u4ee5\u5176\u8ba4\u7f34\u7684\u51fa\u8d44\u989d\u4e3a\u9650\u627f\u62c5\u8d23\u4efb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4f01\u4e1a2016\u5e74\u62e5\u6709\u4e00\u5e62\u4e09\u5c42\u7684\u529e\u516c\u697c\uff0c\u539f\u503c6000\u4e07\u5143\uff0c\u5c06\u5176\u4e2d\u76841/3\u4ee5\u6bcf\u670815\u4e07\u5143\u7684\u79df\u91d1\u51fa\u79df\u7ed9\u5176\u4ed6\u5355\u4f4d\u4f7f\u7528\uff0c2016\u5e744\u6708\u5e95\uff0c\u539f\u79df\u6237\u7684\u79df\u671f\u5230\u671f\uff0c\u8be5\u4f01\u4e1a\u5c06\u8be5\u5e62\u529e\u516c\u697c\u8fdb\u884c\u6539\u5efa\uff0c\u66f4\u6362\u697c\u5185\u7535\u68af\uff0c\u5c06\u539f\u503c80\u4e07\u5143\u7684\u7535\u68af\u66f4\u6362\u4e3a120\u4e07\u5143\u7684\u65b0\u7535\u68af\uff0c\u4e3a\u8be5\u697c\u5b89\u88c5\u4e86300\u4e07\u5143\u7684\u667a\u80fd\u5316\u697c\u5b87\u8bbe\u65bd\uff0c\u8fd9\u4e9b\u6539\u5efa\u5de5\u7a0b\u4e8e7\u6708\u5e95\u5b8c\u5de5\uff0c\u8be5\u4f01\u4e1a\u6240\u5728\u5730\u7701\u4eba\u6c11\u653f\u5e9c\u89c4\u5b9a\u8ba1\u7b97\u623f\u4ea7\u4f59\u503c\u7684\u51cf\u9664\u6bd4\u4f8b\u4e3a30%\uff0c\u8be5\u4f01\u4e1a2016\u5e74\u5e94\u7eb3\u623f\u4ea7\u7a0e____\u4e07\u5143\u3002\nA. 51.49\nB. 52.38\nC. 53.05\nD. 53.19\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4f01\u4e1a\u4e00\u5b9a\u65f6\u671f\u7684\u603b\u76ee\u6807\u662f\u7531____\u6839\u636e\u957f\u671f\u89c4\u5212\uff0c\u5229\u7528\u672c\u91cf\u5229\u5206\u6790\u7b49\u5de5\u5177\u63d0\u51fa\u6765\u7684\u3002\nA. \u9884\u7b97\u59d4\u5458\u4f1a\nB. \u6700\u57fa\u5c42\u6210\u672c\u63a7\u5236\u4eba\u5458\nC. \u4e0a\u7ea7\u4e3b\u7ba1\nD. \u4f01\u4e1a\u51b3\u7b56\u673a\u6784\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7713931908987725, "meta-math/MetaMath-Mistral-7B": 0.9513641125989373, "itpossible/Chinese-Mistral-7B-v0.1": 0.9070971013367424, "HuggingFaceH4/zephyr-7b-beta": 0.9986447023339337, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7677458856988303, "meta-llama/Meta-Llama-3-8B": 0.7507613701214626, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8844369311562899}}, {"question": "\u6839\u636eCOSO\u5185\u90e8\u63a7\u5236\u6846\u67b6\uff0c\u53cd\u821e\u5f0a\u673a\u5236\u5c5e\u4e8e\u5185\u90e8\u63a7\u5236\u8981\u7d20\u4e2d\u7684____\u3002\nA. \u98ce\u9669\u8bc4\u4f30\nB. \u63a7\u5236\u6d3b\u52a8\nC. \u76d1\u63a7\nD. \u4fe1\u606f\u4e0e\u6c9f\u901a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5c5e\u4e8e\u4e2d\u592e\u56fa\u5b9a\u6536\u5165\u7684\u662f____\u3002\nA. \u589e\u503c\u7a0e\nB. \u57ce\u5e02\u7ef4\u62a4\u5efa\u8bbe\u7a0e\nC. \u8d44\u6e90\u7a0e\nD. \u8f66\u8f86\u8d2d\u7f6e\u7a0e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u751f\u4ea7\u4f01\u4e1a(\u5177\u6709\u51fa\u53e3\u7ecf\u8425\u6743)\u4e3a\u589e\u503c\u7a0e\u4e00\u822c\u7eb3\u7a0e\u4eba\uff0c2017\u5e742\u6708\u4ece\u56fd\u5185\u91c7\u8d2d\u751f\u4ea7\u7528\u539f\u6750\u6599\u4e00\u6279\uff0c\u53d6\u5f97\u589e\u503c\u7a0e\u4e13\u7528\u53d1\u7968\uff0c\u6ce8\u660e\u4ef7\u6b3e810\u4e07\u5143\u3001\u589e\u503c\u7a0e\u7a0e\u989d137.7\u4e07\u5143\uff1b\u5f53\u6708\u56fd\u5185\u9500\u552e\u8d27\u7269\u53d6\u5f97\u4e0d\u542b\u7a0e\u9500\u552e\u989d150\u4e07\u5143\uff0c\u51fa\u53e3\u81ea\u4ea7\u8d27\u7269\u53d6\u5f97\u6536\u5165\u6298\u5408\u4eba\u6c11\u5e01690\u4e07\u5143\uff1b\u5df2\u77e5\uff0c\u9002\u7528\u7684\u589e\u503c\u7a0e\u7a0e\u7387\u4e3a17%\uff0c\u51fa\u53e3\u9000\u7a0e\u7387\u4e3a13%\uff0c\u6708\u521d\u65e0\u7559\u62b5\u7a0e\u989d\uff0c\u76f8\u5173\u53d1\u7968\u5747\u5df2\u7ecf\u8fc7\u4e3b\u7ba1\u7a0e\u52a1\u673a\u5173\u8ba4\u8bc1\u5e76\u5141\u8bb8\u62b5\u6263\u3002\u5219\u4e0b\u5217\u5173\u4e8e\u8be5\u4f01\u4e1a\u589e\u503c\u7a0e\u7684\u7a0e\u52a1\u5904\u7406\u4e2d\uff0c\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u5e94\u7f34\u7eb3\u589e\u503c\u7a0e25.5\u4e07\u5143\uff0c\u514d\u62b5\u589e\u503c\u7a0e\u989d\u4e3a89.7\u4e07\u5143\nB. \u5e94\u9000\u589e\u503c\u7a0e84.6\u4e07\u5143\uff0c\u514d\u62b5\u589e\u503c\u7a0e\u989d\u4e3a0\nC. \u5e94\u9000\u589e\u503c\u7a0e89.7\u4e07\u5143\uff0c\u514d\u62b5\u589e\u503c\u7a0e\u989d\u4e3a0\nD. \u5e94\u9000\u589e\u503c\u7a0e84.6\u4e07\u5143\uff0c\u514d\u62b5\u589e\u503c\u7a0e\u989d\u4e3a5.1\u4e07\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3499320087587727, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7a0e\u6536\u7b79\u5212\u6709\u591a\u79cd\u65b9\u6cd5\uff0c\u4ee5\u4e0b\u5173\u4e8e\u7a0e\u52a1\u7b79\u5212\u57fa\u672c\u65b9\u6cd5\u7406\u89e3\u9519\u8bef\u7684\u662f____\u3002\nA. \u4f01\u4e1a\u6b32\u5c06\u8bc4\u4f30\u4ef7\u4e3a100\u4e07\u5143\u7684\u95f2\u7f6e\u623f\u4ea7\u5bf9\u5916\u9500\u552e\uff0c\u53e6\u6709\u610f\u5411\u5411W\u516c\u53f8\u6295\u8d44100\u4e07\u5143\uff0c\u4f01\u4e1a\u4e0eW\u516c\u53f8\u534f\u5546\uff0c\u4ee5\u6b64\u623f\u4ea7\u76f4\u63a5\u6295\u8d44\u5165\u80a1\uff0c\u5171\u62c5\u98ce\u9669\u3002\u8fd9\u5c5e\u4e8e\u5229\u7528\u514d\u7a0e\u7684\u7a0e\u6536\u7b79\u5212\u65b9\u6cd5\nB. \u67d0\u4f01\u4e1a\u4ea7\u54c1\u4ef7\u503c\u8f83\u5927\uff0c\u9500\u552e\u56de\u6b3e\u5468\u671f\u8f83\u957f\uff0c\u4e00\u822c\u60c5\u51b5\u4e0b\u90fd\u8981\u5728\u516d\u4e2a\u6708\u4ee5\u5185\u5206\u4e09\u6b21\u6536\u53d6\uff0c\u6ce8\u518c\u7a0e\u52a1\u5e08\u5efa\u8bae\u4f01\u4e1a\u4e0e\u5ba2\u6237\u7b7e\u5b9a\u5206\u671f\u6536\u6b3e\u5408\u540c\uff0c\u5728\u5408\u540c\u4e2d\u7ea6\u5b9a\u5177\u4f53\u7684\u6536\u6b3e\u65f6\u95f4\u548c\u6536\u6b3e\u91d1\u989d\uff0c\u6ce8\u518c\u7a0e\u52a1\u5e08\u91c7\u7528\u7684\u662f\u5ef6\u671f\u7eb3\u7a0e\u7684\u65b9\u6cd5\nC. A\u516c\u53f8\u5c06\u9500\u552e\u8d27\u7269\u7684\u65b9\u5f0f\u8be6\u7ec6\u5212\u5206\u4e3a\u8d4a\u9500\u4e1a\u52a1\u3001\u5206\u671f\u6536\u6b3e\u9500\u552e\u4e1a\u52a1\u3001\u76f4\u63a5\u6536\u6b3e\u4e1a\u52a1\u7b49\u65b9\u5f0f\uff0c\u8fd9\u5c5e\u4e8e\u5229\u7528\u5206\u5288\u7684\u7b79\u5212\u65b9\u6cd5\nD. \u5f20\u67d0\u56e0\u5de5\u4f5c\u9700\u8981\u5728\u4e0a\u6d77\u8d2d\u7f6e\u623f\u4ea7\uff0c\u62df\u5728\u4e09\u5e74\u540e\u8c03\u56de\u5317\u4eac\u65f6\u5c06\u6b64\u623f\u4ea7\u8f6c\u8ba9\u7ed9\u5218\u67d0\uff0c\u6ce8\u518c\u4f1a\u8ba1\u5e08\u63d0\u9192\u5f20\u67d0\u59a5\u5584\u4fdd\u5b58\u539f\u8d2d\u623f\u5408\u540c\u53ca\u8d2d\u623f\u53d1\u7968\u3002\u5f20\u67d0\u505a\u7684\u662f\u5229\u7528\u7a0e\u6536\u6263\u9664\u7684\u7b79\u5212\u65b9\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.43921757655972987, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u5e02\u573a\u652f\u914d\u5730\u4f4d\u63a8\u5b9a\u6807\u51c6\uff0c\u4e0b\u5217\u4e0d\u7b26\u5408\u6211\u56fd\u300a\u53cd\u5784\u65ad\u6cd5\u300b\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u7ecf\u8425\u8005\u5728\u76f8\u5173\u5e02\u573a\u7684\u5e02\u573a\u4efd\u989d\u8fbe\u52301/2\u7684\uff0c\u63a8\u5b9a\u4e3a\u5177\u6709\u5e02\u573a\u652f\u914d\u5730\u4f4d\nB. 2\u4e2a\u7ecf\u8425\u8005\u5728\u76f8\u5173\u5e02\u573a\u7684\u5e02\u573a\u4efd\u989d\u5408\u8ba1\u8fbe\u52302/3\uff0c\u5176\u4e2d\u6709\u7684\u7ecf\u8425\u8005\u5e02\u573a\u4efd\u989d\u4e0d\u8db31/10\u7684\uff0c\u4e0d\u5e94\u5f53\u63a8\u5b9a\u8be5\u7ecf\u8425\u8005\u5177\u6709\u5e02\u573a\u652f\u914d\u5730\u4f4d\nC. 3\u4e2a\u7ecf\u8425\u8005\u5728\u76f8\u5173\u5e02\u573a\u7684\u5e02\u573a\u4efd\u989d\u5408\u8ba1\u8fbe\u52303/4\uff0c\u5176\u4e2d\u67092\u4e2a\u7ecf\u8425\u8005\u5e02\u573a\u4efd\u989d\u5408\u8ba1\u4e0d\u8db31/5\u7684\uff0c\u4e0d\u5e94\u5f53\u63a8\u5b9a\u8be5\u4e24\u4e2a\u7ecf\u8425\u8005\u5177\u6709\u5e02\u573a\u652f\u914d\u5730\u4f4d\nD. \u88ab\u63a8\u5b9a\u5177\u6709\u5e02\u573a\u652f\u914d\u5730\u4f4d\u7684\u7ecf\u8425\u8005\uff0c\u6709\u8bc1\u636e\u8bc1\u660e\u4e0d\u5177\u6709\u5e02\u573a\u652f\u914d\u5730\u4f4d\u7684\uff0c\u4e0d\u5e94\u5f53\u8ba4\u5b9a\u5176\u5177\u6709\u5e02\u573a\u652f\u914d\u5730\u4f4d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31712010892822357, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u5c5e\u4e8eTPS\u5904\u7406\u8fc7\u7a0b\u7684\u57fa\u672c\u6d3b\u52a8\u7684\u662f____\u3002\nA. \u6570\u636e\u8f93\u5165\nB. \u6570\u636e\u5e93\u7ef4\u62a4\nC. \u6587\u4ef6\u548c\u62a5\u544a\u751f\u6210\nD. \u4fe1\u606f\u8f93\u51fa\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u516c\u53f8\u5e73\u4ef7\u53d1\u884c5\u5e74\u671f\u7684\u516c\u53f8\u503a\u5238\uff0c\u503a\u5238\u7684\u7968\u9762\u5229\u7387\u4e3a12%\uff0c\u6bcf\u5b63\u5ea6\u4ed8\u606f\u4e00\u6b21\uff0c\u5230\u671f\u4e00\u6b21\u507f\u8fd8\u672c\u91d1\uff0c\u8be5\u503a\u5238\u7684\u6709\u6548\u5e74\u5229\u7387\u4e3a____\u3002\nA. 12.25%\nB. 12.55%\nC. 10%\nD. 9.50%\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.424263145164869, "meta-math/MetaMath-Mistral-7B": 0.7103696977153341, "itpossible/Chinese-Mistral-7B-v0.1": 0.37993597849898714, "HuggingFaceH4/zephyr-7b-beta": 0.3060136256597631, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5399900747785036, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ecf\u6279\u51c6\u5f00\u5c71\u586b\u6d77\u6574\u6cbb\u7684\u571f\u5730\u548c\u6539\u9020\u7684\u5e9f\u5f03\u571f\u5730\uff0c\u4ece\u4f7f\u7528\u7684\u6708\u4efd\u8d77\u514d\u7f34\u57ce\u9547\u571f\u5730\u4f7f\u7528\u7a0e5\u5e74\u81f310\u5e74\u3002\u5177\u4f53\u514d\u7a0e\u671f\u9650\u7531____\u786e\u5b9a\u3002\nA. \u7701\u7ea7\u5730\u65b9\u7a0e\u52a1\u5c40\nB. \u5730\u5e02\u7ea7\u5730\u65b9\u7a0e\u52a1\u5c40\nC. \u53bf\u7ea7\u5730\u65b9\u7a0e\u52a1\u5c40\nD. \u56fd\u5bb6\u7a0e\u52a1\u603b\u5c40\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3142819912118394, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5987341664399922, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u8bc1\u5238\u6cd5\u5f8b\u5236\u5ea6\u7684\u89c4\u5b9a\uff0c\u4e0b\u5217\u5173\u4e8e\u4e0a\u5e02\u516c\u53f8\u6536\u8d2d\u7684\u8868\u8ff0\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u91c7\u7528\u8981\u7ea6\u65b9\u5f0f\u6536\u8d2d\u4e0a\u5e02\u516c\u53f8\u80a1\u4efd\u7684\uff0c\u5176\u9884\u5b9a\u6536\u8d2d\u7684\u80a1\u4efd\u6bd4\u4f8b\u4e0d\u5f97\u4f4e\u4e8e\u8be5\u4e0a\u5e02\u516c\u53f8\u5df2\u53d1\u884c\u80a1\u4efd\u768430%\nB. \u8981\u7ea6\u6536\u8d2d\u671f\u95f4\uff0c\u6536\u8d2d\u4eba\u4e0d\u5f97\u64a4\u9500\u6536\u8d2d\u8981\u7ea6\uff0c\u4e5f\u4e0d\u5f97\u53d8\u66f4\u6536\u8d2d\u8981\u7ea6\nC. \u6536\u8d2d\u4eba\u5bf9\u540c\u4e00\u79cd\u7c7b\u80a1\u7968\u7684\u8981\u7ea6\u4ef7\u683c\u4e0d\u5f97\u4f4e\u4e8e\u8981\u7ea6\u6536\u8d2d\u63d0\u793a\u6027\u516c\u544a\u65e5\u524d12\u4e2a\u6708\u5185\u6536\u8d2d\u4eba\u53d6\u5f97\u8be5\u79cd\u80a1\u7968\u6240\u652f\u4ed8\u7684\u6700\u9ad8\u4ef7\u683c\nD. \u8981\u7ea6\u6536\u8d2d\u671f\u95f4\uff0c\u88ab\u6536\u8d2d\u516c\u53f8\u8463\u4e8b\u4e0d\u5f97\u8f9e\u804c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5ba1\u8ba1\u88ab\u5ba1\u8ba1\u5355\u4f4d\u7684\u6295\u8d44\u4e1a\u52a1\u65f6\uff0c\u5bf9\u4e8e\u4e0b\u5217____\u6295\u8d44\u4e1a\u52a1\uff0c\u6ce8\u518c\u4f1a\u8ba1\u5e08\u53ef\u80fd\u65e0\u9700\u5411\u91d1\u878d\u673a\u6784\u53d1\u51fd\u8be2\u8bc1\u3002\nA. \u957f\u671f\u80a1\u6743\u6295\u8d44\nB. \u4ea4\u6613\u6027\u91d1\u878d\u8d44\u4ea7\nC. \u53ef\u4f9b\u51fa\u552e\u91d1\u878d\u8d44\u4ea7\nD. \u6301\u6709\u81f3\u5230\u671f\u6295\u8d44\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.44741291325753885, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4968388078459679, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7694593928234016}}, {"question": "\u67d0\u56fd\u6709\u4f01\u4e1a\u56e0\u6709\u8fdd\u53cd\u7a0e\u6536\u5f81\u6536\u7ba1\u7406\u6cd5\u7684\u884c\u4e3a\uff0c\u88ab\u7a0e\u52a1\u673a\u5173\u5904\u4ee58000\u5143\u7684\u7f5a\u6b3e\u3002\u5047\u5b9a\u8be5\u4f01\u4e1a\u6536\u5230\u7a0e\u52a1\u884c\u653f\u5904\u7f5a\u51b3\u5b9a\u4e66\u7684\u65f6\u95f4\u4e3a2015\u5e743\u67081\u65e5\uff0c\u5219\u8be5\u4f01\u4e1a4\u67085\u65e5\u7f34\u7eb3\u7f5a\u6b3e\u65f6\u7684\u603b\u91d1\u989d\u4e3a____\u3002\nA. 8000\u5143\nB. 9200\u5143\nC. 13040\u5143\nD. 16640\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.37170380811899256, "meta-math/MetaMath-Mistral-7B": 0.42000512233929277, "itpossible/Chinese-Mistral-7B-v0.1": 0.3469506764321279, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4167500531591177, "meta-llama/Meta-Llama-3-8B": 0.3499320087587726, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4827288506217125}}, {"question": "\u7532\u516c\u53f8\u662f\u725b\u8089\u751f\u4ea7\u3001\u52a0\u5de5\u53ca\u96f6\u552e\u4f01\u4e1a\u3002\u8fd1\u671f\u7532\u516c\u53f8\u5f00\u59cb\u8003\u8651\u5c06\u5176\u4e1a\u52a1\u6269\u5c55\u5230\u56fd\u9645\u5e02\u573a\uff0c\u5728\u52b3\u5de5\u6210\u672c\u8f83\u4f4e\u7684\u8d8a\u5357\u8bbe\u7acb\u7edf\u4e00\u7684\u725b\u8089\u52a0\u5de5\u5382\uff0c\u5e76\u5728\u591a\u4e2a\u56fd\u5bb6\u4ece\u4e8b\u725b\u8089\u52a0\u5de5\u98df\u54c1\u96f6\u552e\u4e1a\u52a1\u3002\u7532\u516c\u53f8\u7ba1\u7406\u5c42\u91c7\u7528\u96c6\u6743\u5f0f\u7ba1\u7406\u65b9\u5f0f\uff0c\u4e3a\u786e\u4fdd\u725b\u8089\u52a0\u5de5\u98df\u54c1\u7684\u8d28\u91cf\uff0c\u7532\u516c\u53f8\u8ba1\u5212\u5c06\u6240\u6709\u539f\u6599\u725b\u5728\u65e5\u672c\u519c\u573a\u9972\u517b\u3002\u6839\u636e\u4ee5\u4e0a\u5185\u5bb9\uff0c\u9002\u5408\u7532\u516c\u53f8\u9009\u62e9\u7684\u56fd\u9645\u5316\u53d1\u5c55\u6218\u7565\u662f____\u3002\nA. \u591a\u5143\u5316\u6210\u957f\u6218\u7565\nB. \u5168\u7403\u5316\u6218\u7565\nC. \u591a\u56fd\u5316\u6218\u7565\nD. \u8de8\u56fd\u5316\u6218\u7565\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3875481057829085, "meta-math/MetaMath-Mistral-7B": 0.8457102523086817, "itpossible/Chinese-Mistral-7B-v0.1": 0.35438796843123427, "HuggingFaceH4/zephyr-7b-beta": 0.5651023704586321, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.628361664821136, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2019\u5e745\u67081\u65e5\uff0c\u4eba\u6c11\u6cd5\u9662\u53d7\u7406\u4e86\u5bf9\u7532\u516c\u53f8\u63d0\u8d77\u7684\u7834\u4ea7\u7533\u8bf7\u3002\u6839\u636e\u4f01\u4e1a\u7834\u4ea7\u6cd5\u5f8b\u5236\u5ea6\u7684\u89c4\u5b9a\uff0c\u4e0b\u5217\u6709\u8d44\u683c\u62c5\u4efb\u7ba1\u7406\u4eba\u7684\u662f____\u3002\nA. \u7532\u516c\u53f8\u8463\u4e8b\u4e59\nB. \u7532\u516c\u53f8\u8463\u4e8b\u4f1a\u79d8\u4e66\u7684\u5973\u513f\u4e19\nC. \u66fe\u4e8e2014\u5e741\u67081\u65e5\u81f32015\u5e741\u67081\u65e5\u62c5\u4efb\u7532\u516c\u53f8\u6cd5\u5f8b\u987e\u95ee\u7684\u4e01\u5f8b\u5e08\nD. 3\u5e74\u524d\u88ab\u540a\u9500\u6267\u4e1a\u8bc1\u4e66\uff0c\u4e8b\u540e\u91cd\u65b0\u83b7\u53d6\u6267\u4e1a\u8d44\u683c\u7684\u6ce8\u518c\u4f1a\u8ba1\u5e08\u620a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36260628017702756, "meta-math/MetaMath-Mistral-7B": 0.6889519854895805, "itpossible/Chinese-Mistral-7B-v0.1": 0.49151163360642475, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6801518719835362, "meta-llama/Meta-Llama-3-8B": 0.4491084384216521, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9258288077344379}}, {"question": "\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5728\u5bf9\u4e13\u5bb6\u5de5\u4f5c\u4f7f\u7528\u7684\u91cd\u8981\u539f\u59cb\u6570\u636e\u8fdb\u884c\u8bc4\u4ef7\u65f6\uff0c\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u65e0\u9700\u8bc4\u4ef7\u7684\u662f____\nA. \u539f\u59cb\u6570\u636e\u7684\u5b8c\u6574\u6027\nB. \u539f\u59cb\u6570\u636e\u7684\u51c6\u786e\u6027\nC. \u539f\u59cb\u6570\u636e\u7684\u76f8\u5173\u6027\nD. \u539f\u59cb\u6570\u636e\u7684\u53ef\u7406\u89e3\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.31911523504877376, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5229506475458718, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2018\u5e7412\u6708\uff0c\u67d0\u97ad\u70ae\u751f\u4ea7\u5382\u5c06\u81ea\u4ea7\u7684\u4e00\u6279\u97ad\u70ae\u4e0e\u5176\u4f9b\u5e94\u5546\u6362\u53d6\u751f\u4ea7\u7528\u539f\u6750\u6599\uff0c\u5df2\u77e5\u8be5\u6279\u97ad\u70ae\u7684\u5e73\u5747\u9500\u552e\u4ef7\u683c\u4e3a14\u4e07\u5143\uff0c\u6700\u4f4e\u9500\u552e\u4ef7\u683c\u4e3a10\u4e07\u5143\uff0c\u6700\u9ad8\u9500\u552e\u4ef7\u683c\u4e3a18\u4e07\u5143\uff0c\u5219\u8be5\u97ad\u70ae\u751f\u4ea7\u5382\u5e94\u7f34\u7eb3\u7684\u6d88\u8d39\u7a0e\u4e3a____\u4e07\u5143\u3002(\u4ee5\u4e0a\u4ef7\u683c\u5747\u4e3a\u4e0d\u542b\u7a0e\u4ef7\uff0c\u97ad\u70ae\u6d88\u8d39\u7a0e\u7a0e\u738715%)\nA. 1.5\nB. 2.7\nC. 1.73\nD. 1.05\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.48148338235486976, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3287145937103622, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u8d27\u5e01\u5e02\u573a\u7684\u8868\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u4ea4\u6613\u7684\u8bc1\u5238\u671f\u9650\u957f\nB. \u5229\u7387\u6216\u8981\u6c42\u7684\u62a5\u916c\u7387\u8f83\u9ad8\nC. \u4e3b\u8981\u529f\u80fd\u662f\u4fdd\u6301\u91d1\u878d\u8d44\u4ea7\u7684\u6d41\u52a8\u6027\nD. \u4e3b\u8981\u529f\u80fd\u662f\u8fdb\u884c\u957f\u671f\u8d44\u672c\u7684\u878d\u901a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8022847108975234, "meta-math/MetaMath-Mistral-7B": 0.9866319120234722, "itpossible/Chinese-Mistral-7B-v0.1": 0.865508770211357, "HuggingFaceH4/zephyr-7b-beta": 0.9871793078339146, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7684491699542763, "meta-llama/Meta-Llama-3-8B": 0.9245674992007664, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9886782066451624}}, {"question": "\u4f01\u4e1a\u91c7\u7528\u5916\u90e8\u62db\u8058\u7684\u4f18\u70b9\u662f____\u3002\nA. \u80fd\u8282\u7ea6\u5927\u91cf\u7684\u62db\u8058\u548c\u9009\u62d4\u65f6\u95f4\u53ca\u8d39\u7528\nB. \u53ef\u4ee5\u7ed9\u4f01\u4e1a\u6ce8\u5165\u65b0\u9c9c\u8840\u6db2\nC. \u80fd\u591f\u8c03\u52a8\u5458\u5de5\u7684\u79ef\u6781\u6027\uff0c\u57f9\u517b\u5458\u5de5\u7684\u5fe0\u8bda\u5ea6\nD. \u5bb9\u6613\u8bf1\u53d1\u81ea\u6ee1\u60c5\u7eea\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7834093285163384, "meta-math/MetaMath-Mistral-7B": 0.9630839408223173, "itpossible/Chinese-Mistral-7B-v0.1": 0.9248862799018225, "HuggingFaceH4/zephyr-7b-beta": 0.9841249121683956, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8204937804837856, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4994103073929542}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u4e86\u89e3\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\u7684\u8bf4\u6cd5\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u6ce8\u518c\u4f1a\u8ba1\u5e08\u53ea\u9700\u8981\u5728\u5ba1\u8ba1\u7684\u521d\u59cb\u9636\u6bb5\u4e86\u89e3\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\nB. \u6ce8\u518c\u4f1a\u8ba1\u5e08\u5e94\u5f53\u8fd0\u7528\u804c\u4e1a\u5224\u65ad\u786e\u5b9a\u9700\u8981\u4e86\u89e3\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\u7684\u7a0b\u5ea6\nC. \u8bc4\u4ef7\u5bf9\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\u4e86\u89e3\u7684\u7a0b\u5ea6\u662f\u5426\u6070\u5f53\uff0c\u5173\u952e\u662f\u770b\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5bf9\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\u7684\u4e86\u89e3\u662f\u5426\u8db3\u4ee5\u8bc6\u522b\u548c\u8bc4\u4f30\u8d22\u52a1\u62a5\u8868\u7684\u91cd\u5927\u9519\u62a5\u98ce\u9669\nD. \u8981\u6c42\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5bf9\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\u4e86\u89e3\u7684\u7a0b\u5ea6\uff0c\u8981\u4f4e\u4e8e\u7ba1\u7406\u5c42\u4e3a\u7ecf\u8425\u7ba1\u7406\u4f01\u4e1a\u800c\u5bf9\u88ab\u5ba1\u8ba1\u5355\u4f4d\u53ca\u5176\u73af\u5883\u9700\u8981\u4e86\u89e3\u7684\u7a0b\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u622a\u81f32015\u5e74\u79cb\uff0cU\u56fdN\u822a\u7a7a\u516c\u53f8\u4e0eM\u822a\u7a7a\u516c\u53f8\u5408\u5e76\u5df2\u67095\u5e74\uff0c\u4f46\u539fN\u516c\u53f8\u548cM\u516c\u53f8\u673a\u8231\u670d\u52a1\u5458\u7684\u52b3\u5de5\u5408\u7ea6\u4ecd\u672a\u7edf\u4e00\u3002\u4e3a\u6b64\uff0c\u539fN\u516c\u53f8\u4e0eM\u516c\u53f8\u7684\u673a\u8231\u670d\u52a1\u5458\u5728\u4e34\u8fd1\u5723\u8bde\u8282\u671f\u95f4\uff0c\u53d1\u8d77\u6297\u8bae\u884c\u52a8\uff0c\u6709\u6548\u63a8\u52a8\u4e86\u8be5\u9879\u95ee\u9898\u7684\u89e3\u51b3\u3002\u672c\u6848\u4f8b\u4e2d\u539fN\u516c\u53f8\u4e0eM\u516c\u53f8\u673a\u8231\u670d\u52a1\u5458\u7684\u6743\u529b\u6765\u6e90\u4e8e____\u3002\nA. \u5728\u7ba1\u7406\u5c42\u6b21\u4e2d\u7684\u5730\u4f4d\nB. \u4e2a\u4eba\u7684\u7d20\u8d28\u548c\u5f71\u54cd\nC. \u53c2\u4e0e\u6216\u5f71\u54cd\u4f01\u4e1a\u6218\u7565\u51b3\u7b56\u4e0e\u5b9e\u65bd\u8fc7\u7a0b\nD. \u5229\u76ca\u76f8\u5173\u8005\u96c6\u4e2d\u6216\u8054\u5408\u7684\u7a0b\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.519168974911162, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9511381807756204, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6986604939429267, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6709\u5173\u5185\u90e8\u5ba1\u8ba1\u548c\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5ba1\u8ba1\u7684\u5173\u7cfb\u7684\u8bf4\u6cd5\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u4e3a\u652f\u6301\u6240\u5f97\u51fa\u7684\u7ed3\u8bba\uff0c\u5185\u90e8\u5ba1\u8ba1\u548c\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5ba1\u8ba1\u4e2d\u7684\u5ba1\u8ba1\u4eba\u5458\u90fd\u9700\u8981\u83b7\u53d6\u5145\u5206\u3001\u9002\u5f53\u7684\u5ba1\u8ba1\u8bc1\u636e\uff0c\u4f46\u5185\u90e8\u5ba1\u8ba1\u4e0d\u4f1a\u91c7\u7528\u51fd\u8bc1\u548c\u5206\u6790\u7a0b\u5e8f\nB. \u6ce8\u518c\u4f1a\u8ba1\u5e08\u5e94\u5f53\u8003\u8651\u5185\u90e8\u5ba1\u8ba1\u5de5\u4f5c\u7684\u67d0\u4e9b\u65b9\u9762\u662f\u5426\u6709\u52a9\u4e8e\u786e\u5b9a\u5ba1\u8ba1\u7a0b\u5e8f\u7684\u6027\u8d28\u3001\u65f6\u95f4\u5b89\u6392\u548c\u8303\u56f4\uff0c\u5305\u62ec\u4e86\u89e3\u5185\u90e8\u63a7\u5236\u6240\u91c7\u7528\u7684\u7a0b\u5e8f\u3001\u8bc4\u4f30\u8d22\u52a1\u62a5\u8868\u91cd\u5927\u9519\u62a5\u98ce\u9669\u6240\u91c7\u7528\u7684\u7a0b\u5e8f\u548c\u5b9e\u8d28\u6027\u7a0b\u5e8f\nC. \u5982\u679c\u5185\u90e8\u5ba1\u8ba1\u7684\u5de5\u4f5c\u7ed3\u679c\u8868\u660e\u88ab\u5ba1\u8ba1\u5355\u4f4d\u7684\u8d22\u52a1\u62a5\u8868\u5728\u67d0\u4e9b\u9886\u57df\u5b58\u5728\u91cd\u5927\u9519\u62a5\u98ce\u9669\uff0c\u6ce8\u518c\u4f1a\u8ba1\u5e08\u5e94\u5bf9\u8fd9\u4e9b\u9886\u57df\u7ed9\u4e88\u7279\u522b\u5173\u6ce8\nD. \u6ce8\u518c\u4f1a\u8ba1\u5e08\u5fc5\u987b\u5bf9\u4e0e\u8d22\u52a1\u62a5\u8868\u5ba1\u8ba1\u6709\u5173\u7684\u6240\u6709\u91cd\u5927\u4e8b\u9879\u72ec\u7acb\u4f5c\u51fa\u804c\u4e1a\u5224\u65ad\uff0c\u800c\u4e0d\u5e94\u5b8c\u5168\u4f9d\u8d56\u5185\u90e8\u5ba1\u8ba1\u5de5\u4f5c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6322728818709916, "meta-math/MetaMath-Mistral-7B": 0.9082106277444356, "itpossible/Chinese-Mistral-7B-v0.1": 0.48591456125112875, "HuggingFaceH4/zephyr-7b-beta": 0.903282921100623, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.919481850319471, "meta-llama/Meta-Llama-3-8B": 0.5724807643524719, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9495378060509726}}, {"question": "\u4e0b\u5217\u4f01\u4e1a\u4e2d\uff0c\u8d22\u52a1\u56f0\u5883\u6210\u672c\u6700\u9ad8\u7684\u662f____\u3002\nA. \u77f3\u6cb9\u5f00\u91c7\u4f01\u4e1a\nB. \u65e5\u7528\u54c1\u751f\u4ea7\u4f01\u4e1a\nC. \u6c7d\u8f66\u5236\u9020\u4f01\u4e1a\nD. \u8f6f\u4ef6\u5f00\u53d1\u4f01\u4e1a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u56e0\u571f\u5730\u89c4\u6a21\u5316\u8015\u79cd\u9700\u8981\uff0c\u519c\u6751\u5c45\u6c11\u5f20\u67d0\u7ecf\u6279\u51c6\u642c\u8fc1\uff0c\u642c\u8fc1\u524d\u4f4f\u5b85\u5360\u7528\u8015\u5730220\u5e73\u65b9\u7c73\uff0c\u642c\u8fc1\u540e\u65b0\u5efa\u81ea\u7528\u4f4f\u5b85\u5360\u7528\u8015\u5730260\u5e73\u65b9\u7c73(\u89c4\u5b9a\u7528\u5730\u6807\u51c6\u5185)\uff0c\u5f53\u5730\u8015\u5730\u5360\u7528\u7a0e\u7a0e\u989d\u6bcf\u5e73\u65b9\u7c7320\u5143\uff0c\u5f20\u67d0\u5e94\u7f34\u7eb3\u8015\u5730\u5360\u7528\u7a0e____\u5143\u3002\nA. 0\nB. 400\nC. 800\nD. 2600\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.39249817265965853, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fd1\u5e74\u6765\uff0c\u91d1\u878d\u884c\u4e1a\u7684\u5de5\u8d44\u7387\u4e0d\u65ad\u6500\u5347\u3002\u5728\u6b64\u671f\u95f4\uff0c\u7532\u516c\u53f8\u5206\u6790\u5176\u7ade\u4e89\u5bf9\u624b\u4e59\u516c\u53f8\u53d1\u73b0\uff0c\u4e59\u516c\u53f8\u7684\u6210\u672c\u8d39\u7528\u975e\u5e38\u5c11\uff0c\u4e59\u516c\u53f8\u4e0d\u65ad\u7cbe\u7b80\u516c\u53f8\u90e8\u95e8\u673a\u6784\uff0c\u5728\u4fdd\u6301\u516c\u53f8\u6d3b\u529b\u7684\u540c\u65f6\u8282\u7701\u516c\u53f8\u8d39\u7528\u3002\u7532\u516c\u53f8\u5bf9\u4e59\u516c\u53f8\u8fdb\u884c\u7684\u4e0a\u8ff0\u5206\u6790\u5c5e\u4e8e____\u3002\nA. \u6210\u957f\u80fd\u529b\u5206\u6790\nB. \u5feb\u901f\u53cd\u5e94\u80fd\u529b\u5206\u6790\nC. \u9002\u5e94\u53d8\u5316\u7684\u80fd\u529b\u5206\u6790\nD. \u6301\u4e45\u529b\u5206\u6790\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4606796536370849, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6160998874008828, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5530426963669699, "meta-llama/Meta-Llama-3-8B": 0.4503887036614204, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7229251311293361}}, {"question": "\u67d0\u80a1\u7968\u4e3a\u56fa\u5b9a\u589e\u957f\u80a1\u7968\uff0c\u5176\u56fa\u5b9a\u589e\u957f\u7387\u4e3a3%\uff0c\u9884\u671f\u7b2c\u4e00\u5e74\u7684\u80a1\u5229\u4e3a4\u5143\u3002\u5047\u5b9a\u76ee\u524d100\u5e74\u671f\u957f\u671f\u653f\u5e9c\u503a\u5238\u62a5\u916c\u7387\u4e3a13%\uff0c\u5e73\u5747\u98ce\u9669\u80a1\u7968\u7684\u5fc5\u8981\u62a5\u916c\u7387\u4e3a18%\uff0c\u800c\u8be5\u80a1\u7968\u7684\u8d1d\u5854\u7cfb\u6570\u4e3a1.2\uff0c\u5219\u8be5\u80a1\u7968\u7684\u4ef7\u503c\u4e3a____\u5143\u3002\nA. 25\nB. 40\nC. 26.67\nD. 30\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2019\u5e745\u6708\uff0c\u4e1c\u6e56\u6709\u9650\u8d23\u4efb\u516c\u53f8\u80a1\u4e1c\u7533\u8bf7\u6cd5\u9662\u6307\u5b9a\u6e05\u7b97\u7ec4\u5bf9\u516c\u53f8\u8fdb\u884c\u6e05\u7b97\uff0c\u6cd5\u9662\u4e3a\u5176\u6307\u5b9a\u76f8\u5173\u4eba\u5458\u7ec4\u6210\u6e05\u7b97\u7ec4\u3002\u5173\u4e8e\u8be5\u6e05\u7b97\u7ec4\u6210\u5458\uff0c\u4e0b\u5217\u9009\u9879\u4e0d\u80fd\u6210\u4e3a\u6e05\u7b97\u7ec4\u6210\u5458\u7684\u662f____\u3002\nA. \u516c\u53f8\u503a\u6743\u4eba\u5510\u67d0\nB. \u516c\u53f8\u8463\u4e8b\u957f\u7a0b\u67d0\nC. \u516c\u53f8\u8d22\u52a1\u603b\u76d1\u94b1\u67d0\nD. \u516c\u53f8\u8058\u8bf7\u7684\u67d0\u5f8b\u5e08\u4e8b\u52a1\u6240\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3418241350705705, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u8425\u4e1a\u9884\u7b97\u7684\u8ba1\u7b97\u7b49\u5f0f\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u672c\u671f\u751f\u4ea7\u6570\u91cf=(\u672c\u671f\u9500\u552e\u6570\u91cf+\u671f\u672b\u4ea7\u6210\u54c1\u5b58\u91cf)-\u671f\u521d\u4ea7\u6210\u54c1\u5b58\u91cf\nB. \u672c\u671f\u8d2d\u8d27\u4ed8\u73b0=\u672c\u671f\u8d2d\u8d27\u4ed8\u73b0\u90e8\u5206+\u4ee5\u524d\u671f\u8d4a\u8d2d\u672c\u671f\u4ed8\u73b0\u7684\u90e8\u5206\nC. \u672c\u671f\u6750\u6599\u91c7\u8d2d\u6570\u91cf=(\u672c\u671f\u751f\u4ea7\u8017\u7528\u6570\u91cf+\u671f\u672b\u6750\u6599\u5b58\u91cf)-\u671f\u521d\u6750\u6599\u5b58\u91cf\nD. \u672c\u671f\u9500\u552e\u5546\u54c1\u6240\u6536\u5230\u7684\u73b0\u91d1=\u672c\u671f\u7684\u9500\u552e\u6536\u5165+\u671f\u672b\u5e94\u6536\u8d26\u6b3e-\u671f\u521d\u5e94\u6536\u8d26\u6b3e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.41605132742014833, "meta-llama/Meta-Llama-3-8B": 0.402028656425726, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5775706963261384}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u80fd\u589e\u52a0\u4f01\u4e1a\u6838\u5fc3\u7ade\u4e89\u529b\u7684\u662f____\u3002\nA. \u4ea7\u54c1\u5dee\u5f02\u5316\nB. \u8d2d\u4e70\u751f\u4ea7\u4e13\u5229\u6743\nC. \u521b\u65b0\u751f\u4ea7\u6280\u672f\nD. \u8058\u7528\u751f\u4ea7\u5916\u5305\u5546\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8546349818299772, "meta-math/MetaMath-Mistral-7B": 0.9856774557270104, "itpossible/Chinese-Mistral-7B-v0.1": 0.8922402586467059, "HuggingFaceH4/zephyr-7b-beta": 0.9955558790914224, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9649026777983126, "meta-llama/Meta-Llama-3-8B": 0.8344029696908429, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9738436632240701}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u706b\u707e\u81ea\u52a8\u62a5\u8b66\u7cfb\u7edf\u901a\u8baf\u5e38\u89c1\u6545\u969c\u7684\u6392\u9664\u65b9\u6cd5\u53d9\u8ff0\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u66f4\u6362\u8bbe\u5907\uff0c\u4f7f\u8bbe\u5907\u4f9b\u7535\u6b63\u5e38\uff0c\u5173\u95ed\u62a5\u8b66\u63a7\u5236\u5668\nB. \u68c0\u67e5\u533a\u57df\u62a5\u8b66\u63a7\u5236\u5668\u4e0e\u96c6\u4e2d\u62a5\u8b66\u63a7\u5236\u5668\u7684\u901a\u8baf\u7ebf\u8def\uff0c\u82e5\u5b58\u5728\u5f00\u8def\u3001\u77ed\u8def\u3001\u63a5\u5730\u63a5\u89e6\u4e0d\u826f\u7b49\u6545\u969c\uff0c\u66f4\u6362\u7ebf\u8def\nC. \u68c0\u67e5\u533a\u57df\u62a5\u8b66\u63a7\u5236\u5668\u4e0e\u96c6\u4e2d\u62a5\u8b66\u63a7\u5236\u5668\u7684\u901a\u8baf\u677f\uff0c\u82e5\u5b58\u5728\u6545\u969c\uff0c\u7ef4\u4fee\u6216\u66f4\u6362\u901a\u8baf\u677f\nD. \u82e5\u56e0\u4e3a\u63a2\u6d4b\u5668\u6216\u6a21\u5757\u7b49\u8bbe\u5907\u9020\u6210\u901a\u8baf\u6545\u969c\uff0c\u66f4\u6362\u6216\u7ef4\u4fee\u76f8\u5e94\u8bbe\u5907\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.26463422059185693, "meta-math/MetaMath-Mistral-7B": 0.39768392766866767, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.558177340294083, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5421903765147941}}, {"question": "\u4e24\u5ea7\u591a\u5c42\u5efa\u7b51\uff0c\u5176\u9632\u706b\u95f4\u8ddd\u53ef\u4ee5\u6309\u89c4\u5b9a\u51cf\u5c1125%\u7684\u6761\u4ef6\u662f\u76f8\u90bb\u4e24\u9762\u5916\u5899\u5747\u4e3a\u4e0d\u71c3\u6027\u5899\u4f53\uff0c\u4e14\u65e0\u5916\u9732\u7684\u53ef\u71c3\u6027\u5c4b\u6a90\uff0c\u6bcf\u9762\u5916\u5899\u4e0a\u65e0\u9632\u706b\u4fdd\u62a4\u7684\u95e8\u3001\u7a97\u3001\u6d1e\u53e3\u4e0d\u6b63\u5bf9\u5f00\u8bbe\uff0c\u540c\u65f6\u95e8\u3001\u7a97\u3001\u6d1e\u53e3\u9762\u79ef\u4e4b\u548c\u5404\u4e0d\u5927\u4e8e\u8be5\u5916\u5899\u9762\u79ef\u7684____\u3002\nA. 4%\nB. 5%\nC. 6%\nD. 8%\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.2906893535433972, "meta-math/MetaMath-Mistral-7B": 0.3646363956912232, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u60c5\u51b5\u706d\u706b\u5668\u53ca\u706d\u706b\u5668\u7bb1\u8d28\u91cf\u4fdd\u8bc1\u6587\u4ef6\u68c0\u67e5\u5224\u5b9a\u4e3a\u4e0d\u5408\u683c\u7684\u662f____\u3002\nA. \u6bcf\u5177\u706d\u706b\u5668\u53ca\u5176\u6302\u94a9\u3001\u6258\u67b6\u7b49\u9644\u4ef6\uff0c\u706d\u706b\u5668\u7bb1\uff0c\u53d1\u5149\u6307\u793a\u6807\u5fd7\u5747\u6709\u5bf9\u5e94\u7684\u51fa\u5382\u5408\u683c\u8bc1\nB. \u5230\u573a\u706d\u706b\u5668\u7bb1\u3001\u706d\u706b\u5668\u53ca\u5176\u914d\u4ef6\u7684\u7c7b\u578b\u3001\u89c4\u683c\u3001\u6570\u91cf\uff0c\u4ee5\u53ca\u706d\u706b\u5668\u7684\u706d\u706b\u7ea7\u522b\u7b49\uff0c\u4e0e\u7ecf\u6d88\u9632\u8bbe\u8ba1\u5ba1\u6838\u3001\u5907\u6848\u68c0\u67e5\u5408\u683c\u7684\u5efa\u8bbe\u5de5\u7a0b\u6d88\u9632\u8bbe\u8ba1\u6587\u4ef6\u8981\u6c42\u4e00\u81f4\nC. \u5230\u573a\u706d\u706b\u5668\u3001\u706d\u706b\u5668\u7bb1\u7684\u5916\u89c2\u3001\u6807\u5fd7\u3001\u89c4\u683c\u578b\u53f7\u3001\u7ed3\u6784\u90e8\u4ef6\u3001\u6750\u6599\u3001\u6027\u80fd\u53c2\u6570\u7b49\u4e0e\u5176\u578b\u5f0f\u68c0\u9a8c\u62a5\u544a\u76f8\u4e00\u81f4\uff0c\u751f\u4ea7\u5382\u540d\u53ca\u5176\u5382\u5740\u4e0d\u4e00\u81f4\nD. \u6bcf\u5177\u706d\u706b\u5668\u53ca\u5176\u9644\u4ef6\u5747\u6709\u4f7f\u7528\u8bf4\u660e\u4e66\uff0c\u5176\u5185\u5bb9\u5305\u62ec\u706d\u706b\u5668\u53ca\u5176\u9644\u4ef6\u5b89\u88c5\u3001\u64cd\u4f5c\u548c\u7ef4\u62a4\u4fdd\u517b\u7684\u8bf4\u660e\u3001\u8b66\u544a\u548c\u63d0\u793a\uff1b\u5e76\u6709\u706d\u706b\u5668\u7ef4\u4fee\u3001\u518d\u5145\u88c5\u65f6\u9605\u8bfb\u751f\u4ea7\u5382\u5bb6\u7ef4\u4fee\u624b\u518c\u7684\u63d0\u793a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5678408546488889, "meta-math/MetaMath-Mistral-7B": 0.7221720184982612, "itpossible/Chinese-Mistral-7B-v0.1": 0.7303838922908856, "HuggingFaceH4/zephyr-7b-beta": 0.9938330796412559, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9326267273051211, "meta-llama/Meta-Llama-3-8B": 0.6463379304559671, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6d88\u9632\u8d1f\u8377\u6307\u6d88\u9632\u7528\u7535\u8bbe\u5907\uff0c\u6839\u636e\u4f9b\u7535\u53ef\u9760\u6027\u53ca\u4e2d\u65ad\u4f9b\u7535\u6240\u9020\u6210\u7684\u635f\u5931\u6216\u5f71\u54cd\u7684\u7a0b\u5ea6\uff0c\u5206\u4e3a\u4e00\u7ea7\u8d1f\u8377\u3001\u4e8c\u7ea7\u8d1f\u8377\u548c\u4e09\u7ea7\u8d1f\u8377\u3002\u4ee5\u4e0b\u5e94\u6309\u4e00\u7ea7\u8d1f\u8377\u4f9b\u7535\u7684\u573a\u6240\u662f____\u3002\nA. \u67d0\u5efa\u7b51\u9ad8\u5ea6\u4e3a46m\u7684\u8c37\u7269\u52a0\u5de5\u623f\nB. \u67d0\u5efa\u7b51\u9ad8\u5ea6\u4e3a55m\u7684\u4f4f\u5b85\u5efa\u7b51\nC. \u67d0\u5ba4\u5916\u6d88\u9632\u7528\u6c34\u91cf\u5927\u4e8e30L/s\u7684\u5382\u623f\nD. \u67d0\u5ea7\u4f4d\u6570\u4e3a3500\u4e2a\u7684\u4f53\u80b2\u9986\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4ed3\u5e93\u5de1\u89c6\u5458\u5728\u591c\u665a\u4f8b\u884c\u68c0\u67e5\u65f6\uff0c\u53d1\u73b0\u6c14\u4f53\u706d\u706b\u63a7\u5236\u5668\u53d1\u51fa\u58f0\u5149\u62a5\u8b66\u4fe1\u53f7\u5e76\u5904\u4e8e\u5ef6\u65f6\u9636\u6bb5\uff0c\u7ecf\u68c0\u6d4b\u6b64\u4fe1\u53f7\u4e3a\u8bef\u62a5\u4fe1\u53f7\uff0c\u90a3\u4e48\u8be5\u5de1\u89c6\u5458\u9700\u91c7\u53d6____\u4f7f\u7cfb\u7edf\u505c\u6b62\u706d\u706b\u3002\nA. \u81ea\u52a8\u63a7\u5236\u65b9\u5f0f\nB. \u624b\u52a8\u63a7\u5236\u65b9\u5f0f\nC. \u5e94\u6025\u673a\u68b0\u542f\u52a8\u5de5\u4f5c\u65b9\u5f0f\nD. \u7d27\u6025\u542f\u52a8/\u505c\u6b62\u5de5\u4f5c\u65b9\u5f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34097400704645925, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.36464267153587787, "HuggingFaceH4/zephyr-7b-beta": 0.8618893180378286, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.490753421435364, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5027260848190098}}, {"question": "\u6cf5\u623f\u5185\u7ba1\u9053\u7ba1\u5916\u5e95\u8ddd\u5730\u9762\u7684\u8ddd\u79bb\uff0c\u5f53\u7ba1\u5f84DN\u2264150mm\u65f6\uff0c\u4e0d\u5e94\u5c0f\u4e8e____\uff1b\u5f53\u7ba1\u5f84DN\u2265200mm\u65f6\uff0c\u4e0d\u5e94\u5c0f\u4e8e____\u3002\nA. 0.20m\uff1b0.25m\nB. 0.30m\uff1b0.35m\nC. 0.20m\uff1b0.30m\nD. 0.15m\uff1b0.25m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2772747813211935, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6709\u5173\u6d88\u9632\u6c34\u6cf5\u63a5\u5408\u5668\u5b89\u88c5\u8bf4\u6cd5\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u5899\u58c1\u6c34\u6cf5\u63a5\u5408\u5668\u5b89\u88c5\u9ad8\u5ea6\u8ddd\u5730\u9762\u5b9c\u4e3a1.1m\nB. \u7ec4\u88c5\u65f6\u6d88\u9632\u6c34\u6cf5\u63a5\u5408\u5668\u7684\u5b89\u88c5\uff0c\u5e94\u6309\u63a5\u53e3\u3001\u672c\u4f53\u3001\u63a5\u8fde\u7ba1\u3001\u6b62\u56de\u9600\u3001\u5b89\u5168\u9600\u3001\u653e\u7a7a\u7ba1\u3001\u63a7\u5236\u9600\u7684\u987a\u5e8f\u8fdb\u884c\nC. \u6b62\u56de\u9600\u7684\u5b89\u88c5\u65b9\u5411\u5e94\u4f7f\u6d88\u9632\u7528\u6c34\u80fd\u4ece\u6d88\u9632\u6c34\u6cf5\u63a5\u5408\u5668\u8fdb\u5165\u7cfb\u7edf\nD. \u6d88\u9632\u6c34\u6cf5\u63a5\u5408\u5668\u63a5\u53e3\u8ddd\u79bb\u5ba4\u5916\u6d88\u706b\u6813\u6216\u6d88\u9632\u6c34\u6c60\u7684\u8ddd\u79bb\u5b9c\u4e3a15\uff5e40m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3148300531811561, "meta-math/MetaMath-Mistral-7B": 0.4181874540337694, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u5e94\u6025\u907f\u96be\u573a\u6240\u5b89\u88c5\u6d88\u9632\u5e94\u6025\u7167\u660e\u548c\u758f\u6563\u6307\u793a\u7cfb\u7edf\u7b49\u6d88\u9632\u8bbe\u65bd\uff0c\u5bf9\u4e8e\u9762\u79ef\u5927\u4e8e____\u7684\u9632\u706b\u5206\u533a\u5e94\u5355\u72ec\u8bbe\u7f6e\u5e94\u6025\u7167\u660e\u914d\u7535\u7bb1\u6216\u5e94\u6025\u7167\u660e\u5206\u914d\u7535\u88c5\u7f6e\u3002\nA. 1000m^2\nB. 2000m^2\nC. 2500m^2\nD. 3000m^2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3287145937103622, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.33424000363035195, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4423863496854548}}, {"question": "\u67d0\u6d88\u9632\u8bbe\u65bd\u68c0\u6d4b\u673a\u6784\u5bf9\u5efa\u7b51\u5185\u706b\u707e\u81ea\u52a8\u62a5\u8b66\u7cfb\u7edf\u8fdb\u884c\u68c0\u6d4b\u65f6\uff0c\u5bf9\u624b\u52a8\u706b\u707e\u62a5\u8b66\u6309\u94ae\u8fdb\u884c\u68c0\u67e5\u3002\u6839\u636e\u73b0\u884c\u56fd\u5bb6\u6d88\u9632\u6280\u672f\u6807\u51c6\uff0c\u5173\u4e8e\u624b\u52a8\u706b\u707e\u62a5\u8b66\u6309\u94ae\u5b89\u88c5\u7684\u505a\u6cd5\uff0c\u4e0b\u5217\u9009\u9879\u4e2d\u4e0d\u7b26\u5408\u89c4\u8303\u8981\u6c42\u7684\u662f____\u3002\nA. \u5899\u4e0a\u624b\u52a8\u706b\u707e\u62a5\u8b66\u6309\u94ae\u7684\u5e95\u8fb9\u8ddd\u79bb\u697c\u9762\u9ad8\u5ea6\u4e3a1.5m\nB. \u624b\u52a8\u706b\u707e\u62a5\u8b66\u6309\u94ae\u7684\u8fde\u63a5\u5bfc\u7ebf\u7684\u4f59\u91cf\u4e3a150mm\nC. \u5899\u4e0a\u624b\u52a8\u706b\u707e\u62a5\u8b66\u6309\u94ae\u7684\u5e95\u8fb9\u8ddd\u79bb\u697c\u9762\u9ad8\u5ea6\u4e3a1.3m\nD. \u624b\u52a8\u706b\u707e\u62a5\u8b66\u6309\u94ae\u7684\u8fde\u63a5\u5bfc\u7ebf\u7684\u4f59\u91cf\u4e3a100mm\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5382\u623f\u5185\u8bbe\u7f6e\u7532\u3001\u4e59\u7c7b\u4e2d\u95f4\u4ed3\u5e93\u65f6\uff0c\u5176\u50a8\u91cf\u4e0d\u5b9c\u8d85\u8fc7____\u7684\u9700\u8981\u91cf\u3002\nA. \u4e00\u5929\nB. \u4e24\u5929\nC. \u4e00\u591c\nD. \u4e00\u663c\u591c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3220562534414596, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3919626083521393, "HuggingFaceH4/zephyr-7b-beta": 0.9537759497749386, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5140406481421704, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u603b\u5efa\u7b51\u9762\u79ef\u5927\u4e8e20000m^2\u7684\u5730\u4e0b\u6216\u534a\u5730\u4e0b\u5546\u4e1a\u8425\u4e1a\u5385\uff0c\u5e94\u91c7\u7528\u65e0\u95e8\u3001\u7a97\u3001\u6d1e\u53e3\u7684\u9632\u706b\u5899\u3001\u8010\u706b\u6781\u9650\u4e0d\u4f4e\u4e8e____h\u7684\u697c\u677f\u5206\u9694\u4e3a\u591a\u4e2a\u5efa\u7b51\u9762\u79ef\u4e0d\u5927\u4e8e____m^2\u7684\u533a\u57df\u3002\nA. 1.0\uff0c10000\nB. 1.5\uff0c15000\nC. 2.0\uff0c20000\nD. 2.5\uff0c25000\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3626062801770276, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9676062750923801, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.44304481397371914, "meta-llama/Meta-Llama-3-8B": 0.35888231301687173, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5996737378435757}}, {"question": "\u4e0b\u5217\u4e0d\u5c5e\u4e8e\u62a5\u8b66\u53d7\u7406\u7cfb\u7edf\u8f6f\u4ef6\u68c0\u67e5\u5185\u5bb9\u7684\u662f____\u3002\nA. \u7528\u6237\u4fe1\u606f\u4f20\u8f93\u88c5\u7f6e\u6a21\u62df\u624b\u52a8\u62a5\u8b66\u4fe1\u606f\uff0c\u7ecf\u62a5\u8b66\u53d7\u7406\u7cfb\u7edf\u53d7\u7406\u786e\u8ba4\u4ee5\u540e\uff0c\u68c0\u67e5\u706b\u8b66\u4fe1\u606f\u7ec8\u7aef\u80fd\u5426\u63a5\u6536\u3001\u663e\u793a\u3001\u8bb0\u5f55\u53ca\u67e5\u8be2\u76d1\u63a7\u4e2d\u5fc3\u62a5\u8b66\u53d7\u7406\u7cfb\u7edf\u53d1\u9001\u7684\u706b\u707e\u62a5\u8b66\u4fe1\u606f\nB. \u7528\u6237\u4fe1\u606f\u4f20\u8f93\u88c5\u7f6e\u6a21\u62df\u62a5\u8b66\uff0c\u68c0\u67e5\u62a5\u8b66\u53d7\u7406\u7cfb\u7edf\u80fd\u5426\u5bf9\u706b\u707e\u62a5\u8b66\u4fe1\u606f\u8fdb\u884c\u786e\u8ba4\u548c\u8bb0\u5f55\u5f52\u6863\nC. \u7528\u6237\u4fe1\u606f\u4f20\u8f93\u88c5\u7f6e\u6a21\u62df\u62a5\u8b66\uff0c\u68c0\u67e5\u62a5\u8b66\u53d7\u7406\u7cfb\u7edf\u80fd\u5426\u63a5\u6536\u3001\u663e\u793a\u3001\u8bb0\u5f55\u53ca\u67e5\u8be2\u7528\u6237\u4fe1\u606f\u4f20\u8f93\u88c5\u7f6e\u53d1\u9001\u7684\u706b\u707e\u62a5\u8b66\u4fe1\u606f\u3001\u5efa\u7b51\u6d88\u9632\u8bbe\u65bd\u8fd0\u884c\u72b6\u6001\u4fe1\u606f\nD. \u7528\u6237\u4fe1\u606f\u4f20\u8f93\u88c5\u7f6e\u6a21\u62df\u624b\u52a8\u62a5\u8b66\u4fe1\u606f\uff0c\u68c0\u67e5\u62a5\u8b66\u53d7\u7406\u7cfb\u7edf\u80fd\u5426\u5c06\u4fe1\u606f\u4e0a\u62a5\u81f3\u706b\u8b66\u4fe1\u606f\u7ec8\u7aef\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4535223341046808, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u706b\u7130\u4e2d\u88ab\u71c3\u70e7\uff0c\u4e00\u5b9a\u65f6\u95f4\u5185\u4ecd\u80fd\u6b63\u5e38\u8fd0\u884c\u7684\u7535\u7f06\u662f____\u3002\nA. \u4e00\u822c\u963b\u71c3\u7535\u7f06\nB. \u4f4e\u70df\u4f4e\u5364\u963b\u71c3\u7535\u7f06\nC. \u65e0\u5364\u963b\u71c3\u7535\u7f06\nD. \u8010\u706b\u7535\u7f06\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.43114881263123844, "meta-math/MetaMath-Mistral-7B": 0.7245175647160856, "itpossible/Chinese-Mistral-7B-v0.1": 0.7620353707890359, "HuggingFaceH4/zephyr-7b-beta": 0.9507116940935146, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.783406814213445, "meta-llama/Meta-Llama-3-8B": 0.32871459371036227, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5730552181801112}}, {"question": "\u5176\u4ed6\u6c14\u4f53\u706d\u706b\u7cfb\u7edf\u8bbe\u8ba1\u4e2d\uff0c\u540c\u4e00\u9632\u62a4\u533a\u5185\u7684\u9884\u5236\u706d\u706b\u7cfb\u7edf\u88c5\u7f6e\u591a\u4e8e1\u53f0\u65f6\uff0c\u5fc5\u987b\u80fd\u540c\u65f6\u542f\u52a8\uff0c\u5176\u52a8\u4f5c\u54cd\u5e94\u65f6\u5dee\u4e0d\u5f97\u5927\u4e8e____s\u3002\nA. 1\nB. 2\nC. 15\nD. 30\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0.9115755957628302, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.43913053677182107, "meta-llama/Meta-Llama-3-8B": 0.371068906204966, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7323188925608028}}, {"question": "\u4e0b\u5217\u6709\u5173\u5ba4\u5916\u6d88\u706b\u6813\u7684\u8bf4\u6cd5\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u5efa\u7b51\u5ba4\u5916\u6d88\u706b\u6813\u7684\u4fdd\u62a4\u534a\u5f84\u4e0d\u5e94\u5927\u4e8e150m\nB. \u5de5\u827a\u88c5\u7f6e\u533a\u91c7\u7528\u9ad8\u538b\u6d88\u9632\u7ed9\u6c34\u7cfb\u7edf\uff0c\u5176\u5468\u56f4\u5e94\u8bbe\u7f6e\u5ba4\u5916\u6d88\u706b\u6813\uff0c\u6d88\u706b\u6813\u7684\u95f4\u8ddd\u4e0d\u5e94\u5927\u4e8e60m\nC. \u505c\u8f66\u573a\u7684\u5ba4\u5916\u6d88\u706b\u6813\u4e0e\u6700\u8fd1\u4e00\u6392\u6c7d\u8f66\u7684\u8ddd\u79bb\u4e0d\u5b9c\u5c0f\u4e8e7m\nD. \u8ddd\u7532\u7c7b\u6db2\u4f53\u56fa\u5b9a\u9876\u50a8\u7f50\u7f50\u58c120m\u8303\u56f4\u5185\u7684\u5ba4\u5916\u6d88\u706b\u6813\uff0c\u4e0d\u5e94\u8ba1\u7b97\u5728\u8be5\u7f50\u53ef\u4f7f\u7528\u7684\u6570\u91cf\u5185\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5125245808963474, "meta-math/MetaMath-Mistral-7B": 0.5457546110696165, "itpossible/Chinese-Mistral-7B-v0.1": 0.5451708313080267, "HuggingFaceH4/zephyr-7b-beta": 0.9997649916948548, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7812640920240044, "meta-llama/Meta-Llama-3-8B": 0.31483005318115603, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u4f7f\u7528\u573a\u6240\u4e0d\u540c\uff0c\u95ed\u5f0f\u7ec6\u6c34\u96fe\u706d\u706b\u7cfb\u7edf\u53ef\u4ee5\u5206\u4e3a____\u79cd\u5f62\u5f0f\u3002\nA. 2\nB. 3\nC. 4\nD. 5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.36676408062637145, "meta-math/MetaMath-Mistral-7B": 0.4318600061456281, "itpossible/Chinese-Mistral-7B-v0.1": 0.3647618879011802, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6613\u71c3\u6750\u6599\u7684\u9732\u5929\u5806\u573a\u5b9c\u8bbe\u7f6e\u5728\u5929\u7136\u6c34\u6e90\u5145\u8db3\u7684\u5730\u65b9\uff0c\u5e76\u5b9c\u5e03\u7f6e\u5728\u672c\u5355\u4f4d\u6216\u672c\u5730\u533a\u5168\u5e74\u6700\u5c0f\u9891\u7387\u98ce\u5411\u7684____\u3002\nA. \u4e0a\u98ce\u4fa7\nB. \u4e0b\u98ce\u4fa7\nC. \u4fa7\u98ce\u5411\nD. \u4e0b\u98ce\u6216\u4fa7\u98ce\u5411\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5034277857014513}}, {"question": "\u4e0b\u5217\u8bbe\u65bd\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u6d88\u9632\u8f66\u53d6\u6c34\u7528\u7684\u8bbe\u65bd\u662f____\u3002\nA. \u5e02\u653f\u6d88\u706b\u6813\nB. \u6c34\u6cf5\u63a5\u5408\u5668\nC. \u6d88\u9632\u6c34\u6c60\u53d6\u6c34\u53e3\nD. \u6d88\u9632\u6c34\u9e64\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3468666740605408, "meta-math/MetaMath-Mistral-7B": 0.3788073893731991, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6700\u5c0f\u70b9\u706b\u80fd\u91cf\u662f\u6307\u6bcf\u4e00\u79cd\u6c14\u4f53\u7206\u70b8\u6df7\u5408\u7269\uff0c\u5176\u8d77\u7206\u6240\u9700\u7684____\u70b9\u706b\u80fd\u91cf\u3002\nA. \u6700\u5c0f\nB. \u6700\u5927\nC. \u6700\u5c11\nD. \u6700\u591a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.49720786924396193, "meta-math/MetaMath-Mistral-7B": 0.8263087039164897, "itpossible/Chinese-Mistral-7B-v0.1": 0.7902353139439691, "HuggingFaceH4/zephyr-7b-beta": 0.8586826137813415, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4474128837848782, "meta-llama/Meta-Llama-3-8B": 0.5613323580077196, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.887926126233283}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u7535\u5b50\u4fe1\u606f\u673a\u623f\u706d\u706b\u7cfb\u7edf\u7684\u8bbe\u7f6e\u8bf4\u6cd5\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. A\u7ea7\u4fe1\u606f\u673a\u623f\u7684\u4e3b\u673a\u623f\u5e94\u8bbe\u7f6e\u6d01\u51c0\u6c14\u4f53\u706d\u706b\u7cfb\u7edf\nB. B\u7ea7\u4fe1\u606f\u673a\u623f\u7684\u4e3b\u673a\u623f\uff0c\u4ee5\u53caA\u7ea7\u548cB\u7ea7\u673a\u623f\u4e2d\u7684\u53d8\u914d\u7535\u3001\u4e0d\u95f4\u65ad\u7535\u6e90\u7cfb\u7edf\u548c\u7535\u6c60\u5ba4\uff0c\u9664\u4e86\u53ef\u8bbe\u7f6e\u6d01\u51c0\u6c14\u4f53\u706d\u706b\u7cfb\u7edf\uff0c\u4e5f\u53ef\u8bbe\u7f6e\u9ad8\u538b\u7ec6\u6c34\u96fe\u706d\u706b\u7cfb\u7edf\nC. C\u7ea7\u4fe1\u606f\u673a\u623f\u53ca\u5176\u4ed6\u533a\u57df\uff0c\u53ef\u8bbe\u7f6e\u9ad8\u538b\u7ec6\u6c34\u96fe\u706d\u706b\u7cfb\u7edf\u6216\u81ea\u52a8\u55b7\u6c34\u706d\u706b\u7cfb\u7edf\uff0c\u81ea\u52a8\u55b7\u6c34\u706d\u706b\u7cfb\u7edf\u5b9c\u91c7\u7528\u6e7f\u5f0f\u81ea\u52a8\u55b7\u6c34\u706d\u706b\u7cfb\u7edf\nD. \u51e1\u8bbe\u7f6e\u56fa\u5b9a\u706d\u706b\u7cfb\u7edf\u53ca\u706b\u707e\u63a2\u6d4b\u5668\u7684\u8ba1\u7b97\u673a\u623f\uff0c\u5176\u540a\u9876\u7684\u4e0a\u3001\u4e0b\u7ea7\u6d3b\u52a8\u5730\u677f\u4e0b\uff0c\u5747\u5e94\u8bbe\u7f6e\u63a2\u6d4b\u5668\u548c\u55b7\u5634\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u3001\u4e8c\u7ea7\u8010\u706b\u7b49\u7ea7\u5efa\u7b51\u7684\u4e0a\u4eba\u5e73\u5c4b\u9876\uff0c\u5176\u5c4b\u9762\u7684\u8010\u706b\u7b49\u7ea7\u5206\u522b\u4e0d\u5e94\u4f4e\u4e8e____\u548c____\u3002\nA. 1.00h\uff0c1.00h\nB. 1.50h\uff0c1.50h\nC. 1.50h\uff0c1.00h\nD. 1.00h\uff0c2.00h\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3548205732608227, "meta-math/MetaMath-Mistral-7B": 0.47343779351963483, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6381040165767919, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3602912416786143, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3392357736068919}}, {"question": "\u7cfb\u7edf\u7684\u5468\u671f\u6027\u68c0\u67e5\u7ef4\u62a4\u4e2d\uff0c\u6bcf\u5b63\u5ea6\u81f3\u5c11\u8fdb\u884c\u4e00\u6b21\u68c0\u67e5\u4e0e\u7ef4\u62a4\u7684\u662f____\u3002\nA. \u55b7\u5934\u5b8c\u597d\u60c5\u51b5\nB. \u62a5\u8b66\u9600\u7ec4\u7684\u8bd5\u6c34\u9600\u653e\u6c34\u53ca\u5176\u542f\u52a8\u6027\u80fd\u6d4b\u8bd5\nC. \u7535\u78c1\u9600\u542f\u52a8\u6d4b\u8bd5\nD. \u6c34\u6cf5\u63a5\u5408\u5668\u901a\u6c34\u52a0\u538b\u6d4b\u8bd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29972404264597124, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5602456956967775, "HuggingFaceH4/zephyr-7b-beta": 0.9459719177908773, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6437934317634407, "meta-llama/Meta-Llama-3-8B": 0.35096048266444385, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6834552049694461}}, {"question": "\u5173\u4e8e\u7206\u70b8\u6781\u9650\u5728\u6d88\u9632\u4e0a\u7684\u5e94\u7528\uff0c\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\u3002\nA. \u7206\u70b8\u6781\u9650\u662f\u8bc4\u5b9a\u53ef\u71c3\u6c14\u4f53\u706b\u707e\u5371\u9669\u6027\u5927\u5c0f\u7684\u4f9d\u636e\nB. \u7206\u70b8\u8303\u56f4\u8d8a\u5927\uff0c\u4e0b\u9650\u8d8a\u4f4e\uff0c\u706b\u707e\u5371\u9669\u6027\u5c31\u8d8a\u5927\nC. \u6839\u636e\u7206\u70b8\u6781\u9650\u53ef\u4ee5\u786e\u5b9a\u5efa\u7b51\u7269\u8010\u706b\u7b49\u7ea7\u3001\u5c42\u6570\u3001\u5b89\u5168\u758f\u6563\u8ddd\u79bb\u7b49\nD. \u751f\u4ea7\u3001\u50a8\u5b58\u7206\u70b8\u4e0b\u9650\uff1e10%\u7684\u53ef\u71c3\u6c14\u4f53\uff0c\u5e94\u9009\u7528\u9694\u7206\u578b\u9632\u7206\u7535\u6c14\u8bbe\u5907\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u5b66\u6821\u4e3a\u843d\u5b9e\u6d88\u9632\u5b89\u5168\u6559\u80b2\u5de5\u4f5c\uff0c\u9488\u5bf9\u4e0d\u540c\u5e74\u9f84\u6bb5\u7684\u5b66\u751f\u5206\u6279\u5f00\u5c55\u6d88\u9632\u5b89\u5168\u5ba3\u4f20\u5de5\u4f5c\u3002\u5728\u5404\u7ea7\u5404\u7c7b\u5b66\u6821\u5f00\u5c55\u7684\u6d88\u9632\u5b89\u5168\u5de5\u4f5c\u4e2d\uff0c\u6bcf\u540d\u5b66\u751f\u5728\u6821\u671f\u95f4\u53c2\u52a0\u6d88\u9632\u5b89\u5168\u5fd7\u613f\u6d3b\u52a8\u5e94\u4e0d\u5c11\u4e8e____\u3002\nA. 4h\nB. 6h\nC. 8h\nD. 12h\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u5927\u578b\u5382\u623f\u65bd\u5de5\u73b0\u573a\uff0c\u5728\u7528\u7535\u9632\u706b\u65b9\u9762\u7684\u4e0b\u5217\u505a\u6cd5\u4e2d\uff0c\u7b26\u5408\u73b0\u884c\u56fd\u5bb6\u6807\u51c6\u8981\u6c42\u7684\u662f____\u3002\nA. \u5806\u653e\u7684\u53ef\u71c3\u7269\uff0c\u8ddd\u914d\u7535\u5c4f1.8m\nB. \u4ea7\u751f\u7c89\u5c18\u7684\u4f5c\u4e1a\u533a\u8ddd\u914d\u7535\u5c4f6m\nC. \u666e\u901a\u706f\u5177\u4e0e\u6613\u71c3\u7269\u7684\u8ddd\u79bb\u4e3a0.2m\nD. \u7898\u94a8\u706f\u5177\u4e0e\u6613\u71c3\u7269\u7684\u8ddd\u79bb\u4e3a0.4m\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4481816869726561, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2821833983601387, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5287974605764875}}, {"question": "\u4e0b\u5217\u51e0\u79cd\u5e38\u89c1\u7684\u6613\u71c3\u6216\u53ef\u71c3\u6db2\u4f53\u4e2d\uff0c\u706b\u707e\u5371\u9669\u6027\u6700\u5927\u7684\u662f____\u3002\nA. \u7532\u9187\nB. \u9152\u7cbe\nC. \u4e19\u916e\nD. \u82ef\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u5355\u4f4d\u5bf9\u81ea\u52a8\u55b7\u6c34\u706d\u706b\u7cfb\u7edf\u7684\u62a5\u8b66\u9600\u5bc6\u5c01\u6027\u8fdb\u884c\u6d4b\u8bd5\u65f6\uff0c\u505a\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u8bd5\u9a8c\u538b\u529b\u4e3a3.0MPa\uff0c\u4fdd\u538b\u65f6\u95f4\u4e0d\u5c11\u4e8e3min\nB. \u8bd5\u9a8c\u538b\u529b\u4e3a3.0MPa\uff0c\u4fdd\u538b\u65f6\u95f4\u4e0d\u5c11\u4e8e5min\nC. \u8bd5\u9a8c\u538b\u529b\u4e3a\u989d\u5b9a\u5de5\u4f5c\u538b\u529b2\u500d\u7684\u9759\u6c34\u538b\u529b\uff0c\u4fdd\u538b\u65f6\u95f4\u4e0d\u5c11\u4e8e5min\nD. \u8bd5\u9a8c\u538b\u529b\u4e3a\u989d\u5b9a\u5de5\u4f5c\u538b\u529b2\u500d\u7684\u9759\u6c34\u538b\u529b\uff0c\u4fdd\u538b\u65f6\u95f4\u4e0d\u5c11\u4e8e3min\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3527809287490976, "meta-math/MetaMath-Mistral-7B": 0.4836780308315078, "itpossible/Chinese-Mistral-7B-v0.1": 0.334240003630352, "HuggingFaceH4/zephyr-7b-beta": 0.6454835028184238, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5637559329377879, "meta-llama/Meta-Llama-3-8B": 0.3749196223738778, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8494958311381731}}, {"question": "\u706b\u707e\u81ea\u52a8\u62a5\u8b66\u7cfb\u7edf\u5bf9\u706b\u707e\u58f0\u5149\u8b66\u62a5\u5668\u8fdb\u884c\u8c03\u8bd5\uff0c\u9010\u4e00\u5c06\u706b\u707e\u58f0\u5149\u8b66\u62a5\u5668\u4e0e\u706b\u707e\u62a5\u8b66\u63a7\u5236\u5668\u76f8\u8fde\uff0c\u63a5\u901a\u7535\u6e90\u3002\u64cd\u4f5c\u706b\u707e\u62a5\u8b66\u63a7\u5236\u5668\u4f7f\u706b\u707e\u58f0\u5149\u8b66\u62a5\u5668\u542f\u52a8\uff0c\u706b\u707e\u58f0\u5149\u8b66\u62a5\u5668\u7684\u5149\u4fe1\u53f7\u5728100\uff5e500lx\u73af\u5883\u5149\u7ebf\u4e0b____m\u5904\u5e94\u6e05\u6670\u53ef\u89c1\u3002\nA. 15\nB. 25\nC. 35\nD. 45\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.28108825044289903, "meta-math/MetaMath-Mistral-7B": 0.371068906204966, "itpossible/Chinese-Mistral-7B-v0.1": 0.3060136256597631, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.36464267153587787, "meta-llama/Meta-Llama-3-8B": 0.36150852560561064, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.455131632749541}}, {"question": "\u67d0\u5546\u573a\u50a8\u5b58\u95f4\u50a8\u5b58\u6709\u6a1f\u8111\u3001\u677e\u9999\u3001\u690d\u7269\u98df\u7528\u6cb9\u548c\u6ce1\u6cab\u5851\u6599\u7b49\u7269\u54c1\uff0c\u5219\u8be5\u50a8\u5b58\u95f4\u7684\u706b\u707e\u5371\u9669\u6027\u5e94\u4e3a____\u3002\nA. \u7532\u7c7b\nB. \u4e59\u7c7b\nC. \u4e19\u7c7b\nD. \u4e01\u7c7b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.28108825044289903, "itpossible/Chinese-Mistral-7B-v0.1": 0.3160424181481997, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2575712446970197, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u706b\u707e\u81ea\u52a8\u62a5\u8b66\u7cfb\u7edf\u53ef\u71c3\u6c14\u4f53\u63a2\u6d4b\u5668\uff0c\u64a4\u53bb\u53ef\u71c3\u6c14\u4f53\uff0c\u63a2\u6d4b\u5668\u5e94\u5728____\u5185\u6062\u590d\u5230\u6b63\u5e38\u76d1\u89c6\u72b6\u6001\u3002\nA. 60s\nB. 80s\nC. 100s\nD. 120s\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3035988665653362, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.3728641753223836}}, {"question": "\u6d88\u9632\u63a7\u5236\u5ba4\u5b9e\u884c\u6bcf\u65e524h\u4e13\u4eba\u503c\u73ed\u5236\u5ea6\uff0c\u6bcf\u73ed\u4e0d\u5c11\u4e8e____\uff0c\u503c\u73ed\u4eba\u5458\u6301\u6709\u89c4\u5b9a\u7684\u6d88\u9632\u4e13\u4e1a\u6280\u80fd\u9274\u5b9a\u8bc1\u4e66\u3002\nA. 1\u4eba\nB. 2\u4eba\nC. 3\u4eba\nD. 4\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.29539205153207015, "itpossible/Chinese-Mistral-7B-v0.1": 0.3671700228158849, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.40870097338816025, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5132584120243519}}, {"question": "\u6839\u636e\u300a\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u58f0\u73af\u5883\u300b(HJ2.4\u20142009)\uff0c\u4ee5\u7403\u9762\u6ce2\u5f62\u5f0f\u8f90\u5c04\u6ce2\u7684\u58f0\u6e90\uff0c\u8f90\u5c04\u58f0\u6ce2\u7684\u58f0\u538b\u5e45\u503c\u4e0e\u58f0\u6ce2\u4f20\u64ad\u8ddd\u79bb____\u3002\nA. \u6210\u6b63\u6bd4\nB. \u6210\u53cd\u6bd4\nC. \u65e0\u5173\u7cfb\nD. \u6210\u5e73\u65b9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4283660585802814, "meta-math/MetaMath-Mistral-7B": 0.5604219915922625, "itpossible/Chinese-Mistral-7B-v0.1": 0.3404063441575017, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6153421576782531, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7676778159150013}}, {"question": "\u6839\u636e\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u98ce\u9669\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u300b(HJ169\u20142018)\uff0c\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u98ce\u9669\u6f5c\u52bf\u5212\u5206\u4e3a____\u7ea7\u3002\nA. \u2160\u3001\u2161\u3001\u2162\u3001\u2163\u3001\u2164\nB. \u2160\u3001\u2161\u3001\u2162\u3001\u2163V/\u2163+\nC. \u2160\u3001\u2161\u3001\u2162\u3001\u2163\nD. \u2160\u3001\u2161\u3001\u2162\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2731272040287072, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36150852560561064, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u5927\u6c14\u73af\u5883\u300b(HJ2.2\u20142018)\uff0c\u5728\u91c7\u7528\u8865\u5145\u76d1\u6d4b\u6570\u636e\u8fdb\u884c\u73b0\u72b6\u8bc4\u4ef7\u7684\uff0c\u5bf9\u4e8e\u6709\u591a\u4e2a\u76d1\u6d4b\u70b9\u4f4d\u6570\u636e\u7684\uff0c____\u4f5c\u4e3a\u8bc4\u4ef7\u8303\u56f4\u5185\u73af\u5883\u7a7a\u6c14\u4fdd\u62a4\u76ee\u6807\u53ca\u7f51\u683c\u70b9\u73af\u5883\u8d28\u91cf\u73b0\u72b6\u6d53\u5ea6\u3002\nA. \u5148\u8ba1\u7b97\u4e0d\u540c\u65f6\u523b\u5404\u76d1\u6d4b\u70b9\u4f4d\u5e73\u5747\u503c\uff0c\u518d\u53d6\u5404\u76d1\u6d4b\u65f6\u6bb5\u5e73\u5747\u503c\nB. \u5148\u8ba1\u7b97\u4e0d\u540c\u65f6\u523b\u5404\u76d1\u6d4b\u70b9\u4f4d\u5e73\u5747\u503c\uff0c\u518d\u53d6\u5404\u76d1\u6d4b\u65f6\u6bb5\u5e73\u5747\u503c\u4e2d\u7684\u6700\u5927\u503c\nC. \u5148\u8ba1\u7b97\u4e0d\u540c\u65f6\u523b\u5404\u76d1\u6d4b\u70b9\u4f4d\u5e73\u5747\u503c\uff0c\u518d\u53d6\u5404\u76d1\u6d4b\u65f6\u6bb5\u5e73\u5747\u503c\u4e2d\u7684\u6700\u5c0f\u503c\nD. \u5148\u8ba1\u7b97\u76f8\u540c\u65f6\u523b\u5404\u76d1\u6d4b\u70b9\u4f4d\u5e73\u5747\u503c\uff0c\u518d\u53d6\u5404\u76d1\u6d4b\u65f6\u6bb5\u5e73\u5747\u503c\u4e2d\u7684\u6700\u5927\u503c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6244219463755852, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6cd5\u300b\uff0c\u4f5c\u4e3a\u4e00\u9879\u6574\u4f53\u5efa\u8bbe\u9879\u76ee\u7684\u67d0\u5927\u578b\u4f4f\u5b85\u5c0f\u533a\uff0c\u5e94\u8fdb\u884c____\u3002\nA. \u89c4\u5212\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\nB. \u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\nC. \u89c4\u5212\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u548c\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\nD. \u65e0\u9700\u8fdb\u884c\u4efb\u4f55\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6cd5\u300b\uff0c\u73af\u5883\u5f71\u54cd\u62a5\u544a\u4e66\u9664\u5305\u62ec\u5b9e\u65bd\u8be5\u89c4\u5212\u5bf9\u73af\u5883\u53ef\u80fd\u9020\u6210\u5f71\u54cd\u7684\u5206\u6790\u3001\u9884\u6d4b\u548c\u8bc4\u4f30\uff1b\u9884\u9632\u6216\u8005\u51cf\u8f7b\u4e0d\u826f\u73af\u5883\u5f71\u54cd\u7684\u5bf9\u7b56\u548c\u63aa\u65bd\u5916\uff0c\u8fd8\u5e94\u5f53\u5305\u62ec____\u3002\nA. \u89c4\u5212\u5185\u5bb9\nB. \u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u7ed3\u8bba\nC. \u8be6\u7ec6\u89c4\u5212\u60c5\u51b5\nD. \u89c4\u5212\u60c5\u51b5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6020646642567493, "meta-math/MetaMath-Mistral-7B": 0.9435526153722359, "itpossible/Chinese-Mistral-7B-v0.1": 0.36150852560561064, "HuggingFaceH4/zephyr-7b-beta": 0.9271834758343038, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9157895013376456, "meta-llama/Meta-Llama-3-8B": 0.6912325371145138, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9461651531603579}}, {"question": "\u5728\u666f\u89c2\u4fdd\u62a4\u63aa\u65bd\u4e2d\uff0c\u5bf9\u5efa\u8bbe\u9879\u76ee\u7684\u57fa\u672c\u8981\u6c42\u662f____\u3002\nA. \u505a\u597d\u666f\u89c2\u8bbe\u8ba1\nB. \u4e3a\u666f\u89c2\u9879\u76ee\u7684\u7814\u7a76\u505a\u51c6\u5907\nC. \u4e0d\u5efa\u9020\u4e0d\u826f\u666f\u89c2\nD. \u7b26\u5408\u751f\u6001\u89c4\u5f8b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6944068013996771, "meta-math/MetaMath-Mistral-7B": 0.8449126589410466, "itpossible/Chinese-Mistral-7B-v0.1": 0.8263087103324511, "HuggingFaceH4/zephyr-7b-beta": 0.9952352367257236, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8224343281921089, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9828145493034616}}, {"question": "\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u8349\u539f\u6cd5\u300b\uff0c\u56fd\u5bb6\u5bf9\u8349\u539f\u4fdd\u62a4\u3001\u5efa\u8bbe\u3001\u5229\u7528\u5b9e\u884c____\u3002\u56fd\u52a1\u9662\u8349\u539f\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u4f1a\u540c\u56fd\u52a1\u9662\u6709\u5173\u90e8\u95e8\u7f16\u5236\u5168\u56fd\u8349\u539f\u4fdd\u62a4\u3001\u5efa\u8bbe\u3001\u5229\u7528\u89c4\u5212\uff0c\u62a5\u56fd\u52a1\u9662\u6279\u51c6\u540e\u5b9e\u65bd\u3002\nA. \u5206\u5730\u57df\u89c4\u5212\u5236\u5ea6\nB. \u5206\u6d41\u57df\u89c4\u5212\u5236\u5ea6\nC. \u7edf\u4e00\u89c4\u5212\u5236\u5ea6\nD. \u5730\u65b9\u89c4\u5212\u5236\u5ea6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5144422533592727, "meta-math/MetaMath-Mistral-7B": 0.8125982406517892, "itpossible/Chinese-Mistral-7B-v0.1": 0.7916459227791616, "HuggingFaceH4/zephyr-7b-beta": 0.9695309952242485, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.48181991740993835, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u751f\u6001\u5f71\u54cd\u300b(HJ19\u20142011)\uff0c\u751f\u6001\u73b0\u72b6\u8bc4\u4ef7\u6d89\u53ca\u53d7\u4fdd\u62a4\u7684\u654f\u611f\u7269\u79cd\u65f6\uff0c\u5e94\u91cd\u70b9\u5206\u6790\u8be5\u654f\u611f\u7269\u79cd\u7684____\u3002\nA. \u751f\u6001\u5b66\u7279\u5f81\nB. \u7ed3\u6784\nC. \u53d8\u5316\u8d8b\u52bf\nD. \u529f\u80fd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.45294469597223297, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.4656430048571539, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4566948735620177}}, {"question": "\u5de5\u4e1a\u6c61\u6c34\u751f\u4ea7\u5468\u671f\u57288h\u4ee5\u5185\u7684\uff0c\u6bcf____\u91c7\u6837\u4e00\u6b21\u3002\nA. 2h\nB. 4h\nC. 5h\nD. 6h\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u793e\u4f1a\u751f\u6d3b\u73af\u5883\u566a\u58f0\u6392\u653e\u6807\u51c6\u300b(GB22337\u20142008)\uff0c\u566a\u58f0\u6d4b\u91cf\u503c\u4e0e\u80cc\u666f\u566a\u58f0\u503c\u76f8\u5dee____\u65f6\uff0c\u566a\u58f0\u6d4b\u91cf\u503c\u4e0d\u505a\u4fee\u6b63\u3002\nA. \uff1e5dB(A)\nB. \uff1e8dB(A)\nC. \uff1e10dB(A)\nD. \uff1e15dB(A)\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3638582843838116, "meta-math/MetaMath-Mistral-7B": 0.5212060699896919, "itpossible/Chinese-Mistral-7B-v0.1": 0.333183235354062, "HuggingFaceH4/zephyr-7b-beta": 0.47949886303376593, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u56fa\u4f53\u5e9f\u7269\u6c61\u67d3\u73af\u5883\u9632\u6cbb\u6cd5\u300b\u7684\u6c61\u67d3\u9632\u6cbb\u5bf9\u8c61\u4e0d\u5305\u62ec____\u3002\nA. \u5371\u9669\u5e9f\u7269\nB. \u5de5\u4e1a\u56fa\u4f53\u5e9f\u7269\nC. \u6c14\u6001\u5e9f\u7269\nD. \u57ce\u5e02\u751f\u6d3b\u5783\u573e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.607061918974847, "meta-math/MetaMath-Mistral-7B": 0.9232685598454768, "itpossible/Chinese-Mistral-7B-v0.1": 0.7000143247657844, "HuggingFaceH4/zephyr-7b-beta": 0.8161946041486704, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8638175637822486, "meta-llama/Meta-Llama-3-8B": 0.9097287700762867, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9546613220753722}}, {"question": "\u6c34\u6e29\u89c2\u6d4b\u9891\u6b21\uff0c\u5e94\u6bcf\u95f4\u9694____h\u89c2\u6d4b\u4e00\u6b21\u6c34\u6e29\uff0c\u7edf\u8ba1\u8ba1\u7b97\u65e5\u5e73\u5747\u6c34\u6e29\u3002\nA. 2\nB. 4\nC. 6\nD. 8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3550009601731296, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8496179824902101, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.38834518361163584, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u603b\u7eb2\u300b(HJ2.1\u20142016)\uff0c\u73af\u5883\u8d28\u91cf\u4e0d\u8fbe\u6807\u7684\u533a\u57df\uff0c\u5e94\u91c7\u53d6\u56fd\u5185\u5916\u5148\u8fdb\u53ef\u884c\u7684\u73af\u5883\u4fdd\u62a4\u63aa\u65bd\uff0c\u7ed3\u5408____\u53ca\u5b9e\u65bd\u60c5\u51b5\uff0c\u5206\u6790\u5efa\u8bbe\u9879\u76ee\u5b9e\u65bd\u5bf9\u533a\u57df\u73af\u5883\u8d28\u91cf\u6539\u5584\u76ee\u6807\u7684\u8d21\u732e\u548c\u5f71\u54cd\u3002\nA. \u6574\u4f53\u8fbe\u6807\u89c4\u5212\nB. \u533a\u57df\u8fbe\u6807\u89c4\u5212\nC. \u6574\u4f53\u9650\u671f\u8fbe\u6807\u89c4\u5212\nD. \u533a\u57df\u9650\u671f\u8fbe\u6807\u89c4\u5212\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5678410674841494}}, {"question": "\u67d0\u7701\u5efa\u8bbe\u4e00\u516c\u8def\uff0c\u9700\u7ecf\u8fc7\u4e00\u81ea\u7136\u4fdd\u62a4\u533a\uff0c\u5219\u8be5\u5efa\u8bbe\u9879\u76ee\u7684\u8bc4\u4ef7\u7b49\u7ea7\u5e94\u4e3a____\u3002\nA. \u4e00\u7ea7\nB. \u4e8c\u7ea7\nC. \u4e09\u7ea7\nD. \u56db\u7ea7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.35898421896516036, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5730\u4e0b\u6c34\u6c61\u67d3\u6e90\u8c03\u67e5\u56e0\u5b50\u5e94\u6839\u636e\u62df\u5efa\u9879\u76ee\u7684____\u9009\u5b9a\u3002\nA. \u6c61\u67d3\u7279\u5f81\nB. \u6c61\u67d3\u6e90\u6027\u8d28\nC. \u6c61\u67d3\u534a\u5f84\nD. \u6c61\u67d3\u7269\u79cd\u7c7b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u9ad8\u901f\u516c\u8def\u5efa\u8bbe\u9879\u76ee\u7684\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\uff0c\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6cd5\u300b\uff0c\u5e94____\u3002\nA. \u76f4\u63a5\u62a5\u4ea4\u901a\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u5ba1\u6279\nB. \u76f4\u63a5\u62a5\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u5ba1\u6279\nC. \u7ecf\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u5ba1\u6838\u5e76\u7b7e\u7f72\u610f\u89c1\u540e\uff0c\u62a5\u4ea4\u901a\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u6279\u51c6\nD. \u7ecf\u4ea4\u901a\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u9884\u5ba1\u540e\uff0c\u62a5\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u5ba1\u6279\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4936746344025643, "meta-math/MetaMath-Mistral-7B": 0.7899251337655774, "itpossible/Chinese-Mistral-7B-v0.1": 0.4087872425417324, "HuggingFaceH4/zephyr-7b-beta": 0.7281248865728803, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8423608123784792, "meta-llama/Meta-Llama-3-8B": 0.48201928497326985, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.83185909811637}}, {"question": "\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6cd5\u300b\u548c\u300a\u89c4\u5212\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6761\u4f8b\u300b\uff0c\u89c4\u5212\u5ba1\u6279\u673a\u5173\u5bf9\u4f9d\u6cd5\u5e94\u5f53\u7f16\u5199\u800c\u672a\u7f16\u5199\u73af\u5883\u5f71\u54cd\u7bc7\u7ae0\u6216\u8005\u8bf4\u660e\u7684\u7efc\u5408\u6027\u89c4\u5212\u8349\u6848\uff0c\u4e88\u4ee5\u6279\u51c6\u7684\uff0c\u4e0a\u7ea7\u673a\u5173\u6216\u8005\u76d1\u5bdf\u673a\u5173\u4f9d\u6cd5\u5bf9____\u7ed9\u4e88\u884c\u653f\u5904\u5206\u3002\nA. \u89c4\u5212\u5ba1\u6279\u673a\u5173\nB. \u89c4\u5212\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u673a\u6784\nC. \u89c4\u5212\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u5ba1\u67e5\u673a\u6784\nD. \u89c4\u5212\u5ba1\u6279\u673a\u5173\u76f4\u63a5\u8d1f\u8d23\u7684\u4e3b\u7ba1\u4eba\u5458\u548c\u5176\u4ed6\u76f4\u63a5\u8d23\u4efb\u4eba\u5458\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8575124941851551, "meta-math/MetaMath-Mistral-7B": 0.9596811215452191, "itpossible/Chinese-Mistral-7B-v0.1": 0.8575666184165446, "HuggingFaceH4/zephyr-7b-beta": 0.9906853967616449, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9829271603109088, "meta-llama/Meta-Llama-3-8B": 0.8647190662836491, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9680351330259167}}, {"question": "\u6839\u636e\u300a\u6c61\u6c34\u7efc\u5408\u6392\u653e\u6807\u51c6\u300b(GB8978\u20141996)\uff0c\u4e3a\u5224\u5b9a\u4e0b\u5217\u6c61\u67d3\u7269\u662f\u5426\u8fbe\u6807\uff0c\u53ef\u5728\u6392\u6c61\u5355\u4f4d\u603b\u6392\u653e\u53e3\u91c7\u6837\u7684\u662f____\u3002\nA. \u82ef\u5e76[a]\u8298\nB. \u516d\u4ef7\u94ec\nC. \u603b\u94dc\nD. \u603b\u9549\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u71c3\u6cb9\u3001\u71c3\u6c14\u9505\u7089\u70df\u56f1\u9ad8\u5ea6\u5e94\u6309\u6279\u51c6\u7684\u73af\u5883\u5f71\u54cd\u62a5\u544a\u4e66(\u8868)\u8981\u6c42\u786e\u5b9a\uff0c\u4f46\u4e0d\u5f97\u4f4e\u4e8e____m\u3002\nA. 6\nB. 8\nC. 10\nD. 12\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6120843575431715}}, {"question": "\u6839\u636e\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u5206\u7ea7\u5ba1\u6279\u89c4\u5b9a\u300b\uff0c\u5efa\u8bbe\u9879\u76ee\u53ef\u80fd\u9020\u6210\u8de8\u884c\u653f\u533a\u57df\u7684\u4e0d\u826f\u73af\u5883\u5f71\u54cd\uff0c\u6709\u5173\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u5bf9\u8be5\u9879\u76ee\u7684\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u7ed3\u8bba\u6709\u4e89\u8bae\u7684\uff0c\u5176\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u7531____\u5ba1\u6279\u3002\nA. \u56fd\u52a1\u9662\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\nB. \u56fd\u5bb6\u73af\u5883\u4fdd\u62a4\u90e8\nC. \u5171\u540c\u7684\u4e0a\u4e00\u7ea7\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\nD. \u53d7\u5f71\u54cd\u8f83\u591a\u7684\u533a\u57df\u7684\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.43871332879659014, "meta-math/MetaMath-Mistral-7B": 0.8209867766375084, "itpossible/Chinese-Mistral-7B-v0.1": 0.4343032251852024, "HuggingFaceH4/zephyr-7b-beta": 0.9581135608300568, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8380311442080836, "meta-llama/Meta-Llama-3-8B": 0.49690220609534846, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6387729546880231}}, {"question": "\u4f9d\u636e\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u5ba1\u6279\u7a0b\u5e8f\u89c4\u5b9a\u300b\uff0c\u5bf9\u56fd\u5bb6\u89c4\u5b9a\u5b9e\u884c\u5907\u6848\u5236\u7684\u5efa\u8bbe\u9879\u76ee\uff0c\u5efa\u8bbe\u5355\u4f4d\u63d0\u4ea4\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u7684\u65f6\u9650\u5e94\u5f53\u4e3a____\u3002\nA. \u63d0\u4ea4\u9879\u76ee\u7533\u8bf7\u62a5\u544a\u524d\nB. \u62a5\u9001\u53ef\u884c\u6027\u7814\u7a76\u62a5\u544a\u524d\nC. \u529e\u7406\u5907\u6848\u624b\u7eed\u540e\u81f3\u5f00\u5de5\u524d\nD. \u7533\u8bf7\u7ae3\u5de5\u73af\u5883\u4fdd\u62a4\u9a8c\u6536\u524d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.38392624496445477, "meta-math/MetaMath-Mistral-7B": 0.4701322883131674, "itpossible/Chinese-Mistral-7B-v0.1": 0.4542143982076038, "HuggingFaceH4/zephyr-7b-beta": 0.800608330782537, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5553635776864394, "meta-llama/Meta-Llama-3-8B": 0.4716471879949822, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9494793547824569}}, {"question": "\u5806\u653e\u7684\u56fa\u4f53\u5e9f\u7269\u4ea7\u751f\u7684\u5927\u6c14\u4e3b\u8981\u6c61\u67d3\u7269\u662f____\u3002\nA. \u7ec6\u5fae\u9897\u7c92\u3001\u7c89\u5c18\u3001\u4e8c\u6c27\u5316\u786b\u3001\u4e8c\u6c27\u5316\u78b3\nB. \u7ec6\u5fae\u9897\u7c92\u3001\u7c89\u5c18\u3001\u6bd2\u6c14\u3001\u6076\u81ed\nC. \u4e8c\u6c27\u5316\u786b\u3001\u4e8c\u6c27\u5316\u78b3\u3001\u4e09\u6c27\u5316\u786b\u3001\u6c2f\u6c14\nD. \u4e8c\u6c27\u5316\u786b\u3001\u4e8c\u6c27\u5316\u78b3\u3001\u6bd2\u6c14\u3001\u6076\u81ed\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4560029206922418, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u603b\u7eb2\u300b(HJ2.1\u20142016)\uff0c\u5173\u4e8e\u201c\u6c61\u67d3\u6e90\u6e90\u5f3a\u6838\u7b97\u201d\u7684\u5b9a\u4e49\uff0c\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u9009\u7528\u53ef\u884c\u7684\u65b9\u6cd5\u786e\u5b9a\u89c4\u5212\u9879\u76ee\u5355\u4f4d\u65f6\u95f4\u5185\u6c61\u67d3\u7269\u7684\u4ea7\u751f\u91cf\u6216\u6392\u653e\u91cf\nB. \u9009\u7528\u53ef\u884c\u7684\u65b9\u6cd5\u786e\u5b9a\u5efa\u8bbe\u9879\u76ee\u5355\u4f4d\u65f6\u95f4\u5185\u6c61\u67d3\u7269\u7684\u4ea7\u751f\u91cf\u6216\u6392\u653e\u91cf\nC. \u9009\u7528\u53ef\u884c\u7684\u65b9\u6cd5\u786e\u5b9a\u5efa\u8bbe\u9879\u76ee\u5355\u4f4d\u4ea7\u54c1\u6c61\u67d3\u7269\u7684\u4ea7\u751f\u91cf\u6216\u6392\u653e\u91cf\nD. \u9009\u7528\u5404\u79cd\u65b9\u6cd5\u786e\u5b9a\u5efa\u8bbe\u9879\u76ee\u5355\u4f4d\u65f6\u95f4\u5185\u6c61\u67d3\u7269\u7684\u4ea7\u751f\u91cf\u6216\u6392\u653e\u91cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5305222169267819, "meta-math/MetaMath-Mistral-7B": 0.7804280194003336, "itpossible/Chinese-Mistral-7B-v0.1": 0.5593087567095606, "HuggingFaceH4/zephyr-7b-beta": 0.9543751176896581, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.623888930086531, "meta-llama/Meta-Llama-3-8B": 0.43495988922323, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5009019979007417}}, {"question": "\u6839\u636e\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6280\u672f\u5bfc\u5219\u603b\u7eb2\u300b(HJ2.1\u20142016)\uff0c\u5728\u8bc4\u4ef7\u56e0\u5b50\u7b5b\u9009\u8fc7\u7a0b\u4e2d\uff0c\u4e0d\u9700\u8981\u8003\u8651\u7684\u662f____\u3002\nA. \u73af\u5883\u5f71\u54cd\u7684\u4e3b\u8981\u7279\u5f81\nB. \u8bc4\u4ef7\u6807\u51c6\u548c\u73af\u5883\u5236\u7ea6\u56e0\u7d20\nC. \u533a\u57df\u73af\u5883\u529f\u80fd\u8981\u6c42\nD. \u5efa\u8bbe\u9879\u76ee\u6c61\u67d3\u9632\u6cbb\u63aa\u65bd\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5717697530307788, "meta-math/MetaMath-Mistral-7B": 0.5632763796179501, "itpossible/Chinese-Mistral-7B-v0.1": 0.5364815755964617, "HuggingFaceH4/zephyr-7b-beta": 0.7375911235450896, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.49309197311599057, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u901a\u5e38\u6240\u8bf4\u7684\u73af\u5883\u5bb9\u91cf\u662f\u6307\u5728\u786e\u5b9a\u7684\u73af\u5883\u76ee\u6807\u503c\u4e0b\uff0c\u533a\u57df\u73af\u5883\u6240\u80fd\u591f\u5bb9\u7eb3\u7684\u6c61\u67d3\u7269\u6700\u5927\u5141\u8bb8____\u3002\nA. \u5bb9\u8bb8\u91cf\nB. \u6392\u653e\u91cf\nC. \u6d53\u5ea6\u503c\nD. \u6570\u91cf\u503c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6054069805602924, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8379027332067875}}, {"question": "\u65e0\u4ea7\u9636\u7ea7\u9769\u547d\u662f\u8fc4\u4eca\u4eba\u7c7b\u5386\u53f2\u4e0a\u6700\u5e7f\u6cdb\u3001\u6700\u5f7b\u5e95\u3001\u6700\u6df1\u523b\u7684\u9769\u547d\uff0c\u662f\u4e0d\u540c\u4e8e\u4ee5\u5f80\u4e00\u5207\u9769\u547d\u7684\u6700\u65b0\u7c7b\u578b\u7684\u9769\u547d\u3002\u65e0\u4ea7\u9636\u7ea7\u9769\u547d\u7684\u4e3b\u8981\u7279\u70b9\u662f____\nA. \u65e0\u4ea7\u9636\u7ea7\u9769\u547d\u662f\u5f7b\u5e95\u6d88\u706d\u4e00\u5207\u79c1\u6709\u5236\u3001\u4ee3\u4e4b\u4ee5\u751f\u4ea7\u8d44\u6599\u516c\u6709\u5236\u7684\u9769\u547d\nB. \u65e0\u4ea7\u9636\u7ea7\u9769\u547d\u662f\u8981\u5f7b\u5e95\u6d88\u706d\u4e00\u5207\u9636\u7ea7\u548c\u9636\u7ea7\u7edf\u6cbb\u7684\u9769\u547d\nC. \u65e0\u4ea7\u9636\u7ea7\u9769\u547d\u662f\u4e3a\u6240\u6709\u4eba\u8c0b\u5229\u76ca\u7684\u8fd0\u52a8\nD. \u65e0\u4ea7\u9636\u7ea7\u9769\u547d\u662f\u4e0d\u65ad\u524d\u8fdb\u7684\u5386\u53f2\u8fc7\u7a0b\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u300a\u5efa\u8bbe\u9879\u76ee\u73af\u5883\u4fdd\u62a4\u7ba1\u7406\u6761\u4f8b\u300b\u89c4\u5b9a\uff0c\u5efa\u8bbe\u5355\u4f4d\u7f16\u5236\u73af\u5883\u5f71\u54cd\u62a5\u544a\u4e66\uff0c\u5e94\u5f53\u4f9d\u7167\u6709\u5173\u6cd5\u5f8b\u89c4\u5b9a\uff0c\u5f81\u6c42\u5efa\u8bbe\u9879\u76ee\u6240\u5728\u5730____\u7684\u610f\u89c1\u3002\nA. \u653f\u5e9c\u548c\u5c45\u6c11\nB. \u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\nC. \u5efa\u8bbe\u4e3b\u7ba1\u90e8\u95e8\u548c\u5c45\u6c11\nD. \u6709\u5173\u5355\u4f4d\u548c\u5c45\u6c11\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6883399127890478, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5918385478818752, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u81ea\u7136\u666f\u89c2\u8ddd\u62df\u5efa\u9ad8\u901f\u516c\u8def\u7684\u6700\u5c0f\u8ddd\u79bb\u4e3a1700m\uff0c\u6309\u201c\u76f8\u5bf9\u8ddd\u79bb\u201d\u5355\u9879\u6307\u6807\u5224\u65ad\u8be5\u666f\u89c2\u7684\u201c\u654f\u611f\u7a0b\u5ea6\u201d\u4e3a____\u3002\nA. \u6781\u654f\u611f\nB. \u4e2d\u7b49\u654f\u611f\nC. \u4e0d\u654f\u611f\nD. \u80cc\u666f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u9879\u76ee\u5efa\u8bbe\u3001\u8fd0\u884c\u8fc7\u7a0b\u4e2d\u4ea7\u751f\u4e0d\u7b26\u5408\u7ecf\u5ba1\u6279\u7684\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u7684\u60c5\u5f62\u7684\uff0c____\u4e5f\u53ef\u4ee5\u8d23\u6210\u5efa\u8bbe\u5355\u4f4d\u8fdb\u884c\u73af\u5883\u5f71\u54cd\u7684\u540e\u8bc4\u4ef7\uff0c\u91c7\u53d6\u6539\u8fdb\u63aa\u65bd\u3002\nA. \u539f\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6587\u4ef6\u5ba1\u6279\u90e8\u95e8\nB. \u5f53\u5730\u73af\u5883\u4fdd\u62a4\u884c\u653f\u4e3b\u7ba1\u90e8\u95e8\nC. \u539f\u5efa\u8bbe\u9879\u76ee\u5ba1\u6279\u90e8\u95e8\nD. \u5f53\u5730\u4eba\u6c11\u653f\u5e9c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u73af\u8bc4\u673a\u6784\u5728\u4e3a\u4f4d\u4e8eM\u5e02\u67d0\u5316\u5de5\u5382\u5efa\u8bbe\u9879\u76ee\u505a\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u7684\u8fc7\u7a0b\u4e2d\uff0c\u53d1\u73b0\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u6cd5\u300b\u7684\u89c4\u5b9a\u5728\u5236\u4f5c\u516c\u4f17\u53c2\u4e0e\u7bc7\u7ae0\u65f6\u65e0\u987b\u53ec\u5f00\u542c\u8bc1\u4f1a\uff0c\u800c\u6839\u636e\u300a\u73af\u5883\u5f71\u54cd\u8bc4\u4ef7\u516c\u4f17\u53c2\u4e0e\u6682\u884c\u529e\u6cd5\u300b\u7684\u89c4\u5b9a\u987b\u53ec\u5f00\u542c\u8bc1\u4f1a\uff0c\u5219\u5e94____\u3002\nA. \u53ec\u5f00\u542c\u8bc1\u4f1a\nB. \u4e0d\u53ec\u5f00\u542c\u8bc1\u4f1a\nC. \u8bf7\u793aM\u5e02\u73af\u4fdd\u5c40\nD. \u542c\u4ece\u5316\u5de5\u5382\u9886\u5bfc\u7684\u610f\u89c1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4494260683823469, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u4e2d\u534e\u4eba\u6c11\u5171\u548c\u56fd\u56fa\u4f53\u5e9f\u7269\u6c61\u67d3\u73af\u5883\u9632\u6cbb\u6cd5\u300b\uff0c\u4ece\u4e8b____\u5371\u9669\u5e9f\u7269\u7ecf\u8425\u6d3b\u52a8\u7684\u5355\u4f4d\u548c\u4e2a\u4eba\uff0c\u65e0\u9700\u7533\u8bf7\u5371\u9669\u5e9f\u7269\u7ecf\u8425\u8bb8\u53ef\u8bc1\u3002\nA. \u8d2e\u5b58\nB. \u8fd0\u8f93\nC. \u5229\u7528\nD. \u5904\u7f6e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29972404264597124, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.2906893535433972, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8fdb\u884c\u7a0e\u52a1\u54a8\u8be2\u670d\u52a1\u7684\u6838\u5fc3\u662f____\u3002\nA. \u5f04\u6e05\u54a8\u8be2\u95ee\u9898\u6240\u6d89\u53ca\u7684\u7a0e\u79cd\nB. \u6536\u96c6\u54a8\u8be2\u95ee\u9898\u76f8\u5173\u7684\u7a0e\u6536\u653f\u7b56\u6587\u4ef6\nC. \u5206\u6790\u7a0e\u6536\u653f\u7b56\u9002\u7528\u6761\u6b3e\nD. \u6839\u636e\u9700\u8981\u4f5c\u5fc5\u8981\u7684\u6c9f\u901a\u8bf4\u660e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8872599229446549, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.48454908501491634, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "FY\u516c\u53f8\u4e0eFC\u673a\u68b0\u5382\u5747\u4e3a\u56fd\u6709\u4f01\u4e1a\uff0c\u5408\u8d44\u8bbe\u7acbA\u6709\u9650\u8d23\u4efb\u516c\u53f8(\u4ee5\u4e0b\u7b80\u79f0\u201cA\u516c\u53f8\u201d)\uff0c\u51fa\u8d44\u6bd4\u4f8b\u4e3a30%\u4e0e70%\u3002\u4e0b\u5217\u6709\u5173A\u516c\u53f8\u8463\u4e8b\u4f1a\u7ec4\u6210\u7684\u8bf4\u6cd5\u4e2d\uff0c\u4e0d\u7b26\u5408\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u8463\u4e8b\u4f1a\u6210\u5458\u4e2d\u5e94\u5f53\u6709\u516c\u53f8\u804c\u5de5\u4ee3\u8868\nB. \u8463\u4e8b\u5f20\u67d0\u4efb\u671f\u5185\u8f9e\u804c\uff0c\u5728\u65b0\u9009\u51fa\u8463\u4e8b\u5c31\u4efb\u524d\uff0c\u5f20\u67d0\u4ecd\u5e94\u5c65\u884c\u8463\u4e8b\u804c\u8d23\nC. A\u516c\u53f8\u8463\u4e8b\u957f\u53ef\u7531\u516c\u53f8\u7ae0\u7a0b\u89c4\u5b9a\u7531\u5c0f\u80a1\u4e1cFY\u516c\u53f8\u6d3e\u4eba\u62c5\u4efb\nD. FY\u516c\u53f8\u548cFC\u673a\u68b0\u5382\u53ef\u901a\u8fc7\u516c\u53f8\u7ae0\u7a0b\u7ea6\u5b9a\u4e0d\u6309\u51fa\u8d44\u6bd4\u4f8b\u5206\u7ea2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u7ba1\u7406\u7684\u8868\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u6267\u884c\u671f\u6ee1\u540e\u81ea\u52a8\u5931\u6548\uff0c\u4f01\u4e1a\u7533\u8bf7\u7eed\u7b7e\u7684\uff0c\u5e94\u5f53\u5728\u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u6267\u884c\u671f\u6ee1\u4e4b\u65e5\u524d30\u65e5\u5185\u5411\u7a0e\u52a1\u673a\u5173\u63d0\u51fa\u7eed\u7b7e\u7533\u8bf7\nB. \u4f01\u4e1a\u7533\u8bf7\u53cc\u8fb9\u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u7684\uff0c\u5e94\u53ca\u65f6\u5411\u7701\u7ea7\u7a0e\u52a1\u673a\u5173\u63d0\u51fa\u8c08\u7b7e\u610f\u5411\nC. \u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u9002\u7528\u4e8e\u81ea\u4f01\u4e1a\u63d0\u4ea4\u6b63\u5f0f\u4e66\u9762\u7533\u8bf7\u5e74\u5ea6\u5f53\u5e74\u8d7710\u4e2a\u8fde\u7eed\u5e74\u5ea6\u7684\u5173\u8054\u4ea4\u6613\nD. \u5728\u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u6267\u884c\u671f\u5185\uff0c\u7a0e\u52a1\u673a\u5173\u5e94\u5f53\u6bcf\u5e74\u76d1\u63a7\u4f01\u4e1a\u6267\u884c\u9884\u7ea6\u5b9a\u4ef7\u5b89\u6392\u7684\u60c5\u51b5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.40202865642572594, "HuggingFaceH4/zephyr-7b-beta": 0.7694401986623527, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3867179681783777, "meta-llama/Meta-Llama-3-8B": 0.3908304748611699, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u884c\u4e3a\u4e2d\uff0c\u5e94\u5f81\u6536\u4e2a\u4eba\u6240\u5f97\u7a0e\u7684\u662f____\u3002\nA. \u79bb\u5a5a\u6790\u4ea7\u5206\u5272\u623f\u5c4b\u4ea7\u6743\nB. \u519b\u4eba\u7684\u8f6c\u4e1a\u8d39\u3001\u590d\u5458\u8d39\u3001\u9000\u5f79\u91d1\nC. \u6309\u7167\u56fd\u5bb6\u7edf\u4e00\u89c4\u5b9a\u53d1\u653e\u7684\u9000\u4f11\u8d39\u3001\u79bb\u4f11\u8d39\nD. \u4e2a\u4eba\u8d2d\u4e70\u798f\u5229\u5f69\u7968\uff0c\u4e00\u6b21\u4e2d\u5956\u6536\u516512000\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.5469986039109149, "HuggingFaceH4/zephyr-7b-beta": 0.7854940941149743, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.46454998140218834, "meta-llama/Meta-Llama-3-8B": 0.6640014017937386, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8870763396089536}}, {"question": "\u67d0\u9152\u5382\u4e3a\u589e\u503c\u7a0e\u4e00\u822c\u7eb3\u7a0e\u4eba\uff0c2020\u5e7410\u6708\u53d1\u653e1\u5428\u81ea\u5236\u767d\u9152\u4f5c\u4e3a\u804c\u5de5\u798f\u5229\uff0c\u540c\u7c7b\u767d\u9152\u4e0d\u542b\u7a0e\u552e\u4ef750000\u5143/\u5428\uff0c\u6210\u672c\u4ef735000\u5143/\u5428\u3002\u8be5\u9152\u5382\u4e0a\u8ff0\u4e1a\u52a1\u5f53\u6708\u5e94\u7eb3\u6d88\u8d39\u7a0e____\u5143\u3002\nA. 7700\nB. 8700\nC. 10000\nD. 11000\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u5c5e\u4e8e\u571f\u5730\u589e\u503c\u7a0e\u5f81\u7a0e\u8303\u56f4\u7684\u662f____\u3002\nA. \u623f\u5730\u4ea7\u51fa\u79df\nB. \u623f\u5730\u4ea7\u8bc4\u4f30\u589e\u503c\nC. \u623f\u5730\u4ea7\u7684\u4ee3\u5efa\u623f\u884c\u4e3a\nD. \u5408\u4f5c\u5efa\u623f\u540e\uff0c\u5efa\u6210\u540e\u8f6c\u8ba9\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3635447794781111, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9990009939914297, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9488\u5bf9\u67e5\u8d26\u7684\u987a\u5e8f\u4e0d\u540c\uff0c\u7eb3\u7a0e\u5ba1\u67e5\u7684\u65b9\u6cd5\u53ef\u5206\u4e3a____\u3002\nA. \u987a\u67e5\u6cd5\u548c\u9006\u67e5\u6cd5\nB. \u8be6\u67e5\u6cd5\u548c\u62bd\u67e5\u6cd5\nC. \u6838\u5bf9\u6cd5\u548c\u67e5\u8be2\u6cd5\nD. \u6bd4\u8f83\u5206\u6790\u6cd5\u548c\u63a7\u5236\u8ba1\u7b97\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5644026697473241, "meta-math/MetaMath-Mistral-7B": 0.9482282443136938, "itpossible/Chinese-Mistral-7B-v0.1": 0.48783852322368093, "HuggingFaceH4/zephyr-7b-beta": 0.6117450669292765, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6716717434100856, "meta-llama/Meta-Llama-3-8B": 0.6239667849836834, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7300771615099139}}, {"question": "\u5357\u548c\u516c\u53f8\u56e0\u957f\u671f\u4e0d\u80fd\u6e05\u507f\u5230\u671f\u503a\u52a1\uff0c\u5411\u4eba\u6c11\u6cd5\u9662\u7533\u8bf7\u7834\u4ea7\u3002\u4e1c\u5c1a\u516c\u53f8\u662f\u5357\u548c\u516c\u53f8\u7684\u503a\u6743\u4eba\uff0c\u4e0b\u5217\u4e0e\u4e1c\u5c1a\u516c\u53f8\u6709\u5173\u7684\u4e8b\u9879\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u503a\u6743\u8fd8\u67092\u4e2a\u6708\u5230\u671f\uff0c\u4e1c\u5c1a\u516c\u53f8\u4e0d\u80fd\u7533\u62a5\u7834\u4ea7\u503a\u6743\nB. \u4e1c\u5c1a\u516c\u53f8\u53ef\u4ee5\u53e3\u5934\u5411\u7ba1\u7406\u4eba\u7533\u62a5\u503a\u6743\nC. \u4e1c\u5c1a\u516c\u53f8\u7533\u62a5\u503a\u6743\u540e\uff0c\u5c31\u53ef\u4ee5\u884c\u4f7f\u503a\u6743\u4eba\u7684\u6743\u5229\nD. \u4e1c\u5c1a\u516c\u53f8\u7533\u62a5\u503a\u6743\u65f6\u9700\u8981\u63d0\u4f9b\u503a\u6743\u7533\u8bf7\u4e66\u3001\u503a\u6743\u8bc1\u636e\u6750\u6599\u7b49\u5185\u5bb9\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6704158217569077, "HuggingFaceH4/zephyr-7b-beta": 0.9973749971302079, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.854836445005068, "meta-llama/Meta-Llama-3-8B": 0.8415466821706732, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9606354905628673}}, {"question": "\u5bf9\u4e8e\u4e0d\u7b26\u5408\u6536\u5165\u51c6\u5219\u89c4\u5b9a\u7684\u5408\u540c\u6210\u7acb\u7684\u6761\u4ef6\uff0c\u4f01\u4e1a\u5c06\u5df2\u6536\u53d6\u5ba2\u6237\u7684\u5bf9\u4ef7\u786e\u8ba4\u4e3a\u6536\u5165\u7684\u6761\u4ef6\u4e3a____\u3002\nA. \u5f00\u5177\u589e\u503c\u7a0e\u4e13\u7528\u53d1\u7968\nB. \u4e0d\u518d\u8d1f\u6709\u5411\u5ba2\u6237\u8f6c\u8ba9\u5546\u54c1\u7684\u5269\u4f59\u4e49\u52a1\uff0c\u4e14\u5df2\u5411\u5ba2\u6237\u6536\u53d6\u7684\u5bf9\u4ef7\u65e0\u9700\u9000\u56de\nC. \u5177\u6709\u5546\u4e1a\u5b9e\u8d28\nD. \u5546\u54c1\u5df2\u7ecf\u53d1\u51fa\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.397306262233368, "itpossible/Chinese-Mistral-7B-v0.1": 0.6144468100559675, "HuggingFaceH4/zephyr-7b-beta": 0.9988673446714078, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.43175195993951093, "meta-llama/Meta-Llama-3-8B": 0.46564300779096623, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5466047024390587}}, {"question": "\u5173\u4e8e\u7a0e\u52a1\u767b\u8bb0\u7684\u8bf4\u6cd5\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u4e00\u822c\u7eb3\u7a0e\u4eba\u8d44\u683c\u8ba4\u5b9a\u7684\u6743\u9650\uff0c\u5728\u53bf(\u5e02\u3001\u533a)\u7a0e\u52a1\u5c40\u6216\u540c\u7ea7\u522b\u7684\u7a0e\u52a1\u5206\u5c40\nB. \u7eb3\u7a0e\u4eba\u5e94\u5f53\u5411\u5176\u673a\u6784\u6240\u5728\u5730\u4e3b\u7ba1\u7a0e\u52a1\u673a\u5173\u7533\u8bf7\u4e00\u822c\u7eb3\u7a0e\u4eba\u8d44\u683c\u8ba4\u5b9a\nC. \u5e74\u5e94\u7a0e\u9500\u552e\u989d\u8fbe\u5230\u4e00\u822c\u7eb3\u7a0e\u4eba\u6807\u51c6\u7684\u7eb3\u7a0e\u4eba\uff0c\u672a\u7533\u8bf7\u529e\u7406\u4e00\u822c\u7eb3\u7a0e\u4eba\u624b\u7eed\u7684\uff0c\u5e94\u6309\u9500\u552e\u989d\u4f9d\u7167\u589e\u503c\u7a0e\u7a0e\u7387\u8ba1\u7b97\u5e94\u7eb3\u7a0e\u989d\uff0c\u53ef\u4ee5\u62b5\u6263\u8fdb\u9879\u7a0e\u989d\uff0c\u4f46\u4e0d\u5f97\u4f7f\u7528\u589e\u503c\u7a0e\u4e13\u7528\u53d1\u7968\nD. \u7eb3\u7a0e\u4eba\u5e94\u5728\u9886\u53d6\u300a\u7a0e\u52a1\u767b\u8bb0\u8bc1\u300b\u526f\u672c\u540e\u548c\u7533\u62a5\u7eb3\u7a0e\u4e4b\u524d\uff0c\u7533\u8bf7\u7a0e\u79cd\u8ba4\u5b9a\u767b\u8bb0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5858957832727164, "meta-math/MetaMath-Mistral-7B": 0.7927141211373606, "itpossible/Chinese-Mistral-7B-v0.1": 0.6594839886530023, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3520821795518118, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.4666462904486023}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u5c5e\u4e8e\u975e\u76f8\u5173\u6210\u672c\u7684\u662f____\u3002\nA. \u673a\u4f1a\u6210\u672c\nB. \u91cd\u7f6e\u6210\u672c\nC. \u5dee\u989d\u6210\u672c\nD. \u6c89\u6ca1\u6210\u672c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3431547327443468, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.35125369870111733, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u300a\u884c\u653f\u8bc9\u8bbc\u6cd5\u300b\u89c4\u5b9a\uff0c\u4e0b\u5217\u5173\u4e8e\u884c\u653f\u8bc9\u8bbc\u4e8c\u5ba1\u7a0b\u5e8f\u7684\u8bf4\u6cd5\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u4e8c\u5ba1\u6cd5\u9662\u53ef\u4ee5\u4e0d\u5f00\u5ead\u5ba1\u7406\nB. \u4e8c\u5ba1\u6cd5\u9662\u5ba1\u7406\u4e0a\u8bc9\u6848\u4ef6\uff0c\u4e00\u822c\u5e94\u5f53\u5728\u6536\u5230\u4e0a\u8bc9\u72b6\u4e4b\u65e5\u8d776\u4e2a\u6708\u5185\u4f5c\u51fa\u7ec8\u5ba1\u5224\u51b3\nC. \u5f53\u4e8b\u4eba\u4e0d\u670d\u4e00\u5ba1\u5224\u51b3\u63d0\u8d77\u4e0a\u8bc9\u7684\uff0c\u5e94\u5f53\u5728\u5224\u51b3\u4e66\u9001\u8fbe\u4e4b\u65e5\u8d7715\u65e5\u5185\u63d0\u8d77\nD. \u4e8c\u5ba1\u6cd5\u9662\u5ba1\u7406\u4e0a\u8bc9\u6848\u4ef6\u65f6\uff0c\u5e94\u5f53\u5bf9\u539f\u5ba1\u6cd5\u9662\u7684\u88c1\u5224\u548c\u88ab\u8bc9\u884c\u653f\u884c\u4e3a\u8fdb\u884c\u5168\u9762\u5ba1\u67e5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u516c\u53f8\u4e3a\u5de5\u4e1a\u4f01\u4e1a\uff0c\u5c5e\u4e8e\u589e\u503c\u7a0e\u4e00\u822c\u7eb3\u7a0e\u4eba\u30022019\u5e74\u53d6\u5f97\u4e3b\u8425\u4e1a\u52a1\u6536\u5165\u4e3a2000\u4e07\u5143\uff0c\u672c\u671f\u53d1\u751f\u73b0\u91d1\u6298\u626310\u4e07\u5143\uff0c\u589e\u503c\u7a0e\u9500\u9879\u7a0e\u989d\u4e3a260\u4e07\u5143\uff1b\u5e94\u6536\u8d26\u6b3e\u8d26\u6237\u671f\u521d\u4f59\u989d\u4e3a600\u4e07\u5143\uff0c\u671f\u672b\u4f59\u989d\u4e3a900\u4e07\u5143\uff0c\u574f\u8d26\u51c6\u5907\u7684\u671f\u521d\u4f59\u989d\u4e3a10\u4e07\u5143\uff0c\u671f\u672b\u4f59\u989d\u4e3a30\u4e07\u5143\uff1b\u9884\u6536\u8d26\u6b3e\u8d26\u6237\u671f\u521d\u4f59\u989d\u4e3a100\u4e07\u5143\uff0c\u671f\u672b\u4f59\u989d\u4e3a20\u4e07\u5143\uff1b\u672c\u671f\u6536\u5230\u5b58\u8d27\u62b5\u503a\u51cf\u5c11\u5e94\u6536\u8d26\u6b3e40\u4e07\u5143\uff0c\u672c\u671f\u53d1\u751f\u4e0d\u9644\u8ffd\u7d22\u6743\u7968\u636e\u8d34\u73b0\u5229\u606f5\u4e07\u5143\u3002\u5047\u5b9a\u4e0d\u8003\u8651\u5176\u4ed6\u56e0\u7d20\uff0c\u7532\u516c\u53f82019\u5e74\u5ea6\u73b0\u91d1\u6d41\u91cf\u8868\u4e2d\u201c\u9500\u552e\u5546\u54c1\u3001\u63d0\u4f9b\u52b3\u52a1\u6536\u5230\u7684\u73b0\u91d1\u201d\u9879\u76ee\u7684\u91d1\u989d\u4e3a____\u4e07\u5143\u3002\nA. 1825\nB. 1855\nC. 1860\nD. 1880\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.34239623393788804}}, {"question": "\u4e0b\u5217\u8bf4\u6cd5\u7b26\u5408\u5f8b\u5e08\u4e8b\u52a1\u6240\u53ca\u5176\u4ece\u4e1a\u4eba\u5458\u4e2a\u4eba\u6240\u5f97\u7a0e\u5f81\u6536\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u517c\u804c\u5f8b\u5e08\u4ece\u5f8b\u5e08\u4e8b\u52a1\u6240\u53d6\u5f97\u5de5\u8d44\u3001\u85aa\u91d1\u6027\u8d28\u7684\u6240\u5f97\uff0c\u4e8b\u52a1\u6240\u5728\u4ee3\u6263\u4ee3\u7f34\u5176\u4e2a\u4eba\u6240\u5f97\u7a0e\u65f6\uff0c\u5e94\u5148\u6263\u9664\u7a0e\u6cd5\u89c4\u5b9a\u7684\u8d39\u7528\u6263\u9664\u6807\u51c6\nB. \u8ba1\u7b97\u5f8b\u5e08\u4e8b\u52a1\u6240\u7ecf\u8425\u6240\u5f97\u65f6\uff0c\u51fa\u8d44\u5f8b\u5e08\u672c\u4eba\u7684\u5de5\u8d44\u3001\u85aa\u91d1\u4e0d\u5f97\u6263\u9664\nC. \u5f8b\u5e08\u4e2a\u4eba\u627f\u62c5\u7684\u6309\u7167\u5f8b\u5e08\u534f\u4f1a\u89c4\u5b9a\u53c2\u52a0\u7684\u4e1a\u52a1\u57f9\u8bad\u8d39\u7528\uff0c\u4e0d\u5f97\u6263\u9664\nD. \u53d7\u96c7\u4e8e\u5f8b\u5e08\u4e8b\u52a1\u6240\u7684\u5f8b\u5e08\u4ece\u4e8b\u52a1\u6240\u53d6\u5f97\u7684\u5206\u6210\u6536\u5165\uff0c\u5e94\u5355\u72ec\u4f5c\u4e3a\u4e00\u4e2a\u6708\u7684\u5de5\u8d44\u3001\u85aa\u91d1\uff0c\u6263\u9664\u529e\u6848\u8d39\u7528\u540e\u7f34\u7eb3\u4e2a\u4eba\u6240\u5f97\u7a0e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7533\u8bf7\u4eba\u3001\u7b2c\u4e09\u4eba\u53ef\u4ee5\u59d4\u6258\u4ee3\u7406\u4eba\u53c2\u52a0\u7a0e\u52a1\u884c\u653f\u590d\u8bae\uff0c\u4f46\u662f\u5e94\u5f53\u5411\u884c\u653f\u590d\u8bae\u673a\u6784\u63d0\u4ea4\u6388\u6743\u59d4\u6258\u4e66\u3002\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u6388\u6743\u59d4\u6258\u4e66\u5e94\u5f53\u8f7d\u660e\u7684\u5185\u5bb9\u7684\u662f____\u3002\nA. \u59d4\u6258\u4e8b\u9879\nB. \u59d4\u6258\u6743\u9650\nC. \u59d4\u6258\u671f\u9650\nD. \u59d4\u6258\u7ed3\u679c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7206483855990006, "meta-math/MetaMath-Mistral-7B": 0.6831232705456595, "itpossible/Chinese-Mistral-7B-v0.1": 0.8714763004593965, "HuggingFaceH4/zephyr-7b-beta": 0.9999443366195316, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9648018841727616, "meta-llama/Meta-Llama-3-8B": 0.858899240744628, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9960307231410312}}, {"question": "\u4ee5\u4e0b\u9879\u76ee\u5728\u8ba1\u7b97\u571f\u5730\u589e\u503c\u7a0e\u65f6\uff0c\u4e0d\u5f97\u6263\u9664\u6210\u672c\u8d39\u7528\u662f____\u3002\nA. \u5efa\u6210\u540e\u4ea7\u6743\u5c5e\u4e8e\u5168\u4f53\u4e1a\u4e3b\u7684\u4f1a\u6240\nB. \u5efa\u6210\u540e\u65e0\u507f\u79fb\u4ea4\u6d3e\u51fa\u6240\u7528\u4e8e\u529e\u516c\u7684\u623f\u5c4b\nC. \u5efa\u6210\u540e\u6709\u507f\u51fa\u552e\u7684\u505c\u8f66\u573a\nD. \u5efa\u6210\u540e\u5f85\u552e\u51fa\u79df\u7684\u5546\u4e1a\u7528\u623f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4045257283646438, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.2986334267609958, "meta-llama/Meta-Llama-3-8B": 0.28966338381871215, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u7f16\u5236\u94f6\u884c\u5b58\u6b3e\u4f59\u989d\u8c03\u8282\u8868\u7684\u8868\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u94f6\u884c\u5bf9\u8d26\u5355\u4e0a\u7684\u91d1\u989d\uff0c\u53cd\u6620\u4e86\u4f01\u4e1a\u53ef\u4ee5\u52a8\u7528\u7684\u94f6\u884c\u5b58\u6b3e\u5b9e\u6709\u6570\u989d\nB. \u5bf9\u4e8e\u672a\u8fbe\u8d26\u9879\uff0c\u9700\u8981\u5bf9\u4f01\u4e1a\u548c\u94f6\u884c\u5404\u81ea\u63d0\u4f9b\u7684\u94f6\u884c\u5b58\u6b3e\u4f59\u989d\u8fdb\u884c\u8c03\u6574\nC. \u94f6\u884c\u5b58\u6b3e\u4f59\u989d\u8c03\u8282\u8868\u7528\u6765\u6838\u5bf9\u4f01\u4e1a\u548c\u94f6\u884c\u7684\u8bb0\u8d26\u6709\u65e0\u9519\u8bef\uff0c\u5e76\u4f5c\u4e3a\u8bb0\u8d26\u4f9d\u636e\nD. \u8c03\u8282\u540e\u94f6\u884c\u5b58\u6b3e\u65e5\u8bb0\u8d26\u4f59\u989d\u4e0e\u94f6\u884c\u5bf9\u8d26\u5355\u4f59\u989d\u4e00\u5b9a\u76f8\u7b49\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3728641892601242, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u7b26\u5408\u623f\u4ea7\u7a0e\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u66f4\u6362\u623f\u5c4b\u9644\u5c5e\u8bbe\u65bd\u548c\u914d\u5957\u8bbe\u65bd\u7684\uff0c\u5176\u66f4\u65b0\u4ef7\u503c\u8ba1\u5165\u623f\u4ea7\u539f\u503c\uff0c\u4f46\u4e0d\u6263\u51cf\u539f\u6765\u76f8\u5e94\u65e7\u8bbe\u5907\u548c\u8bbe\u65bd\u7684\u4ef7\u503c\nB. \u5bf9\u5c45\u6c11\u4f4f\u5b85\u533a\u5185\u4e1a\u4e3b\u5171\u6709\u7684\u7ecf\u8425\u6027\u623f\u4ea7\uff0c\u81ea\u8425\u7684\u4e0d\u5f81\u6536\u623f\u4ea7\u7a0e\nC. \u5bf9\u4e8e\u4e0e\u5730\u4e0a\u623f\u5c4b\u76f8\u8fde\u7684\u5730\u4e0b\u5efa\u7b51\uff0c\u5e94\u5c06\u5730\u4e0b\u90e8\u5206\u4e0e\u5730\u4e0a\u623f\u5c4b\u5206\u522b\u6309\u7167\u5730\u4e0a\u4e0e\u5730\u4e0b\u5efa\u7b51\u7269\u7684\u89c4\u5b9a\u8ba1\u7b97\u5f81\u6536\u623f\u4ea7\u7a0e\nD. \u51fa\u79df\u7684\u5730\u4e0b\u5efa\u7b51\uff0c\u6309\u7167\u51fa\u79df\u5730\u4e0a\u623f\u5c4b\u5efa\u7b51\u7684\u6709\u5173\u89c4\u5b9a\u8ba1\u7b97\u5f81\u6536\u623f\u4ea7\u7a0e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u589e\u91cf\u9884\u7b97\u5e94\u9075\u5faa\u7684\u5047\u5b9a\u662f____\u3002\nA. \u4ee5\u73b0\u6709\u4e1a\u52a1\u6d3b\u52a8\u548c\u5404\u9879\u6d3b\u52a8\u7684\u5f00\u652f\u6c34\u5e73\uff0c\u786e\u5b9a\u9884\u7b97\u671f\u5404\u9879\u6d3b\u52a8\u7684\u9884\u7b97\u6570\nB. \u9884\u7b97\u8d39\u7528\u6807\u51c6\u5fc5\u987b\u8fdb\u884c\u8c03\u6574\nC. \u4f01\u4e1a\u73b0\u6709\u5404\u9879\u4e1a\u52a1\u7684\u5f00\u652f\u6c34\u5e73\u662f\u5408\u7406\u7684\uff0c\u5728\u9884\u7b97\u671f\u4e88\u4ee5\u4fdd\u6301\nD. \u4f01\u4e1a\u73b0\u6709\u4e1a\u52a1\u6d3b\u52a8\u662f\u5408\u7406\u7684\uff0c\u4e0d\u9700\u8981\u8fdb\u884c\u8c03\u6574\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.5859787134579136, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8038137054590893}}, {"question": "\u4e0b\u5217\u6709\u5173\u6216\u6709\u4e8b\u9879\u7684\u8868\u8ff0\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u6e05\u507f\u56e0\u6216\u6709\u4e8b\u9879\u800c\u786e\u8ba4\u7684\u8d1f\u503a\u6240\u9700\u652f\u51fa\u5168\u90e8\u6216\u90e8\u5206\u9884\u671f\u7531\u7b2c\u4e09\u65b9\u8865\u507f\u65f6\uff0c\u8865\u507f\u91d1\u989d\u5728\u5f88\u53ef\u80fd\u6536\u5230\u65f6\u624d\u80fd\u4f5c\u4e3a\u8d44\u4ea7\u5355\u72ec\u786e\u8ba4\nB. \u5bf9\u4e8e\u6216\u6709\u4e8b\u9879\u65e2\u8981\u786e\u8ba4\u6216\u6709\u8d1f\u503a\uff0c\u4e5f\u8981\u786e\u8ba4\u6216\u6709\u8d44\u4ea7\nC. \u5bf9\u56fa\u5b9a\u8d44\u4ea7\u8ba1\u63d0\u6298\u65e7\u4e0d\u5c5e\u4e8e\u6216\u6709\u4e8b\u9879\nD. \u6216\u6709\u4e8b\u9879\u5e94\u786e\u8ba4\u4e3a\u9884\u8ba1\u8d1f\u503a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u589e\u503c\u7a0e\u7684\u9500\u552e\u989d\uff0c\u4e0b\u5217\u8bf4\u6cd5\u4e0d\u6b63\u786e\u7684\u662f____\u3002\nA. \u52b3\u52a1\u6d3e\u9063\u670d\u52a1\uff0c\u53ef\u4ee5\u9009\u62e9\u5dee\u989d\u7eb3\u7a0e\nB. \u822a\u7a7a\u8fd0\u8f93\u4f01\u4e1a\u7684\u9500\u552e\u989d\u4e0d\u5305\u62ec\u4ee3\u6536\u7684\u673a\u573a\u5efa\u8bbe\u8d39\nC. \u65c5\u6e38\u670d\u52a1\uff0c\u4e00\u5f8b\u4ee5\u53d6\u5f97\u7684\u5168\u90e8\u4ef7\u6b3e\u548c\u4ef7\u5916\u8d39\u7528\u4e3a\u9500\u552e\u989d\nD. \u7ecf\u7eaa\u4ee3\u7406\u670d\u52a1\uff0c\u4ee5\u53d6\u5f97\u7684\u5168\u90e8\u4ef7\u6b3e\u548c\u4ef7\u5916\u8d39\u7528\uff0c\u6263\u9664\u5411\u59d4\u6258\u65b9\u6536\u53d6\u5e76\u4ee3\u4e3a\u652f\u4ed8\u7684\u653f\u5e9c\u6027\u57fa\u91d1\u6216\u8005\u884c\u653f\u4e8b\u4e1a\u6027\u6536\u8d39\u540e\u7684\u4f59\u989d\u4e3a\u9500\u552e\u989d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3230435121167668, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6839\u636e\u884c\u653f\u5904\u7f5a\u6cd5\u5f8b\u5236\u5ea6\u7684\u89c4\u5b9a\uff0c\u4e0b\u5217\u5173\u4e8e\u5904\u7f5a\u4e0e\u6559\u80b2\u76f8\u7ed3\u5408\u539f\u5219\u7684\u8bf4\u6cd5\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u5904\u7f5a\u53ea\u662f\u624b\u6bb5\u800c\u4e0d\u662f\u76ee\u7684\nB. \u5904\u7f5a\u4e0e\u6559\u80b2\u76f8\u7ed3\u5408\u610f\u5473\u7740\u53ef\u4ee5\u4ee5\u7f5a\u4ee3\u5211\nC. \u884c\u653f\u673a\u5173\u672a\u8d23\u4ee4\u5f53\u4e8b\u4eba\u9650\u671f\u6539\u6b63\u8fdd\u6cd5\u884c\u4e3a\u5373\u4f5c\u51fa\u884c\u653f\u5904\u7f5a\u7684\uff0c\u8be5\u884c\u653f\u5904\u7f5a\u7a0b\u5e8f\u8fdd\u6cd5\uff0c\u884c\u653f\u5904\u7f5a\u884c\u4e3a\u65e0\u6548\nD. \u884c\u653f\u673a\u5173\u672a\u8d23\u4ee4\u5f53\u4e8b\u4eba\u9650\u671f\u6539\u6b63\u8fdd\u6cd5\u884c\u4e3a\u5373\u4f5c\u51fa\u884c\u653f\u5904\u7f5a\u7684\uff0c\u8be5\u884c\u653f\u5904\u7f5a\u7a0b\u5e8f\u4e0d\u8fdd\u6cd5\uff0c\u4f46\u662f\u8be5\u5904\u7f5a\u884c\u4e3a\u4e3a\u53ef\u64a4\u9500\u7684\u884c\u653f\u884c\u4e3a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.40848354399971304, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u516c\u53f82019\u5e743\u670831\u65e5\u53d1\u73b02018\u5e74\u5ea6\u591a\u8ba1\u7ba1\u7406\u8d39\u7528200\u4e07\u5143\uff0c\u5e76\u8fdb\u884c\u4e862018\u5e74\u4f01\u4e1a\u6240\u5f97\u7a0e\u7533\u62a5\uff0c\u7532\u516c\u53f8\u9002\u7528\u4f01\u4e1a\u6240\u5f97\u7a0e\u7a0e\u738725%\uff0c\u5e76\u6309\u51c0\u5229\u6da6\u768410%\u63d0\u53d6\u6cd5\u5b9a\u76c8\u4f59\u516c\u79ef\u3002\u5047\u8bbe\u7532\u516c\u53f82018\u5e74\u5ea6\u8d22\u52a1\u62a5\u8868\u4e8e2019\u5e743\u670810\u65e5\u5bf9\u5916\u62a5\u51fa\uff0c\u4e14\u5f53\u5e74\u5ea6\u4f01\u4e1a\u6240\u5f97\u7a0e\u7533\u62a5\u7684\u5e94\u7eb3\u7a0e\u6240\u5f97\u7a0e\u989d\u5927\u4e8e\u96f6\uff0c\u5219\u4e0b\u5217\u7532\u516c\u53f8\u5bf9\u6b64\u9879\u91cd\u8981\u524d\u671f\u5dee\u9519\u8fdb\u884c\u66f4\u6b63\u7684\u4f1a\u8ba1\u5904\u7406\u4e2d\u6b63\u786e\u7684\u662f____\u3002\nA. \u8c03\u51cf2019\u5e74\u5ea6\u5f53\u671f\u7ba1\u7406\u8d39\u7528200\u4e07\u5143\nB. \u8c03\u589e2019\u5e74\u5f53\u671f\u672a\u5206\u914d\u5229\u6da6150\u4e07\u5143\nC. \u8c03\u51cf2019\u5e74\u5e74\u521d\u672a\u5206\u914d\u5229\u6da6135\u4e07\u5143\nD. \u8c03\u589e2019\u5e74\u5e74\u521d\u672a\u5206\u914d\u5229\u6da6135\u4e07\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3956423519781027, "HuggingFaceH4/zephyr-7b-beta": 0.5654390283038806, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3148300531811561, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8d2d\u7f6e\u65b0\u5efa\u623f\u7684\u57ce\u9547\u571f\u5730\u4f7f\u7528\u7a0e\u7eb3\u7a0e\u4e49\u52a1\u53d1\u751f\u65f6\u95f4\u4e3a____\u3002\nA. \u81ea\u623f\u5c4b\u4ea4\u4ed8\u4f7f\u7528\u4e4b\u6b21\u6708\u8d77\nB. \u81ea\u529e\u7406\u623f\u4ea7\u8bc1\u4e4b\u6b21\u6708\u8d77\nC. \u81ea\u7b7e\u8ba2\u623f\u5c4b\u4e70\u5356\u5408\u540c\u4e4b\u6b21\u6708\u8d77\nD. \u81ea\u623f\u5c4b\u7ae3\u5de5\u9a8c\u6536\u4e4b\u6b21\u6708\u8d77\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2801288226217134, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u516c\u53f82019\u5e74\u5e74\u5ea6\u8d22\u52a1\u62a5\u544a\u7ecf\u8463\u4e8b\u4f1a\u6279\u51c6\u4e8e2020\u5e744\u670820\u65e5\u62a5\u51fa\u3002\u7532\u516c\u53f8\u57282020\u5e741\u67081\u65e5\u81f34\u670820\u65e5\u4e4b\u95f4\u53d1\u751f\u7684\u4e0b\u5217\u4e8b\u9879\u4e2d\uff0c\u5c5e\u4e8e\u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\u540e\u8c03\u6574\u4e8b\u9879\u7684\u662f____\u3002\nA. 2020\u5e743\u670810\u65e5\uff0c\u6cd5\u9662\u5224\u51b3\u67d0\u9879\u8bc9\u8bbc\u8d25\u8bc9\uff0c\u5e76\u9700\u652f\u4ed8\u8d54\u507f\u91d1\u989d80\u4e07\u5143\uff0c\u7532\u516c\u53f8\u57282019\u5e74\u5e74\u672b\u5df2\u7ecf\u786e\u8ba4\u9884\u8ba1\u8d1f\u503a65\u4e07\u5143\nB. 2020\u5e742\u670810\u65e5\u53d1\u751f\u4ea7\u54c1\u9500\u552e\u9000\u56de\uff0c\u8be5\u6279\u4ea7\u54c1\u7cfb2020\u5e741\u6708\u5bf9\u5916\u9500\u552e\nC. 2020\u5e742\u670818\u65e5\u8463\u4e8b\u4f1a\u63d0\u51fa\u8d44\u672c\u516c\u79ef\u8f6c\u589e\u8d44\u672c\u65b9\u6848\nD. 2020\u5e743\u670818\u65e5\u516c\u53f8\u4ed3\u5e93\u53d1\u751f\u706b\u707e\u5bfc\u81f4\u5b58\u8d27\u90e8\u5206\u6bc1\u635f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3879740469430858, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u5916\u5e01\u4ea4\u6613\u4f1a\u8ba1\u5904\u7406\u7684\u8868\u8ff0\u4e2d\uff0c\u9519\u8bef\u7684\u662f____\u3002\nA. \u5916\u5e01\u4ea4\u6613\u5728\u521d\u59cb\u786e\u8ba4\u65f6\uff0c\u53ef\u4ee5\u91c7\u7528\u6309\u7167\u7cfb\u7edf\u5408\u7406\u7684\u65b9\u6cd5\u786e\u5b9a\u7684\u3001\u4e0e\u4ea4\u6613\u65e5\u5373\u671f\u6c47\u7387\u8fd1\u4f3c\u7684\u6c47\u7387\u6298\u7b97\nB. \u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\uff0c\u5bf9\u4e8e\u5916\u5e01\u8d27\u5e01\u6027\u9879\u76ee\u5e94\u5f53\u6839\u636e\u6c47\u7387\u53d8\u52a8\u8ba1\u7b97\u6c47\u5151\u5dee\u989d\u4f5c\u4e3a\u8d22\u52a1\u8d39\u7528\uff0c\u65e0\u9700\u518d\u8ba1\u63d0\u51cf\u503c\u51c6\u5907\nC. \u5916\u5e01\u4ea4\u6613\u5e94\u5f53\u5728\u521d\u59cb\u786e\u8ba4\u65f6\uff0c\u91c7\u7528\u4ea4\u6613\u53d1\u751f\u65e5\u7684\u5373\u671f\u6c47\u7387\u6216\u8fd1\u4f3c\u6c47\u7387\u5c06\u5916\u5e01\u91d1\u989d\u6298\u7b97\u4e3a\u8bb0\u8d26\u672c\u4f4d\u5e01\u91d1\u989d\nD. \u8d44\u4ea7\u8d1f\u503a\u8868\u65e5\uff0c\u5bf9\u4ee5\u5386\u53f2\u6210\u672c\u8ba1\u91cf\u7684\u5916\u5e01\u975e\u8d27\u5e01\u6027\u9879\u76ee\uff0c\u4ecd\u91c7\u7528\u4ea4\u6613\u53d1\u751f\u65e5\u7684\u5373\u671f\u6c47\u7387\u6298\u7b97\uff0c\u4e0d\u6539\u53d8\u8bb0\u8d26\u672c\u4f4d\u5e01\u91d1\u989d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3661763986529049, "HuggingFaceH4/zephyr-7b-beta": 0.9732014651335191, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u6d88\u8d39\u54c1\uff0c\u5c5e\u4e8e\u6d88\u8d39\u7a0e\u5f81\u7a0e\u8303\u56f4\u7684\u662f____\u3002\nA. \u5408\u6210\u5b9d\u77f3\u9996\u9970\nB. \u6d17\u53d1\u6c34\nC. \u5927\u5ba2\u8f66\nD. \u8f6e\u80ce\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.4415437293991451, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u8f66\u8239\u7a0e\u7684\u8bf4\u6cd5\u4e2d\uff0c\u6b63\u786e\u7684\u662f____\u3002\nA. \u62d6\u62c9\u673a\u5c5e\u4e8e\u8f66\u8239\u7a0e\u7684\u5f81\u6536\u8303\u56f4\nB. \u6263\u7f34\u4e49\u52a1\u4eba\u4ee3\u6263\u4ee3\u7f34\u8f66\u8239\u7a0e\u7684\uff0c\u8f66\u8f86\u767b\u8bb0\u5730\u4e3b\u7ba1\u7a0e\u52a1\u673a\u5173\u4e0d\u518d\u5f81\u6536\nC. \u5883\u5185\u5355\u4f4d\u548c\u4e2a\u4eba\u5c06\u8239\u8236\u51fa\u79df\u5230\u5883\u5916\u7684\uff0c\u4e0d\u5f81\u6536\u8f66\u8239\u7a0e\nD. \u5ba2\u8d27\u4e24\u7528\u8f66\u4f9d\u7167\u4e58\u7528\u8f66\u7684\u6807\u51c6\u8ba1\u5f81\u8f66\u8239\u7a0e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.4201996374046128, "itpossible/Chinese-Mistral-7B-v0.1": 0.29863342676099575, "HuggingFaceH4/zephyr-7b-beta": 0.8288005268133729, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.553177123486441, "meta-llama/Meta-Llama-3-8B": 0.35010438628968715, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5728\u7a0e\u52a1\u884c\u653f\u590d\u8bae\u4e2d\uff0c\u4e0d\u53ef\u4ee5\u8fbe\u6210\u548c\u89e3\u548c\u8c03\u89e3\u7684\u60c5\u5f62\u662f____\u3002\nA. \u884c\u653f\u5956\u52b1\nB. \u884c\u653f\u5ba1\u6279\nC. \u786e\u5b9a\u5e94\u7a0e\u6240\u5f97\u7387\nD. \u6838\u5b9a\u7a0e\u989d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3423962339378881, "itpossible/Chinese-Mistral-7B-v0.1": 0.35096048266444385, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.325455072595945, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7533\u8bf7\u4eba\u548c\u88ab\u7533\u8bf7\u4eba\u5728\u884c\u653f\u590d\u8bae\u673a\u5173\u4f5c\u51fa\u884c\u653f\u590d\u8bae\u51b3\u5b9a\u4ee5\u524d\u53ef\u4ee5\u8fbe\u6210\u548c\u89e3\uff0c\u884c\u653f\u590d\u8bae\u673a\u5173\u4e5f\u53ef\u4ee5\u8c03\u89e3\uff0c\u4e0b\u5217\u9009\u9879\u4e2d\u4e0d\u53ef\u4ee5\u548c\u89e3\u4e0e\u8c03\u89e3\u7684\u662f____\u3002\nA. \u786e\u5b9a\u5e94\u7a0e\u6240\u5f97\u7387\nB. \u884c\u653f\u8d54\u507f\nC. \u884c\u653f\u5956\u52b1\nD. \u5f81\u6536\u6ede\u7eb3\u91d1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3227963716692408, "meta-math/MetaMath-Mistral-7B": 0.36144170536635384, "itpossible/Chinese-Mistral-7B-v0.1": 0.6172708871600293, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5173\u4e8e\u552e\u540e\u56de\u8d2d\u4ea4\u6613\u7684\u4f1a\u8ba1\u5904\u7406\u7b26\u5408\u4f01\u4e1a\u4f1a\u8ba1\u51c6\u5219\u89c4\u5b9a\u7684\u662f____\u3002\nA. \u4f01\u4e1a\u56e0\u5b58\u5728\u4e0e\u5ba2\u6237\u7684\u8fdc\u671f\u5b89\u6392\u800c\u8d1f\u6709\u56de\u8d2d\u4e49\u52a1\u6216\u4f01\u4e1a\u4eab\u6709\u56de\u8d2d\u6743\u5229\u7684\uff0c\u56de\u8d2d\u4ef7\u683c\u4f4e\u4e8e\u552e\u4ef7\uff0c\u5e94\u5f53\u89c6\u4e3a\u79df\u8d41\u4ea4\u6613\nB. \u4f01\u4e1a\u5230\u671f\u672a\u884c\u4f7f\u56de\u8d2d\u6743\u5229\u7684\uff0c\u5e94\u5f53\u5728\u8be5\u56de\u8d2d\u6743\u5229\u5230\u671f\u65f6\u7ec8\u6b62\u786e\u8ba4\u91d1\u878d\u8d1f\u503a\uff0c\u4f46\u65e0\u9700\u786e\u8ba4\u6536\u5165\nC. \u4f01\u4e1a\u8d1f\u6709\u5e94\u5ba2\u6237\u8981\u6c42\u56de\u8d2d\u5546\u54c1\u4e49\u52a1\u7684\uff0c\u5ba2\u6237\u5177\u6709\u884c\u4f7f\u8be5\u8981\u6c42\u6743\u91cd\u5927\u7ecf\u6d4e\u52a8\u56e0\u7684\uff0c\u4f01\u4e1a\u5e94\u5f53\u5c06\u552e\u540e\u56de\u8d2d\u4f5c\u4e3a\u878d\u8d44\u4ea4\u6613\nD. \u4f01\u4e1a\u8d1f\u6709\u5e94\u5ba2\u6237\u8981\u6c42\u56de\u8d2d\u5546\u54c1\u4e49\u52a1\u7684\uff0c\u5ba2\u6237\u4e0d\u5177\u6709\u884c\u4f7f\u8be5\u8981\u6c42\u6743\u91cd\u5927\u7ecf\u6d4e\u52a8\u56e0\u7684\uff0c\u5e94\u5f53\u5c06\u5176\u4f5c\u4e3a\u6b63\u5e38\u9500\u552e\u4ea4\u6613\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "M\u516c\u53f8\u8d44\u91d1\u5468\u8f6c\u51fa\u73b0\u56f0\u96be\uff0c\u5176\u6cd5\u5b9a\u4ee3\u8868\u4eba\u7532\u5411\u597d\u53cb\u4e59\u501f\u6b3e100\u4e07\u5143\uff0c\u7532\u628a\u81ea\u5df1\u7684\u5b9d\u9a6c\u6c7d\u8f66\u62b5\u62bc\u7ed9\u4e59\uff0c\u62b5\u62bc\u5408\u540c\u4e2d\u7ea6\u5b9a\u82e5\u7532\u4e0d\u80fd\u6309\u65f6\u8fd8\u94b1\uff0c\u7532\u7684\u5b9d\u9a6c\u6c7d\u8f66\u5f52\u4e59\u6240\u6709\u3002\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u8be5\u62b5\u62bc\u672a\u767b\u8bb0\uff0c\u4e59\u7684\u62b5\u62bc\u6743\u672a\u751f\u6548\nB. \u7532\u3001\u4e59\u7684\u7ea6\u5b9a\u65e0\u6548\nC. \u7532\u3001\u4e59\u7684\u7ea6\u5b9a\u7ecf\u767b\u8bb0\u624d\u6709\u6548\nD. \u7532\u5e94\u628a\u81ea\u5df1\u7684\u6c7d\u8f66\u4ea4\u4ed8\u7ed9\u4e59\uff0c\u62b5\u62bc\u6743\u624d\u751f\u6548\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7532\u3001\u4e59\u3001\u4e19\u6210\u7acb\u4e00\u5bb6\u79d1\u8d38\u6709\u9650\u516c\u53f8\uff0c\u7ea6\u5b9a\u516c\u53f8\u6ce8\u518c\u8d44\u672c100\u4e07\u5143\uff0c\u7532\u3001\u4e59\u3001\u4e19\u5404\u630920%\u300130%\u300150%\u7684\u6bd4\u4f8b\u51fa\u8d44\u3002\u7532\u3001\u4e59\u7f34\u8db3\u4e86\u51fa\u8d44\uff0c\u4e19\u4ec5\u5b9e\u7f3430\u4e07\u5143\u3002\u516c\u53f8\u7ae0\u7a0b\u5bf9\u4e8e\u7ea2\u5229\u5206\u914d\u6ca1\u6709\u7279\u522b\u7ea6\u5b9a\u3002\u5f53\u5e74\u5e74\u5e95\u516c\u53f8\u8fdb\u884c\u5206\u7ea2\u3002\u5bf9\u6b64\uff0c\u4e0b\u5217\u8bf4\u6cd5\u4e2d\u6b63\u786e\u7684\u662f____\u3002\nA. \u4e19\u53ea\u80fd\u630930%\u7684\u6bd4\u4f8b\u5206\u7ea2\nB. \u5e94\u6309\u5b9e\u7f34\u6ce8\u518c\u8d44\u672c80\u4e07\u5143\uff0c\u7531\u7532\u3001\u4e59\u3001\u4e19\u6309\u5404\u81ea\u7684\u5b9e\u9645\u51fa\u8d44\u6bd4\u4f8b\u5206\u7ea2\nC. \u7531\u4e8e\u4e19\u8fdd\u53cd\u51fa\u8d44\u4e49\u52a1\uff0c\u5176\u4ed6\u80a1\u4e1c\u53ef\u901a\u8fc7\u51b3\u8bae\u53d6\u6d88\u5176\u5f53\u5e74\u5206\u7ea2\u8d44\u683c\nD. \u4e19\u6709\u6743\u630950%\u7684\u6bd4\u4f8b\u5206\u7ea2\uff0c\u4f46\u5e94\u5f53\u627f\u62c5\u672a\u8db3\u989d\u51fa\u8d44\u7684\u8fdd\u7ea6\u8d23\u4efb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.29266619320322734, "meta-math/MetaMath-Mistral-7B": 0.448984249197459, "itpossible/Chinese-Mistral-7B-v0.1": 0.3300364758848943, "HuggingFaceH4/zephyr-7b-beta": 0.8314268604688693, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.546199955745649, "meta-llama/Meta-Llama-3-8B": 0.40888408722076547, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5e94\u7a0e\u56fa\u4f53\u5e9f\u7269\u73af\u5883\u4fdd\u62a4\u7a0e\u7684\u8ba1\u7a0e\u4f9d\u636e\u662f____\u3002\nA. \u56fa\u4f53\u5e9f\u7269\u7684\u7efc\u5408\u5229\u7528\u91cf\nB. \u56fa\u4f53\u5e9f\u7269\u7684\u6392\u653e\u91cf\nC. \u56fa\u4f53\u5e9f\u7269\u7684\u4ea7\u751f\u91cf\nD. \u56fa\u4f53\u5e9f\u7269\u7684\u8d2e\u5b58\u91cf\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.683777411832951, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.39418480589795873, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7637257450951053}}, {"question": "\u67d0\u5377\u70df\u6279\u53d1\u4f01\u4e1a\u57282020\u5e7410\u6708\u53d1\u751f\u4e0b\u5217\u4e1a\u52a1\uff1a\u6279\u53d1\u9500\u552e\u7ed9\u5377\u70df\u96f6\u552e\u4f01\u4e1a\u5377\u70df10\u6807\u51c6\u7bb1\uff0c\u53d6\u5f97\u4e0d\u542b\u7a0e\u6536\u5165150\u4e07\u5143\uff1b\u6279\u53d1\u9500\u552e\u7ed9\u5377\u70df\u6279\u53d1\u5546\u5377\u70df5\u6807\u51c6\u7bb1\uff0c\u53d6\u5f97\u4e0d\u542b\u7a0e\u6536\u516565\u4e07\u5143\u3002\u8be5\u4f01\u4e1a\u5f53\u6708\u5e94\u7eb3\u6d88\u8d39\u7a0e____\u4e07\u5143\u3002\nA. 16.5\nB. 16.75\nC. 23.65\nD. 24.03\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.34600580950320253, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u8d22\u4ea7\u62cd\u5356\u7684\u4e2a\u4eba\u6240\u5f97\u7a0e\u5904\u7406\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u4f5c\u8005\u5c06\u81ea\u5df1\u7684\u6587\u5b57\u4f5c\u54c1\u624b\u7a3f\u539f\u4ef6\u62cd\u5356\u53d6\u5f97\u7684\u6240\u5f97\uff0c\u6309\u201c\u7a3f\u916c\u6240\u5f97\u201d\u9879\u76ee\u8ba1\u7b97\u7f34\u7eb3\u4e2a\u4eba\u6240\u5f97\u7a0e\nB. \u8ba1\u7b97\u4e2a\u4eba\u8d22\u4ea7\u62cd\u5356\u7684\u5e94\u7eb3\u7a0e\u6240\u5f97\u989d\u65f6\uff0c\u7eb3\u7a0e\u4eba\u5b9e\u9645\u652f\u4ed8\u7684\u62cd\u5356\u8d39\u4e0d\u5f97\u6263\u9664\nC. \u62cd\u5356\u7956\u4f20\u6536\u85cf\u7684\u8d22\u4ea7\uff0c\u53ef\u4ee5\u7a0e\u524d\u6263\u9664\u7684\u8d22\u4ea7\u539f\u503c\u4e3a\u5176\u6536\u85cf\u8be5\u62cd\u5356\u54c1\u800c\u53d1\u751f\u7684\u8d39\u7528\nD. \u7ecf\u8ba4\u5b9a\u7684\u6d77\u5916\u56de\u6d41\u6587\u7269\u7684\u8d22\u4ea7\u539f\u503c\u65e0\u6cd5\u786e\u5b9a\u7684\uff0c\u6309\u8f6c\u8ba9\u6536\u5165\u76843%\u5f81\u6536\u7387\u8ba1\u7a0e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.34239658121563493, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.31712010892822357, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u53bf\u751f\u732a\u5c60\u5bb0\u4e3b\u7ba1\u90e8\u95e8\u5f3a\u5236\u8be5\u53bf50\u6237\u517b\u732a\u519c\u6c11\u517b\u6b961\u53f7\u732a\uff0c\u5e76\u5bf9\u5176\u4ed6\u54c1\u79cd\u7684\u751f\u732a\u5c06\u4e0d\u4e88\u5c60\u5bb0\u3002\u5bf9\u4e8e\u6b64\u884c\u4e3a\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u7531\u4e8e\u8be5\u884c\u4e3a\u5c5e\u4e8e\u666e\u904d\u7ea6\u675f\u529b\u7684\u51b3\u5b9a\u3001\u547d\u4ee4\uff0c\u5c5e\u4e8e\u884c\u653f\u8bc9\u8bbc\u4e0d\u53d7\u7406\u7684\u6848\u4ef6\u8303\u56f4\nB. \u8be5\u884c\u4e3a\u662f\u884c\u653f\u673a\u5173\u4e3a\u4f5c\u51fa\u884c\u653f\u884c\u4e3a\u800c\u5b9e\u65bd\u7684\u8fc7\u7a0b\u6027\u884c\u653f\u884c\u4e3a\uff0c\u56e0\u6b64\u4e0d\u5177\u53ef\u8bc9\u6027\nC. \u8be5\u884c\u4e3a\u662f\u5177\u4f53\u884c\u653f\u884c\u4e3a\uff0c\u5177\u6709\u53ef\u8bc9\u6027\nD. \u8be5\u884c\u4e3a\u662f\u56fd\u5bb6\u884c\u4e3a\uff0c\u5c5e\u4e8e\u884c\u653f\u8bc9\u8bbc\u4e0d\u53d7\u7406\u7684\u6848\u4ef6\u8303\u56f4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6693879055468271, "meta-math/MetaMath-Mistral-7B": 0.7284591823387165, "itpossible/Chinese-Mistral-7B-v0.1": 0.48464262260161123, "HuggingFaceH4/zephyr-7b-beta": 0.9672353960251556, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8937624347366593, "meta-llama/Meta-Llama-3-8B": 0.8102052578855925, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9307672436880469}}, {"question": "\u4e0b\u5217\u5404\u9879\u4e2d\uff0c\u4e0d\u5c5e\u4e8e\u7a0e\u52a1\u884c\u653f\u8bc9\u8bbc\u76ee\u7684\u7684\u662f____\u3002\nA. \u7ef4\u62a4\u548c\u76d1\u7763\u7a0e\u52a1\u673a\u5173\u4f9d\u6cd5\u884c\u4f7f\u884c\u653f\u804c\u6743\nB. \u4fdd\u8bc1\u7a0e\u6cd5\u7684\u516c\u5e73\u3001\u516c\u6b63\nC. \u4fdd\u62a4\u7eb3\u7a0e\u4eba\u3001\u6263\u7f34\u4e49\u52a1\u4eba\u7b49\u5f53\u4e8b\u4eba\u7684\u5408\u6cd5\u6743\u76ca\nD. \u4fdd\u8bc1\u4eba\u6c11\u6cd5\u9662\u6b63\u786e\u3001\u53ca\u65f6\u5ba1\u7406\u7a0e\u52a1\u884c\u653f\u6848\u4ef6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u652f\u51fa\u4e0d\u80fd\u4f5c\u4e3a\u957f\u671f\u5f85\u644a\u8d39\u7528\u7684\u662f____\u3002\nA. \u56fa\u5b9a\u8d44\u4ea7\u7684\u5927\u4fee\u7406\u652f\u51fa\nB. \u79df\u5165\u56fa\u5b9a\u8d44\u4ea7\u7684\u6539\u5efa\u652f\u51fa\nC. \u5916\u8d2d\u623f\u5c4b\u53d1\u751f\u7684\u88c5\u4fee\u8d39\u7528\nD. \u5df2\u8db3\u989d\u63d0\u53d6\u6298\u65e7\u7684\u56fa\u5b9a\u8d44\u4ea7\u7684\u6539\u5efa\u652f\u51fa\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5630643423175843}}, {"question": "\u4e0b\u5217\u51ed\u8bc1\u4e2d\uff0c\u9700\u8981\u8ba1\u7b97\u7f34\u7eb3\u5370\u82b1\u7a0e\u7684\u662f____\u3002\nA. \u65e0\u606f\u3001\u8d34\u606f\u8d37\u6b3e\u5408\u540c\nB. \u65b0\u8bbe\u7acb\u7684\u8d44\u91d1\u8d26\u7c3f\nC. \u8d22\u4ea7\u6240\u6709\u4eba\u5c06\u8d22\u4ea7\u8d60\u7ed9\u5b66\u6821\u6240\u7acb\u7684\u4e66\u636e\nD. \u65bd\u5de5\u5355\u4f4d\u5206\u5305\u7ed9\u5176\u4ed6\u65bd\u5de5\u5355\u4f4d\u7684\u5206\u5305\u5408\u540c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.29068935354339714, "HuggingFaceH4/zephyr-7b-beta": 0.5340705984553207, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3460058095032025, "meta-llama/Meta-Llama-3-8B": 0.48148338235486976, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9580711323883275}}, {"question": "\u7532\u516c\u53f8\u67d0\u96f6\u4ef6\u5e74\u9700\u8981\u91cf\u4e3a2000\u4ef6\uff0c\u6bcf\u6b21\u8ba2\u8d27\u6210\u672c\u4e3a30\u5143\uff0c\u5355\u4f4d\u50a8\u5b58\u6210\u672c\u4e3a0.75\u5143/\u4ef6\u3002\u6309\u7167\u7ecf\u6d4e\u8ba2\u8d27\u91cf\u8fdb\u8d27\uff0c\u4e0b\u5217\u8ba1\u7b97\u7ed3\u679c\u4e2d\u9519\u8bef\u7684\u662f____\u3002\nA. \u7ecf\u6d4e\u8ba2\u8d27\u91cf\u4e3a400\u4ef6\nB. \u5e74\u8ba2\u8d27\u6b21\u6570\u4e3a5\u6b21\nC. \u603b\u8ba2\u8d27\u6210\u672c\u4e3a300\u5143\nD. \u4e0e\u8fdb\u8d27\u6279\u91cf\u76f8\u5173\u7684\u603b\u6210\u672c\u4e3a300\u5143\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.4989878839244784, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5354728753003317}}, {"question": "\u5173\u4e8e\u571f\u5730\u589e\u503c\u7a0e\u7684\u6e05\u7b97\uff0c\u4e0b\u5217\u8bf4\u6cd5\u9519\u8bef\u7684\u662f____\u3002\nA. \u9500\u552e\u5408\u540c\u6240\u8f7d\u5546\u54c1\u623f\u9762\u79ef\u4e0e\u5b9e\u9645\u6d4b\u91cf\u9762\u79ef\u4e0d\u4e00\u81f4\u5e76\u5728\u6e05\u7b97\u524d\u5df2\u8865\u6216\u9000\u623f\u6b3e\u7684\uff0c\u5728\u8ba1\u7b97\u571f\u5730\u589e\u503c\u7a0e\u65f6\u5e94\u4e88\u8c03\u6574\nB. \u672a\u5168\u989d\u5f00\u5177\u5546\u54c1\u623f\u9500\u552e\u53d1\u7968\u7684\uff0c\u6309\u7167\u9500\u552e\u5408\u540c\u6240\u8f7d\u91d1\u989d\u53ca\u5176\u4ed6\u6536\u76ca\u786e\u8ba4\u6536\u5165\nC. \u672a\u5f00\u5177\u5546\u54c1\u623f\u9500\u552e\u53d1\u7968\u7684\uff0c\u6309\u7167\u5b9e\u9645\u6536\u53d6\u91d1\u989d\u786e\u8ba4\u6536\u5165\nD. \u5df2\u5168\u989d\u5f00\u5177\u5546\u54c1\u623f\u9500\u552e\u53d1\u7968\u7684\uff0c\u6309\u7167\u53d1\u7968\u6240\u683d\u91d1\u989d\u786e\u8ba4\u6536\u5165\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.34445451660108384, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3534716292209113, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2020\u5e745\u670810\u65e5\uff0c\u7a0e\u52a1\u673a\u5173\u5728\u68c0\u67e5\u67d0\u516c\u53f8\u7684\u7eb3\u7a0e\u60c5\u51b5\u8fc7\u7a0b\u4e2d\uff0c\u53d1\u73b0\u8be5\u516c\u53f82019\u5e74\u7684\u4e1a\u52a1\u5b58\u5728\u5173\u8054\u4ea4\u6613\uff0c\u5c11\u7f34\u7eb3\u4f01\u4e1a\u6240\u5f97\u7a0e30\u4e07\u5143\u3002\u8be5\u516c\u53f8\u4e8e2020\u5e745\u670831\u65e5\u8865\u7f34\u4e86\u8be5\u7a0e\u6b3e\uff0c\u5e76\u6309\u89c4\u5b9a\u63d0\u4f9b\u4e86\u540c\u671f\u8d44\u6599\u53ca\u6709\u5173\u8d44\u6599\u3002\u5df2\u77e52019\u5e7412\u670831\u65e5\u4e2d\u56fd\u4eba\u6c11\u94f6\u884c\u516c\u5e03\u7684\u4e00\u5e74\u671f\u4eba\u6c11\u5e01\u8d37\u6b3e\u5e74\u5229\u7387\u4e3a6%\u3002\u7a0e\u52a1\u673a\u5173\u5bf9\u8be5\u516c\u53f8\u8865\u7f34\u7a0e\u6b3e\u5e94\u52a0\u6536\u5229\u606f____\u4e07\u5143\u3002\nA. 1.8\nB. 1.95\nC. 3.3\nD. 3.6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u6d88\u8d39\u7a0e\u4ece\u4ef7\u5b9a\u7387\u8ba1\u7a0e\u9500\u552e\u989d\uff0c\u4e0b\u5217\u8bf4\u6cd5\u6b63\u786e\u7684\u662f____\u3002\nA. \u91d1\u94f6\u9996\u9970\u5305\u88c5\u8d39\u4e0d\u8ba1\u5165\u8ba1\u7a0e\u9500\u552e\u989d\nB. \u6d88\u8d39\u7a0e\u8ba1\u7a0e\u9500\u552e\u989d\u5305\u62ec\u589e\u503c\u7a0e\nC. \u767d\u9152\u5305\u88c5\u7269\u62bc\u91d1\u6536\u53d6\u65f6\u4e0d\u8ba1\u5165\u8ba1\u7a0e\u9500\u552e\u989d\nD. \u9ad8\u6863\u5316\u5986\u54c1\u54c1\u724c\u4f7f\u7528\u8d39\u5e94\u8ba1\u5165\u8ba1\u7a0e\u9500\u552e\u989d\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.2986334267609957, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.6522291361568566, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3468666740605408, "meta-llama/Meta-Llama-3-8B": 0.32545507259594497, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "2020\u5e7410\u6708\uff0c\u4e3a\u54cd\u5e94\u73af\u4fdd\u8282\u80fd\u53f7\u53ec\uff0c\u9648\u67d0\u4ece\u6c7d\u8f664S\u5e97(\u589e\u503c\u7a0e\u4e00\u822c\u7eb3\u7a0e\u4eba)\u8d2d\u4e70\u4e00\u8f86\u65b0\u80fd\u6e90\u6c7d\u8f66\uff0c\u652f\u4ed8\u4e0d\u542b\u7a0e\u4ef7\u6b3e150000\u5143\u3002\u53e6\u652f\u4ed8\u6c7d\u8f664S\u5e97\u4ee3\u529e\u4fdd\u9669\u8d392000\u5143\uff0c\u4ee3\u529e\u8f66\u8f86\u724c\u7167\u8d39300\u5143\uff0c\u4ee3\u6536\u6b3e\u98794S\u5e97\u672a\u5f00\u5177\u53d1\u7968\u3002\u9648\u67d0\u5e94\u7eb3\u8f66\u8f86\u8d2d\u7f6e\u7a0e____\u5143\u3002\nA. 0\nB. 10500\nC. 15000\nD. 15203.54\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.36253010780209793, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u67d0\u4f9b\u70ed\u4f01\u4e1a\u4e3a\u589e\u503c\u7a0e\u4e00\u822c\u7eb3\u7a0e\u4eba\uff0c2020\u5e7410\u6708\u53d6\u5f97\u4e0d\u542b\u7a0e\u4f9b\u70ed\u6536\u5165860\u4e07\u5143\uff0c\u5176\u4e2d\u5411\u5c45\u6c11\u4e2a\u4eba\u6536\u53d6120\u4e07\u5143\uff0c\u5f53\u6708\u5916\u8d2d\u539f\u6750\u6599\u53d6\u5f97\u589e\u503c\u7a0e\u4e13\u7528\u53d1\u7968\u6ce8\u660e\u7a0e\u989d70\u4e07\u5143\u3002\u8be5\u4f01\u4e1a2020\u5e7410\u6708\u53ef\u4ee5\u62b5\u6263\u7684\u8fdb\u9879\u7a0e\u989d\u4e3a____\u4e07\u5143\u3002\nA. 15.13\nB. 24.9\nC. 28.94\nD. 60.23\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5883\u5916\u65c5\u5ba2\u8d2d\u7269\u79bb\u5883\u9000\u7a0e\u7684\u65b9\u5f0f\u5305\u62ec\u73b0\u91d1\u9000\u7a0e\u548c\u94f6\u884c\u8f6c\u8d26\u9000\u7a0e\u4e24\u79cd\u65b9\u5f0f\u3002\u81ea\u884c\u9009\u62e9\u9000\u7a0e\u65b9\u5f0f\u65f6\uff0c\u9000\u7a0e\u989d\u5e94\u672a\u8d85\u8fc7____\u5143\u3002\nA. 500\nB. 1000\nC. 5000\nD. 10000\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u8f6c\u8ba9\u5b9a\u4ef7\u65b9\u6cd5\u4e2d\uff0c\u9002\u7528\u4e8e\u6240\u6709\u5173\u8054\u4ea4\u6613\u7684\u662f____\u3002\nA. \u53ef\u6bd4\u975e\u53d7\u63a7\u4ef7\u683c\u6cd5\nB. \u6210\u672c\u52a0\u6210\u6cd5\nC. \u4ea4\u6613\u51c0\u5229\u6da6\u6cd5\nD. \u5229\u6da6\u5206\u5272\u6cd5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4121891705493393, "meta-math/MetaMath-Mistral-7B": 0.41321600136707937, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5357444765571909}}, {"question": "\u67d0\u4f01\u4e1a\u4e3a\u589e\u503c\u7a0e\u4e00\u822c\u7eb3\u7a0e\u4eba\uff0c2021\u5e746\u6708\u4ece\u67d0\u82b1\u6728\u683d\u57f9\u516c\u53f8\u624b\u4e2d\u8d2d\u5165\u82b1\u53491100\u76c6\uff0c\u53d6\u5f97\u7684\u4e13\u7528\u53d1\u7968\u4e0a\u6ce8\u660e\u4ef7\u6b3e\u4e3a110580\u5143\u3002\u8be5\u4f01\u4e1a\u5c061/4\u7528\u4e8e\u8d60\u9001\u7ed9\u67d0\u8282\u65e5\u5e86\u5178\uff0c\u5176\u4f59\u5168\u90e8\u5356\u7ed9\u5ba2\u6237\u53d6\u5f97\u4ea7\u54c1\u4e0d\u542b\u7a0e\u9500\u552e\u989d705000\u5143\u3002\u5219\u8be5\u4f01\u4e1a\u5f53\u6708\u5e94\u7eb3\u589e\u503c\u7a0e\u7a0e\u989d\u4e3a____\u5143\u3002\nA. 59442\nB. 91236.2\nC. 107824.6\nD. 74647.8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u60a3\u8005\u7684\u4e0b\u5217\u54ea\u79cd\u8868\u73b0\u6709\u53ef\u80fd\u4e0d\u662f\u56e0\u4e3a\u7126\u8651\u5f15\u8d77\u7684\uff1f____\nA. \u654f\u611f\u591a\u7591\nB. \u4e22\u4e09\u843d\u56db\nC. \u624b\u5fc3\u51fa\u6c57\nD. \u5931\u7720\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0e\u4e9a\u6025\u6027\u7532\u72b6\u817a\u708e\u6709\u5173\u7684\u75c7\u72b6\u4e3a____\nA. \u808c\u65e0\u529b\nB. \u5e72\u71e5\u7efc\u5408\u5f81\nC. \u53d1\u70ed\u4f34\u7532\u72b6\u817a\u80bf\u75db\nD. \u76ae\u80a4\u7d2b\u7634\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5141454396375038, "meta-math/MetaMath-Mistral-7B": 0.4902825295682051, "itpossible/Chinese-Mistral-7B-v0.1": 0.9644937790623264, "HuggingFaceH4/zephyr-7b-beta": 0.9999157915575357, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9801051488414524, "meta-llama/Meta-Llama-3-8B": 0.825804146985128, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9887086894989069}}, {"question": "\u7ea660%\u8db3\u6708\u513f\u548c80%\u4ee5\u4e0a\u7684\u65e9\u4ea7\u513f\u53ef\u4e8e\u751f\u540e____\nA. \u751f\u540e1\uff5e2\u5929\u51fa\u73b0\u9ec4\u75b8\nB. \u751f\u540e2\uff5e3\u5929\u51fa\u73b0\u9ec4\u75b8\nC. \u751f\u540e2\uff5e4\u5929\u51fa\u73b0\u9ec4\u75b8\nD. \u751f\u540e2\uff5e5\u5929\u51fa\u73b0\u9ec4\u75b8\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.931667142796655, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ed9\u80c3\u764c\u60a3\u8005\u5b9e\u65bd\u76f4\u80a0\u6307\u8bca\u68c0\u67e5\u7684\u76ee\u7684\u662f\u4e86\u89e3\u6709\u65e0____\nA. \u79cd\u690d\u8f6c\u79fb\nB. \u6dcb\u5df4\u8f6c\u79fb\nC. \u8840\u884c\u8f6c\u79fb\nD. \u76f4\u63a5\u6d78\u6da6\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4675722861884373, "meta-math/MetaMath-Mistral-7B": 0.684453294642058, "itpossible/Chinese-Mistral-7B-v0.1": 0.35909976350004963, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8184174040392111, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5725747331489348}}, {"question": "\u5145\u8840\u6027\u5fc3\u529b\u8870\u7aed\u6240\u4ea7\u751f\u7684\u80f8\u8154\u79ef\u6db2\u4e3a____\nA. \u6f0f\u51fa\u6db2\nB. \u6e17\u51fa\u6db2\nC. \u8113\u6027\u80f8\u6db2\nD. \u8840\u6027\u80f8\u6db2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6709\u6392\u77f3\u53f2\uff0c\u53d1\u73b0\u5de6\u80be\u5185\u6709\u4e00\u76f4\u5f840.4cm\u7684\u7ed3\u77f3\uff0c\u9996\u9009____\nA. \u89c2\u5bdf\uff0c\u591a\u996e\u6c34\nB. \u4f53\u5916\u51b2\u51fb\u6ce2\u788e\u77f3\nC. \u8f93\u5c3f\u7ba1\u955c\u53d6\u77f3\u788e\u77f3\u672f\nD. \u5f00\u653e\u624b\u672f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.3878985556820786, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u98df\u7269\u4e2d\u6bcf\u514b\u78b3\u6c34\u5316\u5408\u7269\u3001\u8102\u80aa\u548c\u86cb\u767d\u8d28\u53ef\u4f9b\u7ed9\u80fd\u91cf(kcal)\u5206\u522b\u4e3a____\nA. 4\uff0c9\uff0c4\nB. 9\uff0c4\uff0c4\nC. 4\uff0c9\uff0c9\nD. 9\uff0c9\uff0c4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3091718417481906, "meta-math/MetaMath-Mistral-7B": 0.8258041191188886, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8774366825979881, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5708457790241669, "meta-llama/Meta-Llama-3-8B": 0.32479161563275305, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8672162616281177}}, {"question": "\u88f8\u9732\u75c5\u6bd2\u4f53\u7684\u7ed3\u6784\u4e2d\u4e0d\u5305\u62ec____\nA. DNA\nB. RNA\nC. \u8863\u58f3\nD. \u5305\u819c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3895645678565385, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u80ce\u76d8\u65e9\u5265\u53d1\u751f\u4ea7\u540e\u51fa\u8840\u7684\u539f\u56e0____\nA. \u5b50\u5bab\u4e0b\u6bb5\u7ec4\u7ec7\u8106\u5f31\u6536\u7f29\u529b\u5dee\nB. \u5b50\u5bab\u4e0b\u6bb5\u8840\u8fd0\u4e30\u5bcc\nC. \u4e24\u8005\u5747\u6709\u5173\nD. \u4e24\u8005\u5747\u65e0\u5173\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u524d\u7f6e\u80ce\u76d8\u53d1\u751f\u4ea7\u540e\u51fa\u8840\u7684\u539f\u56e0____\nA. \u5b50\u5bab\u4e0b\u6bb5\u7ec4\u7ec7\u8106\u5f31\u6536\u7f29\u529b\u5dee\nB. \u5b50\u5bab\u4e0b\u6bb5\u8840\u8fd0\u4e30\u5bcc\nC. \u4e24\u8005\u5747\u6709\u5173\nD. \u4e24\u8005\u5747\u65e0\u5173\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5473580239287993, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.49167866266917665, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7802510877508895, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.7200960171531948}}, {"question": "\u8db3\u6708\u513f\u51fa\u751f7\u5929\u540e\u51fa\u73b0\u9ec4\u75b8\uff0c\u4e0b\u5217\u54ea\u9879\u8bca\u65ad\u662f\u4e0d\u53ef\u80fd\u7684____\nA. \u8d25\u8840\u75c7\nB. ABO\u6eb6\u8840\u75c5\nC. \u65b0\u751f\u513f\u80ba\u708e\nD. \u80c6\u9053\u95ed\u9501\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u54ea\u9879\u4e0d\u662f\u533b\u7597\u673a\u6784\u5e94\u5f53\u572812\u5c0f\u65f6\u5185\u5411\u5f53\u5730\u536b\u751f\u884c\u653f\u90e8\u95e8\u62a5\u544a\u7684\u91cd\u5927\u533b\u7597\u8fc7\u5931\u884c\u4e3a____\nA. \u53d1\u751f\u6b7b\u4ea1\u7684\nB. \u6709\u91cd\u5ea6\u6b8b\u75be\u7684\nC. \u6709\u4e2d\u5ea6\u6b8b\u75be\u7684\nD. \u540c\u65f6\u4e8c\u4eba\u4eba\u8eab\u635f\u5bb3\u540e\u679c\u7684\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.4794988504240779, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.8502824766057486}}, {"question": "\u516c\u6c11\u5728\u533b\u9662\u5c31\u533b\u9700\u8981\u7528\u8840\u65f6\uff0c\u53ea\u9700\u4ea4\u4ed8\u7684\u8d39\u7528\u5305\u62ec____\nA. \u7528\u4e8e\u8840\u6db2\u7684\u91c7\u96c6\u3001\u50a8\u5b58\u3001\u5206\u79bb\u3001\u68c0\u9a8c\u7b49\u8d39\u7528\nB. \u7528\u4e8e\u8840\u6db2\u7684\u5305\u88c5\u3001\u50a8\u5b58\u3001\u8fd0\u8f93\u8d39\u7528\nC. \u533b\u9662\u4e3a\u60a3\u8005\u8f93\u8840\u8fc7\u7a0b\u6240\u4ea7\u751f\u7684\u8d39\u7528\nD. \u8840\u6db2\u91c7\u4f9b\u8840\u7684\u8d39\u7528\u548c\u8840\u6db2\u7684\u4ef7\u683c \u884c\u653f\u90e8\u95e8\u4f1a\u540c\u56fd\u52a1\u9662\u4ef7\u683c\u4e3b\u7ba1\u90e8\u95e8\u5236\u5b9a\u3002\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0d\u80fd\u5f15\u8d77\u80ba\u90e8\u5316\u8113\u6027\u75c5\u53d8\u7684\u75c5\u539f\u4f53\u662f____\nA. \u91d1\u9ec4\u8272\u8461\u8404\u7403\u83cc\nB. \u80ba\u708e\u6746\u83cc\nC. \u80ba\u708e\u7403\u83cc\nD. \u55dc\u80ba\u6027\u519b\u56e2\u6746\u83cc\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.8180629554774681, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.2980747244459592, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5173\u4e8e\u80bf\u7624\u7684\u8f6c\u79fb\u9519\u8bef\u7684\u662f____\nA. \u80c3\u764c\u53ef\u8f6c\u79fb\u81f3\u76c6\u8154\nB. \u4e73\u764c\u53ef\u8f6c\u79fb\u81f3\u9501\u9aa8\u4e0a\u6dcb\u5df4\u7ed3\nC. \u4ea4\u754c\u6027\u80bf\u7624\u4e0d\u51fa\u73b0\u8f6c\u79fb\nD. \u809d\u764c\u53ef\u51fa\u73b0\u8111\u8f6c\u79fb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7007552897885359, "meta-math/MetaMath-Mistral-7B": 0.9623663525267588, "itpossible/Chinese-Mistral-7B-v0.1": 0.9505304309746259, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9234810108461338, "meta-llama/Meta-Llama-3-8B": 0.7963047577236597, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9532420416361463}}, {"question": "\u4e09\u4e2a\u5173\u8282\u540c\u65f6\u53d7\u7d2f\uff0c\u79f0\u4e3a____\nA. \u5355\u5173\u8282\u708e\nB. \u591a\u5173\u8282\u708e\nC. \u5bf9\u79f0\u6027\u5173\u8282\u708e\nD. \u5c11\u5173\u8282\u708e\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "6\u4e2a\u6708\u5973\u5a74\uff0c\u56e0\u8d2b\u8840\u4f4f\u9662\uff0c\u8bd5\u9a8c\u68c0\u67e5\u8840\u6e05\u53f6\u9178\u5c0f\u4e8e3\u03bcg/L\uff0c\u8bca\u65ad\u8425\u517b\u6027\u5de8\u5e7c\u7ea2\u7ec6\u80de\u8d2b\u8840\uff0c\u7ed9\u4e88\u53f6\u9178\u6cbb\u7597\uff0c\u4e3a\u4e86\u63d0\u9ad8\u7597\u6548\uff0c\u5e94\u540c\u65f6\u670d____\nA. VitB2\nB. VitD\nC. VitC\nD. VitA\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5244096164486522, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5973\u6027\uff0c40\u5c81\uff0c\u53c2\u52a0\u5a5a\u5bb4\u540e\u53f3\u4e0a\u8179\u75db\uff0c\u5448\u5267\u70c8\u7ede\u75db\uff0c\u67e5\u4f53\u89c1\u8868\u60c5\u75db\u82e6\u4e0d\u5b89\u3002\u5bf9\u8be5\u60a3\u8005\u5728\u786e\u8bca\u524d\u5e94\u7981\u5fcc\u7684\u5904\u7f6e\u662f____\nA. \u9547\u75db\u836f\u6b62\u75db\nB. \u6297\u751f\u7d20\u6d88\u708e\nC. \u6025\u67e5\u8840\u5e38\u89c4\nD. \u884cPTC\u68c0\u67e5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5575056569099817, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.3431547327443468, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5624155873111472}}, {"question": "\u6b63\u5e38\u60c5\u51b5\u4e0b\uff0c\u5c0f\u513f\u9888\u66f2\u5f62\u6210\u7684\u65f6\u95f4\u662f____\nA. 7\u4e2a\u6708\nB. 6\u4e2a\u6708\nC. 4\u4e2a\u6708\nD. 3\u4e2a\u6708\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u62a2\u6551\u6025\u6027\u4e00\u6c27\u5316\u78b3\u4e2d\u6bd2\uff0c\u5c3d\u5feb\u7ea0\u6b63\u7ec4\u7ec7\u7f3a\u6c27\u6548\u679c\u6700\u4f73\u7684\u662f\u54ea\u9879____\nA. \u8fc5\u901f\u79bb\u5f00\u73b0\u573a\nB. \u5438\u6c27\nC. \u8f93\u8840\nD. \u9ad8\u538b\u6c27\u8231\u6cbb\u7597\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9274461288766359, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.7844821187767843, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8865\u94be\u901f\u5ea6\u4e00\u822c\u6bcf\u5c0f\u65f6\u4e0d\u5b9c\u8d85\u8fc7____\nA. 10mmol\nB. 20mmol\nC. 30mmol\nD. 40mmol\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.333183235354062, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.34686667406054084, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u7ecf\u5178\u9014\u5f84\u6fc0\u6d3b\u8865\u4f53\u7684\u6297\u539f\u6297\u4f53\u590d\u5408\u7269____\nA. SigA\u4e0e\u6297\u539f\u7ec4\u6210\u7684\u590d\u5408\u7269\nB. 1\u4e2algM\u4e0e\u6297\u539f\u7ec4\u6210\u7684\u590d\u5408\u7269\nC. 1\u4e2algG\u4e0e\u6297\u539f\u7ec4\u6210\u7684\u590d\u5408\u7269\nD. 1\u4e2algE\u4e0e\u6297\u539f\u7ec4\u6210\u7684\u590d\u5408\u7269\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5fc3\u7406\u6cbb\u7597\u6210\u529f\u7684\u5173\u952e\u662f____\nA. \u4ee5\u4e0a\u5747\u662f\nB. \u533b\u751f\u7684\u533b\u672f\nC. \u826f\u597d\u7684\u533b\u60a3\u5173\u7cfb\nD. \u5bb6\u5c5e\u7684\u914d\u5408\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.8892692234824836, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u5404\u79cd\u5f15\u6d41\u7ba1\uff0c\u4e0d\u6b63\u786e\u7684\u5904\u7406\u662f____\nA. \u8981\u6ce8\u610f\u89c2\u5bdf\u5404\u79cd\u5f15\u6d41\u7ba1\u662f\u5426\u901a\u7545\nB. \u4ed4\u7ec6\u8bb0\u5f55\u5f15\u6d41\u6db2\u7684\u8272\u6cfd\u548c\u5bb9\u91cf\nC. \u7559\u7f6e\u80c6\u7ba1\u5185\u7684\u201cT\u201d\u5f62\u7ba1\u53ef\u5728\u672f\u540e1\u5468\u62d4\u9664\nD. \u80c3\u80a0\u529f\u80fd\u6062\u590d\u540e\u53ef\u5c06\u80c3\u80a0\u51cf\u538b\u7ba1\u9664\u53bb\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5354728442831377, "meta-math/MetaMath-Mistral-7B": 0.8194281906793299, "itpossible/Chinese-Mistral-7B-v0.1": 0.7034605250992085, "HuggingFaceH4/zephyr-7b-beta": 0.9854123478569744, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9731055407889025, "meta-llama/Meta-Llama-3-8B": 0.7213854807228618, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u5a74\u5e7c\u513f\u5fc3\u7406\u536b\u751f\u6700\u4e3b\u8981\u7684\u4efb\u52a1\u662f____\nA. \u7ee7\u80ce\u6559\u540e\u7acb\u5373\u5f00\u59cb\u751f\u540e\u76f8\u5173\u8bad\u7ec3\nB. \u7ecf\u5e38\u7ed9\u5b69\u5b50\u4ee5\u7231\u629a\nC. \u521b\u9020\u5c3d\u53ef\u80fd\u597d\u7684\u751f\u6d3b\u73af\u5883\nD. \u6293\u4f4f\u5173\u952e\u671f\uff0c\u4fc3\u8fdb\u8ba4\u77e5\u60c5\u611f\u7684\u5065\u5eb7\u53d1\u5c55\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8496034654318949, "meta-math/MetaMath-Mistral-7B": 0.98823341906446, "itpossible/Chinese-Mistral-7B-v0.1": 0.742868526624163, "HuggingFaceH4/zephyr-7b-beta": 0.9998090106527843, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9745729610369593, "meta-llama/Meta-Llama-3-8B": 0.5737569353548704, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9889631215048262}}, {"question": "\u76ee\u524d\u8ba4\u4e3a\u591a\u6570\u4eba\u7c7b\u80be\u5c0f\u7403\u75be\u75c5\u662f____\nA. \u9057\u4f20\u6027\u75be\u75c5\nB. \u662f\u7ec6\u83cc\u611f\u67d3\u6027\u75be\u75c5\nC. \u514d\u75ab\u4ecb\u5bfc\u7684\u75be\u75c5\nD. \u514d\u75ab\u7f3a\u9677\u6027\u75be\u75c5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.48686675521652667, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8830938261346081, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.845616113586424, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.48984933699467337}}, {"question": "\u7b49\u6e17\u6027\u8131\u6c34\u591a\u6e90\u4e8e____\u3002\nA. \u6025\u6027\u80c3\u80a0\u708e\u8179\u6cfb\uff0c\u5455\u5410\u4e0d\u6b62\nB. \u6162\u6027\u80a0\u6897\u963b\nC. \u5267\u70c8\u8fd0\u52a8\u5927\u91cf\u51fa\u6c57\nD. \u4f4e\u4f4d\u5c0f\u80a0\u6f0f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3702582991635287, "meta-math/MetaMath-Mistral-7B": 0.5148729880673844, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6119753810440117, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.6615534004881104}}, {"question": "\u5c5e\u4e8e\u2163\u578b\u8d85\u654f\u53cd\u5e94\u7684\u75be\u75c5\u662f____\nA. \u8840\u6e05\u8fc7\u654f\u6027\u4f11\u514b\nB. \u63a5\u89e6\u6027\u76ae\u708e\nC. \u7c7b\u98ce\u6e7f\u6027\u5173\u8282\u708e\nD. \u65b0\u751f\u513f\u6eb6\u8840\u75c7\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u65e9\u671f\u51fa\u73b0\u80ba\u95e8\u53ca\u7eb5\u8188\u591a\u53d1\u6dcb\u5df4\u7ed3\u8f6c\u79fb\u7684\u80ba\u764c\u7c7b\u578b\u662f____\nA. \u9cde\u764c\nB. \u5927\u7ec6\u80de\u80ba\u764c\nC. \u5c0f\u7ec6\u80de\u80ba\u764c\nD. \u817a\u764c\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36727668454475104, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4ee5\u4e0b\u54ea\u9879\u662f\u9ad8\u8840\u538b\u8111\u51fa\u8840\u4e3b\u8981\u5371\u9669\u56e0\u7d20____\nA. \u7cd6\u5c3f\u75c5\u6216\u8840\u7cd6\u589e\u9ad8\nB. \u8840\u6e05\u80c6\u56fa\u9187\u589e\u9ad8\nC. \u7a81\u7136\u8840\u538b\u589e\u9ad8\nD. \u8111\u52a8\u8109\u786c\u5316\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6441627490783856, "meta-math/MetaMath-Mistral-7B": 0.7361200602824964, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9842109495939133}}, {"question": "\u533b\u7597\u673a\u6784\u4ece\u4e1a\u4eba\u5458\u57fa\u672c\u884c\u4e3a\u89c4\u8303\u662f\u54ea\u4e9b\u4eba\u5e94\u5f53\u9075\u5b88\u7684\u3002____\nA. \u533b\u751f\nB. \u62a4\u58eb\nC. \u6240\u6709\u4ece\u4e1a\u4eba\u5458\nD. \u5176\u4ed6\u4eba\u5458\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.8927053111060292, "meta-math/MetaMath-Mistral-7B": 0.9969357012431059, "itpossible/Chinese-Mistral-7B-v0.1": 0.8489476083526122, "HuggingFaceH4/zephyr-7b-beta": 0.9999085942845244, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9392260784245661, "meta-llama/Meta-Llama-3-8B": 0.9352197961980345, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9980216961242473}}, {"question": "\u5b9a\u671f\u8003\u6838\u4e0d\u5408\u683c\u7684\u533b\u5e08\u6682\u505c\u6267\u4e1a\u6d3b\u52a8\u671f\u6ee1\uff0c\u518d\u6b21\u8003\u6838\u4ecd\u4e0d\u5408\u683c\u7684____\nA. \u53ef\u518d\u8bd5\u7528\u4e00\u5e74\nB. \u6ce8\u9500\u6ce8\u518c\uff0c\u6536\u56de\u533b\u5e08\u6267\u4e1a\u8bc1\u4e66\nC. \u5728\u6267\u4e1a\u533b\u5e08\u6307\u5bfc\u4e0b\u4ece\u4e8b\u6267\u4e1a\u6d3b\u52a8\nD. \u6682\u505c\u6267\u4e1a\u6d3b\u52a8\u4e09\u5e74\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5988418105620767, "meta-math/MetaMath-Mistral-7B": 0.8268623205346403, "itpossible/Chinese-Mistral-7B-v0.1": 0.7695236141150845, "HuggingFaceH4/zephyr-7b-beta": 0.9910691770156858, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.8390785133694457, "meta-llama/Meta-Llama-3-8B": 0.6330268823381644, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9969573527951716}}, {"question": "\u5de6\u5fc3\u8870\u7aed\u80ba\u6c34\u80bf____\nA. \u7c89\u7ea2\u8272\u6d46\u6db2\u6027\u6ce1\u6cab\u6837\u75f0\nB. \u94c1\u9508\u8272\u8840\u75f0\nC. \u7816\u7ea2\u8272\u80f6\u51bb\u6837\u7c98\u75f0\nD. \u7c89\u7ea2\u8272\u4e73\u6837\u75f0\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.7947267531265846, "meta-math/MetaMath-Mistral-7B": 0.9913886804592664, "itpossible/Chinese-Mistral-7B-v0.1": 0.26560468668687814, "HuggingFaceH4/zephyr-7b-beta": 0.936324749503631, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9283810006279328, "meta-llama/Meta-Llama-3-8B": 0.5262386562523383, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5929386539020823}}, {"question": "\u6162\u6027\u80be\u76c2\u80be\u708e\u4e3b\u8981\u8f85\u52a9\u68c0\u67e5\u9879\u76ee\u5e94\u662f____\nA. \u80be\u6d3b\u68c0\nB. \u53cc\u80beCT\nC. \u53cc\u80beB\u8d85\nD. \u9759\u8109\u80be\u76c2\u9020\u5f71\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8483066889361195, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5116773701103422}}, {"question": "\u7532\u809d\u611f\u67d3____\nA. \u6297HIV\u9633\u6027\nB. \u6297HAV\u9633\u6027\nC. \u6297EBV\u9633\u6027\nD. \u6297HBC\u9633\u6027\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.9417369425936459, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bca\u65ad\u6027\u8179\u8154\u7a7f\u523a\u4e0d\u5e94\u7528\u4e8e____\nA. \u5c0f\u513f\u53ca\u8001\u5e74\u4eba\nB. \u7cbe\u795e\u72b6\u6001\u4e0d\u6b63\u5e38\u8005\nC. \u660f\u8ff7\u75c5\u4eba\nD. \u8bca\u65ad\u5df2\u660e\u786e\u7684\u75c5\u4eba\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3460058095032025, "itpossible/Chinese-Mistral-7B-v0.1": 0.5165797095148945, "HuggingFaceH4/zephyr-7b-beta": 0.9159080535827597, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.3925874563673054, "meta-llama/Meta-Llama-3-8B": 0.6429309026546881, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.595121838251005}}, {"question": "\u6708\u7ecf\u7684\u7279\u70b9\uff0c\u4e0b\u5217\u6b63\u786e\u7684\u662f____\nA. \u6708\u7ecf\u8840\u6613\u51dd\u56fa\uff0c\u53ef\u6709\u5c0f\u8840\u5757\nB. \u6708\u7ecf\u671f\u53ef\u6709\u4e0b\u8179\u53ca\u8170\u9ab6\u90e8\u5760\u80c0\u611f\nC. \u6b63\u5e38\u6708\u7ecf\u91cf\u4e3a60-100m\nD. \u6708\u7ecf\u5468\u671f\u4e00\u822c\u4e3a28-30\u5929\uff0c\u63d0\u524d\u6216\u63a8\u540e1\u5468\u4ecd\u5c5e\u6b63\u5e38\u8303\u56f4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e00\u80ce\u9f84\u4e3a38\u5468\u7684\u65b0\u751f\u513f\uff0c\u51fa\u751f\u4f53\u91cd\u4e3a3500g\uff0c\u5176\u4f53\u91cd\u4f4d\u4e8e\u540c\u80ce\u9f84\u4f53\u91cd\u6807\u51c6\u7684\u7b2c85\u767e\u5206\u4f4d\uff0c\u4e0b\u5217\u54ea\u4e2a\u8bca\u65ad\u6700\u4e3a\u5168\u9762\u800c\u51c6\u786e____\nA. \u8db3\u6708\u513f\uff0c\u9002\u4e8e\u80ce\u9f84\u513f\nB. \u8db3\u6708\u513f\uff0c\u5927\u4e8e\u80ce\u9f84\u513f\nC. \u8fc7\u671f\u4ea7\u513f\uff0c\u5de8\u5927\u513f\nD. \u8fc7\u671f\u4ea7\u513f\uff0c\u5927\u4e8e\u80ce\u9f84\u513f\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.3160424181481997, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5676326216933184, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u54ea\u79cd\u65b9\u6cd5\u8bca\u65ad\u598a\u5a20\u6700\u53ef\u9760____\nA. \u505c\u7ecf\u53f2\uff0c\u80ce\u52a8\u611f\uff0c\u8179\u90e8\u6e10\u81a8\u9686\nB. \u65e9\u5b55\u53cd\u5e94\uff0c\u53cc\u5408\u8bca\u5b50\u5bab\u589e\u5927\uff0c\u5c3fHCG\u9633\u6027\nC. \u505c\u7ecf\u53f2\uff0c\u53cc\u5408\u8bca\u5b50\u5bab\u589e\u5927\uff0cB\u8d85\u5bab\u5185\u89c1\u598a\u5a20\u56ca\nD. \u505c\u7ecf\u53f2\uff0c\u65e9\u5b55\u53cd\u5e94\uff0cB\u8d85\u5bab\u5185\u89c1\u5149\u56e2\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.8725756813957016, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6622227813647654, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.983566570367702}}, {"question": "\u4e0b\u8ff0\u6709\u5173\u75db\u98ce\u75c5\u7684\u975e\u836f\u7269\u6cbb\u7597\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u7981\u9152\nB. \u63a7\u5236\u996e\u6c34\nC. \u4fdd\u6301\u7406\u60f3\u4f53\u91cd\nD. \u9650\u5236\u9ad8\u560c\u5464\u98df\u7269\u6444\u5165\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.9663907860521892, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.6039641471997528, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u8bca\u65ad\u524d\u7f6e\u80ce\u76d8\u6700\u53ef\u9760\u800c\u5b89\u5168\u7684\u65b9\u6cd5\u662f____\nA. X\u7ebf\u8179\u90e8\u5e73\u7247\nB. B\u8d85\u68c0\u67e5\nC. \u9634\u9053\u53cc\u5408\u8bca\nD. \u809b\u67e5\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6731278364150028, "meta-math/MetaMath-Mistral-7B": 0.7684312381017749, "itpossible/Chinese-Mistral-7B-v0.1": 0.890399092141069, "HuggingFaceH4/zephyr-7b-beta": 0.9973908174779318, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.9743839348474712, "meta-llama/Meta-Llama-3-8B": 0.7067123459773414, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9635329643518455}}, {"question": "\u5173\u4e8e\u5065\u5eb7\u6863\u6848\u586b\u5199\u7684\u8981\u6c42\uff0c\u63cf\u8ff0\u6709\u8bef\u7684\u662f____\nA. \u6863\u6848\u586b\u5199\u2014\u5f8b\u7528\u94a2\u7b14\u6216\u5706\u73e0\u7b14\nB. \u5b57\u8ff9\u8981\u6e05\u695a\uff0c\u4e66\u5199\u8981\u5de5\u6574\nC. \u5982\u679c\u586b\u9519\uff0c\u7528\u7ea2\u7b14\u6d82\u6539\u4fee\u6b63\nD. \u6570\u5b57\u6216\u4ee3\u7801\u2014\u5f8b\u7528\u963f\u62c9\u4f2f\u6570\u5b57\u4e66\u5199\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5789800491476105, "meta-math/MetaMath-Mistral-7B": 0.8817063198837162, "itpossible/Chinese-Mistral-7B-v0.1": 0.66701837801439, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.6682648137679589, "meta-llama/Meta-Llama-3-8B": 0.5277408265791521, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.673384991176548}}, {"question": "\u4ee5\u4e0b\u6bcd\u4e73\u5582\u517b\u7684\u4f18\u70b9\u4e2d\uff0c\u4e0d\u6b63\u786e\u7684\u662f____\nA. \u86cb\u767d\u8d28\u3001\u8102\u80aa\u3001\u7cd6\u6bd4\u4f8b\u5408\u9002\nB. \u6bcd\u4e73\u542b\u514d\u75ab\u6027\u7269\u8d28\nC. \u6bcd\u4e73\u5582\u517b\u5e2e\u52a9\u6bcd\u4eb2\u4ea7\u540e\u5b50\u5bab\u590d\u539f\nD. \u6bcd\u4e73\u4e2d\u916a\u86cb\u767d\u591a\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.6960684811312957, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.6537253819532218, "HuggingFaceH4/zephyr-7b-beta": 0.997657325184286, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.7350178158950506, "meta-llama/Meta-Llama-3-8B": 0.8503507976011433, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.9556485517440951}}, {"question": "\u60a3\u8005\u7537\uff0c56\u5c81\u3002\u53f3\u819d\u5173\u8282\u75bc\u75db\u534a\u5e74\uff0c\u52a0\u91cd5\u5929\uff0c\u5c24\u4ee5\u4e0a\u697c\u68af\u65f6\u52a0\u5267\u3002X\u7ebf\u68c0\u67e5\u663e\u793a\u819d\u5173\u8282\u9000\u884c\u6027\u6539\u53d8\uff0c\u8bca\u65ad\u4e3a\u9acc\u9aa8\u8f6f\u9aa8\u8f6f\u5316\u75c7\u3002\u975e\u624b\u672f\u6cbb\u7597\u9996\u5148\u5e94\u5236\u52a8\u819d\u5173\u8282\u7684\u65f6\u95f4\u662f____\nA. 1\uff5e2\u5468\nB. 3~4\u5468\nC. 4~5\u5468\nD. 6~7\u5468\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0.36617639865290497, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.49264665571246863}}, {"question": "1981\u5e746\u6708\uff0c\u5728\u4e0a\u6d77\u4e3e\u884c\u7684\u7b2c\u4e00\u6b21\u5168\u56fd\u533b\u5b66\u4f26\u7406\u9053\u5fb7\u5b66\u672f\u8ba8\u8bba\u4f1a\u786e\u7acb\u4e86\u533b\u5fb7\u57fa\u672c\u539f\u5219____\nA. \u6551\u6b7b\u6276\u4f24\nB. \u4ee5\u4e0a\u90fd\u662f\nC. \u5b9e\u884c\u793e\u4f1a\u4e3b\u4e49\u4eba\u9053\u4e3b\u4e49\nD. \u5168\u5fc3\u5168\u610f\u4e3a\u4eba\u6c11\u670d\u52a1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0.4083226004004083, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.5744418985420635, "meta-llama/Meta-Llama-3-8B": 0.7788177955042644, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u6297\u4ee3\u8c22\u7c7b\u6297\u764c\u836f\u662f____\nA. \u73af\u78f7\u9170\u80fa\nB. \u6c1f\u5c3f\u5627\u5576\nC. \u653e\u7ebf\u83cc\u7d20D\nD. \u957f\u6625\u65b0\u78b1\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0.5109596852532194, "itpossible/Chinese-Mistral-7B-v0.1": 0.35347162922091135, "HuggingFaceH4/zephyr-7b-beta": 0.5856675469303246, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.5815682376065227}}, {"question": "\u7537\uff0c60\u5c81\uff0c\u4fbf\u79d8\u3001\u95f4\u65ad\u4fbf\u884010\u4f59\u5e74\uff0c\u4fbf\u540e\u6709\u80bf\u7269\u81ea\u809b\u95e8\u8131\u51fa\uff0c\u8d28\u8f6f\uff0c\u53ef\u4ee5\u8fd8\u7eb3\uff0c\u8bca\u65ad\u4e3a____\nA. \u5185\u75d4\u8131\u51fa\nB. \u80a0\u5b8c\u5168\u8131\u51fa\nC. \u5916\u75d4\nD. \u8840\u6813\u5916\u75d4\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.3401975601814474, "meta-math/MetaMath-Mistral-7B": 0.36717002281588484, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.921278964269825, "cognitivecomputations/dolphin-2.6-mistral-7b": 0.490778006785068, "meta-llama/Meta-Llama-3-8B": 0.5052963230999333, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u4e0b\u5217\u54ea\u9879\u6307\u6807\u6700\u80fd\u53cd\u6620\u7cd6\u5c3f\u75c5\u916e\u75c7\u9178\u4e2d\u6bd2\u7684\u4e25\u91cd\u7a0b\u5ea6____\nA. \u8840\u7cd6\nB. \u8840\u94a0\nC. \u5c3f\u916e\u4f53\nD. \u8840\u78b3\u9178\u6c22\u6839\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0.5620941011264213, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0.5309329651650208, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0}}, {"question": "\u9aa8\u9abc\u808c\u4e2dCa\u79bb\u5b50\u7684\u7ed3\u5408\u4f4d\u70b9\u662f____\nA. \u808c\u7ea4\u86cb\u767d\nB. \u539f\u808c\u51dd\u86cb\u767d\nC. \u808c\u9499\u86cb\u767d\u4e9a\u5355\u4f4dI\nD. \u808c\u9499\u86cb\u767d\u4e9a\u5355\u4f4dC\u7b54\u6848\uff1a", "scores": {"mistralai/Mistral-7B-v0.1": 0, "meta-math/MetaMath-Mistral-7B": 0, "itpossible/Chinese-Mistral-7B-v0.1": 0, "HuggingFaceH4/zephyr-7b-beta": 0, "cognitivecomputations/dolphin-2.6-mistral-7b": 0, "meta-llama/Meta-Llama-3-8B": 0, "cognitivecomputations/dolphin-2.9-llama3-8b": 0.45527639862328384}}]