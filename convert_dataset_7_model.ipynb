{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ae3937852d7d4b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Handling GSM8K\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "849c65d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = \"/data/home/chensh/projects/LLM_router/datasets/split2_model7\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102579b7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8e574a4d570f91c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T13:50:26.765018Z",
     "start_time": "2024-04-17T13:50:23.629507Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_list = [  \n",
    "                ['mistralai','Mistral-7B-v0.1'],\n",
    "                ['meta-math','MetaMath-Mistral-7B'],\n",
    "                ['itpossible','Chinese-Mistral-7B-v0.1'],\n",
    "                [\"HuggingFaceH4\",\"zephyr-7b-beta\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.6-mistral-7b\"],\n",
    "                [\"meta-llama\",\"Meta-Llama-3-8B\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.9-llama3-8b\"],\n",
    "                ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4891d237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# /data/home/chensh/projects/LLM_router/output/humaneval/Arithmo2-Mistral-7B_humaneval.json\n",
    "\n",
    "# for mbpp\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "task = \"mbpp\"\n",
    "\n",
    "mbpp_data = pd.read_parquet(\"/data/home/chensh/data/LLM_datasets/mbpp/full/test-00000-of-00001.parquet\",engine='pyarrow')\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    model_pre = model_info[0]\n",
    "    model = model_info[1]\n",
    "    with open(f\"/data/home/chensh/projects/LLM_router/output/mbpp/{model}/log_samples.json\",'r') as f:\n",
    "        json_file = json.load(f)\n",
    "    json_file = json_file['mbpp']\n",
    "    for index, instance in json_file.items():\n",
    "        correct = 0\n",
    "        for each_resps in instance:\n",
    "            correct += 1 if each_resps[1]['passed'] == True else 0\n",
    "        acc = correct / len(instance)\n",
    "        description = mbpp_data.iloc[int(index)][\"text\"]\n",
    "        test_example = mbpp_data.iloc[int(index)][\"test_list\"][0]\n",
    "        question = f'\"\"\"\\n{description}\\n{test_example}\\n\"\"\"\\n'\n",
    "        if model_index == 0:\n",
    "            output_data.append({\"question\": question, \"scores\": {model_pre + \"/\" + model: acc}})\n",
    "        else:\n",
    "            output_data[int(index)][\"scores\"][model_pre+\"/\" + model] = acc\n",
    "\n",
    "print(len(output_data))\n",
    "# train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "# output_data = [output_data[index] for index in train_split_index]\n",
    "# train_split = output_data[:115]\n",
    "# test_split = output_data[115:]\n",
    "# test_split = output_data[100:]\n",
    "\n",
    "with open(os.path.join(output_file_path, 'mbpp.json'), 'w') as f:\n",
    "    json.dump(output_data, f)\n",
    "#     \n",
    "# train_split[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "416871ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/* Check if in given list of numbers, are any two numbers closer to each other than\n",
      "  given threshold.\n",
      "  >>> hasCloseElements([1.0, 2.0, 3.0], 0.5)\n",
      "  false\n",
      "  >>> hasCloseElements([1.0, 2.8, 3.0, 4.0, 5.0, 2.0], 0.3)\n",
      "  true\n",
      "  */\n",
      "const hasCloseElements = (numbers, threshold) => {\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# /data/home/chensh/projects/LLM_router/output/humaneval/Arithmo2-Mistral-7B_humaneval.json\n",
    "\n",
    "# for javascript\n",
    "model_list = [  \n",
    "                ['mistralai','Mistral-7B-v0.1'],\n",
    "                ['meta-math','MetaMath-Mistral-7B'],\n",
    "                ['itpossible','Chinese-Mistral-7B-v0.1'],\n",
    "                [\"HuggingFaceH4\",\"zephyr-7b-beta\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.6-mistral-7b\"],\n",
    "                [\"meta-llama\",\"Meta-Llama-3-8B\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.9-llama3-8b\"],\n",
    "                ]\n",
    "\n",
    "output_file_path = \"/data/home/chensh/projects/LLM_router/datasets/split2_model7\"\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "task = \"javascript\"\n",
    "\n",
    "javascript_data = pd.read_json(\"/data/home/chensh/data/LLM_datasets/bigcode/humanevalpack/data/js/data/humanevalpack.jsonl\", lines=True)\n",
    "\n",
    "print(javascript_data.iloc[0]['prompt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e3e2b791",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    model_pre = model_info[0]\n",
    "    model = model_info[1]\n",
    "    with open(f\"/data/home/chensh/projects/LLM_router/output/humanevalpack_js/{model}/log_samples.json\",'r') as f:\n",
    "        json_file = json.load(f)\n",
    "    json_file = json_file['humanevalsynthesize-js']\n",
    "    for index, instance in json_file.items():\n",
    "        correct = 0\n",
    "        for each_resps in instance:\n",
    "            correct += 1 if each_resps[1]['passed'] == True else 0\n",
    "        acc = correct / len(instance)\n",
    "        question = javascript_data.iloc[int(index)][\"prompt\"][0]\n",
    "        if model_index == 0:\n",
    "            output_data.append({\"question\": question, \"scores\": {model_pre + \"/\" + model: acc}})\n",
    "        else:\n",
    "            output_data[int(index)][\"scores\"][model_pre + \"/\" + model] = acc\n",
    "\n",
    "print(len(output_data))\n",
    "# train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "# output_data = [output_data[index] for index in train_split_index]\n",
    "# train_split = output_data[:115]\n",
    "# test_split = output_data[115:]\n",
    "# test_split = output_data[100:]\n",
    "\n",
    "with open(os.path.join(output_file_path, 'javascript.json'), 'w') as f:\n",
    "    json.dump(output_data, f)\n",
    "#     \n",
    "# train_split[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d855852",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca713df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "af05a285",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "# for gsm8k\n",
    "\n",
    "task = \"gsm8k_train\"\n",
    "# task = \"gsm8k-repeat10\"\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    model_pre = model_info[0]\n",
    "    model = model_info[1]\n",
    "    with open(f\"/data/home/chensh/projects/LLM_router/output/gsm8k_train-t0.2/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_{task}.jsonl\", 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "    for i in range(len(json_file)):\n",
    "        # extract answer_list & answer\n",
    "        resps = json_file[i]['resps'][0]\n",
    "        pattern = \"#### (\\\\-?[0-9\\\\.\\\\,]+)\"\n",
    "        ans_list = [re.search(pattern, resp).group(1) if re.search(pattern, resp) else None for resp in resps]\n",
    "        target = re.search(pattern, json_file[i]['target']).group(1)\n",
    "         # compare with origin answer & get score\n",
    "        correct = 0\n",
    "        for ans in ans_list:\n",
    "            correct += 1 if ans == target else 0 \n",
    "        acc = correct / len(ans_list)\n",
    "        if model_index == 0:\n",
    "            output_data.append({\"question\":json_file[i]['doc'][\"question\"], \"scores\": {model_pre+\"/\" + model: acc}})\n",
    "        else:\n",
    "            output_data[i][\"scores\"][model_pre+\"/\" + model] = acc\n",
    "            \n",
    "output_data = output_data[:int(len(output_data)/2)]\n",
    "with open(os.path.join(output_file_path, 'gsm8k-train.json'), 'w') as f:\n",
    "    json.dump(output_data, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "23efe811",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modified_model_names = [\"Meta-Llama-3-8B\",\"Llama3-8B-Chinese-Chat\",\"dolphin-2.9-llama3-8b\"]\n",
    "# for modified_model_name in modified_model_names:\n",
    "#     path = os.path.join(\"/data/home/chensh/projects/LLM_router/output/mmlu_5shot\", modified_model_name)\n",
    "#     files = os.listdir(path)\n",
    "#     for file in files:\n",
    "#         print(file)\n",
    "#         if file.startswith(\"pretrained\"):\n",
    "#             os.rename(os.path.join(path, file), os.path.join(path, file.replace(\",max_model_len__4096\", \"\")))        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b6469276e69aaf6",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# MMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3fcaecf816259d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T02:04:17.747956Z",
     "start_time": "2024-04-18T02:03:59.839784Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "# for mmlu (multiple choice problem)\n",
    "\n",
    "task_list = ['abstract_algebra', 'anatomy', 'astronomy', 'business_ethics', 'clinical_knowledge', 'college_biology', 'college_chemistry', 'college_computer_science', 'college_mathematics', 'college_medicine', 'college_physics', 'computer_security', 'conceptual_physics', 'econometrics', 'electrical_engineering', 'elementary_mathematics', 'formal_logic', 'global_facts', 'high_school_biology', 'high_school_chemistry', 'high_school_computer_science', 'high_school_european_history', 'high_school_geography', 'high_school_government_and_politics', 'high_school_macroeconomics', 'high_school_mathematics', 'high_school_microeconomics', 'high_school_physics', 'high_school_psychology', 'high_school_statistics', 'high_school_us_history', 'high_school_world_history', 'human_aging', 'human_sexuality', 'international_law', 'jurisprudence', 'logical_fallacies', 'machine_learning', 'management', 'marketing', 'medical_genetics', 'miscellaneous', 'moral_disputes', 'moral_scenarios', 'nutrition', 'philosophy', 'prehistory', 'professional_accounting', 'professional_law', 'professional_medicine', 'professional_psychology', 'public_relations', 'security_studies', 'sociology', 'us_foreign_policy', 'virology', 'world_religions']\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    count = 0\n",
    "    choices_head = ['A. ', 'B. ', 'C. ', 'D. ']\n",
    "    for task in task_list:\n",
    "        model_pre = model_info[0]\n",
    "        model = model_info[1]\n",
    "        with open(f\"/data/home/chensh/projects/LLM_router/output/mmlu_5shot/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_mmlu_{task}.jsonl\", 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        for i in range(len(json_file)):\n",
    "            resps = np.array(json_file[i]['resps'])\n",
    "            log_probability = resps[:,0,0]\n",
    "            probability = np.exp(log_probability)\n",
    "            sum_probability = np.sum(probability)\n",
    "            probability = probability / sum_probability\n",
    "            score = probability[json_file[i]['target']] if json_file[i]['acc'] == 1 else 0\n",
    "\n",
    "            if model_index == 0:\n",
    "                output_data.append(\n",
    "                    {\"question\":json_file[i]['doc'][\"question\"] + \n",
    "                                \"\".join([\"\\n\" + choices_head[j] + choice for j, choice in enumerate(json_file[i]['doc']['choices'])]), \"scores\": {model_pre+\"/\" + model: score}}\n",
    "                )\n",
    "            else:\n",
    "                output_data[count][\"scores\"][model_pre+\"/\" + model] = score\n",
    "                count += 1\n",
    "\n",
    "train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "output_data = [output_data[index] for index in train_split_index]\n",
    "train_split = output_data[:int(0.7* len(output_data))]\n",
    "test_split = output_data[int(0.7* len(output_data)):]\n",
    "\n",
    "# print(len(output_data))\n",
    "# output training data as a json file\n",
    "with open(os.path.join(output_file_path, f'mmlu_train.json'), 'w') as f:\n",
    "    json.dump(train_split, f)\n",
    "\n",
    "with open(os.path.join(output_file_path, f'mmlu_test.json'), 'w') as f:\n",
    "    json.dump(test_split, f) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90364170b5ba9a5e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Humaneval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8c1583723bf47146",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T15:18:06.488617Z",
     "start_time": "2024-04-17T15:18:06.362495Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "115\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# /data/home/chensh/projects/LLM_router/output/humaneval/Arithmo2-Mistral-7B_humaneval.json\n",
    "\n",
    "# for humaneval\n",
    "\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "random.seed(42)\n",
    "\n",
    "task = \"humaneval\"\n",
    "\n",
    "humaneval_data = pd.read_parquet(\"/data/home/chensh/data/LLM_datasets/openai_humaneval/openai_humaneval/test-00000-of-00001.parquet\",engine='pyarrow')\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    model_pre = model_info[0]\n",
    "    model = model_info[1]\n",
    "    with open(f\"/data/home/chensh/projects/LLM_router/output/humaneval/{model}/log_samples.json\",'r') as f:\n",
    "        json_file = json.load(f)\n",
    "    json_file = json_file['humaneval']\n",
    "    for index, instance in json_file.items():\n",
    "        correct = 0\n",
    "        for each_resps in instance:\n",
    "            correct += 1 if each_resps[1]['passed'] == True else 0\n",
    "        acc = correct / len(instance)\n",
    "        question = humaneval_data.iloc[int(index)]['prompt']\n",
    "        if model_index == 0:\n",
    "            output_data.append({\"question\": question, \"scores\": {model_pre + \"/\" + model: acc}})\n",
    "        else:\n",
    "            output_data[int(index)][\"scores\"][model_pre+\"/\" + model] = acc\n",
    "\n",
    "train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "output_data = [output_data[index] for index in train_split_index]\n",
    "train_split = output_data[:115]\n",
    "test_split = output_data[115:]\n",
    "# test_split = output_data[100:]\n",
    "\n",
    "with open(os.path.join(output_file_path, 'humaneval_train.json'), 'w') as f:\n",
    "    json.dump(train_split, f)\n",
    "\n",
    "with open(os.path.join(output_file_path, 'humaneval_test.json'), 'w') as f:\n",
    "    json.dump(test_split, f) \n",
    "\n",
    "print(len(train_split))\n",
    "print(len(test_split))\n",
    "#     \n",
    "# train_split[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "110794afd5d57f46",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ARC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f2b5f93481da8d7d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T13:59:58.639353Z",
     "start_time": "2024-04-17T13:59:57.784770Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(100)\n",
    "\n",
    "# for arc (multiple choice problem)\n",
    "\n",
    "# task = \"arc_easy\"\n",
    "task = \"arc_challenge\"\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    count = 0\n",
    "    model_pre = model_info[0]\n",
    "    model = model_info[1]\n",
    "    with open(f\"/data/home/chensh/projects/LLM_router/output/{task}/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_{task}.jsonl\", 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "    for i in range(len(json_file)):\n",
    "        resps = np.array(json_file[i]['resps'])\n",
    "        log_probability = resps[:,0,0]\n",
    "        probability = np.exp(log_probability)\n",
    "        sum_probability = np.sum(probability)\n",
    "        probability = probability / sum_probability\n",
    "        score = probability[json_file[i]['target']] if json_file[i]['acc'] == 1 else 0\n",
    "\n",
    "        if model_index == 0:\n",
    "            output_data.append(\n",
    "                {\"question\": \"Question:\" + json_file[i]['doc'][\"question\"] + \"\\nAnswer:\", \"scores\": {model_pre+\"/\" + model: score}}\n",
    "            )\n",
    "        else:\n",
    "            output_data[count][\"scores\"][model_pre + \"/\" + model] = score\n",
    "            count += 1\n",
    "\n",
    "train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "output_data = [output_data[index] for index in train_split_index]\n",
    "train_split = output_data[:int(0.7* len(output_data))]\n",
    "test_split = output_data[int(0.7* len(output_data)):]\n",
    "       \n",
    "\n",
    "# output training data as a json file\n",
    "# output_file_path = \"/data/home/chensh/projects/LLM_router/datasets/\"\n",
    "# with open(os.path.join(output_file_path, f'{task}.json'), 'w') as f:\n",
    "#     json.dump(output_data, f)\n",
    "\n",
    "with open(os.path.join(output_file_path, f'{task}_train.json'), 'w') as f:\n",
    "    json.dump(train_split, f)\n",
    "\n",
    "with open(os.path.join(output_file_path, f'{task}_test.json'), 'w') as f:\n",
    "    json.dump(test_split, f) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "772eaa208a3fa8dd",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Hellaswag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "361e7844c515fbc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T02:07:17.587540Z",
     "start_time": "2024-04-18T02:06:40.661765Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Removing ice from car: Then, the man writes over the snow covering the window of a car, and a woman wearing winter clothes smiles. Then',\n",
       " 'scores': {'mistralai/Mistral-7B-v0.1': 0.9999965516457299,\n",
       "  'meta-math/MetaMath-Mistral-7B': 0.9997326286037237,\n",
       "  'teknium/OpenHermes-2.5-Mistral-7B': 0.9999999632149246,\n",
       "  'WizardLM/WizardMath-7B-V1.1': 0.9999973056897147,\n",
       "  'itpossible/Chinese-Mistral-7B-v0.1': 0.9999980523735081,\n",
       "  'HuggingFaceH4/zephyr-7b-beta': 0.9999996688090383,\n",
       "  'cognitivecomputations/dolphin-2.6-mistral-7b': 0.9999998706397251,\n",
       "  'NousResearch/Hermes-2-Pro-Mistral-7B': 0.9999999561210721,\n",
       "  'cognitivecomputations/dolphin-2.2.1-mistral-7b': 0.9999994994896325,\n",
       "  'abhishekchohan/mistral-7B-forest-dpo': 0.9999999418205058}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "# for hellaswag (multiple choice problem)\n",
    "\n",
    "task = \"hellaswag\"\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.strip()\n",
    "    # NOTE: Brackets are artifacts of the WikiHow dataset portion of HellaSwag.\n",
    "    text = text.replace(\" [title]\", \". \")\n",
    "    text = re.sub(\"\\\\[.*?\\\\]\", \"\", text)\n",
    "    text = text.replace(\"  \", \" \")\n",
    "    return text\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    count = 0\n",
    "    model_pre = model_info[0]\n",
    "    model = model_info[1]\n",
    "    with open(f\"/data/home/chensh/projects/LLM_router/output/{task}_train/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_{task}.jsonl\", 'r') as f:\n",
    "        json_file = json.load(f)\n",
    "    for i in range(len(json_file)):\n",
    "        resps = np.array(json_file[i]['resps'])\n",
    "        log_probability = resps[:,0,0]\n",
    "        probability = np.exp(log_probability)\n",
    "        sum_probability = np.sum(probability)\n",
    "        probability = probability / sum_probability\n",
    "        score = probability[json_file[i]['target']] if json_file[i]['acc_norm'] == 1 else 0\n",
    "        question = json_file[i]['doc'][\"ctx_a\"] + \" \" + json_file[i]['doc'][\"ctx_b\"].capitalize()\n",
    "        question = preprocess(json_file[i]['doc'][\"activity_label\"] + \": \" + question)\n",
    "\n",
    "        if model_index == 0:\n",
    "            output_data.append(\n",
    "                {\"question\": question, \"scores\": {model_pre+\"/\" + model: score}}\n",
    "            )\n",
    "        else:\n",
    "            output_data[count][\"scores\"][model_pre + \"/\" + model] = score\n",
    "            count += 1\n",
    "       \n",
    "# output training data as a json file\n",
    "# output_data = output_data[:1000]\n",
    "with open(os.path.join(output_file_path, f'hellaswag_validation.json'), 'w') as f:\n",
    "    json.dump(output_data, f)\n",
    "\n",
    "# len(output_data)\n",
    "\n",
    "output_data[0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbeaaae8b70e936",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# C-Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bd5f74e0465a8cf9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T14:01:44.697641Z",
     "start_time": "2024-04-17T14:01:43.250187Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "# modified_model_names = [\"Meta-Llama-3-8B\",\"Llama3-8B-Chinese-Chat\",\"dolphin-2.9-llama3-8b\"]\n",
    "# for modified_model_name in modified_model_names:\n",
    "#     path = os.path.join(\"/data/home/chensh/projects/LLM_router/output/ceval-validation\", modified_model_name)\n",
    "#     files = os.listdir(path)\n",
    "#     for file in files:\n",
    "#         if file.startswith(\"pretrained\"):\n",
    "#             os.rename(os.path.join(path, file), os.path.join(path, file.replace(\",max_model_len__4096\", \"\")))        \n",
    "\n",
    "# for ceval (multiple choice problem)\n",
    "\n",
    "task_list = ['computer_network', 'operating_system', 'computer_architecture', 'college_programming', 'college_physics', 'college_chemistry', 'advanced_mathematics', 'probability_and_statistics', 'discrete_mathematics', 'electrical_engineer', 'metrology_engineer', 'high_school_mathematics', 'high_school_physics', 'high_school_chemistry', 'high_school_biology', 'middle_school_mathematics', 'middle_school_biology', 'middle_school_physics', 'middle_school_chemistry', 'veterinary_medicine', 'college_economics', 'business_administration', 'marxism', 'mao_zedong_thought', 'education_science', 'teacher_qualification', 'high_school_politics', 'high_school_geography', 'middle_school_politics', 'middle_school_geography', 'modern_chinese_history', 'ideological_and_moral_cultivation', 'logic', 'law', 'chinese_language_and_literature', 'art_studies', 'professional_tour_guide', 'legal_professional', 'high_school_chinese', 'high_school_history', 'middle_school_history', 'civil_servant', 'sports_science', 'plant_protection', 'basic_medicine', 'clinical_medicine', 'urban_and_rural_planner', 'accountant', 'fire_engineer', 'environmental_impact_assessment_engineer', 'tax_accountant', 'physician']\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    count = 0\n",
    "    choices_head = ['A', 'B', 'C', 'D']\n",
    "    for task in task_list:\n",
    "        model_pre = model_info[0]\n",
    "        model = model_info[1]\n",
    "        with open(f\"/data/home/chensh/projects/LLM_router/output/ceval-validation/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_ceval-valid_{task}.jsonl\", 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        for i in range(len(json_file)):\n",
    "            resps = np.array(json_file[i]['resps'])\n",
    "            log_probability = resps[:,0,0]\n",
    "            probability = np.exp(log_probability)\n",
    "            sum_probability = np.sum(probability)\n",
    "            probability = probability / sum_probability\n",
    "            score = probability[json_file[i]['target']] if json_file[i]['acc'] == 1 else 0\n",
    "\n",
    "            if model_index == 0:\n",
    "                output_data.append(\n",
    "                    {\"question\":json_file[i]['doc'][\"question\"] + \n",
    "                                \"\".join([\"\\n\" + choices_head[j] + \". \" + json_file[i]['doc'][choices_head[j]] for j in range(4)]) + \"答案：\", \"scores\": {model_pre+\"/\" + model: score}}\n",
    "                )\n",
    "            else:\n",
    "                output_data[count][\"scores\"][model_pre+\"/\" + model] = score\n",
    "                count += 1\n",
    "\n",
    "\n",
    "# output training data as a json file\n",
    "# train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "# output_data = [output_data[index] for index in train_split_index]\n",
    "# train_split = output_data[:1000]\n",
    "# test_split = output_data[1000:]\n",
    "\n",
    "\n",
    "# output training data as a json file\n",
    "with open(os.path.join(output_file_path, 'ceval.json'), 'w') as f:\n",
    "    json.dump(output_data, f)\n",
    "\n",
    "# len(output_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24ee1b9ba25abb7b",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# CMMLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "852a348525a5d031",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T16:24:02.965837Z",
     "start_time": "2024-04-17T16:23:54.786990Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(52)\n",
    "\n",
    "# modified_model_names = [\"Meta-Llama-3-8B\",\"Llama3-8B-Chinese-Chat\",\"dolphin-2.9-llama3-8b\"]\n",
    "# for modified_model_name in modified_model_names:\n",
    "#     path = os.path.join(\"/data/home/chensh/projects/LLM_router/output/cmmlu\", modified_model_name)\n",
    "#     files = os.listdir(path)\n",
    "#     for file in files:\n",
    "#         if file.startswith(\"pretrained\"):\n",
    "#             os.rename(os.path.join(path, file), os.path.join(path, file.replace(\",max_model_len__4096\", \"\")))    \n",
    "\n",
    "# for cmmlu (multiple choice problem)\n",
    "\n",
    "task_list = ['agronomy', 'anatomy', 'ancient_chinese', 'arts', 'astronomy', 'business_ethics', 'chinese_civil_service_exam', 'chinese_driving_rule', 'chinese_food_culture', 'chinese_foreign_policy', 'chinese_history', 'chinese_literature', 'chinese_teacher_qualification', 'clinical_knowledge', 'college_actuarial_science', 'college_education', 'college_engineering_hydrology', 'college_law', 'college_mathematics', 'college_medical_statistics', 'college_medicine', 'computer_science', 'computer_security', 'conceptual_physics', 'construction_project_management', 'economics', 'education', 'electrical_engineering', 'elementary_chinese', 'elementary_commonsense', 'elementary_information_and_technology', 'elementary_mathematics', 'ethnology', 'food_science', 'genetics', 'global_facts', 'high_school_biology', 'high_school_chemistry', 'high_school_geography', 'high_school_mathematics', 'high_school_physics', 'high_school_politics', 'human_sexuality', 'international_law', 'journalism', 'jurisprudence', 'legal_and_moral_basis', 'logical', 'machine_learning', 'management', 'marketing', 'marxist_theory', 'modern_chinese', 'nutrition', 'philosophy', 'professional_accounting', 'professional_law', 'professional_medicine', 'professional_psychology', 'public_relations', 'security_study', 'sociology', 'sports_science', 'traditional_chinese_medicine', 'virology', 'world_history', 'world_religions']\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    count = 0\n",
    "    choices_head = ['A', 'B', 'C', 'D']\n",
    "    for task in task_list:\n",
    "        model_pre = model_info[0]\n",
    "        model = model_info[1]\n",
    "        with open(f\"/data/home/chensh/projects/LLM_router/output/cmmlu/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_cmmlu_{task}.jsonl\", 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        for i in range(len(json_file)):\n",
    "            resps = np.array(json_file[i]['resps'])\n",
    "            log_probability = resps[:,0,0]\n",
    "            probability = np.exp(log_probability)\n",
    "            sum_probability = np.sum(probability)\n",
    "            probability = probability / sum_probability\n",
    "            score = probability[json_file[i]['target']] if json_file[i]['acc'] == 1 else 0\n",
    "\n",
    "            if model_index == 0:\n",
    "                output_data.append(\n",
    "                    {\"question\":json_file[i]['doc']['Question'].strip() + \"\".join([\"\\n\" + choices_head[j] + \". \" + json_file[i]['doc'][choices_head[j]] for j in range(4)]) + \"\\n答案：\", \"scores\": {model_pre+\"/\" + model: score}}\n",
    "                )\n",
    "            else:\n",
    "                output_data[count][\"scores\"][model_pre+\"/\" + model] = score\n",
    "                count += 1\n",
    "                \n",
    "train_split_index = random.sample(range(len(output_data)), len(output_data))\n",
    "output_data = [output_data[index] for index in train_split_index]\n",
    "train_split = output_data[:int(0.7* len(output_data))]\n",
    "test_split = output_data[int(0.7* len(output_data)):]\n",
    "\n",
    "\n",
    "# output training data as a json file\n",
    "with open(os.path.join(output_file_path, 'cmmlu_train.json'), 'w') as f:\n",
    "    json.dump(train_split, f)\n",
    "\n",
    "with open(os.path.join(output_file_path, 'cmmlu_test.json'), 'w') as f:\n",
    "    json.dump(test_split, f) \n",
    "# json_file[i]['arguments']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27cce83a",
   "metadata": {},
   "source": [
    "# MATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e57ac78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "random.seed(52)\n",
    "\n",
    "\n",
    "# for cmmlu (multiple choice problem)\n",
    "\n",
    "# task_list = [\"minerva_math_precalc\", \"minerva_math_prealgebra\", \"minerva_math_num_theory\", \"minerva_math_intermediate_algebra\", \"minerva_math_geometry\", \"minerva_math_counting_and_prob\", \"minerva_math_algebra\"]\n",
    "\n",
    "task_list = [\"minerva_math_prealgebra\"]\n",
    "\n",
    "output_data = []\n",
    "for model_index, model_info in enumerate(model_list):\n",
    "    count = 0\n",
    "    for task in task_list:\n",
    "        model_pre = model_info[0]\n",
    "        model = model_info[1]\n",
    "        with open(f\"/data/home/chensh/projects/LLM_router/output/MATH/{model}/pretrained____data__home__chensh__data__huggingface_model__{model_pre}__{model}_{task}.jsonl\", 'r') as f:\n",
    "            json_file = json.load(f)\n",
    "        for i in range(len(json_file)):\n",
    "            if model_index == 0:\n",
    "                score = json_file[i]['exact_match']\n",
    "                output_data.append(\n",
    "                    {\"question\": json_file[i]['doc']['problem'], \"scores\": {model_pre+\"/\" + model: score}}\n",
    "                )\n",
    "            else:\n",
    "                score = json_file[i]['exact_match']\n",
    "                output_data[count][\"scores\"][model_pre+\"/\" + model] = score\n",
    "                count += 1\n",
    "\n",
    "\n",
    "# output training data as a json file\n",
    "with open(os.path.join(output_file_path, 'MATH_prealgebra.json'), 'w') as f:\n",
    "    json.dump(output_data, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c90761c1ffce295",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-17T15:45:56.598909Z",
     "start_time": "2024-04-17T15:45:56.579202Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "820\n",
      "1138\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'mistralai/Mistral-7B-v0.1': 29,\n",
       " 'meta-math/MetaMath-Mistral-7B': 109,\n",
       " 'teknium/OpenHermes-2.5-Mistral-7B': 0,\n",
       " 'WizardLM/WizardMath-7B-V1.1': 0,\n",
       " 'itpossible/Chinese-Mistral-7B-v0.1': 35,\n",
       " 'HuggingFaceH4/zephyr-7b-beta': 308,\n",
       " 'cognitivecomputations/dolphin-2.6-mistral-7b': 115,\n",
       " 'NousResearch/Hermes-2-Pro-Mistral-7B': 0,\n",
       " 'cognitivecomputations/dolphin-2.2.1-mistral-7b': 0,\n",
       " 'abhishekchohan/mistral-7B-forest-dpo': 0,\n",
       " 'meta-llama/Meta-Llama-3-8B': 70,\n",
       " 'shenzhi-wang/Llama3-8B-Chinese-Chat': 243,\n",
       " 'cognitivecomputations/dolphin-2.9-llama3-8b': 229}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_file_path = \"/data/home/chensh/projects/LLM_router/datasets/split2_model8\"\n",
    "with open(os.path.join(output_file_path, 'arc_challenge_train.json'),'r') as f: \n",
    "    output_data = json.load(f)\n",
    "\n",
    "\n",
    "count_dict = {\n",
    "'mistralai/Mistral-7B-v0.1': 0,\n",
    "'meta-math/MetaMath-Mistral-7B' :0, \n",
    "'teknium/OpenHermes-2.5-Mistral-7B':0,\n",
    "# 'upaya07/Arithmo2-Mistral-7B':0,\n",
    "# 'ajibawa-2023/Code-Mistral-7B':0,\n",
    "'WizardLM/WizardMath-7B-V1.1':0,\n",
    "'itpossible/Chinese-Mistral-7B-v0.1':0,\n",
    "'HuggingFaceH4/zephyr-7b-beta':0,\n",
    "'cognitivecomputations/dolphin-2.6-mistral-7b':0,\n",
    "# 'Open-Orca/Mistral-7B-OpenOrca':0,\n",
    "# 'HuggingFaceH4/mistral-7b-grok':0,\n",
    "# 'HuggingFaceH4/mistral-7b-sft-beta':0,\n",
    "'NousResearch/Hermes-2-Pro-Mistral-7B':0,\n",
    "'cognitivecomputations/dolphin-2.2.1-mistral-7b':0,\n",
    "'abhishekchohan/mistral-7B-forest-dpo':0,\n",
    "# 'wandb/mistral-7b-zephyr-sft':0,\n",
    "# 'Locutusque/Hercules-2.5-Mistral-7B':0,\n",
    "# 'nvidia/OpenMath-Mistral-7B-v0.1-hf':0,\n",
    "\"meta-llama/Meta-Llama-3-8B\":0,\n",
    "\"shenzhi-wang/Llama3-8B-Chinese-Chat\":0,\n",
    "\"cognitivecomputations/dolphin-2.9-llama3-8b\":0,\n",
    "}\n",
    "\n",
    "print(len(output_data))\n",
    "\n",
    "# print(output_data[i])\n",
    "for i in range(len(output_data)):\n",
    "    sorted_dict = dict(sorted(output_data[i]['scores'].items(), key=lambda x: x[1], reverse=True))\n",
    "    # max_value = max(output_data[i]['scores'].values())\n",
    "    # it = iter([index for index, value in output_data[i]['scores'].items() if value == max_value])\n",
    "    for index, (key, value) in enumerate(sorted_dict.items()):\n",
    "        if index > 1:\n",
    "            break\n",
    "        if value > 0:\n",
    "            count_dict[key] += 1\n",
    "    \n",
    "print(sum(count_dict.values()))\n",
    "\n",
    "count_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa9dd759a8e3a4a1",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n",
    "\n",
    "# Get ACC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "54200d44b45a60f8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-18T02:04:47.184347Z",
     "start_time": "2024-04-18T02:04:47.112839Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mistralai/Mistral-7B-v0.1</th>\n",
       "      <td>29.878049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-math/MetaMath-Mistral-7B</th>\n",
       "      <td>31.829268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>teknium/OpenHermes-2.5-Mistral-7B</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WizardLM/WizardMath-7B-V1.1</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>itpossible/Chinese-Mistral-7B-v0.1</th>\n",
       "      <td>17.682927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuggingFaceH4/zephyr-7b-beta</th>\n",
       "      <td>11.707317</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cognitivecomputations/dolphin-2.6-mistral-7b</th>\n",
       "      <td>45.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NousResearch/Hermes-2-Pro-Mistral-7B</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cognitivecomputations/dolphin-2.2.1-mistral-7b</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>abhishekchohan/mistral-7B-forest-dpo</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Meta-Llama-3-8B</th>\n",
       "      <td>37.073171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shenzhi-wang/Llama3-8B-Chinese-Chat</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cognitivecomputations/dolphin-2.9-llama3-8b</th>\n",
       "      <td>53.841463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meta-llama/Llama-2-13b-hf</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        0\n",
       "mistralai/Mistral-7B-v0.1                       29.878049\n",
       "meta-math/MetaMath-Mistral-7B                   31.829268\n",
       "teknium/OpenHermes-2.5-Mistral-7B                0.000000\n",
       "WizardLM/WizardMath-7B-V1.1                      0.000000\n",
       "itpossible/Chinese-Mistral-7B-v0.1              17.682927\n",
       "HuggingFaceH4/zephyr-7b-beta                    11.707317\n",
       "cognitivecomputations/dolphin-2.6-mistral-7b    45.000000\n",
       "NousResearch/Hermes-2-Pro-Mistral-7B             0.000000\n",
       "cognitivecomputations/dolphin-2.2.1-mistral-7b   0.000000\n",
       "abhishekchohan/mistral-7B-forest-dpo             0.000000\n",
       "meta-llama/Meta-Llama-3-8B                      37.073171\n",
       "shenzhi-wang/Llama3-8B-Chinese-Chat              0.000000\n",
       "cognitivecomputations/dolphin-2.9-llama3-8b     53.841463\n",
       "meta-llama/Llama-2-13b-hf                        0.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "\n",
    "output_file_path = \"/data/home/chensh/projects/LLM_router/datasets/split2_model7\"\n",
    "with open(os.path.join(output_file_path, 'javascript.json'),'r') as f: \n",
    "    output_data = json.load(f)\n",
    "\n",
    "correct_dict = {\n",
    "'mistralai/Mistral-7B-v0.1': 0,\n",
    "'meta-math/MetaMath-Mistral-7B' :0, \n",
    "'teknium/OpenHermes-2.5-Mistral-7B':0,\n",
    "# 'upaya07/Arithmo2-Mistral-7B':0,\n",
    "# 'ajibawa-2023/Code-Mistral-7B':0,\n",
    "'WizardLM/WizardMath-7B-V1.1':0,\n",
    "'itpossible/Chinese-Mistral-7B-v0.1':0,\n",
    "'HuggingFaceH4/zephyr-7b-beta':0,\n",
    "'cognitivecomputations/dolphin-2.6-mistral-7b':0,\n",
    "# 'Open-Orca/Mistral-7B-OpenOrca':0,\n",
    "# 'HuggingFaceH4/mistral-7b-grok':0,\n",
    "# 'HuggingFaceH4/mistral-7b-sft-beta':0,\n",
    "'NousResearch/Hermes-2-Pro-Mistral-7B':0,\n",
    "'cognitivecomputations/dolphin-2.2.1-mistral-7b':0,\n",
    "'abhishekchohan/mistral-7B-forest-dpo':0,\n",
    "\"meta-llama/Meta-Llama-3-8B\":0,\n",
    "\"shenzhi-wang/Llama3-8B-Chinese-Chat\":0,\n",
    "\"cognitivecomputations/dolphin-2.9-llama3-8b\":0,\n",
    "\"meta-llama/Llama-2-13b-hf\": 0,\n",
    "# 'wandb/mistral-7b-zephyr-sft':0,\n",
    "# 'Locutusque/Hercules-2.5-Mistral-7B':0,\n",
    "# 'nvidia/OpenMath-Mistral-7B-v0.1-hf':0,\n",
    "}\n",
    "\n",
    "# print(output_data[0])\n",
    "\n",
    "data_size = len(output_data)\n",
    "print(data_size)\n",
    "\n",
    "for item in output_data:\n",
    "    scores = item['scores']\n",
    "    for key, score in scores.items():\n",
    "        # if score > 0: \n",
    "        correct_dict[key] += score / data_size * 100\n",
    "\n",
    "dataframe = pd.DataFrame.from_dict(correct_dict, orient='index')\n",
    "dataframe\n",
    "# for key, value in correct_dict.items():\n",
    "#     print(key,value)\n",
    "# print(correct_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b85bfc1",
   "metadata": {},
   "source": [
    "# Split for fewer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bc83ab95d5ce2691",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:00:43.844501Z",
     "start_time": "2024-04-12T08:00:43.366511Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "model_list = [  \n",
    "                ['mistralai','Mistral-7B-v0.1'],\n",
    "                ['meta-math','MetaMath-Mistral-7B'],\n",
    "                ['itpossible','Chinese-Mistral-7B-v0.1'],\n",
    "                [\"HuggingFaceH4\",\"zephyr-7b-beta\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.6-mistral-7b\"],\n",
    "                [\"meta-llama\",\"Meta-Llama-3-8B\"],\n",
    "                # [\"shenzhi-wang\",\"Llama3-8B-Chinese-Chat\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.9-llama3-8b\"],\n",
    "                ]\n",
    "model_list = [item[0] + '/' + item[1] for item in model_list]\n",
    "\n",
    "\n",
    "source_output_path = \"/data/home/chensh/projects/LLM_router/datasets/split2_model8_2\"\n",
    "target_output_path = \"/data/home/chensh/projects/LLM_router/datasets/split2_model8_zero_test\"\n",
    "os.makedirs(target_output_path)\n",
    "\n",
    "\n",
    "source_dataset_list = os.listdir(source_output_path)\n",
    "for source_dataset in source_dataset_list:\n",
    "    with open(os.path.join(source_output_path, source_dataset),'r') as f: \n",
    "        source_data = json.load(f)\n",
    "    target_data = []\n",
    "    for item in source_data:\n",
    "        target_item = item\n",
    "        target_score = {}\n",
    "        for key, value in item['scores'].items():\n",
    "            if key == \"meta-llama/Llama-2-13b-hf\":\n",
    "                target_score[key] = 0\n",
    "            if key in model_list:\n",
    "                target_score[key] = value\n",
    "        target_item['scores'] = target_score\n",
    "        target_data.append(target_item)\n",
    "\n",
    "    with open(os.path.join(target_output_path, source_dataset),'w') as f: \n",
    "        json.dump(target_data, f)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "712b96f26d622265",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T08:06:01.460498Z",
     "start_time": "2024-04-12T08:06:01.407184Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'doc_id': 0,\n",
       " 'doc': {'ind': 24,\n",
       "  'activity_label': 'Roof shingle removal',\n",
       "  'ctx_a': 'A man is sitting on a roof.',\n",
       "  'ctx_b': 'he',\n",
       "  'ctx': 'A man is sitting on a roof. he',\n",
       "  'endings': ['is using wrap to wrap a pair of skis.',\n",
       "   'is ripping level tiles off.',\n",
       "   \"is holding a rubik's cube.\",\n",
       "   'starts pulling up roofing on a roof.'],\n",
       "  'source_id': 'activitynet~v_-JhWjGDPHMY',\n",
       "  'split': 'val',\n",
       "  'split_type': 'indomain',\n",
       "  'label': '3',\n",
       "  'query': 'Roof shingle removal: A man is sitting on a roof. He',\n",
       "  'choices': ['is using wrap to wrap a pair of skis.',\n",
       "   'is ripping level tiles off.',\n",
       "   \"is holding a rubik's cube.\",\n",
       "   'starts pulling up roofing on a roof.'],\n",
       "  'gold': 3},\n",
       " 'target': 3,\n",
       " 'arguments': [['Roof shingle removal: A man is sitting on a roof. He',\n",
       "   ' is using wrap to wrap a pair of skis.'],\n",
       "  ['Roof shingle removal: A man is sitting on a roof. He',\n",
       "   ' is ripping level tiles off.'],\n",
       "  ['Roof shingle removal: A man is sitting on a roof. He',\n",
       "   \" is holding a rubik's cube.\"],\n",
       "  ['Roof shingle removal: A man is sitting on a roof. He',\n",
       "   ' starts pulling up roofing on a roof.']],\n",
       " 'resps': [[[-42.246849060058594, False]],\n",
       "  [[-30.698698043823242, False]],\n",
       "  [[-23.134632110595703, False]],\n",
       "  [[-25.474287033081055, False]]],\n",
       " 'filtered_resps': [[-42.246849060058594, False],\n",
       "  [-30.698698043823242, False],\n",
       "  [-23.134632110595703, False],\n",
       "  [-25.474287033081055, False]],\n",
       " 'acc': 0.0,\n",
       " 'acc_norm': 1.0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_file[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "44e75556236bfb26",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T02:50:31.533981Z",
     "start_time": "2024-04-10T02:50:31.471459Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 5, 5, 4]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "\n",
    "data_paths = [\"./datasets/split2_model7_cluster/gsm8k-train.json\",\"./datasets/split2_model7_cluster/humaneval_train.json\", \"./datasets/split2_model7_cluster/arc_challenge_train.json\", \"./datasets/split2_model7_cluster/mmlu_train.json\",\"./datasets/split2_model7_cluster/cmmlu_train.json\",]\n",
    "cluster_counters = {}\n",
    "for data_path in data_paths:\n",
    "    with open(data_path, \"r\") as f:\n",
    "        dataset_file = json.load(f)\n",
    "    for data_item in dataset_file:\n",
    "        if data_item['cluster_id'] in cluster_counters:\n",
    "            for key, value in data_item['scores'].items():\n",
    "                if value > 0:\n",
    "                    cluster_counters[data_item['cluster_id']][key] += 1\n",
    "        else:\n",
    "            cluster_counters[ data_item['cluster_id']] = Counter()\n",
    "\n",
    "model_list = ['mistralai/Mistral-7B-v0.1',\n",
    "                'meta-math/MetaMath-Mistral-7B',\n",
    "                'itpossible/Chinese-Mistral-7B-v0.1',\n",
    "                \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "                \"cognitivecomputations/dolphin-2.6-mistral-7b\",\n",
    "                \"meta-llama/Meta-Llama-3-8B\",\n",
    "                \"cognitivecomputations/dolphin-2.9-llama3-8b\"]\n",
    "    \n",
    "cluster_model_map = []\n",
    "for i in range(5):\n",
    "    suitable_model_name, _ = cluster_counters[i].most_common()[0]\n",
    "    suitable_model_index = model_list.index(suitable_model_name)\n",
    "    cluster_model_map.append(suitable_model_index)\n",
    "\n",
    "cluster_model_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "288c4a97b91f0079",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-16T10:31:58.283001Z",
     "start_time": "2024-04-16T10:31:58.275145Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 6, 5, 5, 4]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "\n",
    "output_path = \"./datasets/lora_retriever\"\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "data_paths = [\"./datasets/split2_model7_cluster/gsm8k-train.json\",\"./datasets/split2_model7_cluster/humaneval_train.json\", \"./datasets/split2_model7_cluster/arc_challenge_train.json\", \"./datasets/split2_model7_cluster/mmlu_train.json\",\"./datasets/split2_model7_cluster/cmmlu_train.json\",]\n",
    "cluster_counters = {}\n",
    "\n",
    "cluster_samples_dict = {}\n",
    "\n",
    "for data_path in data_paths:\n",
    "    with open(data_path, \"r\") as f:\n",
    "        dataset_file = json.load(f)\n",
    "    for data_item in dataset_file:\n",
    "        if data_item['cluster_id'] in cluster_samples_dict:\n",
    "            cluster_samples_dict[data_item['cluster_id']].append(data_item)\n",
    "        else:\n",
    "            cluster_samples_dict[data_item['cluster_id']] = [data_item]\n",
    "        if data_item['cluster_id'] in cluster_counters:\n",
    "            for key, value in data_item['scores'].items():\n",
    "                if value > 0:\n",
    "                    cluster_counters[data_item['cluster_id']][key] += 1\n",
    "        else:\n",
    "            cluster_counters[ data_item['cluster_id']] = Counter()\n",
    "\n",
    "\n",
    "for cluster_id, cluster_sample_list in cluster_samples_dict.items():\n",
    "    with open(os.path.join(output_path, f\"cluster_{cluster_id}.json\"), \"w\") as f:\n",
    "        json.dump(cluster_sample_list, f)\n",
    "\n",
    "model_list = ['mistralai/Mistral-7B-v0.1',\n",
    "                'meta-math/MetaMath-Mistral-7B',\n",
    "                'itpossible/Chinese-Mistral-7B-v0.1',\n",
    "                \"HuggingFaceH4/zephyr-7b-beta\",\n",
    "                \"cognitivecomputations/dolphin-2.6-mistral-7b\",\n",
    "                \"meta-llama/Meta-Llama-3-8B\",\n",
    "                \"cognitivecomputations/dolphin-2.9-llama3-8b\"]\n",
    "    \n",
    "cluster_model_map = []\n",
    "for i in range(5):\n",
    "    suitable_model_name, _ = cluster_counters[i].most_common()[0]\n",
    "    suitable_model_index = model_list.index(suitable_model_name)\n",
    "    cluster_model_map.append(suitable_model_index)\n",
    "\n",
    "cluster_model_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c9b3cad5041284b",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_list = [  ['mistralai','Mistral-7B-v0.1'],\n",
    "                ['meta-math','MetaMath-Mistral-7B'],\n",
    "                ['teknium','OpenHermes-2.5-Mistral-7B'],\n",
    "                ['upaya07','Arithmo2-Mistral-7B'],\n",
    "                # ['ajibawa-2023','Code-Mistral-7B'],\n",
    "                ['WizardLM', 'WizardMath-7B-V1.1'],\n",
    "                ['itpossible','Chinese-Mistral-7B-v0.1'],\n",
    "                [\"HuggingFaceH4\",\"zephyr-7b-beta\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.6-mistral-7b\"],\n",
    "                [\"Open-Orca\",\"Mistral-7B-OpenOrca\"],\n",
    "                [\"HuggingFaceH4\",\"mistral-7b-grok\"],\n",
    "                [\"HuggingFaceH4\",\"mistral-7b-sft-beta\"],\n",
    "                [\"NousResearch\",\"Hermes-2-Pro-Mistral-7B\"],\n",
    "                [\"cognitivecomputations\",\"dolphin-2.2.1-mistral-7b\"],\n",
    "                [\"abhishekchohan\",\"mistral-7B-forest-dpo\"],\n",
    "                [\"wandb\",\"mistral-7b-zephyr-sft\"],\n",
    "                [\"Locutusque\",\"Hercules-2.5-Mistral-7B\"],\n",
    "                [\"nvidia\",\"OpenMath-Mistral-7B-v0.1-hf\"]]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02207364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check nan\n",
    "\n",
    "import pandas as pd \n",
    "for i in pd.read_json(\"./datasets/one_task/humaneval_train.json\")[\"scores\"]:\n",
    "    for value in i.values():\n",
    "        if value == None:\n",
    "            print(\"nan\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6d7fa1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
